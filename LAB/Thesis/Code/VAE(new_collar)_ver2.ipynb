{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 14176978042427907959,\n",
       " name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 3040504820344242984\n",
       " physical_device_desc: \"device: XLA_CPU device\",\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 3129973147\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 7068565893781779826\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\",\n",
       " name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 7586198148299747671\n",
       " physical_device_desc: \"device: XLA_GPU device\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os, sys\n",
    "from os.path import join, dirname\n",
    "\n",
    "import datetime, time\n",
    "import csv\n",
    "from glob import glob\n",
    "import chardet\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, MaxAbsScaler, MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Conv1D, Conv2D, SimpleRNN, LSTM, GRU, Reshape, RepeatVector, MaxPooling2D, Dropout, Bidirectional, Attention, BatchNormalization, Conv2DTranspose, TimeDistributed, GlobalAveragePooling1D, Conv1DTranspose\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.optimizers import Adadelta, RMSprop,SGD,Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "\n",
    "import imblearn\n",
    "\n",
    "from IPython.display import SVG\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(tf.__version__)\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7                           # {\"0\" : \"Playing\", \"1\" : \"Talking\", \"2\" : \"Petting\", \"3\" : \"TV / Radio\", \"4\" : \"Eating / Cooking\", \"5\" : \"Moved It\", \"6\" : \"None of the above\", \"7\" : \"Other\"}\n",
    "time_offset = 10                          # 5초 단위 window: 50, 10초 단위 window: 90, 15초 단위 window: 128\n",
    "window_size = 50\n",
    "overlap_ratio = 0.5\n",
    "bi_class = 0                              # Binary Classification (1 : Playing or not, 2 : Talking or not, 3 : Petting or not, 4: TV / Radio or not, 5 : Eating / Cooking or not, 6 : Moved It or not)\n",
    "cross_val = 0\n",
    "rand_st=2\n",
    "mode = 0                                 # Split data {0: Didn't split, 1: US only, 2: Korea only, 3: train with US and test with Korea 4: train with Korea and test with US}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fname = '../Data/Preprocessed(new)/preprocessed_data(New collar_2).csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_fname)\n",
    "data = data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iaq = data['iaq']\n",
    "iaq_cat = []\n",
    "\n",
    "for num in iaq:\n",
    "    if num < 50 and num >=0:\n",
    "        iaq_cat.append('Good')\n",
    "    elif num >= 50 and num < 100:\n",
    "        iaq_cat.append('Average')\n",
    "    elif num >= 100 and num < 150:\n",
    "        iaq_cat.append('Little bad')\n",
    "    elif num >= 150 and num < 200:\n",
    "        iaq_cat.append('Bad')\n",
    "    elif num >= 200 and num < 300:\n",
    "        iaq_cat.append('Worse')\n",
    "    elif num >= 300 and num <= 500:\n",
    "        iaq_cat.append('Very bad')\n",
    "    else:\n",
    "        print(num)\n",
    "data['iaq_cat'] = iaq_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data,pd.get_dummies(data['sound category'])],axis=1)         # Onehot encode sound category\n",
    "data = pd.concat([data,pd.get_dummies(data['orientation_cat'])],axis=1)         # Onehot encode orientation category\n",
    "data = pd.concat([data,pd.get_dummies(data['iaq_cat'])],axis=1)         # Onehot encode iaq category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rowID list\n",
    "rowID_list = np.array(data['RowID'].drop_duplicates())\n",
    "data = data.to_records(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# data['pressure'] = scaler.fit_transform(data['pressure'].reshape(-1,1)).reshape(-1)\n",
    "data['gasResistance'] = scaler.fit_transform(data['gasResistance'].reshape(-1,1)).reshape(-1)\n",
    "data['staticIaq'] = scaler.fit_transform(data['staticIaq'].reshape(-1,1)).reshape(-1)\n",
    "data['co2Equivalent'] = scaler.fit_transform(data['co2Equivalent'].reshape(-1,1)).reshape(-1)\n",
    "data['breathVocEquivalent'] = scaler.fit_transform(data['breathVocEquivalent'].reshape(-1,1)).reshape(-1)\n",
    "data['audioLevel'] = scaler.fit_transform(data['audioLevel'].reshape(-1,1)).reshape(-1)\n",
    "data['rawTemp'] = scaler.fit_transform(data['rawTemp'].reshape(-1,1)).reshape(-1)\n",
    "data['rawHumidity'] = scaler.fit_transform(data['rawHumidity'].reshape(-1,1)).reshape(-1)\n",
    "data['pressure'] = scaler.fit_transform(data['pressure'].reshape(-1,1)).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split US and Korea\n",
    "us_rowIDs = []\n",
    "korea_rowIDs = []\n",
    "\n",
    "if mode != 0:\n",
    "    for rowid in rowID_list:\n",
    "    #     print(rowid, rowid[0])\n",
    "        if rowid[0] == '1':\n",
    "            korea_rowIDs.append(rowid)\n",
    "        else:\n",
    "            us_rowIDs.append(rowid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_col_name = ['accX', 'accY', 'accZ', 'chord', 'orientation', 'ir', 'full', 'iaq', 'iaqAccuracy', 'rawTemp',\n",
    "#                     'pressure', 'rawHumidity', 'gasResistance', 'compGasAccuracy', 'gasPercentageAccuracy', 'temperature', \n",
    "#                     'humidity', 'staticIaq', 'statIaqAccuracy', 'co2Equivalent', 'co2Accuracy', 'breathVocEquivalent', \n",
    "#                     'breathVocAccuracy', 'audioLevel', 'Loud', 'Moderate', 'Quiet']\n",
    "feature_col_name = ['accX', 'accY', 'accZ', 'chord', 'full', 'iaq', 'rawTemp',\n",
    "                    'pressure', 'rawHumidity', 'gasResistance', 'staticIaq', 'co2Equivalent', 'breathVocEquivalent', \n",
    "                    'audioLevel', 'Loud', 'Moderate', 'Quiet', 'Landscape Left Back', 'Landscape Left Front', 'Landscape Right Back',\n",
    "                    'Landscape Right Front', 'Portrait Down Back', 'Portrait Down Front', 'Portrait Up Back', \n",
    "                    'Portrait Up Front', 'Average', 'Bad', 'Good', 'Little bad', 'Very bad', 'Worse']\n",
    "target_col_name = ['Modality_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_num = len(feature_col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "us_X = []\n",
    "korea_X = []\n",
    "\n",
    "Y = []\n",
    "us_Y = []\n",
    "korea_Y = []\n",
    "\n",
    "\n",
    "if mode != 0:\n",
    "    for rowID in us_rowIDs:\n",
    "        #Split raw data by rowID & split X, Y data\n",
    "        tmp_data = data[data['RowID'] == rowID]\n",
    "        feature = tmp_data[feature_col_name]\n",
    "        feature = np.array(feature.tolist())\n",
    "        target = tmp_data[target_col_name][0][0]\n",
    "        target = np.array(target.tolist())\n",
    "        us_X.append(feature)\n",
    "        us_Y.append(target)\n",
    "    \n",
    "    for rowID in korea_rowIDs:\n",
    "        #Split raw data by rowID & split X, Y data\n",
    "        tmp_data = data[data['RowID'] == rowID]\n",
    "        feature = tmp_data[feature_col_name]\n",
    "        feature = np.array(feature.tolist())\n",
    "        target = tmp_data[target_col_name][0][0]\n",
    "        target = np.array(target.tolist())\n",
    "        korea_X.append(feature)\n",
    "        korea_Y.append(target)\n",
    "\n",
    "else:\n",
    "    for rowID in rowID_list:\n",
    "        #Split raw data by rowID & split X, Y data\n",
    "        tmp_data = data[data['RowID'] == rowID]\n",
    "        feature = tmp_data[feature_col_name]\n",
    "        feature = np.array(feature.tolist())\n",
    "        target = tmp_data[target_col_name][0][0]\n",
    "        target = np.array(target.tolist())\n",
    "        X.append(feature)\n",
    "        Y.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bi_class != 0:\n",
    "    #Transit multi classification to binary classification\n",
    "    if mode != 0:\n",
    "        for idx in range(len(us_Y)):\n",
    "            if us_Y[idx] == bi_class-1:\n",
    "                us_Y[idx]=1\n",
    "            else:\n",
    "                us_Y[idx]=0\n",
    "                \n",
    "        for idx in range(len(korea_Y)):\n",
    "            if korea_Y[idx] == bi_class-1:\n",
    "                korea_Y[idx]=1\n",
    "            else:\n",
    "                korea_Y[idx]=0\n",
    "    else:\n",
    "        for idx in range(len(Y)):\n",
    "            if Y[idx] == bi_class-1:\n",
    "                Y[idx]=1\n",
    "            else:\n",
    "                Y[idx]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_preprocess(X, window_size, overlap_ratio):\n",
    "    #Transform data shape using the set time window\n",
    "    processed_X = []\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        tmp_X = X[i]\n",
    "        tmp = []\n",
    "        start_row = 0\n",
    "        end_row = start_row + window_size\n",
    "        \n",
    "        if len(tmp_X)%int(window_size*overlap_ratio) == 0:\n",
    "            for j in range(len(tmp_X)//int(window_size*overlap_ratio)-1):\n",
    "                tmp.append(tmp_X[int(start_row):int(end_row)])\n",
    "                start_row += (window_size*overlap_ratio)\n",
    "                end_row += (window_size*overlap_ratio)\n",
    "        else:\n",
    "            for j in range(len(tmp_X)//int(window_size*overlap_ratio)+1):\n",
    "                if end_row > len(tmp_X):\n",
    "                    \n",
    "                    tmp.append(tmp_X[-window_size:])\n",
    "                    start_row += (window_size*overlap_ratio)\n",
    "                    end_row += (window_size*overlap_ratio)\n",
    "                    break\n",
    "                else:\n",
    "                    \n",
    "                    tmp.append(tmp_X[int(start_row):int(end_row)])\n",
    "                    start_row += (window_size*overlap_ratio)\n",
    "                    end_row += (window_size*overlap_ratio)\n",
    "        processed_X.append(tmp)\n",
    "        \n",
    "    return processed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode != 0:\n",
    "    us_X = X_preprocess(us_X, window_size, overlap_ratio)        ### preprocess with input shape\n",
    "    korea_X = X_preprocess(korea_X, window_size, overlap_ratio)\n",
    "    if bi_class == 0:\n",
    "        ### onehot encode Y\n",
    "        us_Y = np.eye(num_classes)[us_Y]\n",
    "        korea_Y = np.eye(num_classes)[korea_Y]\n",
    "    else: \n",
    "        us_Y = np.eye(2)[us_Y]\n",
    "        korea_Y = np.eye(2)[korea_Y]\n",
    "\n",
    "else:    \n",
    "    X = X_preprocess(X, window_size, overlap_ratio)        ### preprocess with input shape\n",
    "    if bi_class == 0:\n",
    "        ### onehot encode Y\n",
    "        Y = np.eye(num_classes)[Y]\n",
    "    else: Y = np.eye(2)[Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample X Data size\n",
    "\n",
    "def subsample(X, min_us_len, min_korea_len):\n",
    "    sampled_X = []\n",
    "    addon = 0\n",
    "    \n",
    "    if min_korea_len > min_us_len:\n",
    "        if np.array(X).shape[1] == min_us_len:\n",
    "            return X\n",
    "        else:\n",
    "            interval = min_korea_len / min_us_len\n",
    "            quotient = int(np.modf(interval)[1])\n",
    "            remainder = np.modf(interval)[0]\n",
    "\n",
    "            for i in range(len(X)):\n",
    "                temp_X = []\n",
    "                for j in range(min_us_len):\n",
    "                    if addon >= 1:\n",
    "                        temp_X.append(X[i][j*quotient + 1])\n",
    "                        addon = 0\n",
    "                        addon += remainder\n",
    "                    else:\n",
    "                        temp_X.append(X[i][j*quotient])\n",
    "                        addon += remainder\n",
    "\n",
    "                sampled_X.append(temp_X)\n",
    "            \n",
    "    else:\n",
    "        if np.array(X).shape[1] == min_korea_len:\n",
    "            return X\n",
    "        else:\n",
    "            interval = min_us_len / min_korea_len\n",
    "            quotient = int(np.modf(interval)[1])\n",
    "            remainder = np.modf(interval)[0]\n",
    "\n",
    "            for i in range(len(X)):\n",
    "                temp_X = []\n",
    "                for j in range(min_korea_len):\n",
    "                    if addon >= 1:\n",
    "                        temp_X.append(X[i][j*quotient + 1])\n",
    "                        addon = 0\n",
    "                        addon += remainder\n",
    "                    else:\n",
    "                        temp_X.append(X[i][j*quotient])\n",
    "                        addon += remainder\n",
    "\n",
    "            sampled_X.append(temp_X)\n",
    "                    \n",
    "    return sampled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit to minimum length\n",
    "\n",
    "min_len = 99999999\n",
    "min_us_len = 99999999\n",
    "min_korea_len = 99999999\n",
    "min_X = []\n",
    "min_us_X = []\n",
    "min_korea_X = []\n",
    "\n",
    "if mode == 0:\n",
    "#     print('Start mode 0\\n')\n",
    "    for x in X:\n",
    "        if len(x) < min_len:\n",
    "            min_len = len(x)\n",
    "#     print(min_len)\n",
    "\n",
    "    for x in X:\n",
    "        min_X.append(x[:min_len])\n",
    "\n",
    "else:\n",
    "    for x in us_X:\n",
    "        if len(x) < min_us_len:\n",
    "            min_us_len = len(x)\n",
    "            \n",
    "    for x in korea_X:\n",
    "        if len(x) < min_korea_len:\n",
    "            min_korea_len = len(x)\n",
    "            \n",
    "    if mode == 1:\n",
    "        for x in us_X:\n",
    "            min_us_X.append(x[:min_us_len])\n",
    "        for x in korea_X:\n",
    "            min_korea_X.append(x[:min_korea_len])\n",
    "        \n",
    "    elif mode == 2:\n",
    "        min_korea_len = 60\n",
    "        for x in us_X:\n",
    "            min_us_X.append(x[:min_us_len])\n",
    "        for x in korea_X:\n",
    "            min_korea_X.append(x[:min_korea_len])\n",
    "        \n",
    "    else:\n",
    "        if min_korea_len < min_us_len:\n",
    "            min_len = min_korea_len\n",
    "        else: min_len = min_us_len\n",
    "\n",
    "        for x in us_X:\n",
    "            min_us_X.append(x[:min_len])\n",
    "\n",
    "        for x in korea_X:\n",
    "            min_korea_X.append(x[:min_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop duplicate\n",
    "\n",
    "if bi_class != 0:\n",
    "    \n",
    "    target_list = []\n",
    "    us_target_list = []\n",
    "    korea_target_list = []\n",
    "    del_list = []\n",
    "    us_del_list = []\n",
    "    korea_del_list = []\n",
    "    \n",
    "    if mode == 0:\n",
    "        for i in range(len(Y)):\n",
    "            if Y[i][1] == 1:\n",
    "                target_list.append(i)\n",
    "\n",
    "        for i in target_list:\n",
    "            for j in range(len(min_X)):\n",
    "                if j in target_list:\n",
    "                    pass\n",
    "                else:\n",
    "                    if np.array_equal(np.array(min_X[i]), np.array(min_X[j])):\n",
    "                        if j not in del_list:\n",
    "                            del_list.append(j)\n",
    "        X = []\n",
    "        Target = []\n",
    "\n",
    "        for i in range(len(Y)):\n",
    "            if i not in del_list:\n",
    "                X.append(min_X[i])\n",
    "                Target.append(Y[i])\n",
    "                \n",
    "    else:\n",
    "        for i in range(len(us_Y)):\n",
    "            if us_Y[i][1] == 1:\n",
    "                us_target_list.append(i)\n",
    "\n",
    "        for i in us_target_list:\n",
    "            for j in range(len(min_us_X)):\n",
    "                if j in us_target_list:\n",
    "                    pass\n",
    "                else:\n",
    "                    if np.array_equal(np.array(min_us_X[i]), np.array(min_us_X[j])):\n",
    "                        if j not in us_del_list:\n",
    "                            us_del_list.append(j)\n",
    "                            \n",
    "        for i in range(len(korea_Y)):\n",
    "            if korea_Y[i][1] == 1:\n",
    "                korea_target_list.append(i)\n",
    "\n",
    "        for i in korea_target_list:\n",
    "            for j in range(len(min_korea_X)):\n",
    "                if j in korea_target_list:\n",
    "                    pass\n",
    "                else:\n",
    "                    if np.array_equal(np.array(min_korea_X[i]), np.array(min_korea_X[j])):\n",
    "                        if j not in korea_del_list:\n",
    "                            korea_del_list.append(j)\n",
    "        \n",
    "        us_X = []\n",
    "        us_Target = []\n",
    "        korea_X = []\n",
    "        korea_Target = []\n",
    "\n",
    "        for i in range(len(us_Y)):\n",
    "            if i not in us_del_list:\n",
    "                us_X.append(min_us_X[i])\n",
    "                us_Target.append(us_Y[i])\n",
    "                \n",
    "        for i in range(len(korea_Y)):\n",
    "            if i not in korea_del_list:\n",
    "                korea_X.append(min_korea_X[i])\n",
    "                korea_Target.append(korea_Y[i])\n",
    "\n",
    "else:\n",
    "    target_list = []\n",
    "    us_target_list = []\n",
    "    korea_target_list = []\n",
    "    del_list = []\n",
    "    us_del_list = []\n",
    "    korea_del_list = []\n",
    "    \n",
    "    if mode == 0:\n",
    "        X = min_X\n",
    "        Target = Y\n",
    "\n",
    "    else:\n",
    "        for i in range(len(us_Y)):\n",
    "            if us_Y[i][1] == 1:\n",
    "                us_target_list.append(i)\n",
    "\n",
    "        for i in us_target_list:\n",
    "            for j in range(len(min_us_X)):\n",
    "                if j in us_target_list:\n",
    "                    pass\n",
    "                else:\n",
    "                    if np.array_equal(np.array(min_us_X[i]), np.array(min_us_X[j])):\n",
    "                        if j not in us_del_list:\n",
    "                            us_del_list.append(j)\n",
    "\n",
    "        for i in range(len(korea_Y)):\n",
    "            if korea_Y[i][1] == 1:\n",
    "                korea_target_list.append(i)\n",
    "\n",
    "        for i in korea_target_list:\n",
    "            for j in range(len(min_korea_X)):\n",
    "                if j in korea_target_list:\n",
    "                    pass\n",
    "                else:\n",
    "                    if np.array_equal(np.array(min_korea_X[i]), np.array(min_korea_X[j])):\n",
    "                        if j not in korea_del_list:\n",
    "                            korea_del_list.append(j)\n",
    "\n",
    "        us_X = []\n",
    "        us_Target = []\n",
    "        korea_X = []\n",
    "        korea_Target = []\n",
    "\n",
    "        for i in range(len(us_Y)):\n",
    "            if i not in us_del_list:\n",
    "                us_X.append(min_us_X[i])\n",
    "                us_Target.append(us_Y[i])\n",
    "\n",
    "        for i in range(len(korea_Y)):\n",
    "            if i not in korea_del_list:\n",
    "                korea_X.append(min_korea_X[i])\n",
    "                korea_Target.append(korea_Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 0:\n",
    "#     X = subsample(X, min_us_len, min_korea_len)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Target, test_size=0.2)\n",
    "    \n",
    "elif mode == 1:\n",
    "    us_X = subsample(us_X, min_us_len, min_korea_len)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(us_X, us_Target, test_size=0.2)\n",
    "\n",
    "elif mode == 2:\n",
    "    korea_X = subsample(korea_X, min_us_len, min_korea_len)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(korea_X, korea_Target, test_size=0.2)\n",
    "\n",
    "elif mode == 3:\n",
    "    X_train = subsample(us_X, min_us_len, min_korea_len)\n",
    "    X_test = subsample(korea_X, min_us_len, min_korea_len)\n",
    "    Y_train = us_Target \n",
    "    Y_test = korea_Target\n",
    "\n",
    "else:\n",
    "    X_train = subsample(korea_X, min_us_len, min_korea_len)\n",
    "    X_test = subsample(us_X, min_us_len, min_korea_len)\n",
    "    Y_train = korea_Target\n",
    "    Y_test = us_Target "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------\n",
    "### End Setup, separate model sections\n",
    "-----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative Replay #3 - Variational Autoencoder\n",
    "- https://blog.keras.io/building-autoencoders-in-keras.html (scroll down to VAE section near end)\n",
    "- https://keras.io/examples/generative/vae/\n",
    "- https://blog.paperspace.com/how-to-build-variational-autoencoder-keras/\n",
    "- https://github.com/analytique-bourassa/VAE-Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sckim\\.conda\\envs\\grad\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1 2 3 4 5 6] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "### Data Setup ###\n",
    "\n",
    "#Rebalance the data\n",
    "if bi_class == 0:\n",
    "    sm = imblearn.over_sampling.SMOTE()\n",
    "    X_shape = np.array(X_train).shape\n",
    "    Y_shape = np.array(Y_train).shape\n",
    "    new_X_train = np.array(X_train).reshape(X_shape[0], X_shape[1]*X_shape[2]*X_shape[3])\n",
    "    Y_train = np.array(Y_train).astype('float64')\n",
    "    X_train, Y_train = sm.fit_resample(new_X_train, Y_train)\n",
    "    temp = X_train.shape\n",
    "    X_train = X_train.reshape([temp[0], X_shape[1], X_shape[2], X_shape[3]])\n",
    "    X_train = np.array(X_train).transpose([0,1,2,3])\n",
    "    Y_train = Y_train.reshape(temp[0], Y_shape[1])\n",
    "\n",
    "else:\n",
    "    sm = imblearn.over_sampling.SMOTE()         # random state do not set\n",
    "    origin_shape = np.array(X_train).shape\n",
    "    new_X_train = np.array(X_train).reshape(origin_shape[0], origin_shape[1]*origin_shape[2]*origin_shape[3])\n",
    "    Y_train = np.array(Y_train).astype('float64')\n",
    "    X_train, Y_train = sm.fit_resample(new_X_train, Y_train)\n",
    "    temp = X_train.shape\n",
    "    X_train = X_train.reshape([temp[0], origin_shape[1], origin_shape[2], origin_shape[3]])\n",
    "    X_train = np.array(X_train).transpose([0,1,2,3])\n",
    "    Y_train = np.eye(2)[Y_train.reshape(temp[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(X_train).transpose([0,1,2,3]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(X_train).transpose([0,3,2,1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(276, 50, 31)\n",
      "(None, 276, 50, 31)\n"
     ]
    }
   ],
   "source": [
    "# This is the size of our encoded representations\n",
    "encoding_dim = num_classes  # Same as original model above, final dense layer should be \n",
    "input_shape = np.array(X_train[0]).shape\n",
    "print(input_shape)\n",
    "\n",
    "# This is our input data\n",
    "feature_input = keras.Input(shape=input_shape)\n",
    "feat_shape=feature_input.shape\n",
    "print(feat_shape)\n",
    "\n",
    "#Setup latent dims\n",
    "original_dim = feature_num                     #feature count\n",
    "intermediate_dim = 128                 #hidden units\n",
    "latent_dim = feature_num                        #latent count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_unit = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 276, 50, 31) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_reshape1 (Reshape)      (None, 276, 1550)    0           encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "encoder_rnn1 (GRU)              (None, 276, 200)     1051200     encoder_reshape1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_norm_4 (BatchNormalizat (None, 276, 200)     800         encoder_rnn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_1 (Conv1D)         (None, 276, 64)      12864       encoder_norm_4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_norm_1 (BatchNormalizat (None, 276, 64)      256         encoder_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_activ_1 (LeakyReLU)     (None, 276, 64)      0           encoder_norm_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 64)           0           encoder_activ_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_fc1 (Dense)             (None, 31)           2015        global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_mu (Dense)              (None, 31)           992         encoder_fc1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "encoder_log_variance (Dense)    (None, 31)           992         encoder_fc1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "encoder_output (Lambda)         (None, 31)           0           encoder_mu[0][0]                 \n",
      "                                                                 encoder_log_variance[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 1,069,119\n",
      "Trainable params: 1,068,591\n",
      "Non-trainable params: 528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Encoder\n",
    "x = Input(shape=input_shape, name=\"encoder_input\")\n",
    "\n",
    "shape_before_reshape = K.int_shape(x)[1:]\n",
    "rnn_input = Reshape((shape_before_reshape[0], -1), name='encoder_reshape1')(x)\n",
    "rnn_layer = GRU(units=rnn_unit, return_sequences=True, name='encoder_rnn1')(rnn_input)\n",
    "# rnn_layer = LSTM(units=rnn_unit, return_sequences=True, name='encoder_rnn2')(rnn_layer)\n",
    "# rnn_layer = TimeDistributed(Dense(rnn_unit), name='encoder_TD1')(rnn_layer)\n",
    "# rnn_layer= BatchNormalization(name='encoder_norm_3')(rnn_layer)\n",
    "# rnn_layer = Bidirectional(GRU(units=rnn_unit, name='encoder_rnn2'))(rnn_layer)\n",
    "rnn_layer= BatchNormalization(name='encoder_norm_4')(rnn_layer)\n",
    "\n",
    "encoder_conv_layer1 = Conv1D(filters=64, kernel_size=1, padding=\"same\", strides=1, name=\"encoder_conv_1\")(rnn_layer)\n",
    "# encoder_conv_layer2 = Conv1D(filters=128, kernel_size=1, padding=\"same\", strides=1, name=\"encoder_conv_2\")(encoder_conv_layer1)\n",
    "\n",
    "encoder_norm_layer1 = BatchNormalization(name=\"encoder_norm_1\")(encoder_conv_layer1)\n",
    "encoder_activ_layer1 = tf.keras.layers.LeakyReLU(name=\"encoder_activ_1\")(encoder_norm_layer1)\n",
    "encoder_gap_layer1 = GlobalAveragePooling1D()(encoder_activ_layer1)\n",
    "\n",
    "\n",
    "output = Dense(units=latent_dim, activation='sigmoid', name='encoder_fc1')(encoder_gap_layer1)\n",
    "\n",
    "shape_before_gap = K.int_shape(encoder_activ_layer1)[1:]\n",
    "# encoder_flatten = Flatten()(rnn_output)\n",
    "\n",
    "encoder_mu = Dense(units=latent_dim, name=\"encoder_mu\")(output)\n",
    "encoder_log_variance = Dense(units=latent_dim, name=\"encoder_log_variance\")(output)\n",
    "\n",
    "encoder_mu_log_variance_model = Model(x, (encoder_mu, encoder_log_variance), name=\"encoder_mu_log_variance_model\")\n",
    "\n",
    "def sampling(mu_log_variance):\n",
    "    mu, log_variance = mu_log_variance\n",
    "    epsilon = K.random_normal(shape=K.shape(mu), mean=0.0, stddev=1.0)\n",
    "    random_sample = mu + K.exp(log_variance/2) * epsilon\n",
    "    return random_sample\n",
    "\n",
    "encoder_output = tf.keras.layers.Lambda(sampling, name=\"encoder_output\")([encoder_mu, encoder_log_variance])\n",
    "\n",
    "encoder = Model(x, encoder_output, name=\"encoder_model\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(276, 64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape_before_gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape_before_reshape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1550"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape_before_reshape[1]*shape_before_reshape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 31)]              0         \n",
      "_________________________________________________________________\n",
      "decoder_dense_1 (Dense)      (None, 17664)             565248    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 276, 64)           0         \n",
      "_________________________________________________________________\n",
      "decoder_rnn1 (GRU)           (None, 276, 50)           17400     \n",
      "_________________________________________________________________\n",
      "tf_op_layer_ExpandDims (Tens [(None, 276, 50, 1)]      0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_tran_1 (Conv2DT (None, 276, 50, 31)       62        \n",
      "_________________________________________________________________\n",
      "decoder_norm_1 (BatchNormali (None, 276, 50, 31)       124       \n",
      "_________________________________________________________________\n",
      "decoder_output (LeakyReLU)   (None, 276, 50, 31)       0         \n",
      "=================================================================\n",
      "Total params: 582,834\n",
      "Trainable params: 582,772\n",
      "Non-trainable params: 62\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Decoder\n",
    "\n",
    "decoder_input = Input(shape=(latent_dim), name=\"decoder_input\")\n",
    "decoder_dense_layer1 = Dense(units=np.prod(shape_before_gap), name=\"decoder_dense_1\")(decoder_input)\n",
    "# cnn_input = RepeatVector(shape_before_reshape[0])(decoder_dense_layer1)\n",
    "decoder_reshape = Reshape(target_shape=shape_before_gap)(decoder_dense_layer1)\n",
    "\n",
    "rnn_layer = GRU(units=shape_before_reshape[1], return_sequences=True, name='decoder_rnn1')(decoder_reshape)\n",
    "cnn_input = tf.expand_dims(rnn_layer, -1)\n",
    "decoder_conv_tran_layer1 = Conv2DTranspose(filters=31, kernel_size=1, padding=\"same\", strides=1, name=\"decoder_conv_tran_1\")(cnn_input)\n",
    "# decoder_conv_tran_layer2 = Conv2DTranspose(filters=shape_before_reshape[2], kernel_size=1, padding=\"same\", strides=1, name=\"decoder_conv_tran_2\")(decoder_conv_tran_layer1)\n",
    "decoder_norm_layer1 = BatchNormalization(name=\"decoder_norm_1\")(decoder_conv_tran_layer1)\n",
    "decoder_conv_output = tf.keras.layers.LeakyReLU(name=\"decoder_output\")(decoder_norm_layer1)\n",
    "\n",
    "# rnn_layer = BatchNormalization(name=\"decoder_norm_2\")(rnn_layer)\n",
    "# rnn_layer = RepeatVector(shape_before_reshape[1])(rnn_layer)\n",
    "# decoder_output = Reshape(shape_before_reshape, name='decoder_reshape1')(rnn_layer)\n",
    "\n",
    "\n",
    "\n",
    "decoder = Model(decoder_input, decoder_conv_output, name=\"decoder_model\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VAE\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "VAE_input (InputLayer)       [(None, 276, 50, 31)]     0         \n",
      "_________________________________________________________________\n",
      "encoder_model (Functional)   (None, 31)                1069119   \n",
      "_________________________________________________________________\n",
      "decoder_model (Functional)   (None, 276, 50, 31)       582834    \n",
      "=================================================================\n",
      "Total params: 1,651,953\n",
      "Trainable params: 1,651,363\n",
      "Non-trainable params: 590\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae_input = Input(shape=input_shape, name=\"VAE_input\")\n",
    "vae_encoder_output = encoder(vae_input)\n",
    "vae_decoder_output = decoder(vae_encoder_output)\n",
    "vae = Model(vae_input, vae_decoder_output, name=\"VAE\")\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(encoder_mu, encoder_log_variance):\n",
    "    def vae_reconstruction_loss(y_true, y_predict):\n",
    "        reconstruction_loss_factor = 1000\n",
    "        reconstruction_loss = K.mean(K.square(y_true-y_predict), axis=[1, 2, 3])\n",
    "        return reconstruction_loss_factor * reconstruction_loss\n",
    "\n",
    "    def vae_kl_loss(encoder_mu, encoder_log_variance):\n",
    "        kl_loss = -0.5 * K.sum(1.0 + encoder_log_variance - K.square(encoder_mu) - K.exp(encoder_log_variance), axis=[1,2,3])\n",
    "        return kl_loss\n",
    "\n",
    "    def vae_kl_loss_metric(y_true, y_predict):\n",
    "        kl_loss = -0.5 * K.sum(1.0 + encoder_log_variance - K.square(encoder_mu) - K.exp(encoder_log_variance), axis=[1,2,3])\n",
    "        return kl_loss\n",
    "\n",
    "    def vae_loss(y_true, y_predict):\n",
    "        reconstruction_loss = vae_reconstruction_loss(y_true, y_predict)\n",
    "        kl_loss = vae_kl_loss(y_true, y_predict)\n",
    "\n",
    "        loss = reconstruction_loss + kl_loss\n",
    "        return loss\n",
    "\n",
    "    return vae_loss\n",
    "\n",
    "vae.compile(optimizer=Adam(lr=0.0005), loss=loss_func(encoder_mu, encoder_log_variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 52431405056.0000\n",
      "Epoch 2/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431413248.0000\n",
      "Epoch 3/500\n",
      "43/43 [==============================] - 4s 82ms/step - loss: 52431392768.0000\n",
      "Epoch 4/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431392768.0000\n",
      "Epoch 5/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431392768.0000\n",
      "Epoch 6/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431376384.0000\n",
      "Epoch 7/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431392768.0000\n",
      "Epoch 8/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431388672.0000: 0s - loss: 56957485056.000 - ETA: 0s - loss: 55554023424.0\n",
      "Epoch 9/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431376384.0000\n",
      "Epoch 10/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431380480.0000\n",
      "Epoch 11/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431380480.0000\n",
      "Epoch 12/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 13/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 14/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000\n",
      "Epoch 15/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 16/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431376384.0000\n",
      "Epoch 17/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431380480.0000\n",
      "Epoch 18/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431380480.0000\n",
      "Epoch 19/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 20/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000: 1s \n",
      "Epoch 21/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431355904.0000\n",
      "Epoch 22/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 23/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 24/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431376384.0000\n",
      "Epoch 25/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 26/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000\n",
      "Epoch 27/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431376384.0000\n",
      "Epoch 28/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431376384.0000\n",
      "Epoch 29/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431376384.0000\n",
      "Epoch 30/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431376384.0000\n",
      "Epoch 31/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431380480.0000\n",
      "Epoch 32/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431388672.0000\n",
      "Epoch 33/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 34/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431380480.0000\n",
      "Epoch 35/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431376384.0000\n",
      "Epoch 36/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431376384.0000\n",
      "Epoch 37/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 38/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 39/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431380480.0000\n",
      "Epoch 40/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 41/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431355904.0000\n",
      "Epoch 42/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431376384.0000\n",
      "Epoch 43/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431380480.0000\n",
      "Epoch 44/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431376384.0000\n",
      "Epoch 45/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431376384.0000\n",
      "Epoch 46/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431376384.0000\n",
      "Epoch 47/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000: 0s - loss: 5876690534\n",
      "Epoch 48/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431355904.0000\n",
      "Epoch 49/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431355904.0000: 0s - loss: 6338736\n",
      "Epoch 50/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431380480.0000\n",
      "Epoch 51/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000\n",
      "Epoch 52/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431376384.0000:\n",
      "Epoch 53/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 54/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431355904.0000\n",
      "Epoch 55/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431376384.0000\n",
      "Epoch 56/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 57/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 58/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431380480.0000\n",
      "Epoch 59/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431376384.0000\n",
      "Epoch 60/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 61/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 62/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431376384.0000\n",
      "Epoch 63/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 64/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000: 1s - \n",
      "Epoch 65/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 66/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431376384.0000\n",
      "Epoch 67/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431355904.0000\n",
      "Epoch 68/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000\n",
      "Epoch 69/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000: 1s - loss: 7\n",
      "Epoch 70/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 71/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 72/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431376384.0000\n",
      "Epoch 73/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 74/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 75/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431376384.0000\n",
      "Epoch 76/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 77/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431355904.0000\n",
      "Epoch 78/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 79/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431355904.0000\n",
      "Epoch 80/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431380480.0000\n",
      "Epoch 81/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431376384.0000\n",
      "Epoch 82/500\n",
      "43/43 [==============================] - 4s 82ms/step - loss: 52431368192.0000\n",
      "Epoch 83/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 84/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 85/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 86/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000\n",
      "Epoch 87/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431376384.0000\n",
      "Epoch 88/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 3s 79ms/step - loss: 52431351808.0000\n",
      "Epoch 89/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431376384.00001s -\n",
      "Epoch 90/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 91/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 92/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 93/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000\n",
      "Epoch 94/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 95/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431376384.0000\n",
      "Epoch 96/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000\n",
      "Epoch 97/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 98/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 99/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 100/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431355904.0000 1s - los\n",
      "Epoch 101/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431355904.0000\n",
      "Epoch 102/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 103/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431355904.0000\n",
      "Epoch 104/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 105/500\n",
      "43/43 [==============================] - 3s 81ms/step - loss: 52431355904.0000\n",
      "Epoch 106/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 107/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000\n",
      "Epoch 108/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 109/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431376384.0000\n",
      "Epoch 110/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431376384.0000\n",
      "Epoch 111/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431376384.0000\n",
      "Epoch 112/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 113/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000\n",
      "Epoch 114/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000\n",
      "Epoch 115/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 116/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431351808.0000\n",
      "Epoch 117/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 118/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000: 0s - loss: 54211801088.00\n",
      "Epoch 119/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431376384.0000\n",
      "Epoch 120/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431376384.0000\n",
      "Epoch 121/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431355904.0000A: 1s - lo\n",
      "Epoch 122/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 123/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431355904.0000\n",
      "Epoch 124/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431355904.0000\n",
      "Epoch 125/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431376384.0000\n",
      "Epoch 126/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000\n",
      "Epoch 127/500\n",
      "43/43 [==============================] - 3s 81ms/step - loss: 52431368192.0000\n",
      "Epoch 128/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431388672.0000\n",
      "Epoch 129/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 130/500\n",
      "43/43 [==============================] - 3s 81ms/step - loss: 52431368192.0000\n",
      "Epoch 131/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431376384.0000\n",
      "Epoch 132/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 133/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 134/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431355904.0000\n",
      "Epoch 135/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 136/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000\n",
      "Epoch 137/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 138/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431380480.0000\n",
      "Epoch 139/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431380480.0000\n",
      "Epoch 140/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 141/500\n",
      "43/43 [==============================] - 3s 81ms/step - loss: 52431376384.0000: 1s - l\n",
      "Epoch 142/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431380480.0000\n",
      "Epoch 143/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 144/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 145/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431376384.0000\n",
      "Epoch 146/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431376384.0000\n",
      "Epoch 147/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431388672.0000\n",
      "Epoch 148/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431380480.0000\n",
      "Epoch 149/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 150/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431376384.0000\n",
      "Epoch 151/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431380480.0000\n",
      "Epoch 152/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431376384.0000\n",
      "Epoch 153/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000\n",
      "Epoch 154/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000\n",
      "Epoch 155/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000\n",
      "Epoch 156/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 157/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000: 0s - loss: 663681\n",
      "Epoch 158/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 159/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 160/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000\n",
      "Epoch 161/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 162/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000\n",
      "Epoch 163/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000\n",
      "Epoch 164/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000: 0s - loss: 52967579648.00\n",
      "Epoch 165/500\n",
      "43/43 [==============================] - 3s 81ms/step - loss: 52431368192.0000\n",
      "Epoch 166/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431355904.0000\n",
      "Epoch 167/500\n",
      "43/43 [==============================] - 3s 81ms/step - loss: 52431368192.0000\n",
      "Epoch 168/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 169/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 170/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431351808.0000\n",
      "Epoch 171/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431355904.0000\n",
      "Epoch 172/500\n",
      "43/43 [==============================] - 3s 81ms/step - loss: 52431364096.0000\n",
      "Epoch 173/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000\n",
      "Epoch 174/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000: 0s - loss: 10\n",
      "Epoch 175/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431355904.0000\n",
      "Epoch 176/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 177/500\n",
      "43/43 [==============================] - 3s 81ms/step - loss: 52431355904.0000\n",
      "Epoch 178/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431355904.0000\n",
      "Epoch 179/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000\n",
      "Epoch 180/500\n",
      "43/43 [==============================] - 3s 81ms/step - loss: 52431351808.0000\n",
      "Epoch 181/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 182/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 183/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431376384.0000\n",
      "Epoch 184/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 185/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000\n",
      "Epoch 186/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431355904.0000: 0s - loss: 64547\n",
      "Epoch 187/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 188/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431355904.0000\n",
      "Epoch 189/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 190/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 191/500\n",
      "43/43 [==============================] - 3s 81ms/step - loss: 52431368192.0000\n",
      "Epoch 192/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000\n",
      "Epoch 193/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000\n",
      "Epoch 194/500\n",
      "43/43 [==============================] - 4s 82ms/step - loss: 52431355904.0000\n",
      "Epoch 195/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431355904.0000\n",
      "Epoch 196/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 197/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431351808.0000\n",
      "Epoch 198/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431355904.0000\n",
      "Epoch 199/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431343616.0000\n",
      "Epoch 200/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 201/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 202/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 203/500\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 52431368192.0000\n",
      "Epoch 204/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000\n",
      "Epoch 205/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431388672.0000\n",
      "Epoch 206/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 207/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 208/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000\n",
      "Epoch 209/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 210/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 211/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000\n",
      "Epoch 212/500\n",
      "43/43 [==============================] - 3s 81ms/step - loss: 52431355904.0000\n",
      "Epoch 213/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 214/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000\n",
      "Epoch 215/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000\n",
      "Epoch 216/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431376384.0000: 1s - l\n",
      "Epoch 217/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000\n",
      "Epoch 218/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431380480.0000\n",
      "Epoch 219/500\n",
      "43/43 [==============================] - 4s 82ms/step - loss: 52431343616.0000\n",
      "Epoch 220/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431380480.0000\n",
      "Epoch 221/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431388672.0000\n",
      "Epoch 222/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431380480.0000\n",
      "Epoch 223/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431376384.0000\n",
      "Epoch 224/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431376384.0000: 0s - loss: 52971773952.00\n",
      "Epoch 225/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431380480.0000: 1s - loss: 72\n",
      "Epoch 226/500\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 52431364096.0000\n",
      "Epoch 227/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431376384.0000\n",
      "Epoch 228/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 229/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 230/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431380480.0000\n",
      "Epoch 231/500\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 52431376384.0000: 0s - loss: 5666376499\n",
      "Epoch 232/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431355904.0000\n",
      "Epoch 233/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 234/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431376384.0000\n",
      "Epoch 235/500\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 52431376384.0000\n",
      "Epoch 236/500\n",
      "43/43 [==============================] - 3s 81ms/step - loss: 52431368192.0000\n",
      "Epoch 237/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431355904.0000\n",
      "Epoch 238/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431380480.0000\n",
      "Epoch 239/500\n",
      "43/43 [==============================] - 4s 82ms/step - loss: 52431380480.0000\n",
      "Epoch 240/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000: \n",
      "Epoch 241/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 242/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431376384.0000\n",
      "Epoch 243/500\n",
      "43/43 [==============================] - 3s 81ms/step - loss: 52431343616.0000\n",
      "Epoch 244/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000\n",
      "Epoch 245/500\n",
      "43/43 [==============================] - 3s 81ms/step - loss: 52431351808.0000\n",
      "Epoch 246/500\n",
      "43/43 [==============================] - 4s 82ms/step - loss: 52431376384.0000\n",
      "Epoch 247/500\n",
      "43/43 [==============================] - 3s 81ms/step - loss: 52431364096.0000\n",
      "Epoch 248/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 249/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 250/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 251/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431376384.0000\n",
      "Epoch 252/500\n",
      "43/43 [==============================] - 3s 81ms/step - loss: 52431364096.0000\n",
      "Epoch 253/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 254/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 255/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 256/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000\n",
      "Epoch 257/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 258/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431355904.0000\n",
      "Epoch 259/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 260/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000\n",
      "Epoch 261/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 262/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431376384.0000\n",
      "Epoch 263/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 264/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 265/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000\n",
      "Epoch 266/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000\n",
      "Epoch 267/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000\n",
      "Epoch 268/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431355904.0000: 1s - \n",
      "Epoch 269/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 270/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431351808.0000\n",
      "Epoch 271/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431355904.0000\n",
      "Epoch 272/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 273/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 274/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 275/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431380480.0000\n",
      "Epoch 276/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 277/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 278/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431351808.0000\n",
      "Epoch 279/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000\n",
      "Epoch 280/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 281/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431376384.0000\n",
      "Epoch 282/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000\n",
      "Epoch 283/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 284/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000\n",
      "Epoch 285/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000\n",
      "Epoch 286/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431351808.0000\n",
      "Epoch 287/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 288/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431376384.0000\n",
      "Epoch 289/500\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 52431376384.0000\n",
      "Epoch 290/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431376384.0000\n",
      "Epoch 291/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431380480.0000\n",
      "Epoch 292/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 293/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 294/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431355904.0000\n",
      "Epoch 295/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431351808.0000\n",
      "Epoch 296/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 297/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 298/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 299/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 300/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000\n",
      "Epoch 301/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 302/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431376384.0000\n",
      "Epoch 303/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431376384.0000\n",
      "Epoch 304/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431376384.0000\n",
      "Epoch 305/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431380480.0000\n",
      "Epoch 306/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431388672.0000\n",
      "Epoch 307/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431376384.0000\n",
      "Epoch 308/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 309/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431376384.0000\n",
      "Epoch 310/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 311/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431355904.0000\n",
      "Epoch 312/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 313/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 314/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 315/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431380480.0000\n",
      "Epoch 316/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431376384.0000\n",
      "Epoch 317/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 318/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431355904.0000\n",
      "Epoch 319/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431376384.0000\n",
      "Epoch 320/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431355904.0000\n",
      "Epoch 321/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 322/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000\n",
      "Epoch 323/500\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 52431364096.0000\n",
      "Epoch 324/500\n",
      "43/43 [==============================] - 3s 81ms/step - loss: 52431364096.0000\n",
      "Epoch 325/500\n",
      "43/43 [==============================] - 3s 81ms/step - loss: 52431368192.0000\n",
      "Epoch 326/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 327/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 328/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 329/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000\n",
      "Epoch 330/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431368192.0000\n",
      "Epoch 331/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 332/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 333/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431355904.0000\n",
      "Epoch 334/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 335/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431355904.0000\n",
      "Epoch 336/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431351808.0000\n",
      "Epoch 337/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 338/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000\n",
      "Epoch 339/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 340/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431355904.0000\n",
      "Epoch 341/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000\n",
      "Epoch 342/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431355904.00000s - loss: 57108365312\n",
      "Epoch 343/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431351808.0000\n",
      "Epoch 344/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 345/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431380480.0000\n",
      "Epoch 346/500\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 52431376384.0000\n",
      "Epoch 347/500\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 52431364096.0000\n",
      "Epoch 348/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 349/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431380480.0000\n",
      "Epoch 350/500\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 52431368192.0000\n",
      "Epoch 351/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 352/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431376384.0000\n",
      "Epoch 353/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431380480.0000\n",
      "Epoch 354/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431376384.0000\n",
      "Epoch 355/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431380480.0000\n",
      "Epoch 356/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431355904.0000\n",
      "Epoch 357/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 358/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 359/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431376384.0000\n",
      "Epoch 360/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 361/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000\n",
      "Epoch 362/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 363/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000\n",
      "Epoch 364/500\n",
      "43/43 [==============================] - ETA: 0s - loss: 52966187008.000 - 3s 79ms/step - loss: 52431376384.0000\n",
      "Epoch 365/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000\n",
      "Epoch 366/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 367/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 368/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 369/500\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 52431364096.0000\n",
      "Epoch 370/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 371/500\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 52431368192.0000\n",
      "Epoch 372/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 373/500\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 52431368192.0000\n",
      "Epoch 374/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000: 0s - loss: 6369168\n",
      "Epoch 375/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 376/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431376384.0000\n",
      "Epoch 377/500\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 52431355904.0000\n",
      "Epoch 378/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 379/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 380/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000\n",
      "Epoch 381/500\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 52431355904.0000\n",
      "Epoch 382/500\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 52431368192.0000\n",
      "Epoch 383/500\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 52431364096.0000\n",
      "Epoch 384/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 385/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 386/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 387/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000\n",
      "Epoch 388/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 389/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431376384.0000\n",
      "Epoch 390/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.00000s - loss:\n",
      "Epoch 391/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 392/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 393/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431355904.0000\n",
      "Epoch 394/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000: \n",
      "Epoch 395/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431355904.0000\n",
      "Epoch 396/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 397/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000\n",
      "Epoch 398/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 399/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000\n",
      "Epoch 400/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 401/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 402/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431376384.0000\n",
      "Epoch 403/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431376384.0000\n",
      "Epoch 404/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000\n",
      "Epoch 405/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 406/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 407/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 408/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 409/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431355904.0000\n",
      "Epoch 410/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431376384.0000\n",
      "Epoch 411/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431355904.0000\n",
      "Epoch 412/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000\n",
      "Epoch 413/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.00001s - los\n",
      "Epoch 414/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 415/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431351808.0000\n",
      "Epoch 416/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 417/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000\n",
      "Epoch 418/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 419/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431355904.0000\n",
      "Epoch 420/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 421/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000: 0s - loss: 60557295\n",
      "Epoch 422/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000\n",
      "Epoch 423/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 424/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000: 0s - loss: 6421364\n",
      "Epoch 425/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 426/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000\n",
      "Epoch 427/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431355904.0000\n",
      "Epoch 428/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 429/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 430/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431355904.0000\n",
      "Epoch 431/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000\n",
      "Epoch 432/500\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 52431351808.0000\n",
      "Epoch 433/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431355904.0000\n",
      "Epoch 434/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000\n",
      "Epoch 435/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 3s 78ms/step - loss: 52431355904.0000\n",
      "Epoch 436/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431343616.0000\n",
      "Epoch 437/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431343616.0000\n",
      "Epoch 438/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431380480.0000\n",
      "Epoch 439/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 440/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 441/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431380480.0000\n",
      "Epoch 442/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 443/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 444/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 445/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 446/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431376384.00000s - loss: 6062019\n",
      "Epoch 447/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 448/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431355904.0000\n",
      "Epoch 449/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000\n",
      "Epoch 450/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431376384.0000\n",
      "Epoch 451/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 452/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 453/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 454/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 455/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431355904.0000\n",
      "Epoch 456/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 457/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 458/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 459/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431364096.0000\n",
      "Epoch 460/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431355904.0000: 0s - loss: 54228680704.00\n",
      "Epoch 461/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 462/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000: 0s - loss: 54236856320.00\n",
      "Epoch 463/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000\n",
      "Epoch 464/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 465/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431364096.0000\n",
      "Epoch 466/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431355904.0000\n",
      "Epoch 467/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 468/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 469/500\n",
      "43/43 [==============================] - ETA: 0s - loss: 52976988160.000 - 3s 81ms/step - loss: 52431368192.0000\n",
      "Epoch 470/500\n",
      "43/43 [==============================] - 3s 81ms/step - loss: 52431364096.0000\n",
      "Epoch 471/500\n",
      "43/43 [==============================] - 3s 81ms/step - loss: 52431355904.0000\n",
      "Epoch 472/500\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 52431380480.0000\n",
      "Epoch 473/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431368192.0000\n",
      "Epoch 474/500\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 52431376384.0000\n",
      "Epoch 475/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 476/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431376384.0000\n",
      "Epoch 477/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000\n",
      "Epoch 478/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000\n",
      "Epoch 479/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000\n",
      "Epoch 480/500\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 52431376384.00001s - - ETA: 0s - loss: 663192\n",
      "Epoch 481/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431376384.00000s - loss: 94395\n",
      "Epoch 482/500\n",
      "43/43 [==============================] - ETA: 0s - loss: 52956401664.000 - 3s 77ms/step - loss: 52431368192.0000\n",
      "Epoch 483/500\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 52431368192.0000\n",
      "Epoch 484/500\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 52431368192.0000\n",
      "Epoch 485/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 486/500\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 52431368192.0000\n",
      "Epoch 487/500\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 52431364096.0000\n",
      "Epoch 488/500\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 52431364096.0000\n",
      "Epoch 489/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000\n",
      "Epoch 490/500\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 52431368192.0000\n",
      "Epoch 491/500\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 52431368192.0000\n",
      "Epoch 492/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431355904.0000\n",
      "Epoch 493/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000: 1s - los\n",
      "Epoch 494/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431368192.0000\n",
      "Epoch 495/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431376384.0000\n",
      "Epoch 496/500\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 52431364096.0000\n",
      "Epoch 497/500\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 52431364096.0000\n",
      "Epoch 498/500\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 52431368192.0000\n",
      "Epoch 499/500\n",
      "43/43 [==============================] - 3s 76ms/step - loss: 52431376384.0000\n",
      "Epoch 500/500\n",
      "43/43 [==============================] - 3s 76ms/step - loss: 52431368192.0000\n"
     ]
    }
   ],
   "source": [
    "### Train the model###\n",
    "\n",
    "#Fit it to some training data\n",
    "hist = vae.fit(np.array(X_train).transpose([0,1,2,3]), np.array(X_train).transpose([0,1,2,3]),epochs=500, batch_size=16,\n",
    "              verbose=1, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa8AAAERCAYAAADMqygEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAABiAElEQVR4nO29eZgdVZn4/3lvr0knnY0ESAJJ2AkQAokxgrKow6IzA45bVAQdZ1AHZ5zBDcYZFZHvqIOjMoMyqIyA/kTGFREGQY24QCCBEBKSkJWksyeddKe709vt9/dHVd1abtW9dbvv7S3v53n66VunTp06tZ33vMs5R1QVwzAMwxhJZIa6AoZhGIZRKia8DMMwjBGHCS/DMAxjxGHCyzAMwxhxmPAyDMMwRhwmvAzDMIwRhwmvlIjI50Rkh4isdP/eFJPnBBH5rYisFZE1IvLRmDwfFxEVkWPc7UWBMl8QkbcE8t4mIttFpC1lHc8QkadEpEtEPh7Zd4WIrBeRjSJyU+l3wDAMY/ggNs4rHxG5BHifqr4vkPY5oE1Vby9w3PHA8ar6nIiMB1YAV6vqS+7+E4BvA2cAC1R1v4iMBbpVtdc9/gVguru9GHgF2KCq41LUexowC7gaOOjVVUSqgJeBPwOagGeBd3n1MgzDGGmY5lVGVHWXqj7n/j4MrAVmBLJ8FfgkoIFjOlS1192sj+x7WlV3Rc8jIlNF5Mci8qz7d6Gbf6+qPgv0RA5ZBGxU1c2q2g08AFw10Os1DMMYKkx4lcZHRGSViNwjIpMKZRSR2cB5wDJ3+y+BHar6QkzeV4vIGuBF4EMBYZbE14GvquqrgLfiaHOFmAFsD2w3ERaqhmEYI4rqoa7AcEJElgF1wDhgsoisdHd9CvgmcCuOZnQr8BXgrxPKGQf8GPhHVW11TYOfBi6Ly6+qy4CzRORM4F4ReVRVOwtU9Y3AXBHxthtFZLyr7cVWKe60Bco3DMMY1pjwCqCqr4Z4n1cQEfkW8HDCvhocwfV9Vf2Jm3wyMAd4wRU4M4HnRGSRqu4OnH+tiLQDZwPLC1Q1A7xGVY+kvLQm4ITA9kxgZ8pjDcMwhh1mNkyJG0zh8RZgdUweAb4DrFXV//DSVfVFVZ2mqrNVdTaOMDlfVXeLyBwRqXaPnwWcDmwtUp1fAR8JnHd+kfzPAqe656oFlgAPFTnGMAxj2GLCKz1fFpEXRWQVcCnwTwAiMl1EHnHzXAi8F3h9oZD6CK/F0chWAj8F/k5V97tlf1lEmoCxItLkRjwC/AOw0PW/vQR8yM1/nJv/RuBf3GMaXR/aR4DHcIJIHlTVNWW4J4ZhGAVxYwT2ikheh9/dLyJyhzuMZ5WInJ+qXAuVNwzDMCqFiFwEtAH3qerZMfvfBPw98Cbg1cDXPRdOIUzzMgzDMCqGqj4JNBfIchWOYFNVfRqYGHHTxGIBGy6ZTEbHjBkz1NUwDMMYUXR0dCjwXCDpblW9u4Qikoby5I1xDWLCy2XMmDG0t7cPdTUMwzBGFCJyRFUXDqSImLSi/iwzGxqGYRhDSb+G8pjwMgzDMIaSh4Br3ajDxUBL3LR4UcxsaBiGYVQMEfkBcAlwjDuU57NADYCq3gU8ghNpuBHoAN6fqlwLlXdoaGjQqM+rp6eHpqYmOjsLzdRkFKK+vp6ZM2dSU1Mz1FUxDKMCiEiHqjYM9nlN8ypAU1MT48ePZ/bs2QTmETRSoqocOHCApqYm5syZM9TVMQxjFGE+rwJ0dnYyZcoUE1z9RESYMmWKaa6GYZQdE15FMME1MOz+GYZRCUx4lYG+vh56eg4OdTUMwzCOGkx4lYEjR16ms3MTqtmylnvo0CG+8Y1v9OvYN73pTRw6dCh1/s997nPcfvvt/TqXYRjGYGPCqwz09VXGp1NIeGWzhQXlI488wsSJEytQK8MwjKHHhFdZqMxwg5tuuolNmzYxf/58PvGJT7B06VIuvfRS3v3ud3POOecAcPXVV7NgwQLOOuss7r7bn05s9uzZ7N+/n61bt3LmmWfyt3/7t5x11llcdtllHDlSeA3LlStXsnjxYubNm8db3vIWDh50TKJ33HEHc+fOZd68eSxZsgSA3/3ud8yfP5/58+dz3nnncfhw0mLOhmEY5cNC5VOyYcM/0ta2MnZfNus02FVV44ifpiuecePmc+qpX0vc/8UvfpHVq1ezcqVz3qVLl/LMM8+wevXqXOj5Pffcw+TJkzly5AivetWreOtb38qUKVMidd/AD37wA771rW/xjne8gx//+Mdcc801iee99tpr+c///E8uvvhiPvOZz3DLLbfwta99jS9+8Yts2bKFurq6nEny9ttv58477+TCCy+kra2N+vr61NdvGIbRX0zzGmEsWrQoNGbqjjvu4Nxzz2Xx4sVs376dDRs25B0zZ84c5s+fD8CCBQvYunVrYvktLS0cOnSIiy++GIDrrruOJ598EoB58+bxnve8h+9973tUVzv9ngsvvJAbb7yRO+64g0OHDuXSDcMwKom1NCkppCEdPrwcgIaGc8lkKjuTREODP5B96dKlPPHEEzz11FOMHTuWSy65JHZMVV1dXe53VVVVUbNhEr/85S958skneeihh7j11ltZs2YNN910E29+85t55JFHWLx4MU888QRnnHFGv8o3DMNIS8U1LxGpEpHnReRhd/vtIrJGRPpEZGEk783uUtDrReTyQPoCEXnR3XeHuIOHRKRORH7opi8TkdmBY64TkQ3u33WVvs5KMH78+II+pJaWFiZNmsTYsWNZt24dTz/99IDPOWHCBCZNmsTvf/97AO6//34uvvhi+vr62L59O5deeilf/vKXOXToEG1tbWzatIlzzjmHT33qUyxcuJB169YNuA6GYRjFGAzN66PAWqDR3V4N/BXw38FMIjIXWAKcBUwHnhCR09SJP/8mcD3wNM4kjlcAjwIfAA6q6ikisgT4EvBOEZmMM/njQpxoihUi8pCqVngwVnkDN6ZMmcKFF17I2WefzZVXXsmb3/zm0P4rrriCu+66i3nz5nH66aezePHispz33nvv5UMf+hAdHR2cdNJJ/M///A/ZbJZrrrmGlpYWVJV/+qd/YuLEifzrv/4rv/3tb6mqqmLu3LlceeWVZamDYRhGISo6Ma+IzATuBW4DblTVPw/sWwp8XFWXu9s3A6jqv7nbjwGfA7YCv1XVM9z0dwGXqOoHvTyq+pSIVAO7gak4QvASVf2ge8x/A0tV9QdJdY2bmHft2rWceeaZRa/TNxvOI5OpLZr/aCPtfTQMY+QxVBPzVtps+DXgk0BfirxJS0HPcH9H00PHqGov0AJMKVBWCBG5XkSWi8jy3t7eFFUshs3QbxiGMRhUTHiJyJ8De1V1RdpDYtK0QHp/j/ETVO9W1YWqutCi5AzDMEYOldS8LgT+UkS2Ag8ArxeR7xXIn7QUdJP7O5oeOsY1G04AmguUVTKlmFVtbbR87J4YhlEJKia8VPVmVZ2pqrNxfFC/UdXkkbHOUtBL3AjCOcCpwDPuctCHRWSxG2V4LfDzwDFeJOHb3HMo8BhwmYhMEpFJwGVuWknU19dz4MCBEhpga6iDeOt52cBlwzDKzaDbykTkLcB/4gRW/FJEVqrq5aq6RkQeBF4CeoEb1J/p9sPAd4ExOFGGj7rp3wHuF5GNOBrXEgBVbRaRW4Fn3XyfV9XmUus6c+ZMmpqa2LdvX8F8nZ37Aait3VDxcV4jDW8lZcMwjHJS0WjDkURctGFali51XGwLF65i3LhzylktwzCMYc1ojTY8qij3kiiGYRhGPCa8ykqaEQGGYRjGQDHhVUZM8zIMwxgcTHiVERNehmEYg4MJr7JiwsswDGMwMOE1QFT7Yn8bhmEYlcOE1wDp6+vK/TazoWEYxuBgwmuAqHYHtkx4GYZhDAYmvAZIWPMys6FhGMZgYMJrgFRXT+Skk74ImNnQMAxjsDDhNUAymVomTrzU3TLhZRiGMRiY8CoDIlWAmQ0NwzAGCxNeZcG5jWY2NAzDGBxMeJUBT/Mys6FhGMbgYMKrDJjZ0DAMY3Ax4VUWzGxoGIYxmJjwKgNmNjQMw0hGRK4QkfUislFEborZP0FEfiEiL4jIGhF5f7EyTXiVATMbGoZhxCNOA3kncCUwF3iXiMyNZLsBeElVzwUuAb4iIrWFyjXhVRbMbGgYhpHAImCjqm5WZz69B4CrInkUGC8iAowDmoHeQoWa8CoDZjY0DOMoplpElgf+ro/snwFsD2w3uWlB/gs4E9gJvAh8VIuYsiouvESkSkSeF5GH3e3JIvK4iGxw/08K5L3ZtYmuF5HLA+kLRORFd98drnRGROpE5Idu+jIRmR045jr3HBtE5LrKXqOZDQ3DOGrpVdWFgb+7I/sl5hiNbF8OrASmA/OB/xKRxkInHQzN66PA2sD2TcCvVfVU4NfuNq4NdAlwFnAF8A3xVZpvAtcDp7p/V7jpHwAOquopwFeBL7llTQY+C7waR2X9bFBIlh8zGxqGYSTQBJwQ2J6Jo2EFeT/wE3XYCGwBzihUaEWFl4jMBN4MfDuQfBVwr/v7XuDqQPoDqtqlqluAjcAiETkeaFTVp1RVgfsix3hl/Qh4g6uVXQ48rqrNqnoQeBxf4JUdMxsahmEk8ixwqojMcYMwlgAPRfJsA94AICLHAqcDmwsVWl2Bigb5GvBJYHwg7VhV3QWgqrtEZJqbPgN4OpDPs4v2uL+j6d4x292yekWkBZhCOhsrrm32eoDa2oKBLQXxzYYmvAzDMIK4bfNHgMeAKuAeVV0jIh9y998F3Ap8V0RexDEzfkpV9xcqt2LCS0T+HNirqitE5JI0h8SkaYH0/h7jJzi22bsBGhoa8vanxzMbms/LMAwjiqo+AjwSSbsr8HsncFkpZVbSbHgh8JcishUnNPL1IvI9YI9rCsT9v9fNn2QXbXJ/R9NDx4hINTABJ8QyjY21bJjZ0DAMY3CpmPBS1ZtVdaaqzsaxcf5GVa/BsXV60X/XAT93fz8ELHEjCOfgBGY845oYD4vIYtefdW3kGK+st7nnUBz19DIRmeQGalzmplUEMxsahmEMLpX2ecXxReBBEfkAjpPu7QCuDfRB4CWcwWk3qC8NPgx8FxgDPOr+AXwHuF9ENuJoXEvcsppF5FYcRyHA51W1uXKXZKHyhmEYg4k4iorR0NCg7e3t/Tq2r6+bJ5+sY86cLzBr1qfLXDPDMIzhi4h0qGrDYJ/XZtgoA2Y2NAzDGFxMeJUFizY0DMMYTEx4lQEnjkSwaEPDMIzBwYRXmRCpMrOhYRjGIGHCq2xUmdnQMAxjkDDhVSZEMpjZ0DAMY3Aw4VUmzGxoGIYxeJjwKhtmNjQMwxgsTHiVCTMbGoZhDB4mvMqEmQ0NwzAGDxNeZcPMhoZhGIOFCa8yYWZDwzCMwcOEV5kws6FhGMbgYcKrbFTR0fEyLS1P09r6zFBXxjAMY1QzFOt5jUpqa4+jtfWPPP/8awBYvHgb9fUnFDnKMAzD6A+meZWJ+fN/wzHHvCW33dOzdwhrYxiGMbox4VUmqqrGUl09MbedzXYMXWUMwzBGOSa8yoi3KCVAX58JL8MwjEphwquMiPguRNO8DMMwKkfFhJeI1IvIMyLygoisEZFb3PRzReQpEXlRRH4hIo2BY24WkY0isl5ELg+kL3DzbxSRO8RZ/RERqRORH7rpy0RkduCY60Rkg/t3XaWuM4xpXoZhGINBJTWvLuD1qnouMB+4QkQWA98GblLVc4CfAp8AEJG5wBLgLOAK4Bvi2+G+CVwPnOr+XeGmfwA4qKqnAF8FvuSWNRn4LPBqYBHwWRGZVMFrxTmvL7yy2bZKn84wDOOopWLCSx28FrzG/VPgdOBJN/1x4K3u76uAB1S1S1W3ABuBRSJyPNCoqk+pqgL3AVcHjrnX/f0j4A2uVnY58LiqNqvqQfc8nsCrGEGzYW/v4UqfzjAM46iloj4vEakSkZXAXhxhsgxYDfylm+XtgDcYagawPXB4k5s2w/0dTQ8do6q9QAswpUBZ0fpdLyLLRWR5b29vP68yWF5Q8zLhZRiGUSkqKrxUNauq84GZOFrU2cBfAzeIyApgPNDtZpe4Igqk9/eYYP3uVtWFqrqwunrg47XDwqt1wOUZhmEY8QxKtKGqHgKWAleo6jpVvUxVFwA/ADa52ZrwtTBwBN5ON31mTHroGHFsdhOA5gJlVRQzGxqGYQwOlYw2nCoiE93fY4A3AutEZJqblgH+BbjLPeQhYIkbQTgHJzDjGVXdBRwWkcWuP+ta4OeBY7xIwrcBv3H9Yo8Bl4nIJDdQ4zI3rcIMTPPq6+ti/fq/patrdzkrNSxpbn6M7dv/I1VeVWXTpk/Q1vZChWuVjv37f0FT038Vzbdt2+00Nz8+CDWqPKrKxo0fo61t9VBXxTCAympexwO/FZFVwLM4Pq+HgXeJyMvAOhxt6H8AVHUN8CDwEvB/wA3qT9P+YZwoxY04mtqjbvp3gCkishG4EbjJLasZuNU977PA5920ihIepNxZ8vH79v2IXbu+zaZNHy9ntYYlq1ZdwaZNH0uVN5ttZfv221m58tIK1yodq1f/JRs3/n3RfJs3f4JVqy4bhBpVnu7uXTQ1/QerVlU87skwUlGxiXlVdRVwXkz614GvJxxzG3BbTPpy4OyY9E6coI+4su4B7imt1gMjaDZU7Sn5+L6+HrecqiI5jy4cZbp/99QoD7bcjzHcsBk2ykhQ6DjBj6XhNc4iNWWr02jAu5e2UvXQ4Qkv61gZwwUTXmUkrHn1R3g5x2QyJryC+MLLev9DhfcMHFe1YQw99iaWkbDPq3QTl99A2DJrQXxz4cjRvPr6Bj5ucDih2uX+sibDKB0RucKd9m+jiNyUkOcSEVnpTif4u2JlWitZVsplNrTHEmQkmg39xn500NfnXI9pXkapuNP83Qn8Gc4wpmdF5CFVfSmQZyLwDZzhVNu8qPRC2JtYRgYasGE+r3hGpubVXTzTCMITXsEOmmGkZBGwUVU3q2o38ADO1H5B3g38RFW3Aahq0dV8TXiVkYEHbHhmQxNeQfx7mTdJyrDFb+xHB06bY5qXEUu1N82e+3d9ZH+a6fpOAyaJyFIRWSEi1xY96cDqbAQJCy/zeZWLkRgiP1rNhtbfNWLoVdWFBfanma6vGlgAvAEYAzwlIk+r6stJhVorWUYGGm3oj/OyxxKkP/dyqBltmpf5vIwBkGa6viZgv6q2A+0i8iRwLpAovOxNLCPl07zMbBikP5GbQ81o83n5ZkPzeRkl8yxwqojMEZFanHUbH4rk+TnwOhGpFpGxOGsxri1UqHXxy0p5og1tnFeYkah5mdnQMBxUtVdEPoIzv2wVcI+qrhGRD7n771LVtSLyf8AqnMisb6tqwYk0TXiVkaC5byDjvKyBCDMSfV5mNjQMH1V9BHgkknZXZPvfgX9PW6a9iWWkXNNDjaSouoHizVtYOM/I07xGm9nQNC9juGFvYhkZ+DivkTcYd+CkEV4jT/MabWZD83kZww0TXmWkfJrX0SO80gjqkal5+cJrNMzJaJqXMdywN7GMDDTa0POTjYbGLj3Fr3Ukal5B4TUa/F/m8zKGG/YmlpFyzSpvmlc0z/DUvAr56zwzG4wO/5d/PUePP9YY3pjwKitBf4CWrEEdnT6vkSu8CjXkYbPh6NG8ji6rgDGcMeFVRqLO7FIbXfN5xTNcBykXqvtoNRuORBOuMTox4VVGotM69Vd4meYVJngfh1fPP7nuo9VsOHy1YONoo2LCS0TqReQZEXnBXVzsFjd9vog87S46tlxEFgWOudldrGy9iFweSF8gIi+6++4QEXHT60Tkh276MhGZHTjmOhHZ4P5dV6nrDF9zWPMqVWM4Gk0zaa412NsfToKgUN1Hq9lwuGrBxtFHJTWvLuD1qnouMB+4QkQWA18GblHV+cBn3G1EZC7OnFdnAVcA3xBfGnwTuB441f27wk3/AHBQVU8Bvgp8yS1rMvBZnPmxFgGfFZFJFbxWnPOGhdcrr3yBzk5nJYDe3ja2b/8Khw79IfF4r4E4ePCx3HEHDy7lyJEtdHfvY//+X+Tyqip79nw/1Jj39XWxZ8/3Uw38DXLo0O84cmRzSceUi6iW2dm5jVde+SIdHRvYt++n9PQcCvX2OzrWcfDgbwe7mgnEa15tbatoaflTbrurayf79ztTufX2trBv349D+f1r3lj2GjY3P05nZ1PBPKrK7t3fK9gx8DtWYc2rs3Mbzc1PDLieqll2774f1T5aWp6mvX0tvb1t7N37IHv2/IBstnPA5xhqurp20Nz8K9raVtPa+mxZymxtfZa2toKzKI1aUk0PJSIfBf4HOAx8GzgPuElVf5V0jDotaJu7WeP+qfvX6KZPwJ9d+CrgAXW6qVtEZCOwSES2Ao2q+pRbl/uAq4FH3WM+5x7/I+C/XK3scuBxVW12j3kcR+D9IM319peo2bCp6StUVY1lzpzP09z8f2za9HHq6mbxmtdsjT2+r+8IAIcPL+fZZ8/hda87xAsvXApAY+NiWluf5rWvbaG6upH9+3/G2rXX0NGxjjlzbgUcYfnKK18gk2lg6tSrU9d75cpLALjkkqGIJAsLgF27vsUrr3yBQ4eWcvDgY0yZchUTJ16U279ixfnAUNU1TJJ5d/nyc0Pbq1ZdBsCFFx7k5Zc/yL59D/KqV71EQ8OZAOzceTfbtt1GV1cTp532X2Wt46pVl1FTcwwXXrgvMc++ff/LunXvpbNzC7Nn/2tsHu/djPq8li8/j97e5gE/j50772LDho+QzbazYcOHATj22PeyZ8/9AMyc+TFOOeX2AZ1jqFmxYiHd3btz2+V4h597blHZyhpppNW8/lpVW4HLgKnA+4EvFjtIRKpEZCWwF0eYLAP+Efh3EdkO3A7c7GZPWrBshvs7mh46Rp0uYQswpUBZFSZ/9gGvx9rbe8jdbk88Ops9HPjdEtrX3r7WTW9zyzsIOL05j+7ufe7/XaVWfMiICgDvfnV378z9H75+ltJ9k11dzqvc03Mgl+b7OitjXuzp2V+kTjvy6hTFezejz6K3t9lNH5ipu6fHe5/9zzZoDSh2DSOBoOAyBk5a4eUtJvYm4H9U9YVAWiKqmnXNgzNxtKizgQ8D/6SqJwD/BHwnco5QEQXS+3tMDhG53lv9s7d34A1k3DpcXsPkffyZTEPi8UHhVTxPxi3fb0CrqsYAfi95ZBBu9LxGsLfXEd6ZzNjYCLfhEMFXeoOdJZPJf0ZeOUPlT/Lq4r0/cfjCK76OXqeqvxR7d6uqkr8b4+gkrfBaISK/whFej4nIeErodqrqIWApjunuOuAn7q7/xfFJQfKCZU3u72h66BhxJMcEoLlAWdF63a2qC1V1YXX1wCfYj5v3zeupZrOtQOEGore3teg5vDz+TAf+Y4hrGIc7Uc0r/36NjdW80tyrSlNqVKhqb0Ij3ZfbX07S+j69unjvTxze/U6q40CfR7F314SXESWt8PoAcBPwKlXtwPFfvb/QASIyVUQmur/HAG8E1uEIkYvdbK8HNri/HwKWuBGEc3ACM55R1V3AYRFZ7PqzrsVZuMw7xoskfBvwG9fX9hhwmYhMcgM1LnPTKkq88HJ6qr29Xs81vkFRzdLX11H0HPmal9/79xuAkeTcjgqvfM0rTiNJo6VWnlKFV5Lm5Qmv8mpeaTXDbLa48ErSvDKZsaH9/cU7t1eXKFVV4wZUvjH6SKtuvAZYqartInINcD7w9SLHHA/c60YMZoAHVfVhETkEfN3VlDpxoghxFyd7EHgJ6AVuUP/r+zDwXWAMTqDGo276d4D73eCOZpxoRVS1WURuxVnBE+DzXvBGJYk3G4Y1iaS5/DzhVgxf8/IEZb7mldQADEfytRfv/jhCPknzGg7Cq5jmJVITauyDwiv8jCqjeaWZNxIGpnlVVY2lr69jwM/DWz3cNC8jLWmF1zeBc0XkXOCTOELjPnwNKg9VXYUTlRhN/wOwIOGY24DbYtKXA2fHpHcCb08o6x7gnqT6VYI4zcvTGpIc3h5pP34vn2c2DDag3grMI8tsGPV5he9Pks9rOJgNiwkHkRpEqgORer0B4eX7iLx7UH7NK50w9OqXNOmuqubeu6gW7GleA30eXl2T3l3vPIbhkdZs2Oua464Cvq6qXwfGV65aI5Vkn5ffc41v8HzNLHhsvonRz5fv8/Id//0TXqWODysP8WZDj5GseYFQVdWY21LN5nxe4eddKZ9XaZpX0vkdc3afq0nma14w8OcRL7z8+zs6ZrMvGuNmlEDaN+KwiNwMvBf4pWsKrKlctUYmaaINkxqUOLNhXF4vn695ZQP5vXMV953FMRS+svyAjfA1i9QOY82rmNkwQ3V1sI+Xxfvkgo39cPF5JZ3fe+eqqycB2VAnp3yal/fu+sIrm20P7B/5U6bZQp7lJa3weifOjBl/raq7ccZM/XvFajVCiesd5mteSWbD/I8/OCYs33dW5ab35eXpr+YVV4fKEx9t6JMdRZpXb9774FApzas0s2Gxd7OmZnJevkpqXuEyR77wirPMGP0nlfByBdb3gQki8udAp6reV9GajRLSal5xH783cBN8Qeb7vDwTRDaQp8f93z/hlTZopJzk+7zyt+M0gqERtGGKazYSipILXktY86rMOK9SzYZJ5/fqWl3tCS8/nx9tWB7NKxhxGxTwo2G+T9O8yksq4SUi7wCewQmOeAewTETeVsmKjUySNS/v4/Z7mL0899xr2bPnByxfvoCXX/67vGO3bPnnvLTdu+/l5Zc/kjvXgQMPs2vXd3n22fkcPrzcPVcba9e+jx07vsHBg7/luecuyDVMmzZ9iq1bP8/q1X/Fnj3h2bK8Ou7YcSfLlp3BihWvzs0pt3nzv7B5c359PLq797N8+UKWLTudAwceCZTZyXPPvZYXX/wLAA4e/DXPPffa3P5Nm27klVf8GJ24ufN27/5u3vnKIWj7+rp57rkLOHTod/0tIS9l9eq35H6LZMhkanPby5efm5s1ore3lTVr3s6KFYsDwRDtrFjxalpa/khT0x2sW/cBAHbt+g4vvfSu2BqsXXsdO3feHbsvei87Ojby7LPn0N29393fx6pVV9Lauiw2P0Bz869YvfqtgK95PfvsWRw5ssW9RqdB7u7ew/LlC/o9Z1+cRho1rW7deiubNn0SgG3bbo/9ZgDa2l5wp62Kf0cOHXqS5557TeJcjs3Nv2LZstPZvfveXNqOHXexdu17S7uoCHHCa/v2r7J+/Qfp7t7Ls8+e0+85RpctOyN3zWvXXsfy5QtDnd8omzZ9ki1bPkd7+1qWLz+Pnp5D/TrvUJLWbPhpnDFe16nqtTgDi+MnQTuKqamZyMkn386rXvUSJ574zzQ0nBNjy3d6kN3du2lt/SNr176btrbnaGg4h5kzP0bQtHD48IpQ+Q0N51JTcwwHDvyC4IQh69e/n/b2F2hu/iXg9KT37LmXDRtuYN2662htfSo33dL27V9m69bPsn//T1m79t0h/4XXA9+w4SMcObKew4efoaPjJQC2bbuNbdv+LfHajxzZQFvbCo4ceZmWFn/y4e7uXbS2/pEDBx5GtY+1a6+ltfWPuf0HDz7Bli3/Eigp3MNub3cmHR079qxQejkiKjs7t9La+lROSJRKnNlw//6fBbaEE074ONXVU3IpBw8+5h7bxb59P+Lw4WV0dm4FnAl9Dx9+hpdfvoGNGz/K7t1OsOz69X/D3r0PxNZhz577ePnlDybUMHwvt2//Eu3tq9m/35kjIJvtoLn5/2hoOMutU77m1dLyB7q6XuH44z9IY+OFgHPfduy4wz0mm8vX1vYcmzbdmFCXwviaV3A2/m7GjDnV3epj69bPsH27463YvPkT7Nz5zdiyNm36FG1tK0PvYZD16z9Aa+vTufsepaXl9xw58jIHD/4ml7Zhw4fZs+d7JV5VmPz1/vrYtOlGdu26mz17/j/a21fT1PS1fpV95Mh695r/yJ4997nfYvJEz9u3/zuvvHILW7d+jra2lbn3ciSRVnhlVHVvYPtACcceVZxwwsdoaDiTk066jerqSbkepTdvnfexR/1js2d/Lm/i0eig5enTP8jEia93fSfpFkL0zu+No4nJHXucf3w6U1Z4zS3/d7gufbFBLeFywg2uF0QyY8YNkfShnx4qTcDG5MmXc+aZ+Y1e0ETnd2yc8rwhDwMl3wTr1dcL9nHu4XHHvQ+RuljNq6+vC5E6Tj/9rpzm5RyroXMM9Hn430n4fZs27Z2RuqcvK+ldi96HKEkz6A+cgS1Wm4aggEz3TLznOPIm9k07zuv/ROQx/FnZ3wk8UiC/gSMw+vo6Ue0LfJzxL2wmU+f+8j/SaNSgSBWZjBeuXJrwSvpQgw1cvPBK94ElCa/gooyQTSG8wufzhFd0AG15JrF1/Ia+/7A00gRsOOXHjf87EvgdjvIsdo/Skv/s+tzyM+55nWeTydQF3qtoGd25d9N/R/PPUS7hFS0nk6kP1b2UspLvY/g+5O3tq8zCm/maV09gn/cODiycPnhNo2EduUKk+kpU9RMi8lbgQpy7e7eq/rSiNRsFiFSj2huwrVeRNCA16BtxU/I0L5Eqt8yegg7soMDwP8D4/OFoxXwfQHrh1RP7OyxI0wivqLbgHB+dE3J4LEqZpNl4OA1JceEVNoGKRN+F/pGkeXn18Z6NSG3uvcqvZ1fu3QzWKxowNNCG0tNEo+V4ASGlBGyk1bySOh++laS8ATT5wqsSqyX4wivdNzKwDtxQkrqLp6o/Bn5cNKORw+nN9gQa4LFks4dR1bwXV8Tr1Wogb3Sm7kxgoGhpmleyllDYbJg2Aq7SZsOo5lUes2Hp4ddB80r+GLXwvfIahLhrDmrV+Z2UdGbDYg16ciRn2GyYydTFDkB26taVezfjNS/PbDiwzkSyRcJ77uU0G2ZD+aJUymw40JXW050jKLyOYs1LRA5D/lIiOOJaVbUxZp/h4mteXiPhCa9szDQ7dZHtfOEV1rxKFV7FNa+B+byC2lZQCwuWWS6zYaYsJpH+NR7Bz6HYGLV0mld0Lsokn5eqhnrIxRqn4mbDoPAqpHnlCy/f51Uus2H8s/A07v75vJJC0wsPCveFV7mFS+U1r3An8ij2eamqTQE1ALyJWb1eaVXVWHp6IG7gbdRs6OcNlleVE4il+7ySeunBGToGYjZM0ryCJsziwiupnkHhVVU1vixmw/40HmEza3QhzWhj5wmaOOHla1vRRiZJ81LtDe0rfg8KB2x4xztmw0I+r3yzob8/m8s3EJI1r/77vJLNgoUHhXvXMpg+r3IR9J+W1qEYecLLIgYriCdofPOMb7/PNzHla175VOUamcI+r/Rmw+KaV9pZGtL4vEo3G3oEfV7V1Y1lMYn0r/EICvvCkwp7Gk682TA51D9ZePVEtotpXtF7Gda8wmbD6lhNNMls6GmA5Ys2jH8WnvDqj88rWeCl07zKbdYbDJ9X8L0qxec10M7HUGDCq4J4gsb7GLypdILTBHlEzYZe3nB5mVxDmF7z8EOa4wVYuUPlqwqYLko3G3pENa9ymA0Hqnnlmw3jNa9iZsMoQeEVN/2XX0ZpZkNfSwoLnGI+rzRmw4FO35T0LBzBWVVQ400qK9lUPjx8XpXRvILrxMW/H2ETobrHjTz/mAmvCuL5EfyQ5GTNK87nlV9eVa5hK73xzsYKvFKjDZM1OOd6qqrGRDSv0syGSQ1OZcyG/Wk8khvRZM0rzveS3AAHfV7hjkC4vsXuQZLm5Q8I9syGyT6vYKh8fBRkeaZtSta8at37GOxkBd+pfHNXMeFVTPPyzYaD5/Mq1/RX4SjWJOEVp2Gb5mUE8E18Uc0r3+cVNRXFaV6O2bBUzQv3nH2xAq/4OK90DaZ3PZnMmIjPa2Ch8h5B4VU+s+FgaV6ljdsKa17xvkRnuzSzYdTX45sNaxPHeTlmw1o3X3K04UApPP4xU0Cbz+8EFNMGi/m8hkLzKte50givcLpnNjTNywjg+RF8s6GzGqwj0IIDFGvzxllkMvkrxzpz5XkLTpb2sjkRjnGCp1iofDgt2RThXI8jvJKiDfsS/Tl9fYUHcQd9XlVV48pkNiy9Zx1egqawz6tQtGEhwsIruYHrb7ShP4HzQKINyxvUkORfcrTCTCQQoTvwO05bTKd5JZ2zULThQJZmKeTz6t+7GLfeX9BsGN/RTPOdjwRMeFUQrzfrNxJeAxzWvOJ6tNFBueBHG0J/zYZxmlVpwivZFJFW84pvyP3riW9wggEtmUzdkGle4d58unFepS6FkaR5RRvb0qMNw74ef5Byss8rbDb0n4HfwFde8xKpStQo4utcOZ/XQK630Div/pnt8gVpOrNhvuZqwssI4Y/Jyvd5BV/cOF9CoWhD6I/mFW82DPtw4nxe4bRks6Hv80r6KAuZDf0peZLMhn6DLlJbFht9f6LJCgUOJGtepZkNg9cajuIsl9nQm83Cey8Lz7Dhmw3999TXvCrv84JMRKMICq9kzau42bA/Pq+BBKZEhVdn7O+0xGmB6cyG+ZprpaMNReQKEVkvIhtF5KYC+V4lItk0q5aY8Kog+dGGQbNhMc0r3mzYf59XkuYV9nnlz3DRFWmwS9O80psNC/kZJNRrzWTqymQ2LK/mlTTOa2Bmw0IBG8FGPDlwIXBEKH0g0Ybl9gsVijZ0zIbl07yi9yFv76BpXu2B3/1ZJaG/wit4/7oK5i0H4lz4ncCVwFzgXSIyNyHfl4DH0pRbMeElIvUi8oyIvCAia0TkFjf9hyKy0v3bKiIrA8fc7Erm9SJyeSB9gYi86O67Q1x7jIjUueVtFJFlIjI7cMx1IrLB/buuUtdZCD/aMGw2jEYbxgmv6HRITnnljzaM+rzizIRJZsBwvnifV6lmw7jGIaq5lM9s6PU60w/QLMXnVTjaMJng9ab1ecVrIElmw7DPy4s2jPcfdRU0G1Y+2tAJ2Ag3ykFtvnSfV9L8on75yeO8yim8gjPo+NfXv3fRL7O4zyvYdngaX4XNhouAjaq6WZ1KPQBcFZPv73GmINwbsy+P8kxfHU8X8HpVbROnxf2DiDyqqu/0MojIV4AW9/dcYAlwFjAdeEJETlPnCX0TuB54Gmc2+yuAR4EPAAdV9RQRWYIjtd8pIpOBzwILcd6GFSLykKomr85WAZxGSHMvSNI4rzizYfFow/iXLZMZE9uLS442DJsNowJOtTsivIpFG9bT23soNn86s2F+bzd6TLnMhgPVvIrNbdjfaMNwmcmaV7Bx6uvrJjpLSzHNK99sGKd5dRcxG1ZW8/JC5ZPGLxXSvJJNfAOZYaN8ARvZbHvg9xH3nKXMJDJws6FXhwGaDatFZHlg+25VDa6QOgPYHthuAl4dLEBEZgBvAV4PvCrNSSumeamD17Wocf9y3QpXe3oH/jIrVwEPqGqXqm4BNgKLROR4oFFVn1Kni3wfcHXgGG+50x8Bb3DLvRx4XFWbXYH1OI7AG1Q8Lcl7QXyzYRrNK8lsWNjnFWdu9M4ZbzYMNoBdeQLOSUuKHgyW0wNUkcnUFsjfR/IyFIU0r7CpsXxmw4H5vPIDNkrXvPzpj0IlxdaxsOZV2CQcPD6qeflmw8LRhnGTvlba5+UNUg7PHJHO51V84uL+RBsO5HqThZcndErrDAzcbOjVYYCaV6+qLgz8RZf2jpuyPqpifg34lJZwgyupeXk2zBXAKcCdqrossPt1wB5V3eBuz8DRrDya3LQe93c03TtmO4Cq9opICzCFeEk/gwgicj2ORkdtbXmWoQiX79xezzzgB2GkiTZMGqTsRRvG95Qcobc/Zk/+ZMBO3cIve3/Nhs68e9V5Pfio2TDZlJNshoozGzraa7IwTMNw0LycAddhZ33SrBqFfF7xzyXffxks09muIjxnZpig2TC+rMGINizN5+Uv01JMeA2tz2ugwquY5pXc0Sy78CpGE3BCYHsmsDOSZyHwgOsROgZ4k4j0qurPkgqtaMCGqmZVdT5OZReJyNmB3e/C17ogWToXktr9OSZYv7u93kJ1dfnluK8leZpXvNkwXvOKNxv647zihVey5tUXK/CiL/tAhFcmU5Pn+M8XXvFmkUINRlTz8nwv5VqGo5S1jErRvPzPK1nzqqqKm/s6SXhFow3DWnN+XeM1taDZ0A/GyA/Y8BZRjR+c7JvWovNy9ofkgI1qHJ9XMDIvOKlxocY+3TRS4bQsvvArd7Rh+D0L+7w6E+uUTH5d0sxtGNa82tzzVjTa8FngVBGZI44NegnwUDCDqs5R1dmqOhvHivZ3hQQXDFK0oaoeApbimu7EeSP/CvhhIFuSdG5yf0fTQ8e4ZU4AmguUNaj4mpcjvJKmh0rr8wpHGyaZDcfFpieZDaOO8OhL7PjBekLb8eX3BDSv+PzBhiG/Hsmh1/maV62bd2C9xfIPUk5az6uQ8Mp/XuE1w+KXmnG2gx2DuGEO0fp1h8pxTILejPH5ofLBWeejBDWveP9safT19cSaUEUkT/MKayzJz7CYlhQ/EbF3H6Xsmld+dGqc5pX+nYyri3+fMilD5SuvealzIz+CE0W4FnhQVdeIyIdE5EP9LbeS0YZTRWSi+3sM8EZgnbv7jcA6VQ2aAx8ClrgRhHOAU4FnVHUXcFhEFrv+rGuBnweO8SIJ3wb8xvWLPQZcJiKTRGQScBkpwy/Liacl+cIrGG0YDNjI1/r6O7dhkuaVNEg5ao4ZmNmwsOYFfUXNhnH7o+tbeZrAwGcyL/cg5dLGeYnUxWo1aTWvYmbDuGEPwXKCM8bHhcoHZ53Pq2FflytkswlWgtJwNLz8CFunblWhxTuDGkuhZxj3LoU7BvFDA8D5jpwxmmGDzcCEV7is+ICN8vi8nPoXNxsOUrQhqvqIqp6mqier6m1u2l2qeldM3vep6o+KlVlJn9fxwL2u3yuDI20fdvctIWwyxJXEDwIvAb3ADQHn3YeB7wJjcKIMH3XTvwPcLyIbcTSuJW5ZzSJyK466CvB5VW0u/yUWxmu0Dh36Dd5S6wBNTV/l4MFfB3Lmh8f2N9owSXht3HgjtbXH56UHzQyHDy+jo+Pl0P6+vi527fpWbnvHjv+itfVp5sz5Qq7X3tW1k507v0lt7fGIVNPV1cSGDf/ArFn/mtrn1dm5nQ0b/oHoqsIQF23oNKabN99Mff1surq2I1JLXd3xdHa+gkg1Y8acRiZTQ03NVKZOfSvbtv07M2b8HdXVjXR0bKCl5fe5nveRIxtpbX2GxsZF9PX1sn37l6mqGs/kyZcxduzpABw69CTZbBuHDz+Xq8eePT+gpeUp6utPJJOpo61tVbTmbn3jNa9MJl547dvnL1i+fftXcr/7+jrZvPlm6upmMmbMqezb92Ao35w5t9HTs5cjRzYjUsWGDTfk9jc3P557Fjt33smsWf8cCcaopqtrO21tq2lufoSpU9/Gtm1fytUzSmfnllz5wXe1peUPHD78PDU1kzlw4JeMGzef3bu/C8DUqe9g8uQ3oqps3347VVVjmTDhdYwbNw/VHld4xQUEZ+jtPZDb2rXrntzvl1++nokTL6aqqpHu7l2ho7ZsuZlstoVx4xZw+PByjhxZHzJBv/LKLUyb9g727n2QE074GCLCgQO/cK+5gWy2jc7OVzhw4OHcMQcO/JKxY89g0qRLQudSVXbsuIOpU99OV9cOurq2MXXqWyN5wsIm+F15Qmffvgfp6LiNsWNPobe3hR07vskxx/wFO3bcyZgxpzJmzMlks20cOrSU+vqT8u6UH9ncQEfHetavv56qqvHMmXMrBw48TEvLnxgz5uSY40beDBsVE16qugo4L2Hf+xLSbwNui0lfDpwdk94JvD2hrHuAe+L2DRYNDedSXz+bbLadyZMvyzVi+/b9by5PdfUUJk/OD4SMMyeFow3jzXfV1RNj048ceZmenn3U188BlM7OrW45zkfT2LiY1tan2bPn/tBxfX0dbNv2/3Lbhw79lkOHfsu0aUsYP/58ANascQbDd3fvytVvx47/ZPz4RRGfWhavtyhSGzJ1HTjwCw4ccMzgxxxzNa2tTzNu3Hyam/8vV+axx15DXd1Mxo2bT13dCeze7Tze4PCATKY+LwDi7LN/xpYtN9PZuZXTT7+LFSsWks22Mnv2rbk8zz33ai65RNm370G2bPk0AFVVjbzudS0ArFx5cd49PXDg53lpQfxow3gDh6OpOh2AhoZz3MZyC11d23J59u//ae53e/uLbNv2RQAmTbqctraVuX179txHe/tq2toc4Vpbe1zIBLVq1WVUV0/Kba9Z8w7q62fl7u2ECReya9e3ePnlv6W19Wk2b74JUGprZzBunP8ZT5u2hL17H0C1h507vwnkj0lcseJ8xo6dS0fHS0yadDkHDz6BSIbOzm1MnvxGWlr+wObNn8zlv+QSdTUv32xYW3s8EyZcFHv/Dh/2477a2p6nre15wPEfBr+b7u7dbNz4jySRzbbx9NOz3Ot/DRMmXJgTtI2Nizhw4Be8+OKb6eh4KXfMhg0fztU5SGfnZjZu/Ef27v0hra1PxeaJ66R6BL+T55+/gAsv3MvGjTeye/c97Nv3w9CzHjPmVI4c2RA6PpMZS19fR66cSZP+jIMHn2Dfvp/Q23uAKVPexEsvvRvIMmXKX+SdP6ndGM7YDBsVpLFxIYsXb+GCC3Zyzjm/iDUfXXDBbk444ca89GBD45E/t2GGmTM/FspTW+sHVS5YsIKFC1/IbZ911v+yePFmFi/ewlln/cQtxxEgs2b9CwBdXTtC5XV3x48XDDaMwTzBa8xmW8lmDwfC/h2z4fjxzn0J0tPj96wbGuZxwQW7qKubGSrzzDPv56ST/o3GxoUsWOAPK5kx4x9yv4877q/z6uqZnLzxZ9lsa+ja4/IG85XKtGnvcX/FB4J4DawT4OJc29ixZ7J48Waqqycnltvb6xsPstk2GhsXc/75z+TSenr85xAfWXo4kHc/wXF3xx13HZnM2IDZymlozz//KSZMuCB33Ny5P2D69LCbIs5X1d29x/2/m3HjzmXChIty548T5qrZUDmveU0TZ531gHcGAKZPvyHvuCAnnfRvXHDBTl7zmtLd215nMJttY/LkK5gw4XVA/vdQ7PienrhIX4eg5jVx4hsix/vCq6dnHwC9vQfd/62RvOH39vTTv81FF7VTXT0pZ0mZNevTXHDBTs4993G3jMN4/ubgtwYwe/YtzJv3MCMNE16DSJz5KMmkFN8TCs9tKFKV5w+qqTkmUHZNqPygYIlqcCLVVFWNo7s7KrziP97k0Ga/PtnsYXp7W3PX4psNq/KuO9gw+/uqQnUNUlXVmPtdWzsVT1DU1MQ1/vFCpNh8cvHrVxXHD4KI/7y8++H5CJ3fVQWPAejp8e9Rb2+z+8ziohXjJ3bO92n1Rt6Pmrxrrq5uJEr+uLu4sWoO3d07qK5upLq6MdcZiPNtRTWv4H3w6lhdPSHxPOC/E6XOaBIkm22lqmp8wLecLoAi6L/yyJ+5xd+uqQl3TgutrB333ML434knBL36e88v2BELfmsQ/pZGEia8BpF44RXfsMY12EHNy7FRZ4hqc8HGxtkXbpzC+4K27gxVVY15PceknmTyEhZ+fXp7D5PNHg4JL2egsucGDZ4nX3j5/+MCWnw/jPPxOfcxTmNNjnCMs/P7DUxSAEExfAEQ/2x94VUduDbvfiSH7QcbnZ6eZkRqYoULFBYoPlnyOzfhBjfefB2N/kw+V0/PftecN97t/UN8s5MtUI7nO4yfF9Ov63g3XykdwjC9vYepqmoMWDjSBVAEtVqP/JlufM0rWpdCcxtG90UDMXzzdHVAeDn19+5Jb29LLn/wW3PqEt8BGu6Y8BpESpkmKC5vcD0v1e6QD8wj2BN3etLBHqxfpl+ON79dVWIvPo7kj9pvOLLZ1pDm5ZkNnXr79cpkGiK9wbDQihfkfiMfbMCDDY9fjzbiiNO8gmlx2ksa/GmUigmvmtxz8O9HeTSvNNMMRafrymRqQtefyTQkdLjSa17gvJNBzSuuMxE1G4bpy9WvEH4jnKTxJptkPbLZVqqrxwe+j7TCK9/EHDX3BTWx/E5W8vPyzIf+9qHIO+4JL38SI+8ZeVpVd/fuwPGmeRklk96cEd97LF3zipqFgvv8cgAyJfXAkpeT8HuFvb0t9PW1x5oNg69edfV44qaUKqR5BQk24NXV4/MaV7/HHyZOeAV70APXvOLxhVcVUc2rkNkw2Og44+pqCgxKL2bu0hizYXXoniS9D0nj7qLl++U0UlU1nmz2MKoaGSbijdnrTRReniAu/h4UNhvGD0sInyebbXPNht65kpZVCWuo/jvmp+drY0HNK85CkFSvfLNhUBAHNS8/zfntLTQa9N1Fyyul0zqcMOE1iJRii0/yj0V9XoU0L6f3mNbnlSmpB5bUIw3a7ru7Hce5Z98Pmg2D1xc9rxc04eUp1uMOHh+veXk94Ogg0XzhFewt91d4xTfmPr4m6mvO/v1INhtGzT1O5yT+E06jMfgdCa+8mojmGf8+RN+5YuuiOWbDRrzlgYLDJYJjH5OFiye8BmY2LIbjt1L3HSp8rqiPK85smK+NBQX6xBQ1So5ODPp2474T/70SdxhBcuBJkul5uGPCaxApzWyY/2iiM2wEtz3CZsNw4xanefmaUqZEs2HSpKZ+4+f19qqqPEd7Nmc2DL560fN6Y718s2Hh++ZoCJIrK9rweA1LtIEZes0rE7jG0jQvJ29yA1tc8xK8+Sj98qojwiud5lXsXI7Z0Ckrm20NCVbPNFtY88rGnjdKMbNhYTT37B3tvfC5ooLJ3/Y7H1GNP2jKTaN5xQWB+McHTaDJmhc49z8aNRl8R03zMooykCgoh+AMG90Ee+4eYbNhmmhD30RXSg8s3LMPLmjpa17eB+ObDfvwow2DZsN4zatQtGGQoIZQXZ2veXnaVLQxKSa8Bu7zisfvdUvg2or7vPJnrY8KkfiZOeLL6iG6vlpU80oOBgk/j/g5M/0hB47Z0It6O1xA8ypmNox7D4KdoP5HG6r25t6TdJpX+F3y3q1gh6Cw5lVcYMRpcx5hzSvo83IIPqPq6ka6usLDB4LHm+ZlFGWgwivsI9FUmlfQLBQ2K4R9Xo7ZsH+aV1Ao+I2W5D7eOLNhOs0rHHWYRPD4sL/Cq98hIL8xCTbUXk+0HGbDYp+V38jma16FzIYANTXTAvWLapjBufIKT7TqNIz50Yb90bzizhUtx496a80TXv40U4UDNuKjTv1n5Pn/+ie8enLCIu4dihINxghq916dosInHERT+B1R1bxzBClV88pmWwgSPN40L6MoA50FPV9YVcUIr2jARny0Yf7SKpl+a17Bj9TzedXWHptL8zUN32wYbGCSNK/8MPJ4gr1Yp6ywAPCitQqZDT1tKZgnHImXXpAVW6bFv/bg8yw+zgsITfGV79sLdiIKj2FzNKDCZsOk96F0s2FjYLzR4dC749xXL5rQm+E+LMQKBWwEteM0EZtJqPbmOjdx2nuU6LvkHdvb6wuvfOHja17Fn097CZpXXGBTsmUjevxIFV4VXc/LiFJ86Y3guko1NdNCsyYEzYZO3kxe7zuTqWPMmFM4cmRjjNkw36G7Z8/3cmX5vqni7NjxDdate19eujdIur5+di481xNea9deQyYzlrq6E3MNTX397LyPx/MH+IN940041dUT6e09FLjm9bEfoie8Oju3snSp/wwOH/Znp8hm20L7wJnuaulSYd68X1FV1VhwLE6Yws85GJzhO9bTNbw1NZPIZBro62uPuS/JkwZH6evrpLX16dDUZMFQa0gfsFFTM6XgubxoQ3Cm2Zo48ZLcvra2FTz//MVuuc7zHjv2jEgJns+rhvr6OXR2+rOzjBlzWt5YxKSxk3V1J9LRsTZ23+rVV+caf+dZFxYuL7zwBkRqXc3Rn9BatSv3zW7Y8He0tj7FgQMPuzPY+M+kmFnyD39opFDARpzm5c9TWRe6B3HfdXAyg2IBUcMVE16DSEPDGUyb9i727nXmJD733Cfy8ixatI72ducDW7BgOa+8chu7dv034DR6YX9KJuR4PfvsnyEizJ//O1pa/kgmU0M2m+Tzij76Ko477r2uyU555ZUvIFLDnDm3UlMzFVAmTXojBw48yoYNHw41/ABTplzF7NmfY8yYOUya9EY6Ol6itdVZWzQ463hfXwdetOHcuf/LhAkX5CafraqawCmnfDU3oem0ae8mm23jmGPCE5x6LFjwHO3tzmS48+f/mpaWP8X6m5LGeQHMmPFRdu68M6QNnHLK19m48aO5+eSamr5Kbe2x9PTs4bTTnEmwPW1g4sRLefbZM93rrOf00+/JRVkGOffcX9PTs5/q6kl0dKwHopq0Z/rxG526uhOYM+dWOju3UVNzDF1d25g8+c2sWfMWV3g5xy5cuJL29tWsXXtN6JzHHnsNU6b8BevWXUdfXycitZx//tN0dKxl7dr3uOeLfycmT34zM2b8few9C+Y77bRvMWHCBaHJa+vrZ3Psse+lru5Eenr2MGHC6zhyZFNu/6FDS0Pltbb+EXC0gTPP/AGTJl0a2h/UvObPf5KWlt+TzbaSyTQwefLl9PTso6uriUJkMg3Mnft9urp20d29m0ymls2b/zl3boApU/6CxsbFjBt3Dn19XcyZ8wX6+jrZufOu2MH6qt1ks92IVHPiiZ9izJhTWL/+b0J5vLlCN236GA0N5zJp0uVMnfpXTJnyZubNe4yamqmsWOHMETpu3HxOOOHj7nNU916eTGfnJsaNO59p097F5s2fAMKDx72Oz+zZt9Dc/Chjx84N1cGp2xzq6k7ITabc0HAujY0XUlc3veB9G86Y8Bpkjj/+AznhNWnSG/L2jxlzcm7W5/r6E5g2bUlAeGVyDZ5j8smEwouPOeYqAOrqpjNt2ttzx3gkOXS9fHV1M5gz5/Ps3/9zN62KE0/8VCjf1Klvy01OGmTy5D9j/Pj57jW+j82bPx04VzgE2qvTtGlvc/fX5up0/PHvz+Wrr3ca7yTGjJnDmDFz3GueEbhmcY+fTWfn1tB8hVGOP/4DZLMtuQlZvbT9+3/GoUO/dcurApRjjnkL06d/MK+MxsYLaG39EyeeeDPHHvsutm//j7w8kya9Pvfbn1TV15zjNK9p097FccddRxSvw+I9z3HjzmXcuHNpavoahw/7cz6OHXsG06a9g5aWP7Jjxx2I1DB+/HmMH38er7zy/+joWEOST/Skk/6NhoaoBuSd3883ffrf0NkZFhyzZ9/CccddG0qL61R4z8enimOPXRJzRn+Qcn39TOrr3xXaW1s7lYaGuTHH+Rx//PupqZniaonOHN+Nja8OCa/jjns/xxzjTFpbVTWWWbOcd7i5+f8KzlmYyTRw0kn/BkBT03/S3v5CQs4+qqrGMH369QBMnnxZyA/W0DCPY499D7t2/Q+HDv2a2trjaWg4m87OTVRVNTBz5t/nhFe0EwswceJFTJx4Ud5ZvWcO5IRXJlPPiSd+PPGaRgLm8xpkSgmXh+hL6tm2vbSw5hV/vrSaVybhd7Q+8SaG6Gq6YX9RdPxOVSRvXWz6QPF8J3HLrPjnrs67F8Hla9yS3CCDYr6sdD664DyG/jGSS/PzxZcTXMYkWu+4+sQNOfDTkt6P5GeRP0g52hEqPJ2Xnxb2bSWdM+0g5Tg8rT++TrUFt/16FTarBY8rHGmqRN+N4Dvgd+K8zklt6FkHn2/4WZXejBcbsD0SMOE1yBT7EKIEXzJ/MGJdbrv4S1jY5+Vv50+EGkdSA5KvXQXPFd0XLt8/NtnG3x+8xrGQ5hWcHNdNcRuKsG/Rj5JMJjgwtDDBgA3vPF4PXGLyhfGff/winfn1yR/E6mt8+cMnoulR8t+dqBCNm84rjfBKOme6Qcpx+BGIxesUV8fC9XII3vdC36MjhPPfDX9BUC9gxf8ffNbB9yr8rErv9JnwMkqm1N5j8IPyBIz/QmeKvoRJQim/wQl+AMmvRVIDkt9wBjWvaCMVLt8/tvh8fKXgnTduHJJfl2qiWqKz9Hw4qlO1r2gPN73m5Q9I9qM+8689eR0wr2ce1YDin0FcNFo5Na9iwiyubk5aWs0r3SDlOHzhVbxOSd9SsfOGv9FC36PGPtOgsAqWERZe0XseH1mYFhNeRsmUrnnl27b7bzaM77kFy3b2FRJe8R9ytB7hXn4xs6E3v115hVe4UUnSGKOaV/7AaE/zKi6UvGNKjzaMX2E6SXh5nZio0IiaDcPaVZzmnRSNWsiEW8xMGPeOx5nTimnkHoUHKRfGW0suvk5R4ZVkNiymeQXNhqVrXlHhFfwf9W/6dYq+n6XR3+V+hhMmvAaZ0n1ewQZYQmlpNK/kBjDa4KTzeUWndoqrZ7T8/H1JZsPKaF5QKOw73+flpQdKCkxrlUz+gOMk4nxe3rX7ptPkcuInLE5+BvmDvQv5weLKji/X2y6ueZXHbNgfn1d9gTpFhX2pmlfYEuL8Luzzip/2zetIFPZ5JdfJNC9jECi19xj/0fsBDsXNhknrhSUHbBT37RQ3wYQjG+OjDaP747WP/hMWXkmzRUQ1L+/YcM/W6TUXvi/+McU0Lz+yMGo2DM5WnvQc4qYDcs5f2OcVfsbesUk+0UJmw8LCKi6oJ5OJe2eiM2pUQvOK9w8G9yVteyQJL98kmdZsGK95eWmFzIb52q75vComvESkXkSeEZEXRGSNiNwS2Pf3IrLeTf9yIP1mEdno7rs8kL5ARF50990hbossInUi8kM3fZmIzA4cc52IbHD/8uONh4iBaF5+GaVoXkn1kMh2sBFLax4LpsVHukHxRqpSZsPgeQst71FM83LuTXqfV9oZNsIzjcRde1I5+dMBOdtJPq9wRGN4Xzl8XtF3Kd07ntbn5Q9S7o/mFe8fdPaVR3ilNxvmRxvGnT/ObJj/zQxM8xoNZsNKjvPqAl6vqm3itHZ/EJFHgTHAVcA8Ve0SkWkAIjIXWAKcBUwHnhCR09Tpjn8TuB54GngEuAJ4FPgAcFBVTxGRJcCXgHeKyGTgs8BCHDvMChF5SFXDq7oNAaWOZo8zQ/hpxX1eJZwp4Xc+pWpe+YJtOJkNa2KfSVhAe5pXeXxefkMkuXsRp3UmB2wkaV7xfkdfWOb7PMOdjP5FG5a63z9fOrOh16npz0wQXl3itcHoO1uaz8vzp4U12kJNal+iJSRYn6AGlhSJG7UMlIppXgVQB29qgxr3T4EPA19Udy0OVfXmP7oKeEBVu1R1C7ARWCQixwONqvqUOl2X+4CrA8fc6/7+EfAGVyu7HHhcVZtdgfU4jsAbcgYSbehRms8r7XnSBWw450/TECT34pOEV2U1r/77vJz7kd7nVVzIBc14Xt58n1eyvzLe55Vkzqu05lXqfo/0mlf/fV6FFjTNDzLqr9kweF8LPfvCmpcfnOEP2k/q2JnPq8I+LxGpEpGVwF4cYbIMOA14nWvm+52IvMrNPgPYHji8yU2b4f6OpoeOUWd+nxZgSoGyovW7XkSWi8jy3t50y30PlNKjDZOd3+nGeaU+U+B3eX1e+Y1SUqh8uX1efp0KzZAebwbN17zKNc4rHCrv/PYFd3Gfl282TB6rF66Pr+nlSshE90XLS+/zKnW/n6/QcI3+lxsm/l5B+cyG4VWVk68hKdowen6/HpL71qOa+UB9XoV9cyODSpoNcU1+80VkIvBTETnbPeckYDHwKuBBETmJ+KeqBdLp5zHB+t0N3A3Q0NBQ3hGyCfSn9xilEmbDSvq8osIqXxMrr8/La0zSBWxEx3R56fk+r/Tm1GJ9wuBUUFHNKy5f9DzxPq/8+xyNNsw3b5Uj2rDU/X6+pPoOrNy4c6TrcJVmNvSEV9z54omPNozWJy56MfptDHyGjZHv8xqUaENVPQQsxTHdNQE/cc2Kz+B8tce46ScEDpsJ7HTTZ8akEzxGnKc5AWguUNaQ07/eY5hKmw3L4fMK2+STg0PCxw6+2dCpT5zwCj+ndIOU0/q81M3vB2z4Pes0ofJJARtJmlec2bD/0YbFfE/p3/Ho9Q2u5hXVPuKsHE6+JOE1zt0ffN7J70gxzSs6w0b4d5zwyo8iTYuZDQsgIlNdjQsRGQO8EVgH/Ax4vZt+GlAL7AceApa4EYRzgFOBZ1R1F3BYRBa7/qxrgZ+7p3kI8CIJ3wb8xvWLPQZcJiKTRGQScJmbNuSUQ/PyP7pM0QY1Pel9XmlMMIWvM8lsWF7SaF5JBOuv2lvS3IbF7p/fi/Y1r7hQ+WKaV74Qiddk4gRRcc2r8j6vUqMUy695pdM+igds5J8vnmKaV9jn5fyO9wc7QzzSjivMx8yGhTkeuFf8ZXMfVNWHxXky94jIaqAbuM4VOGtE5EHgJaAXuEH97uiHge/iRCo+6v4BfAe4X0Q24mhcSwBUtVlEbgWedfN9XlWbK3itqSmv5lW+iWzTzm3o7E8z4LOQ2SnebFhu0gqvOHNlUDA47tTiPq+047z8AAQJ3Pe46aGK+byKaV5R4ZU2YEMKNojFJ6rt3zteWZ9XcWtB8nlLMRsWuoZSfV5BARvs8PThBRo5cW/9Gec18s2GFRNeqroKOC8mvRu4Jv8IUNXbgNti0pfjrWMQTu8E3p5Q1j3APaXVuvKUQ+AEfV7lI93chpBW80puaJLNhuUlWG7hVaJ9Z7inDYQ1r54iofKethQVEvFu1EKaV5rJif37F32Xop2CZLOh36jHmQ0L16E8GlImRpsovdNUjELj6NJqH6UIr8Jmw3h3vP/OxQVshKcPE/Hm2XSGePT19dfnNfI1L5thY5ApPuN4mjJ8n1e5KCVUPo2PaPiZDZOFV7AR9cx2UbNhmkHKHsXz9eXy+XnjIi2ThEgmdn8xzSv8jPOFdHpz38CFlx8EU95y84l2DgJ7Umte8R2x4IKQft5Czz7+HfIDjHyh5e6JEb6+JunX6+g0G5rwGoH4L3k5H19+wEbY/xI8f5zzO+q/SK95VepDSm82jBsg7Ne/r6+Y5pV3dOR/3hlz+/2AjfzGNSn6MtnUGO0UFNK8POEVvxhlIcoTKq8x4d9pzbLpKWSWTe/zSlqaxlu1oLif0snXQ2GzYVx9vG/R07x8f6evWZvmZYwQfMfu8NG8SsmTbzaslM8raDYsFLARZ1KKal7FByn7x5YesBE/SDmJeG0iOfQ83+flnzd5mZwkyqEhOUEw0ftefrNhIc1roGbD+AjG5Gvo6+ukUJMbV5/8cYBBzSuuU5KOcgSODTUmvEYgSRFIAysz+NHlTycUJEkjC5dXqJdcWbOhbxLzhWJas6F/bDhgo/AgZe+YYhqXR77ZMN7nFX+fk6aUytdoC00PFbdy82BqXlC62bA/g3GTp98aqNkwflB6cpPa19cZ+01FV4sIau5Rs6H/LP1ow/5MaF0O98VQY8JrBOJPp9RTzlJzv9L6bAoxHKINg+epqhpbIGcxn1cPaQYp+xTTvDSQL2wWSqpXkLRmw0LTQ8UHDgye5gVxmmP5omf9MguZDdMKr6TZ/T3hkWZsXu6seSn+8dFAH386KX9mfT/Qxg/mKGc7UBlE5Ap3wvWNInJTzP73iMgq9+9PInJusTJNeI1A/FH35ZvSKm3v0TlvceFVyD+RL7wq0wsMR9IVWyQweqxf/0OHfuOmpTUblqJ5JUfDJWu4ac2GydNDeb/DWmfaCXWLaV5pTVKVF16FzYb9m8aqcHqxd6S0dz1f+Pr+aF94Ds7Udv3FHS51J3AlMBd4lzsRe5AtwMWqOg+4FXfmo0KMfMPnCGTWrM8wbtz81PnPOOM+enr25rYnTLiYCRNey3HHvR+AU0+9s+CHf9JJX6KuLm9qR04//ds0N/+K2tppofRijfT06deze3cNNTXHIlLNuHHz8vJEP+xZsz5Le/tqenr2MGHCRXn5Z878J6ZM+fOC503L2Wc/xI4d/0ld3axcWlXVWGbO/BidnVvp7NxMW9vzuX0zZtxAW9vziFRxwgkfA2DChNcwYcJFtLQ8GSg5/r6cccY9bN16C+PHLyqYz2Pq1Leyf/9DzJnz/6itncrUqe9kzpwvAFGBFS+8Tj75dkA55pi/DKVPn/4hdu++n46ONU4tcgsxJguv4Dnyl65JIsP06R9m2rR351JOO+1uDh58gpqaqYnC+5xzHmHDho/Q2bkZgDlzvkBn5zYOHfq1W8/45mjevF/R3Pxo7L4kTjvtLlSzHHPMW8hmW5k2bUleHhFhxoy/p6dnHxMnXppY1vTpH6S19RlEMsyc+VGef/61AEyadCnTpr2b2bM/l8s7c+ZHaW9fzcyZ/8DKlRfHnDP/3TjnnJ/T1PR16utPBGDKlL9g6tR3cPLJt1NbexzTpr2H2bM/496Lx9i167+pqZnMWWf9kG3bvsTYsWemvi9nn/0LDh9eljp/mVgEbFTVzQAi8gDOpOoveRlU9U+B/E8TnlUpFknjvzgaaGho0Pb29qGuxrCgq2sHTz01k0ymnosuOtKvMjo7t/H0047wuOSSoXnHjhzZxLJlpwDwutd1UFU1BoBstoPf/74hVd1eeOEKDh50JmeZM+c2Zs3656Ln3bfvZ6xZ8xYaGy/g/PP/WFKdn3pqFl1d2wA4+eSvcMIJN5Z0fEfHBp555jQALrqok0ymjoMHf80LL7yR8eMXsmCBM25/06ZPsH377Zx00pc48cRPAnDgwC958UWnA1GpZ3bgwCO8+OKbc+fo6+vhyScdS8KiResYO/b0ipy3nCxd6gjnxYu3UV9/QmK+Xbu+y/r17w+lzZx5I6ec8pWK1m+wEZFu4MVA0t3uvLHe/rcBV6jq37jb7wVeraofSSjv48AZXv4kTPMyYhi4NXl4RDMFw8B9raIU85QTIZYrJdUx5YsCLV2AhEPf/RW33ZRAzvyxYqVOodUfooEzYRNkJcyGlaM/vr9yRggPI3pVdWGB/akmSgcQkUtx1ml8bbGTDocWxhhmlOMDK8c0WAOvQ3AAbv7USGno6/M1z/T3ZSA+PP+b7o9VpPAM+XE+r8EVXoWGLAyPDk96+jdN1siP8usHqSZKF5F5wLeBK1X1QLFCR2U3wBgoo0PzKjY3YBqCwmtwNK/iPq/C546bhNeLUMsPlQ+eo/AUWuWh0JCFygRsVI7+RV0elU3us8CpIjLHndt2Cc6k6jlE5ETgJ8B7VfXlNIUOfQtjDDvK0YgMD80rKcQ5fe83rHmlvS/l6l33x+8UV8e45e+8334U3uCYDQtpXiNLePVnaZjRML6qVFS1V0Q+grOyRxVwj6quEZEPufvvAj6Ds5DwN9x7VMwUacLLiGO0aF4Dr0M22x+zYf/vX9CM159B6HHXnD+OyP8dNhtWXvMaXWZD07zSoqqPAI9E0u4K/P4boGCARpSj804aBSmHz6u/y2KUk3L05PtnNhw6zSv+mgtpXsFQ+crPd1foHCNN8yo+04gnvILvzdGneVUKE15GDOV4LYb+1SpHTz4YbTgYmtfAfV5x1+zNGlLY5zXUJq2Rp3kVG8zvzJoSNJWO0mjDIcHupJFHeaINh0MPs9ya12D4vMofsJFW8xp6RpbmVQzv3QkHwgyH72J0YMLLiGF0fGDlMUOVMm9dafmKnrlfofL515zW5zXUjDSzYTGy2Q7ANK9KYXfSyMNrRMaNO3/AZdXWHj/gMvqLfx15C3oDkMkUmqzXYezY4BRsgzHOy6eurugMOflndk1v48f7gVo1NZMBaGjwr6W+frb7P3mGiMGisXExMHLMhrW1x6XKV1MzBYBx44JzzI6OjuFwYGS8LcagksnUct55f2Ds2LMGVM755z+Tm69tKBDJcN55f4yd+23BghWpBOv8+b/jT3+amisv7Xn7j6MJzZr1GY477rqSjxapcp+dL6jGjZvHvHmPM3Hi63Jpxx33Pmprj2Py5CtCxy9atJ5KN7DOOXzOOedR2ttXD4sgnzQsXLiSzs5tRfNNnnwF55zzCPX1s9m79wduqukL5cKElxHLhAkXDriMxsZXlaEmA2PChAti08ePT6dV1tYeQ0PDObS3v8hgaF6eGW/KlDf3228Y9+wmT35jaFtEmDLlyrx8Y8ee1q9zlkL0HDU1E5k4sehsQMOG2tpjqa09tmg+7x4fObI5lGaUh4p1A0SkXkSeEZEXRGSNiNzipn9ORHaIyEr3702BY25213tZLyKXB9IXiMiL7r47xH0DRKRORH7opi8TkdmBY64TkQ3uX+ldWMNw8RcATOuTGR3RmkZ5CIfU23MtF5XUvLqA16tqmzhP7w8i4q1r8FVVvT2Y2V3fZQlwFjAdeEJETlMn3vSbwPU4U+U/AlwBPIozgeNBVT1FRJYAXwLeKSKTgc8CC3HsMCtE5CFVPVjB6zVGLd70SoM3zmu0BS8czYR9eaZ5lYuKdQPUoc3drHH/CoU2XQU8oKpdqroF2AgsEpHjgUZVfUodm8p9wNWBY+51f/8IeIOrlV0OPK6qza7AehxH4BlGyfiCZDB6zd6YLOuhjxaCmpc91/JR0TspIlUishLYiyNMvFXQPuIu93yPiExy02YA2wOHN7lpM9zf0fTQMeosJ9qCMz9WUlnR+l0vIstFZHlv7/BejdQYSkrTvAaG17+zRm60YJpXZajoF6KqWVWdjzMF/iIRORvHBHgyMB/YBXgrsyWt+VJoLZj+HBOs392qulBVF1ZXW+yKEY8vtAbPlGc99NFDMIrSnmv5GJQ7qaqHgKU4q2nucYVaH/AtnCWiIXnNlybCS0IH14LJHSNO92YC0FygLMPoB0OheZnPa7RgmldlqGS04VQRmej+HgO8EVjn+rA83gKsdn8/BCxxIwjnAKcCz6jqLuCwiCx2/VnXAj8PHONFEr4N+I3rF3sMuExEJrlmycvcNMMomcH1eXnntB76aMGiDStDJW1lxwP3ivPlZ4AHVfVhEblfRObjdDG3Ah8EcNd3eRB4CegFblBvZkv4MPBdYAxOlKEXtfgd4H4R2YijcS1xy2oWkVtxFkED+LyqNlfwWo1RjL+YY+UbHn+6JmvkRgvB98bGeZWPigkvVV0F5M3Lo6rvLXDMbcBtMenLgbNj0juBtyeUdQ9wTwlVNowEPOE1GKY8izYc3dhzLRd2Jw2jCL4gGUyzofm8RiemeZULE16GUZShECT2aY5GTKMuH3YnDaMIfoMzGMuHmNlwdGOaV7mwL8QwiuJ8Js7ojkpjARujGeuUlA+7k4ZRBL/ByRbMV95zms9rdOG9Q6Z5lQsTXoZRBE+QDI7m5WGf5mhiKMYKjnbsThpGUZzesj/ssHJ447zMvDTa8IZbmOZVLuwLMYyieJ+J+byM/mGaV/mxO2kYRRgKs6FpXqMLX3iZ5lUu7AsxjCL4gmQwNS9r5EYT/mrc1uSWC7uThlGUoQjYMOE1ujDNq9yY8DKMIlRVjQVK6TU7DVUmU9+PczWUfIwx/PHeIRNe5cNWYDSMIpx00peprp7E1Kmxc0Dn0di4iFmz/pXp0z9U8rnmz1/K/v0/p7p6XMnHGsOXk076Ms3Nv2TSpEuHuiqjBvGXYDi6aWho0Pb29qGuhmEYxohCRDpUddBNBmY2NAzDMEYcJrwMwzCMEYcJL8MwDGPEYcLLMAzDGHGY8DIMwzBGHCa8DMMwjIoiIleIyHoR2SgiN8XsFxG5w92/SkTOL1amCS/DMAyjYogzN9adwJXAXOBdIjI3ku1K4FT373rgm8XKNeFlGIZhVJJFwEZV3ayq3cADwFWRPFcB96nD08BEETm+UKE2w4ZLR0eHisiRARRRDfSWqz4jBLvmowO75qOD/l7zGBFZHti+W1XvDmzPALYHtpuAV0fKiMszA9hVqLIGoKoD0kJFZLmqLixXfUYCds1HB3bNRwcVvOa4CR2jUzulyRPCzIaGYRhGJWkCTghszwR29iNPCBNehmEYRiV5FjhVROaISC2wBHgokuch4Fo36nAx0KKqiSZDMLNhObm7eJZRh13z0YFd89FBRa5ZVXtF5CPAYzjrBd2jqmtE5EPu/ruAR4A3ARuBDuD9xcq1WeUNwzCMEYeZDQ3DMIwRhwkvwzAMY8RhwmuAFJv2ZKQiIveIyF4RWR1Imywij4vIBvf/pMC+m917sF5ELh+aWg8METlBRH4rImtFZI2IfNRNH7XXLSL1IvKMiLzgXvMtbvqovWYPEakSkedF5GF3e1Rfs4hsFZEXRWSlNy5rRF+zqtpfP/9wnI+bgJOAWuAFYO5Q16tM13YRcD6wOpD2ZeAm9/dNwJfc33Pda68D5rj3pGqor6Ef13w8cL77ezzwsntto/a6ccbXjHN/1wDLgMWj+ZoD134j8P8BD7vbo/qaga3AMZG0EXvNpnkNjDTTnoxIVPVJoDmSfBVwr/v7XuDqQPoDqtqlqltwIoYWDUY9y4mq7lLV59zfh4G1OKP8R+11q0Obu1nj/imj+JoBRGQm8Gbg24HkUX3NCYzYazbhNTCSpjQZrRyr7tgL9/80N33U3QcRmQ2ch6OJjOrrds1nK4G9wOOqOuqvGfga8EmgL5A22q9ZgV+JyAoRud5NG7HXbOO8BkbJU5qMUkbVfRCRccCPgX9U1VaRuMtzssakjbjrVtUsMF9EJgI/FZGzC2Qf8dcsIn8O7FXVFSJySZpDYtJG1DW7XKiqO0VkGvC4iKwrkHfYX7NpXgOj5ClNRjh7vJme3f973fRRcx9EpAZHcH1fVX/iJo/66wZQ1UPAUuAKRvc1Xwj8pYhsxTH1v15EvsfovmZUdaf7fy/wUxwz4Ii9ZhNeAyPNtCejiYeA69zf1wE/D6QvEZE6EZmDsybPM0NQvwEhjor1HWCtqv5HYNeovW4RmepqXIjIGOCNwDpG8TWr6s2qOlNVZ+N8s79R1WsYxdcsIg0iMt77DVwGrGYkX/NQR4yM9D+cKU1exonG+fRQ16eM1/UDnOUIenB6YR8ApgC/Bja4/ycH8n/avQfrgSuHuv79vObX4phGVgEr3b83jebrBuYBz7vXvBr4jJs+aq85cv2X4EcbjtprxomIfsH9W+O1VSP5mm16KMMwDGPEYWZDwzAMY8RhwsswDMMYcZjwMgzDMEYcJrwMwzCMEYcJL8MwDGPEYcLLMEYBInKJNzu6YRwNmPAyDMMwRhwmvAxjEBGRa9z1s1aKyH+7k+K2ichXROQ5Efm1iEx1884XkadFZJWI/NRba0lEThGRJ9w1uJ4TkZPd4seJyI9EZJ2IfF8KTMpoGCMdE16GMUiIyJnAO3EmSJ0PZIH3AA3Ac6p6PvA74LPuIfcBn1LVecCLgfTvA3eq6rnABTgzoYAzC/4/4qzFdBLOHH6GMSqxWeUNY/B4A7AAeNZVisbgTITaB/zQzfM94CciMgGYqKq/c9PvBf7XnZ9uhqr+FEBVOwHc8p5R1SZ3eyUwG/hDxa/KMIYAE16GMXgIcK+q3hxKFPnXSL5Cc7YVMgV2BX5nse/bGMWY2dAwBo9fA29z11NCRCaLyCyc7/Btbp53A39Q1RbgoIi8zk1/L/A7VW0FmkTkareMOhEZO5gXYRjDAeuZGcYgoaovici/4Kxmm8GZsf8GoB04S0RWAC04fjFwlqi4yxVOm4H3u+nvBf5bRD7vlvH2QbwMwxgW2KzyhjHEiEibqo4b6noYxkjCzIaGYRjGiMM0L8MwDGPEYZqXYRiGMeIw4WUYhmGMOEx4GYZhGCMOE16GYRjGiMOEl2EYhjHi+P8BBBMAMcoVPZgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display acc, loss\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "\n",
    "# acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "# acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "# acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 41ms/step - loss: 8681083904.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8681083904.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Test the model###\n",
    "\n",
    "vae.evaluate(np.array(X_test).transpose([0,1,2,3]), np.array(X_test).transpose([0,1,2,3]), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc(enco, bi_class, num_classes):\n",
    "\n",
    "    den = Dense(16, activation='sigmoid')(enco)\n",
    "#     den = BatchNormalization()(den)\n",
    "#     den = tf.keras.layers.LeakyReLU()(den)\n",
    "    if bi_class == 0:\n",
    "        den = Dense(num_classes, activation='softmax')(den)\n",
    "    else:\n",
    "        den = Dense(2, activation='softmax')(den)\n",
    "#     den = BatchNormalization()(den)\n",
    "#     den = tf.keras.layers.LeakyReLU()(den)\n",
    "#     den = Dense(7)(den)\n",
    "#     den = BatchNormalization()(den)\n",
    "#     out = tf.keras.activations.softmax(den)\n",
    "    \n",
    "    return den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Classification_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 276, 50, 31)]     0         \n",
      "_________________________________________________________________\n",
      "encoder_model (Functional)   (None, 31)                1069119   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                512       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 119       \n",
      "=================================================================\n",
      "Total params: 1,069,750\n",
      "Trainable params: 631\n",
      "Non-trainable params: 1,069,119\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encode = encoder(feature_input)\n",
    "full_model = Model(feature_input,fc(encode, bi_class, num_classes), name=\"Classification_model\")\n",
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x1c1f3ad6dc0>,\n",
       " <tensorflow.python.keras.layers.core.Reshape at 0x1c1f3abd0d0>,\n",
       " <tensorflow.python.keras.layers.recurrent_v2.GRU at 0x1c1f3ad6d30>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1c1f3abd550>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv1D at 0x1c1fb5b20d0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1c1fd3ed9a0>,\n",
       " <tensorflow.python.keras.layers.advanced_activations.LeakyReLU at 0x1c1fbbecca0>,\n",
       " <tensorflow.python.keras.layers.pooling.GlobalAveragePooling1D at 0x1c1ff931070>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1c1ff92bf10>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1c1ff95d520>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1c1ff92be80>,\n",
       " <tensorflow.python.keras.layers.core.Lambda at 0x1c1ff96ba90>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x1c1f3ad6dc0>,\n",
       " <tensorflow.python.keras.layers.core.Reshape at 0x1c1f3abd0d0>,\n",
       " <tensorflow.python.keras.layers.recurrent_v2.GRU at 0x1c1f3ad6d30>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1c1f3abd550>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv1D at 0x1c1fb5b20d0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1c1fd3ed9a0>,\n",
       " <tensorflow.python.keras.layers.advanced_activations.LeakyReLU at 0x1c1fbbecca0>,\n",
       " <tensorflow.python.keras.layers.pooling.GlobalAveragePooling1D at 0x1c1ff931070>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1c1ff92bf10>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1c1ff95d520>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1c1ff92be80>,\n",
       " <tensorflow.python.keras.layers.core.Lambda at 0x1c1ff96ba90>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model.layers[1].layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l1,l2 in zip(full_model.layers[1].layers[:], encoder.layers[:]):\n",
    "    l1.set_weights(l2.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in full_model.layers[0:2]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "17/17 [==============================] - 2s 108ms/step - loss: 1.9682 - categorical_accuracy: 0.1381 - auc_1: 0.4682 - f1_score: 0.1017 - val_loss: 2.9980 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1713 - val_f1_score: 0.0162\n",
      "Epoch 2/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.8622 - categorical_accuracy: 0.1915 - auc_1: 0.5267 - f1_score: 0.1216 - val_loss: 2.9825 - val_categorical_accuracy: 0.0000e+00 - val_auc_1: 0.1713 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.8157 - categorical_accuracy: 0.2376 - auc_1: 0.5581 - f1_score: 0.1506 - val_loss: 3.5672 - val_categorical_accuracy: 0.0000e+00 - val_auc_1: 0.1681 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.8082 - categorical_accuracy: 0.1823 - auc_1: 0.5478 - f1_score: 0.1310 - val_loss: 3.1591 - val_categorical_accuracy: 0.0000e+00 - val_auc_1: 0.1735 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.8024 - categorical_accuracy: 0.2320 - auc_1: 0.5640 - f1_score: 0.1366 - val_loss: 3.1478 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1829 - val_f1_score: 0.0162\n",
      "Epoch 6/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7995 - categorical_accuracy: 0.1952 - auc_1: 0.5694 - f1_score: 0.1492 - val_loss: 3.2914 - val_categorical_accuracy: 0.0000e+00 - val_auc_1: 0.1805 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.8027 - categorical_accuracy: 0.2339 - auc_1: 0.5542 - f1_score: 0.1558 - val_loss: 2.9998 - val_categorical_accuracy: 0.0000e+00 - val_auc_1: 0.1932 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7892 - categorical_accuracy: 0.2376 - auc_1: 0.5732 - f1_score: 0.1543 - val_loss: 3.2113 - val_categorical_accuracy: 0.0000e+00 - val_auc_1: 0.2000 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7820 - categorical_accuracy: 0.2468 - auc_1: 0.5725 - f1_score: 0.1585 - val_loss: 3.2223 - val_categorical_accuracy: 0.0074 - val_auc_1: 0.1951 - val_f1_score: 0.0056\n",
      "Epoch 10/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7718 - categorical_accuracy: 0.2302 - auc_1: 0.6045 - f1_score: 0.1601 - val_loss: 3.2094 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1932 - val_f1_score: 0.0162\n",
      "Epoch 11/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7813 - categorical_accuracy: 0.2173 - auc_1: 0.5782 - f1_score: 0.1602 - val_loss: 3.0553 - val_categorical_accuracy: 0.0074 - val_auc_1: 0.1928 - val_f1_score: 0.0056\n",
      "Epoch 12/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7684 - categorical_accuracy: 0.2505 - auc_1: 0.5813 - f1_score: 0.1675 - val_loss: 3.3711 - val_categorical_accuracy: 0.0147 - val_auc_1: 0.1902 - val_f1_score: 0.0110\n",
      "Epoch 13/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7629 - categorical_accuracy: 0.2449 - auc_1: 0.6047 - f1_score: 0.1591 - val_loss: 2.9352 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1879 - val_f1_score: 0.0162\n",
      "Epoch 14/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7570 - categorical_accuracy: 0.2357 - auc_1: 0.6135 - f1_score: 0.1519 - val_loss: 3.3620 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1868 - val_f1_score: 0.0162\n",
      "Epoch 15/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7578 - categorical_accuracy: 0.2339 - auc_1: 0.6067 - f1_score: 0.1599 - val_loss: 3.1515 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1855 - val_f1_score: 0.0162\n",
      "Epoch 16/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7632 - categorical_accuracy: 0.2468 - auc_1: 0.5979 - f1_score: 0.1695 - val_loss: 3.1716 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1911 - val_f1_score: 0.0162\n",
      "Epoch 17/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7501 - categorical_accuracy: 0.2413 - auc_1: 0.6192 - f1_score: 0.1569 - val_loss: 3.2974 - val_categorical_accuracy: 0.0000e+00 - val_auc_1: 0.1883 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7434 - categorical_accuracy: 0.2597 - auc_1: 0.6226 - f1_score: 0.1767 - val_loss: 3.1330 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1809 - val_f1_score: 0.0162\n",
      "Epoch 19/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7488 - categorical_accuracy: 0.2541 - auc_1: 0.6041 - f1_score: 0.1777 - val_loss: 3.2634 - val_categorical_accuracy: 0.0074 - val_auc_1: 0.1851 - val_f1_score: 0.0056\n",
      "Epoch 20/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7483 - categorical_accuracy: 0.2376 - auc_1: 0.6142 - f1_score: 0.1517 - val_loss: 3.2358 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1906 - val_f1_score: 0.0162\n",
      "Epoch 21/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7491 - categorical_accuracy: 0.2449 - auc_1: 0.5985 - f1_score: 0.1727 - val_loss: 3.3664 - val_categorical_accuracy: 0.0000e+00 - val_auc_1: 0.1821 - val_f1_score: 0.0000e+00\n",
      "Epoch 22/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7470 - categorical_accuracy: 0.2597 - auc_1: 0.6146 - f1_score: 0.1739 - val_loss: 3.2068 - val_categorical_accuracy: 0.0000e+00 - val_auc_1: 0.1803 - val_f1_score: 0.0000e+00\n",
      "Epoch 23/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7467 - categorical_accuracy: 0.2431 - auc_1: 0.5991 - f1_score: 0.1564 - val_loss: 3.2470 - val_categorical_accuracy: 0.0074 - val_auc_1: 0.1830 - val_f1_score: 0.0056\n",
      "Epoch 24/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7436 - categorical_accuracy: 0.2541 - auc_1: 0.6035 - f1_score: 0.1683 - val_loss: 3.1778 - val_categorical_accuracy: 0.0147 - val_auc_1: 0.1887 - val_f1_score: 0.0110\n",
      "Epoch 25/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7496 - categorical_accuracy: 0.2541 - auc_1: 0.6172 - f1_score: 0.1720 - val_loss: 3.0818 - val_categorical_accuracy: 0.0000e+00 - val_auc_1: 0.1811 - val_f1_score: 0.0000e+00\n",
      "Epoch 26/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7472 - categorical_accuracy: 0.2486 - auc_1: 0.6084 - f1_score: 0.1563 - val_loss: 3.3577 - val_categorical_accuracy: 0.0000e+00 - val_auc_1: 0.1866 - val_f1_score: 0.0000e+00\n",
      "Epoch 27/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7488 - categorical_accuracy: 0.2394 - auc_1: 0.5993 - f1_score: 0.1632 - val_loss: 3.1137 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1832 - val_f1_score: 0.0162\n",
      "Epoch 28/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7453 - categorical_accuracy: 0.2449 - auc_1: 0.6159 - f1_score: 0.1612 - val_loss: 3.3350 - val_categorical_accuracy: 0.0000e+00 - val_auc_1: 0.1794 - val_f1_score: 0.0000e+00\n",
      "Epoch 29/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7448 - categorical_accuracy: 0.2486 - auc_1: 0.6039 - f1_score: 0.1515 - val_loss: 3.1863 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1855 - val_f1_score: 0.0162\n",
      "Epoch 30/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7262 - categorical_accuracy: 0.2357 - auc_1: 0.6236 - f1_score: 0.1659 - val_loss: 3.1556 - val_categorical_accuracy: 0.0000e+00 - val_auc_1: 0.1853 - val_f1_score: 0.0000e+00\n",
      "Epoch 31/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7447 - categorical_accuracy: 0.2597 - auc_1: 0.6045 - f1_score: 0.1633 - val_loss: 3.1414 - val_categorical_accuracy: 0.0147 - val_auc_1: 0.1833 - val_f1_score: 0.0110\n",
      "Epoch 32/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7433 - categorical_accuracy: 0.2376 - auc_1: 0.6010 - f1_score: 0.1707 - val_loss: 3.3802 - val_categorical_accuracy: 0.0147 - val_auc_1: 0.1882 - val_f1_score: 0.0110\n",
      "Epoch 33/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7393 - categorical_accuracy: 0.2578 - auc_1: 0.6115 - f1_score: 0.1647 - val_loss: 3.2600 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1843 - val_f1_score: 0.0162\n",
      "Epoch 34/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7332 - categorical_accuracy: 0.2357 - auc_1: 0.6097 - f1_score: 0.1605 - val_loss: 3.2546 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1848 - val_f1_score: 0.0162\n",
      "Epoch 35/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7524 - categorical_accuracy: 0.2652 - auc_1: 0.6006 - f1_score: 0.1772 - val_loss: 2.9885 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1810 - val_f1_score: 0.0162\n",
      "Epoch 36/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7390 - categorical_accuracy: 0.2376 - auc_1: 0.6208 - f1_score: 0.1756 - val_loss: 3.3641 - val_categorical_accuracy: 0.0147 - val_auc_1: 0.1842 - val_f1_score: 0.0110\n",
      "Epoch 37/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7342 - categorical_accuracy: 0.2486 - auc_1: 0.6282 - f1_score: 0.1625 - val_loss: 3.2795 - val_categorical_accuracy: 0.0147 - val_auc_1: 0.1907 - val_f1_score: 0.0110\n",
      "Epoch 38/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7369 - categorical_accuracy: 0.2523 - auc_1: 0.6236 - f1_score: 0.1839 - val_loss: 3.1006 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1812 - val_f1_score: 0.0162\n",
      "Epoch 39/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7420 - categorical_accuracy: 0.2670 - auc_1: 0.6068 - f1_score: 0.1804 - val_loss: 3.3220 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1868 - val_f1_score: 0.0162\n",
      "Epoch 40/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7383 - categorical_accuracy: 0.2468 - auc_1: 0.6150 - f1_score: 0.1610 - val_loss: 3.3411 - val_categorical_accuracy: 0.0147 - val_auc_1: 0.1810 - val_f1_score: 0.0110\n",
      "Epoch 41/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7307 - categorical_accuracy: 0.2707 - auc_1: 0.6143 - f1_score: 0.1939 - val_loss: 3.3623 - val_categorical_accuracy: 0.0147 - val_auc_1: 0.1828 - val_f1_score: 0.0110\n",
      "Epoch 42/500\n",
      "17/17 [==============================] - 1s 73ms/step - loss: 1.7434 - categorical_accuracy: 0.2486 - auc_1: 0.6107 - f1_score: 0.1628 - val_loss: 3.1128 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1836 - val_f1_score: 0.0162\n",
      "Epoch 43/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7322 - categorical_accuracy: 0.2597 - auc_1: 0.6308 - f1_score: 0.1646 - val_loss: 3.2854 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1827 - val_f1_score: 0.0162\n",
      "Epoch 44/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7366 - categorical_accuracy: 0.2523 - auc_1: 0.6068 - f1_score: 0.1722 - val_loss: 3.4934 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1830 - val_f1_score: 0.0162\n",
      "Epoch 45/500\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 1.7222 - categorical_accuracy: 0.2689 - auc_1: 0.6333 - f1_score: 0.1717 - val_loss: 3.3151 - val_categorical_accuracy: 0.0074 - val_auc_1: 0.1852 - val_f1_score: 0.0056\n",
      "Epoch 46/500\n",
      "17/17 [==============================] - 1s 54ms/step - loss: 1.7367 - categorical_accuracy: 0.2339 - auc_1: 0.6115 - f1_score: 0.1537 - val_loss: 3.1910 - val_categorical_accuracy: 0.0147 - val_auc_1: 0.1807 - val_f1_score: 0.0110\n",
      "Epoch 47/500\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 1.7269 - categorical_accuracy: 0.2615 - auc_1: 0.6143 - f1_score: 0.1771 - val_loss: 3.2617 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1861 - val_f1_score: 0.0162\n",
      "Epoch 48/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7395 - categorical_accuracy: 0.2357 - auc_1: 0.6132 - f1_score: 0.1607 - val_loss: 3.2456 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1801 - val_f1_score: 0.0162\n",
      "Epoch 49/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7495 - categorical_accuracy: 0.2560 - auc_1: 0.6141 - f1_score: 0.1611 - val_loss: 3.6000 - val_categorical_accuracy: 0.0000e+00 - val_auc_1: 0.1800 - val_f1_score: 0.0000e+00\n",
      "Epoch 50/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7457 - categorical_accuracy: 0.2118 - auc_1: 0.6086 - f1_score: 0.1524 - val_loss: 3.1554 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1872 - val_f1_score: 0.0162\n",
      "Epoch 51/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7435 - categorical_accuracy: 0.2597 - auc_1: 0.6218 - f1_score: 0.1710 - val_loss: 3.2625 - val_categorical_accuracy: 0.0000e+00 - val_auc_1: 0.1868 - val_f1_score: 0.0000e+00\n",
      "Epoch 52/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7416 - categorical_accuracy: 0.2044 - auc_1: 0.6040 - f1_score: 0.1442 - val_loss: 3.4033 - val_categorical_accuracy: 0.0147 - val_auc_1: 0.1811 - val_f1_score: 0.0110\n",
      "Epoch 53/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7357 - categorical_accuracy: 0.2541 - auc_1: 0.6120 - f1_score: 0.1749 - val_loss: 3.3329 - val_categorical_accuracy: 0.0147 - val_auc_1: 0.1889 - val_f1_score: 0.0110\n",
      "Epoch 54/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7356 - categorical_accuracy: 0.2523 - auc_1: 0.6044 - f1_score: 0.1728 - val_loss: 3.2279 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1870 - val_f1_score: 0.0162\n",
      "Epoch 55/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7311 - categorical_accuracy: 0.2634 - auc_1: 0.6247 - f1_score: 0.1681 - val_loss: 3.2842 - val_categorical_accuracy: 0.0074 - val_auc_1: 0.1883 - val_f1_score: 0.0056\n",
      "Epoch 56/500\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 1.7460 - categorical_accuracy: 0.2413 - auc_1: 0.5972 - f1_score: 0.1633 - val_loss: 3.4679 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1870 - val_f1_score: 0.0162\n",
      "Epoch 57/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7365 - categorical_accuracy: 0.2505 - auc_1: 0.6232 - f1_score: 0.1581 - val_loss: 3.1459 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1876 - val_f1_score: 0.0162\n",
      "Epoch 58/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7298 - categorical_accuracy: 0.2726 - auc_1: 0.6174 - f1_score: 0.1770 - val_loss: 3.0786 - val_categorical_accuracy: 0.0074 - val_auc_1: 0.1812 - val_f1_score: 0.0056\n",
      "Epoch 59/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7247 - categorical_accuracy: 0.2578 - auc_1: 0.6244 - f1_score: 0.1774 - val_loss: 3.3107 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1803 - val_f1_score: 0.0162\n",
      "Epoch 60/500\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 1.7317 - categorical_accuracy: 0.2560 - auc_1: 0.6128 - f1_score: 0.1667 - val_loss: 3.3700 - val_categorical_accuracy: 0.0074 - val_auc_1: 0.1874 - val_f1_score: 0.0056\n",
      "Epoch 61/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7285 - categorical_accuracy: 0.2523 - auc_1: 0.6120 - f1_score: 0.1604 - val_loss: 3.1225 - val_categorical_accuracy: 0.0074 - val_auc_1: 0.1821 - val_f1_score: 0.0056\n",
      "Epoch 62/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7272 - categorical_accuracy: 0.2634 - auc_1: 0.6094 - f1_score: 0.1783 - val_loss: 3.2019 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1828 - val_f1_score: 0.0162\n",
      "Epoch 63/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7358 - categorical_accuracy: 0.2394 - auc_1: 0.6080 - f1_score: 0.1649 - val_loss: 3.2557 - val_categorical_accuracy: 0.0147 - val_auc_1: 0.1837 - val_f1_score: 0.0110\n",
      "Epoch 64/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7251 - categorical_accuracy: 0.2855 - auc_1: 0.6276 - f1_score: 0.1847 - val_loss: 3.1990 - val_categorical_accuracy: 0.0147 - val_auc_1: 0.1783 - val_f1_score: 0.0110\n",
      "Epoch 65/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7255 - categorical_accuracy: 0.2762 - auc_1: 0.6283 - f1_score: 0.1855 - val_loss: 3.1972 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1819 - val_f1_score: 0.0162\n",
      "Epoch 66/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7344 - categorical_accuracy: 0.2560 - auc_1: 0.6132 - f1_score: 0.1724 - val_loss: 3.3382 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1807 - val_f1_score: 0.0162\n",
      "Epoch 67/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7308 - categorical_accuracy: 0.2468 - auc_1: 0.6227 - f1_score: 0.1710 - val_loss: 3.1935 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1839 - val_f1_score: 0.0162\n",
      "Epoch 68/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7264 - categorical_accuracy: 0.2597 - auc_1: 0.6167 - f1_score: 0.1778 - val_loss: 3.3943 - val_categorical_accuracy: 0.0074 - val_auc_1: 0.1844 - val_f1_score: 0.0056\n",
      "Epoch 69/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7430 - categorical_accuracy: 0.2413 - auc_1: 0.6133 - f1_score: 0.1645 - val_loss: 3.1545 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1879 - val_f1_score: 0.0162\n",
      "Epoch 70/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7485 - categorical_accuracy: 0.2634 - auc_1: 0.6018 - f1_score: 0.1813 - val_loss: 3.4367 - val_categorical_accuracy: 0.0000e+00 - val_auc_1: 0.1856 - val_f1_score: 0.0000e+00\n",
      "Epoch 71/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7290 - categorical_accuracy: 0.2431 - auc_1: 0.6200 - f1_score: 0.1678 - val_loss: 3.1913 - val_categorical_accuracy: 0.0000e+00 - val_auc_1: 0.1827 - val_f1_score: 0.0000e+00\n",
      "Epoch 72/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7320 - categorical_accuracy: 0.2634 - auc_1: 0.6198 - f1_score: 0.1643 - val_loss: 3.2346 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1810 - val_f1_score: 0.0162\n",
      "Epoch 73/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7284 - categorical_accuracy: 0.2541 - auc_1: 0.6236 - f1_score: 0.1689 - val_loss: 3.1733 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1829 - val_f1_score: 0.0121\n",
      "Epoch 74/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7286 - categorical_accuracy: 0.2468 - auc_1: 0.6194 - f1_score: 0.1685 - val_loss: 3.3432 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1871 - val_f1_score: 0.0175\n",
      "Epoch 75/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7273 - categorical_accuracy: 0.2541 - auc_1: 0.6219 - f1_score: 0.1851 - val_loss: 3.3129 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1851 - val_f1_score: 0.0096\n",
      "Epoch 76/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7295 - categorical_accuracy: 0.2431 - auc_1: 0.6187 - f1_score: 0.1908 - val_loss: 3.1211 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1862 - val_f1_score: 0.0121\n",
      "Epoch 77/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7164 - categorical_accuracy: 0.2523 - auc_1: 0.6246 - f1_score: 0.2020 - val_loss: 3.4502 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1829 - val_f1_score: 0.0227\n",
      "Epoch 78/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7219 - categorical_accuracy: 0.2597 - auc_1: 0.6133 - f1_score: 0.2016 - val_loss: 3.3908 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1851 - val_f1_score: 0.0175\n",
      "Epoch 79/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7286 - categorical_accuracy: 0.2726 - auc_1: 0.6159 - f1_score: 0.1965 - val_loss: 3.1954 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1883 - val_f1_score: 0.0227\n",
      "Epoch 80/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7229 - categorical_accuracy: 0.2431 - auc_1: 0.6257 - f1_score: 0.1887 - val_loss: 3.2637 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1881 - val_f1_score: 0.0227\n",
      "Epoch 81/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7060 - categorical_accuracy: 0.2652 - auc_1: 0.6268 - f1_score: 0.2125 - val_loss: 3.2260 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1861 - val_f1_score: 0.0227\n",
      "Epoch 82/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7179 - categorical_accuracy: 0.2541 - auc_1: 0.6172 - f1_score: 0.1995 - val_loss: 3.3100 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1911 - val_f1_score: 0.0227\n",
      "Epoch 83/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7115 - categorical_accuracy: 0.2689 - auc_1: 0.6320 - f1_score: 0.2046 - val_loss: 3.1385 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1939 - val_f1_score: 0.0121\n",
      "Epoch 84/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7229 - categorical_accuracy: 0.2505 - auc_1: 0.6280 - f1_score: 0.1901 - val_loss: 3.1669 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1812 - val_f1_score: 0.0175\n",
      "Epoch 85/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7156 - categorical_accuracy: 0.2652 - auc_1: 0.6194 - f1_score: 0.2027 - val_loss: 3.3852 - val_categorical_accuracy: 0.0147 - val_auc_1: 0.1799 - val_f1_score: 0.0065\n",
      "Epoch 86/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7259 - categorical_accuracy: 0.2541 - auc_1: 0.6265 - f1_score: 0.1881 - val_loss: 3.3991 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1871 - val_f1_score: 0.0175\n",
      "Epoch 87/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7323 - categorical_accuracy: 0.2597 - auc_1: 0.6133 - f1_score: 0.1965 - val_loss: 3.4594 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1932 - val_f1_score: 0.0143\n",
      "Epoch 88/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7217 - categorical_accuracy: 0.2320 - auc_1: 0.6064 - f1_score: 0.1881 - val_loss: 3.2244 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1855 - val_f1_score: 0.0121\n",
      "Epoch 89/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7225 - categorical_accuracy: 0.2670 - auc_1: 0.6273 - f1_score: 0.2001 - val_loss: 3.2527 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1894 - val_f1_score: 0.0227\n",
      "Epoch 90/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7231 - categorical_accuracy: 0.2670 - auc_1: 0.6191 - f1_score: 0.2046 - val_loss: 3.3857 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1874 - val_f1_score: 0.0152\n",
      "Epoch 91/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7262 - categorical_accuracy: 0.2597 - auc_1: 0.6278 - f1_score: 0.1889 - val_loss: 3.4203 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1830 - val_f1_score: 0.0121\n",
      "Epoch 92/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7365 - categorical_accuracy: 0.2578 - auc_1: 0.6130 - f1_score: 0.2063 - val_loss: 3.1667 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1861 - val_f1_score: 0.0258\n",
      "Epoch 93/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7290 - categorical_accuracy: 0.2431 - auc_1: 0.6295 - f1_score: 0.2049 - val_loss: 3.2843 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1897 - val_f1_score: 0.0152\n",
      "Epoch 94/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7329 - categorical_accuracy: 0.2468 - auc_1: 0.6149 - f1_score: 0.1847 - val_loss: 3.3692 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1851 - val_f1_score: 0.0227\n",
      "Epoch 95/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7302 - categorical_accuracy: 0.2413 - auc_1: 0.6202 - f1_score: 0.1746 - val_loss: 3.3149 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1883 - val_f1_score: 0.0258\n",
      "Epoch 96/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7304 - categorical_accuracy: 0.2707 - auc_1: 0.6208 - f1_score: 0.1910 - val_loss: 3.3020 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1859 - val_f1_score: 0.0096\n",
      "Epoch 97/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7259 - categorical_accuracy: 0.2707 - auc_1: 0.6159 - f1_score: 0.2003 - val_loss: 3.2307 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1908 - val_f1_score: 0.0206\n",
      "Epoch 98/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7298 - categorical_accuracy: 0.2505 - auc_1: 0.6293 - f1_score: 0.1979 - val_loss: 3.3659 - val_categorical_accuracy: 0.0147 - val_auc_1: 0.1887 - val_f1_score: 0.0065\n",
      "Epoch 99/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7261 - categorical_accuracy: 0.2799 - auc_1: 0.6189 - f1_score: 0.2064 - val_loss: 3.3007 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1894 - val_f1_score: 0.0152\n",
      "Epoch 100/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7263 - categorical_accuracy: 0.2652 - auc_1: 0.6252 - f1_score: 0.1979 - val_loss: 3.2232 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1863 - val_f1_score: 0.0258\n",
      "Epoch 101/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7149 - categorical_accuracy: 0.2394 - auc_1: 0.6308 - f1_score: 0.2081 - val_loss: 3.2805 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1904 - val_f1_score: 0.0175\n",
      "Epoch 102/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7170 - categorical_accuracy: 0.2652 - auc_1: 0.6203 - f1_score: 0.2075 - val_loss: 3.2786 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1888 - val_f1_score: 0.0152\n",
      "Epoch 103/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7109 - categorical_accuracy: 0.2486 - auc_1: 0.6371 - f1_score: 0.1799 - val_loss: 3.1102 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1873 - val_f1_score: 0.0227\n",
      "Epoch 104/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7184 - categorical_accuracy: 0.2670 - auc_1: 0.6213 - f1_score: 0.2141 - val_loss: 3.3653 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1811 - val_f1_score: 0.0258\n",
      "Epoch 105/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7253 - categorical_accuracy: 0.2689 - auc_1: 0.6311 - f1_score: 0.2048 - val_loss: 3.3791 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1853 - val_f1_score: 0.0258\n",
      "Epoch 106/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7327 - categorical_accuracy: 0.2339 - auc_1: 0.6089 - f1_score: 0.1917 - val_loss: 3.1916 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1858 - val_f1_score: 0.0258\n",
      "Epoch 107/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7242 - categorical_accuracy: 0.2541 - auc_1: 0.6249 - f1_score: 0.1902 - val_loss: 3.2023 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1867 - val_f1_score: 0.0206\n",
      "Epoch 108/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7244 - categorical_accuracy: 0.2486 - auc_1: 0.6201 - f1_score: 0.1998 - val_loss: 3.3512 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1857 - val_f1_score: 0.0258\n",
      "Epoch 109/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7289 - categorical_accuracy: 0.2634 - auc_1: 0.6193 - f1_score: 0.1945 - val_loss: 3.3118 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1848 - val_f1_score: 0.0152\n",
      "Epoch 110/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7249 - categorical_accuracy: 0.2468 - auc_1: 0.6229 - f1_score: 0.1997 - val_loss: 3.2619 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1825 - val_f1_score: 0.0258\n",
      "Epoch 111/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7388 - categorical_accuracy: 0.2597 - auc_1: 0.6132 - f1_score: 0.1930 - val_loss: 3.2433 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1851 - val_f1_score: 0.0227\n",
      "Epoch 112/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7206 - categorical_accuracy: 0.2541 - auc_1: 0.6320 - f1_score: 0.1807 - val_loss: 3.3053 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1821 - val_f1_score: 0.0227\n",
      "Epoch 113/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7259 - categorical_accuracy: 0.2486 - auc_1: 0.6238 - f1_score: 0.1666 - val_loss: 3.2669 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1848 - val_f1_score: 0.0195\n",
      "Epoch 114/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7234 - categorical_accuracy: 0.2615 - auc_1: 0.6171 - f1_score: 0.2047 - val_loss: 3.3661 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1884 - val_f1_score: 0.0258\n",
      "Epoch 115/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7175 - categorical_accuracy: 0.2560 - auc_1: 0.6295 - f1_score: 0.2022 - val_loss: 3.1811 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1901 - val_f1_score: 0.0206\n",
      "Epoch 116/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7191 - categorical_accuracy: 0.2320 - auc_1: 0.6236 - f1_score: 0.1803 - val_loss: 3.2714 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1860 - val_f1_score: 0.0258\n",
      "Epoch 117/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7273 - categorical_accuracy: 0.2523 - auc_1: 0.6303 - f1_score: 0.1991 - val_loss: 3.2627 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1855 - val_f1_score: 0.0227\n",
      "Epoch 118/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7154 - categorical_accuracy: 0.2652 - auc_1: 0.6333 - f1_score: 0.1952 - val_loss: 3.2103 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1835 - val_f1_score: 0.0227\n",
      "Epoch 119/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7120 - categorical_accuracy: 0.2707 - auc_1: 0.6258 - f1_score: 0.2198 - val_loss: 3.4125 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1809 - val_f1_score: 0.0175\n",
      "Epoch 120/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7245 - categorical_accuracy: 0.2468 - auc_1: 0.6182 - f1_score: 0.1859 - val_loss: 3.2108 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1889 - val_f1_score: 0.0227\n",
      "Epoch 121/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7236 - categorical_accuracy: 0.2578 - auc_1: 0.6074 - f1_score: 0.2029 - val_loss: 3.2295 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1901 - val_f1_score: 0.0227\n",
      "Epoch 122/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7113 - categorical_accuracy: 0.2744 - auc_1: 0.6239 - f1_score: 0.2102 - val_loss: 3.4144 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1881 - val_f1_score: 0.0227\n",
      "Epoch 123/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7131 - categorical_accuracy: 0.2615 - auc_1: 0.6258 - f1_score: 0.2092 - val_loss: 3.3894 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1831 - val_f1_score: 0.0175\n",
      "Epoch 124/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7115 - categorical_accuracy: 0.2634 - auc_1: 0.6214 - f1_score: 0.2071 - val_loss: 3.3120 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1881 - val_f1_score: 0.0227\n",
      "Epoch 125/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7223 - categorical_accuracy: 0.2634 - auc_1: 0.6213 - f1_score: 0.2093 - val_loss: 3.2532 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1863 - val_f1_score: 0.0258\n",
      "Epoch 126/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7180 - categorical_accuracy: 0.2578 - auc_1: 0.6336 - f1_score: 0.1994 - val_loss: 3.1996 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1896 - val_f1_score: 0.0258\n",
      "Epoch 127/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7036 - categorical_accuracy: 0.2707 - auc_1: 0.6232 - f1_score: 0.2103 - val_loss: 3.3989 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1924 - val_f1_score: 0.0121\n",
      "Epoch 128/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7159 - categorical_accuracy: 0.2578 - auc_1: 0.6285 - f1_score: 0.1890 - val_loss: 3.2170 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1881 - val_f1_score: 0.0206\n",
      "Epoch 129/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7097 - categorical_accuracy: 0.2891 - auc_1: 0.6263 - f1_score: 0.2268 - val_loss: 3.2023 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1917 - val_f1_score: 0.0258\n",
      "Epoch 130/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7116 - categorical_accuracy: 0.2486 - auc_1: 0.6319 - f1_score: 0.1885 - val_loss: 3.2422 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1863 - val_f1_score: 0.0227\n",
      "Epoch 131/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7131 - categorical_accuracy: 0.2634 - auc_1: 0.6293 - f1_score: 0.1983 - val_loss: 3.6449 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1800 - val_f1_score: 0.0227\n",
      "Epoch 132/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7342 - categorical_accuracy: 0.2560 - auc_1: 0.6232 - f1_score: 0.1915 - val_loss: 3.2626 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1843 - val_f1_score: 0.0175\n",
      "Epoch 133/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7146 - categorical_accuracy: 0.2726 - auc_1: 0.6249 - f1_score: 0.2009 - val_loss: 3.2129 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1899 - val_f1_score: 0.0227\n",
      "Epoch 134/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7246 - categorical_accuracy: 0.2486 - auc_1: 0.6178 - f1_score: 0.1999 - val_loss: 3.3478 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1859 - val_f1_score: 0.0227\n",
      "Epoch 135/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7189 - categorical_accuracy: 0.2670 - auc_1: 0.6129 - f1_score: 0.2083 - val_loss: 3.2924 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1863 - val_f1_score: 0.0175\n",
      "Epoch 136/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7216 - categorical_accuracy: 0.2597 - auc_1: 0.6211 - f1_score: 0.1887 - val_loss: 3.2112 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1875 - val_f1_score: 0.0227\n",
      "Epoch 137/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7303 - categorical_accuracy: 0.2726 - auc_1: 0.6129 - f1_score: 0.2088 - val_loss: 3.2655 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1841 - val_f1_score: 0.0175\n",
      "Epoch 138/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7151 - categorical_accuracy: 0.2597 - auc_1: 0.6264 - f1_score: 0.1808 - val_loss: 3.3379 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1800 - val_f1_score: 0.0175\n",
      "Epoch 139/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7109 - categorical_accuracy: 0.2707 - auc_1: 0.6327 - f1_score: 0.2038 - val_loss: 3.3608 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1733 - val_f1_score: 0.0227\n",
      "Epoch 140/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7277 - categorical_accuracy: 0.2634 - auc_1: 0.6187 - f1_score: 0.1926 - val_loss: 3.2301 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1883 - val_f1_score: 0.0258\n",
      "Epoch 141/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7111 - categorical_accuracy: 0.2652 - auc_1: 0.6129 - f1_score: 0.2062 - val_loss: 3.3406 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1834 - val_f1_score: 0.0227\n",
      "Epoch 142/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7040 - categorical_accuracy: 0.2744 - auc_1: 0.6348 - f1_score: 0.2196 - val_loss: 3.2086 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1789 - val_f1_score: 0.0258\n",
      "Epoch 143/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7134 - categorical_accuracy: 0.2670 - auc_1: 0.6268 - f1_score: 0.2064 - val_loss: 3.2916 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1883 - val_f1_score: 0.0175\n",
      "Epoch 144/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7102 - categorical_accuracy: 0.2781 - auc_1: 0.6154 - f1_score: 0.2102 - val_loss: 3.3447 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1809 - val_f1_score: 0.0227\n",
      "Epoch 145/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7047 - categorical_accuracy: 0.2781 - auc_1: 0.6433 - f1_score: 0.2285 - val_loss: 3.1857 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1827 - val_f1_score: 0.0258\n",
      "Epoch 146/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7069 - categorical_accuracy: 0.2652 - auc_1: 0.6237 - f1_score: 0.2009 - val_loss: 3.2800 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1834 - val_f1_score: 0.0227\n",
      "Epoch 147/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7195 - categorical_accuracy: 0.2634 - auc_1: 0.6153 - f1_score: 0.2080 - val_loss: 3.3192 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1892 - val_f1_score: 0.0258\n",
      "Epoch 148/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7055 - categorical_accuracy: 0.2652 - auc_1: 0.6250 - f1_score: 0.2034 - val_loss: 3.3682 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1839 - val_f1_score: 0.0227\n",
      "Epoch 149/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7194 - categorical_accuracy: 0.2597 - auc_1: 0.6252 - f1_score: 0.2060 - val_loss: 3.2645 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1837 - val_f1_score: 0.0121\n",
      "Epoch 150/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7169 - categorical_accuracy: 0.2615 - auc_1: 0.6266 - f1_score: 0.2119 - val_loss: 3.1734 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1855 - val_f1_score: 0.0227\n",
      "Epoch 151/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7184 - categorical_accuracy: 0.2689 - auc_1: 0.6266 - f1_score: 0.2029 - val_loss: 3.2833 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1867 - val_f1_score: 0.0227\n",
      "Epoch 152/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7072 - categorical_accuracy: 0.2744 - auc_1: 0.6269 - f1_score: 0.2032 - val_loss: 3.2508 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1829 - val_f1_score: 0.0227\n",
      "Epoch 153/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7186 - categorical_accuracy: 0.2689 - auc_1: 0.6163 - f1_score: 0.2059 - val_loss: 3.3607 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1941 - val_f1_score: 0.0227\n",
      "Epoch 154/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7107 - categorical_accuracy: 0.2652 - auc_1: 0.6097 - f1_score: 0.2028 - val_loss: 3.2362 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1866 - val_f1_score: 0.0227\n",
      "Epoch 155/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7073 - categorical_accuracy: 0.2689 - auc_1: 0.6279 - f1_score: 0.2053 - val_loss: 3.3069 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1860 - val_f1_score: 0.0175\n",
      "Epoch 156/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7224 - categorical_accuracy: 0.2523 - auc_1: 0.6158 - f1_score: 0.1943 - val_loss: 3.2051 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1813 - val_f1_score: 0.0227\n",
      "Epoch 157/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7156 - categorical_accuracy: 0.2670 - auc_1: 0.6321 - f1_score: 0.2202 - val_loss: 3.3815 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1886 - val_f1_score: 0.0121\n",
      "Epoch 158/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7317 - categorical_accuracy: 0.2468 - auc_1: 0.6165 - f1_score: 0.1930 - val_loss: 3.2905 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1861 - val_f1_score: 0.0121\n",
      "Epoch 159/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7270 - categorical_accuracy: 0.2634 - auc_1: 0.6124 - f1_score: 0.2027 - val_loss: 3.3372 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1851 - val_f1_score: 0.0096\n",
      "Epoch 160/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7138 - categorical_accuracy: 0.2670 - auc_1: 0.6215 - f1_score: 0.1966 - val_loss: 3.3009 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1847 - val_f1_score: 0.0175\n",
      "Epoch 161/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7177 - categorical_accuracy: 0.2541 - auc_1: 0.6282 - f1_score: 0.1953 - val_loss: 3.3710 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1864 - val_f1_score: 0.0121\n",
      "Epoch 162/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7193 - categorical_accuracy: 0.2670 - auc_1: 0.6194 - f1_score: 0.2030 - val_loss: 3.2992 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1885 - val_f1_score: 0.0175\n",
      "Epoch 163/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7248 - categorical_accuracy: 0.2836 - auc_1: 0.6157 - f1_score: 0.2157 - val_loss: 3.2493 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1842 - val_f1_score: 0.0227\n",
      "Epoch 164/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7179 - categorical_accuracy: 0.2597 - auc_1: 0.6224 - f1_score: 0.2080 - val_loss: 3.3239 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1918 - val_f1_score: 0.0227\n",
      "Epoch 165/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7187 - categorical_accuracy: 0.2505 - auc_1: 0.6194 - f1_score: 0.1977 - val_loss: 3.3337 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1823 - val_f1_score: 0.0227\n",
      "Epoch 166/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7106 - categorical_accuracy: 0.2762 - auc_1: 0.6346 - f1_score: 0.2112 - val_loss: 3.3775 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1865 - val_f1_score: 0.0227\n",
      "Epoch 167/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7174 - categorical_accuracy: 0.2615 - auc_1: 0.6197 - f1_score: 0.2108 - val_loss: 3.4477 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1853 - val_f1_score: 0.0121\n",
      "Epoch 168/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7114 - categorical_accuracy: 0.2560 - auc_1: 0.6305 - f1_score: 0.1961 - val_loss: 3.3392 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1838 - val_f1_score: 0.0121\n",
      "Epoch 169/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7113 - categorical_accuracy: 0.2689 - auc_1: 0.6243 - f1_score: 0.1957 - val_loss: 3.2597 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1890 - val_f1_score: 0.0258\n",
      "Epoch 170/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.6977 - categorical_accuracy: 0.2781 - auc_1: 0.6304 - f1_score: 0.2186 - val_loss: 3.2575 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1907 - val_f1_score: 0.0227\n",
      "Epoch 171/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7068 - categorical_accuracy: 0.2689 - auc_1: 0.6221 - f1_score: 0.2061 - val_loss: 3.4163 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1882 - val_f1_score: 0.0227\n",
      "Epoch 172/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7245 - categorical_accuracy: 0.2357 - auc_1: 0.6216 - f1_score: 0.2046 - val_loss: 3.2892 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1885 - val_f1_score: 0.0227\n",
      "Epoch 173/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7252 - categorical_accuracy: 0.2634 - auc_1: 0.6317 - f1_score: 0.1958 - val_loss: 3.2953 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1925 - val_f1_score: 0.0121\n",
      "Epoch 174/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7209 - categorical_accuracy: 0.2652 - auc_1: 0.6172 - f1_score: 0.2037 - val_loss: 3.3542 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1821 - val_f1_score: 0.0175\n",
      "Epoch 175/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7149 - categorical_accuracy: 0.2799 - auc_1: 0.6162 - f1_score: 0.2160 - val_loss: 3.3006 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1862 - val_f1_score: 0.0175\n",
      "Epoch 176/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7120 - categorical_accuracy: 0.2634 - auc_1: 0.6147 - f1_score: 0.1999 - val_loss: 3.3500 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1811 - val_f1_score: 0.0258\n",
      "Epoch 177/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7048 - categorical_accuracy: 0.2762 - auc_1: 0.6189 - f1_score: 0.2154 - val_loss: 3.2767 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1851 - val_f1_score: 0.0121\n",
      "Epoch 178/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7065 - categorical_accuracy: 0.2670 - auc_1: 0.6238 - f1_score: 0.2004 - val_loss: 3.2379 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1909 - val_f1_score: 0.0227\n",
      "Epoch 179/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7076 - categorical_accuracy: 0.2799 - auc_1: 0.6126 - f1_score: 0.2131 - val_loss: 3.2025 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1872 - val_f1_score: 0.0258\n",
      "Epoch 180/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7253 - categorical_accuracy: 0.2505 - auc_1: 0.6178 - f1_score: 0.1994 - val_loss: 3.2845 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1852 - val_f1_score: 0.0258\n",
      "Epoch 181/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7136 - categorical_accuracy: 0.2652 - auc_1: 0.6321 - f1_score: 0.2084 - val_loss: 3.3160 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1859 - val_f1_score: 0.0175: 1.7077 - categorical_accuracy: 0.2750 - auc_1: 0.6357 - f1_score: 0.21\n",
      "Epoch 182/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7147 - categorical_accuracy: 0.2560 - auc_1: 0.6298 - f1_score: 0.2070 - val_loss: 3.3222 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1835 - val_f1_score: 0.0227\n",
      "Epoch 183/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7081 - categorical_accuracy: 0.2597 - auc_1: 0.6239 - f1_score: 0.2014 - val_loss: 3.3293 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1883 - val_f1_score: 0.0258\n",
      "Epoch 184/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7144 - categorical_accuracy: 0.2670 - auc_1: 0.6223 - f1_score: 0.1962 - val_loss: 3.3042 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1830 - val_f1_score: 0.0121\n",
      "Epoch 185/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7021 - categorical_accuracy: 0.2836 - auc_1: 0.6223 - f1_score: 0.2178 - val_loss: 3.4200 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1807 - val_f1_score: 0.0206\n",
      "Epoch 186/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7056 - categorical_accuracy: 0.2781 - auc_1: 0.6214 - f1_score: 0.2115 - val_loss: 3.2232 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1845 - val_f1_score: 0.0258\n",
      "Epoch 187/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7115 - categorical_accuracy: 0.2615 - auc_1: 0.6101 - f1_score: 0.1994 - val_loss: 3.3768 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1960 - val_f1_score: 0.0258\n",
      "Epoch 188/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7027 - categorical_accuracy: 0.2689 - auc_1: 0.6274 - f1_score: 0.2111 - val_loss: 3.2547 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1849 - val_f1_score: 0.0175\n",
      "Epoch 189/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7056 - categorical_accuracy: 0.2762 - auc_1: 0.6245 - f1_score: 0.2127 - val_loss: 3.2978 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1841 - val_f1_score: 0.0227\n",
      "Epoch 190/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7159 - categorical_accuracy: 0.2726 - auc_1: 0.6255 - f1_score: 0.2106 - val_loss: 3.3579 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1847 - val_f1_score: 0.0227\n",
      "Epoch 191/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7086 - categorical_accuracy: 0.2578 - auc_1: 0.6185 - f1_score: 0.2049 - val_loss: 3.3758 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1860 - val_f1_score: 0.0175\n",
      "Epoch 192/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7261 - categorical_accuracy: 0.2707 - auc_1: 0.6231 - f1_score: 0.2026 - val_loss: 3.3836 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1871 - val_f1_score: 0.0258\n",
      "Epoch 193/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7102 - categorical_accuracy: 0.2597 - auc_1: 0.6247 - f1_score: 0.2219 - val_loss: 3.3295 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1828 - val_f1_score: 0.0227\n",
      "Epoch 194/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7035 - categorical_accuracy: 0.2781 - auc_1: 0.6221 - f1_score: 0.2073 - val_loss: 3.3010 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1856 - val_f1_score: 0.0206\n",
      "Epoch 195/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7068 - categorical_accuracy: 0.2634 - auc_1: 0.6288 - f1_score: 0.2097 - val_loss: 3.2334 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1874 - val_f1_score: 0.0258\n",
      "Epoch 196/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7057 - categorical_accuracy: 0.2689 - auc_1: 0.6290 - f1_score: 0.2049 - val_loss: 3.3671 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1805 - val_f1_score: 0.0121\n",
      "Epoch 197/500\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 1.7100 - categorical_accuracy: 0.2634 - auc_1: 0.6201 - f1_score: 0.2000 - val_loss: 3.3197 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1853 - val_f1_score: 0.0175\n",
      "Epoch 198/500\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.7094 - categorical_accuracy: 0.2707 - auc_1: 0.6215 - f1_score: 0.2065 - val_loss: 3.2727 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1866 - val_f1_score: 0.0227\n",
      "Epoch 199/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7068 - categorical_accuracy: 0.2597 - auc_1: 0.6189 - f1_score: 0.2076 - val_loss: 3.3345 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1877 - val_f1_score: 0.0227\n",
      "Epoch 200/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7124 - categorical_accuracy: 0.2744 - auc_1: 0.6162 - f1_score: 0.2004 - val_loss: 3.3364 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1834 - val_f1_score: 0.0258\n",
      "Epoch 201/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7137 - categorical_accuracy: 0.2726 - auc_1: 0.6200 - f1_score: 0.2094 - val_loss: 3.2142 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1862 - val_f1_score: 0.0227\n",
      "Epoch 202/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7133 - categorical_accuracy: 0.2560 - auc_1: 0.6255 - f1_score: 0.1952 - val_loss: 3.2495 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1847 - val_f1_score: 0.0096\n",
      "Epoch 203/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7068 - categorical_accuracy: 0.2615 - auc_1: 0.6348 - f1_score: 0.1913 - val_loss: 3.3538 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1871 - val_f1_score: 0.0206\n",
      "Epoch 204/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7094 - categorical_accuracy: 0.2707 - auc_1: 0.6115 - f1_score: 0.2108 - val_loss: 3.3444 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1872 - val_f1_score: 0.0237\n",
      "Epoch 205/500\n",
      "17/17 [==============================] - 1s 54ms/step - loss: 1.7114 - categorical_accuracy: 0.2560 - auc_1: 0.6192 - f1_score: 0.2065 - val_loss: 3.2895 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1862 - val_f1_score: 0.0258\n",
      "Epoch 206/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7144 - categorical_accuracy: 0.2578 - auc_1: 0.6223 - f1_score: 0.1901 - val_loss: 3.2705 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1886 - val_f1_score: 0.0258\n",
      "Epoch 207/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7197 - categorical_accuracy: 0.2523 - auc_1: 0.6059 - f1_score: 0.2004 - val_loss: 3.2448 - val_categorical_accuracy: 0.0735 - val_auc_1: 0.1847 - val_f1_score: 0.0447\n",
      "Epoch 208/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.6997 - categorical_accuracy: 0.2762 - auc_1: 0.6382 - f1_score: 0.2085 - val_loss: 3.3149 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1909 - val_f1_score: 0.0258\n",
      "Epoch 209/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7174 - categorical_accuracy: 0.2431 - auc_1: 0.6124 - f1_score: 0.2006 - val_loss: 3.2887 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1839 - val_f1_score: 0.0206\n",
      "Epoch 210/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7153 - categorical_accuracy: 0.2486 - auc_1: 0.6324 - f1_score: 0.1886 - val_loss: 3.2332 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1864 - val_f1_score: 0.0183\n",
      "Epoch 211/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7075 - categorical_accuracy: 0.2707 - auc_1: 0.6326 - f1_score: 0.2097 - val_loss: 3.3278 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1884 - val_f1_score: 0.0258\n",
      "Epoch 212/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7048 - categorical_accuracy: 0.2799 - auc_1: 0.6119 - f1_score: 0.2109 - val_loss: 3.2734 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1883 - val_f1_score: 0.0258\n",
      "Epoch 213/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7081 - categorical_accuracy: 0.2523 - auc_1: 0.6256 - f1_score: 0.2016 - val_loss: 3.2047 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1896 - val_f1_score: 0.0258\n",
      "Epoch 214/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7022 - categorical_accuracy: 0.2670 - auc_1: 0.6306 - f1_score: 0.1988 - val_loss: 3.3125 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1808 - val_f1_score: 0.0206\n",
      "Epoch 215/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7093 - categorical_accuracy: 0.2762 - auc_1: 0.6202 - f1_score: 0.2120 - val_loss: 3.3350 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1851 - val_f1_score: 0.0227\n",
      "Epoch 216/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7106 - categorical_accuracy: 0.2597 - auc_1: 0.6194 - f1_score: 0.2025 - val_loss: 3.4072 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1850 - val_f1_score: 0.0206\n",
      "Epoch 217/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7105 - categorical_accuracy: 0.2560 - auc_1: 0.6120 - f1_score: 0.2056 - val_loss: 3.1664 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1852 - val_f1_score: 0.0258\n",
      "Epoch 218/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7112 - categorical_accuracy: 0.2744 - auc_1: 0.6162 - f1_score: 0.2038 - val_loss: 3.2850 - val_categorical_accuracy: 0.0515 - val_auc_1: 0.1894 - val_f1_score: 0.0289\n",
      "Epoch 219/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7061 - categorical_accuracy: 0.2615 - auc_1: 0.6324 - f1_score: 0.2052 - val_loss: 3.3077 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1882 - val_f1_score: 0.0258\n",
      "Epoch 220/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7067 - categorical_accuracy: 0.2634 - auc_1: 0.6184 - f1_score: 0.2088 - val_loss: 3.3366 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1872 - val_f1_score: 0.0227\n",
      "Epoch 221/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7218 - categorical_accuracy: 0.2413 - auc_1: 0.6072 - f1_score: 0.1915 - val_loss: 3.3045 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1851 - val_f1_score: 0.0227\n",
      "Epoch 222/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7246 - categorical_accuracy: 0.2726 - auc_1: 0.5945 - f1_score: 0.2022 - val_loss: 3.3139 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1891 - val_f1_score: 0.0227\n",
      "Epoch 223/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7214 - categorical_accuracy: 0.2394 - auc_1: 0.6247 - f1_score: 0.1968 - val_loss: 3.3606 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1900 - val_f1_score: 0.0258\n",
      "Epoch 224/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7023 - categorical_accuracy: 0.2707 - auc_1: 0.6338 - f1_score: 0.2140 - val_loss: 3.3029 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1799 - val_f1_score: 0.0206\n",
      "Epoch 225/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7149 - categorical_accuracy: 0.2744 - auc_1: 0.6325 - f1_score: 0.2196 - val_loss: 3.2471 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1940 - val_f1_score: 0.0258\n",
      "Epoch 226/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7177 - categorical_accuracy: 0.2799 - auc_1: 0.6192 - f1_score: 0.2138 - val_loss: 3.2411 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1884 - val_f1_score: 0.0258\n",
      "Epoch 227/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7042 - categorical_accuracy: 0.2652 - auc_1: 0.6264 - f1_score: 0.2020 - val_loss: 3.4730 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1864 - val_f1_score: 0.0258\n",
      "Epoch 228/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7130 - categorical_accuracy: 0.2652 - auc_1: 0.6164 - f1_score: 0.2052 - val_loss: 3.3690 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1823 - val_f1_score: 0.0206\n",
      "Epoch 229/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7101 - categorical_accuracy: 0.2726 - auc_1: 0.6185 - f1_score: 0.2109 - val_loss: 3.4145 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1854 - val_f1_score: 0.0206\n",
      "Epoch 230/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7188 - categorical_accuracy: 0.2357 - auc_1: 0.6250 - f1_score: 0.1743 - val_loss: 3.1748 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1805 - val_f1_score: 0.0258\n",
      "Epoch 231/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7256 - categorical_accuracy: 0.2781 - auc_1: 0.6121 - f1_score: 0.2117 - val_loss: 3.3274 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1864 - val_f1_score: 0.0258\n",
      "Epoch 232/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7193 - categorical_accuracy: 0.2744 - auc_1: 0.6232 - f1_score: 0.2058 - val_loss: 3.2333 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1880 - val_f1_score: 0.0258\n",
      "Epoch 233/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7221 - categorical_accuracy: 0.2689 - auc_1: 0.6105 - f1_score: 0.1953 - val_loss: 3.4263 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1803 - val_f1_score: 0.0206\n",
      "Epoch 234/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7178 - categorical_accuracy: 0.2634 - auc_1: 0.6100 - f1_score: 0.2022 - val_loss: 3.2707 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1872 - val_f1_score: 0.0258\n",
      "Epoch 235/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7234 - categorical_accuracy: 0.2486 - auc_1: 0.6122 - f1_score: 0.2015 - val_loss: 3.3864 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1873 - val_f1_score: 0.0175\n",
      "Epoch 236/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7008 - categorical_accuracy: 0.2781 - auc_1: 0.6295 - f1_score: 0.2136 - val_loss: 3.2856 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1839 - val_f1_score: 0.0227\n",
      "Epoch 237/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7116 - categorical_accuracy: 0.2670 - auc_1: 0.6168 - f1_score: 0.1948 - val_loss: 3.3365 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1854 - val_f1_score: 0.0258\n",
      "Epoch 238/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7078 - categorical_accuracy: 0.2689 - auc_1: 0.6237 - f1_score: 0.2045 - val_loss: 3.2523 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1856 - val_f1_score: 0.0227\n",
      "Epoch 239/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7174 - categorical_accuracy: 0.2468 - auc_1: 0.6201 - f1_score: 0.1838 - val_loss: 3.3047 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1875 - val_f1_score: 0.0227\n",
      "Epoch 240/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7083 - categorical_accuracy: 0.2523 - auc_1: 0.6202 - f1_score: 0.1890 - val_loss: 3.1807 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1896 - val_f1_score: 0.0206\n",
      "Epoch 241/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7129 - categorical_accuracy: 0.2634 - auc_1: 0.6277 - f1_score: 0.1966 - val_loss: 3.2064 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1892 - val_f1_score: 0.0258\n",
      "Epoch 242/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7019 - categorical_accuracy: 0.2726 - auc_1: 0.6270 - f1_score: 0.2081 - val_loss: 3.4734 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1848 - val_f1_score: 0.0227\n",
      "Epoch 243/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7170 - categorical_accuracy: 0.2781 - auc_1: 0.6242 - f1_score: 0.2133 - val_loss: 3.3096 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1870 - val_f1_score: 0.0227\n",
      "Epoch 244/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7009 - categorical_accuracy: 0.2726 - auc_1: 0.6304 - f1_score: 0.2129 - val_loss: 3.2954 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1862 - val_f1_score: 0.0258\n",
      "Epoch 245/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7039 - categorical_accuracy: 0.2762 - auc_1: 0.6234 - f1_score: 0.2144 - val_loss: 3.2578 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1828 - val_f1_score: 0.0121\n",
      "Epoch 246/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7167 - categorical_accuracy: 0.2357 - auc_1: 0.6322 - f1_score: 0.1632 - val_loss: 3.4061 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1858 - val_f1_score: 0.0258\n",
      "Epoch 247/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7094 - categorical_accuracy: 0.2781 - auc_1: 0.6196 - f1_score: 0.2193 - val_loss: 3.3675 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1864 - val_f1_score: 0.0258\n",
      "Epoch 248/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7050 - categorical_accuracy: 0.2523 - auc_1: 0.6142 - f1_score: 0.1905 - val_loss: 3.2303 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1900 - val_f1_score: 0.0258\n",
      "Epoch 249/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7080 - categorical_accuracy: 0.2652 - auc_1: 0.6289 - f1_score: 0.2001 - val_loss: 3.3519 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1832 - val_f1_score: 0.0227\n",
      "Epoch 250/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.6998 - categorical_accuracy: 0.2707 - auc_1: 0.6264 - f1_score: 0.2069 - val_loss: 3.3822 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1867 - val_f1_score: 0.0227\n",
      "Epoch 251/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7072 - categorical_accuracy: 0.2486 - auc_1: 0.6130 - f1_score: 0.1952 - val_loss: 3.2040 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1891 - val_f1_score: 0.0258\n",
      "Epoch 252/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7006 - categorical_accuracy: 0.2947 - auc_1: 0.6269 - f1_score: 0.2272 - val_loss: 3.3035 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1855 - val_f1_score: 0.0227\n",
      "Epoch 253/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7012 - categorical_accuracy: 0.2689 - auc_1: 0.6228 - f1_score: 0.2086 - val_loss: 3.4225 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1832 - val_f1_score: 0.0175\n",
      "Epoch 254/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7040 - categorical_accuracy: 0.2744 - auc_1: 0.6292 - f1_score: 0.2132 - val_loss: 3.3306 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1844 - val_f1_score: 0.0227\n",
      "Epoch 255/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7046 - categorical_accuracy: 0.2523 - auc_1: 0.6226 - f1_score: 0.1957 - val_loss: 3.3968 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1853 - val_f1_score: 0.0227\n",
      "Epoch 256/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7078 - categorical_accuracy: 0.2689 - auc_1: 0.6229 - f1_score: 0.2045 - val_loss: 3.2823 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1857 - val_f1_score: 0.0227\n",
      "Epoch 257/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7126 - categorical_accuracy: 0.2652 - auc_1: 0.6277 - f1_score: 0.1995 - val_loss: 3.3123 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1828 - val_f1_score: 0.0227\n",
      "Epoch 258/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7042 - categorical_accuracy: 0.2707 - auc_1: 0.6211 - f1_score: 0.2129 - val_loss: 3.4505 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1887 - val_f1_score: 0.0258\n",
      "Epoch 259/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7034 - categorical_accuracy: 0.2615 - auc_1: 0.6268 - f1_score: 0.2048 - val_loss: 3.2345 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1821 - val_f1_score: 0.0227\n",
      "Epoch 260/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7139 - categorical_accuracy: 0.2560 - auc_1: 0.6293 - f1_score: 0.2026 - val_loss: 3.2998 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1893 - val_f1_score: 0.0258\n",
      "Epoch 261/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7243 - categorical_accuracy: 0.2523 - auc_1: 0.6122 - f1_score: 0.1931 - val_loss: 3.3188 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1829 - val_f1_score: 0.0206\n",
      "Epoch 262/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7188 - categorical_accuracy: 0.2541 - auc_1: 0.6184 - f1_score: 0.1973 - val_loss: 3.4107 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1877 - val_f1_score: 0.0258\n",
      "Epoch 263/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7123 - categorical_accuracy: 0.2486 - auc_1: 0.6266 - f1_score: 0.1863 - val_loss: 3.3153 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1912 - val_f1_score: 0.0258\n",
      "Epoch 264/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7126 - categorical_accuracy: 0.2541 - auc_1: 0.6148 - f1_score: 0.1977 - val_loss: 3.3365 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1853 - val_f1_score: 0.0096\n",
      "Epoch 265/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7348 - categorical_accuracy: 0.2707 - auc_1: 0.6264 - f1_score: 0.1990 - val_loss: 3.4006 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1891 - val_f1_score: 0.0227\n",
      "Epoch 266/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7082 - categorical_accuracy: 0.2726 - auc_1: 0.6194 - f1_score: 0.2127 - val_loss: 3.2868 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1870 - val_f1_score: 0.0258\n",
      "Epoch 267/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7053 - categorical_accuracy: 0.2652 - auc_1: 0.6237 - f1_score: 0.2080 - val_loss: 3.4391 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1763 - val_f1_score: 0.0121\n",
      "Epoch 268/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7053 - categorical_accuracy: 0.2634 - auc_1: 0.6269 - f1_score: 0.1992 - val_loss: 3.3311 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1881 - val_f1_score: 0.0175\n",
      "Epoch 269/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7200 - categorical_accuracy: 0.2560 - auc_1: 0.6155 - f1_score: 0.1884 - val_loss: 3.4452 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1828 - val_f1_score: 0.0227\n",
      "Epoch 270/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7275 - categorical_accuracy: 0.2394 - auc_1: 0.6056 - f1_score: 0.1974 - val_loss: 3.3323 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1833 - val_f1_score: 0.0175\n",
      "Epoch 271/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7131 - categorical_accuracy: 0.2578 - auc_1: 0.6249 - f1_score: 0.2010 - val_loss: 3.2664 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1840 - val_f1_score: 0.0227\n",
      "Epoch 272/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7059 - categorical_accuracy: 0.2726 - auc_1: 0.6328 - f1_score: 0.2107 - val_loss: 3.3165 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1842 - val_f1_score: 0.0227\n",
      "Epoch 273/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7140 - categorical_accuracy: 0.2560 - auc_1: 0.6184 - f1_score: 0.2023 - val_loss: 3.3181 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1833 - val_f1_score: 0.0227\n",
      "Epoch 274/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7101 - categorical_accuracy: 0.2578 - auc_1: 0.6222 - f1_score: 0.2030 - val_loss: 3.2298 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1867 - val_f1_score: 0.0258\n",
      "Epoch 275/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7089 - categorical_accuracy: 0.2781 - auc_1: 0.6309 - f1_score: 0.2159 - val_loss: 3.3192 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1884 - val_f1_score: 0.0227\n",
      "Epoch 276/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7069 - categorical_accuracy: 0.2670 - auc_1: 0.6147 - f1_score: 0.2089 - val_loss: 3.3589 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1866 - val_f1_score: 0.0175\n",
      "Epoch 277/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.6996 - categorical_accuracy: 0.2578 - auc_1: 0.6372 - f1_score: 0.1965 - val_loss: 3.3611 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1846 - val_f1_score: 0.0227\n",
      "Epoch 278/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7050 - categorical_accuracy: 0.2707 - auc_1: 0.6167 - f1_score: 0.2110 - val_loss: 3.3412 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1863 - val_f1_score: 0.0175\n",
      "Epoch 279/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7069 - categorical_accuracy: 0.2578 - auc_1: 0.6160 - f1_score: 0.2088 - val_loss: 3.4539 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1851 - val_f1_score: 0.0227\n",
      "Epoch 280/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7076 - categorical_accuracy: 0.2597 - auc_1: 0.6263 - f1_score: 0.1979 - val_loss: 3.3225 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1884 - val_f1_score: 0.0227\n",
      "Epoch 281/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7110 - categorical_accuracy: 0.2726 - auc_1: 0.6183 - f1_score: 0.2140 - val_loss: 3.3720 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1864 - val_f1_score: 0.0227\n",
      "Epoch 282/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7090 - categorical_accuracy: 0.2578 - auc_1: 0.6120 - f1_score: 0.1946 - val_loss: 3.4154 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1839 - val_f1_score: 0.0227\n",
      "Epoch 283/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7085 - categorical_accuracy: 0.2615 - auc_1: 0.6316 - f1_score: 0.2082 - val_loss: 3.3999 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1863 - val_f1_score: 0.0121\n",
      "Epoch 284/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7086 - categorical_accuracy: 0.2652 - auc_1: 0.6205 - f1_score: 0.1989 - val_loss: 3.2587 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1893 - val_f1_score: 0.0227\n",
      "Epoch 285/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7064 - categorical_accuracy: 0.2615 - auc_1: 0.6303 - f1_score: 0.1929 - val_loss: 3.4172 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1876 - val_f1_score: 0.0258\n",
      "Epoch 286/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7029 - categorical_accuracy: 0.2634 - auc_1: 0.6230 - f1_score: 0.2033 - val_loss: 3.3027 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1841 - val_f1_score: 0.0227\n",
      "Epoch 287/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.6999 - categorical_accuracy: 0.2762 - auc_1: 0.6259 - f1_score: 0.2142 - val_loss: 3.3703 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1847 - val_f1_score: 0.0206\n",
      "Epoch 288/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.6940 - categorical_accuracy: 0.2523 - auc_1: 0.6416 - f1_score: 0.2039 - val_loss: 3.3769 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1817 - val_f1_score: 0.0227\n",
      "Epoch 289/500\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.7033 - categorical_accuracy: 0.2468 - auc_1: 0.6195 - f1_score: 0.200 - 1s 57ms/step - loss: 1.7033 - categorical_accuracy: 0.2468 - auc_1: 0.6195 - f1_score: 0.2008 - val_loss: 3.3101 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1857 - val_f1_score: 0.0258\n",
      "Epoch 290/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7034 - categorical_accuracy: 0.2670 - auc_1: 0.6281 - f1_score: 0.2158 - val_loss: 3.3764 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1854 - val_f1_score: 0.0227\n",
      "Epoch 291/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7058 - categorical_accuracy: 0.2818 - auc_1: 0.6209 - f1_score: 0.2183 - val_loss: 3.3646 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1843 - val_f1_score: 0.0258\n",
      "Epoch 292/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7172 - categorical_accuracy: 0.2541 - auc_1: 0.6263 - f1_score: 0.1897 - val_loss: 3.2342 - val_categorical_accuracy: 0.0515 - val_auc_1: 0.1891 - val_f1_score: 0.0289\n",
      "Epoch 293/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7065 - categorical_accuracy: 0.2707 - auc_1: 0.6231 - f1_score: 0.2043 - val_loss: 3.3976 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1911 - val_f1_score: 0.0258\n",
      "Epoch 294/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7084 - categorical_accuracy: 0.2486 - auc_1: 0.6347 - f1_score: 0.1937 - val_loss: 3.3573 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1868 - val_f1_score: 0.0206\n",
      "Epoch 295/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7169 - categorical_accuracy: 0.2615 - auc_1: 0.6227 - f1_score: 0.2056 - val_loss: 3.3065 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1811 - val_f1_score: 0.0206\n",
      "Epoch 296/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.6995 - categorical_accuracy: 0.2744 - auc_1: 0.6244 - f1_score: 0.2101 - val_loss: 3.3891 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1862 - val_f1_score: 0.0206\n",
      "Epoch 297/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7019 - categorical_accuracy: 0.2652 - auc_1: 0.6253 - f1_score: 0.2063 - val_loss: 3.3997 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1809 - val_f1_score: 0.0227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 298/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7287 - categorical_accuracy: 0.2762 - auc_1: 0.6183 - f1_score: 0.2074 - val_loss: 3.3881 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1891 - val_f1_score: 0.0227\n",
      "Epoch 299/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7167 - categorical_accuracy: 0.2652 - auc_1: 0.6231 - f1_score: 0.2025 - val_loss: 3.3448 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1893 - val_f1_score: 0.0258\n",
      "Epoch 300/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7222 - categorical_accuracy: 0.2173 - auc_1: 0.6013 - f1_score: 0.1936 - val_loss: 3.2780 - val_categorical_accuracy: 0.0515 - val_auc_1: 0.1925 - val_f1_score: 0.0289\n",
      "Epoch 301/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7123 - categorical_accuracy: 0.2707 - auc_1: 0.6240 - f1_score: 0.2082 - val_loss: 3.2805 - val_categorical_accuracy: 0.0515 - val_auc_1: 0.1880 - val_f1_score: 0.0289\n",
      "Epoch 302/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7135 - categorical_accuracy: 0.2615 - auc_1: 0.6204 - f1_score: 0.2024 - val_loss: 3.1693 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1905 - val_f1_score: 0.0258\n",
      "Epoch 303/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7081 - categorical_accuracy: 0.2707 - auc_1: 0.6183 - f1_score: 0.2113 - val_loss: 3.2972 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1863 - val_f1_score: 0.0227\n",
      "Epoch 304/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7019 - categorical_accuracy: 0.2726 - auc_1: 0.6243 - f1_score: 0.2119 - val_loss: 3.4033 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1834 - val_f1_score: 0.0227\n",
      "Epoch 305/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7124 - categorical_accuracy: 0.2726 - auc_1: 0.6255 - f1_score: 0.2087 - val_loss: 3.3684 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1889 - val_f1_score: 0.0258\n",
      "Epoch 306/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7069 - categorical_accuracy: 0.2541 - auc_1: 0.6154 - f1_score: 0.1906 - val_loss: 3.2501 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1864 - val_f1_score: 0.0227\n",
      "Epoch 307/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7175 - categorical_accuracy: 0.2799 - auc_1: 0.6161 - f1_score: 0.2161 - val_loss: 3.5347 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1850 - val_f1_score: 0.0227\n",
      "Epoch 308/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7100 - categorical_accuracy: 0.2670 - auc_1: 0.6206 - f1_score: 0.2094 - val_loss: 3.4122 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1850 - val_f1_score: 0.0121\n",
      "Epoch 309/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7164 - categorical_accuracy: 0.2541 - auc_1: 0.6108 - f1_score: 0.1903 - val_loss: 3.3473 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1879 - val_f1_score: 0.0121\n",
      "Epoch 310/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.6952 - categorical_accuracy: 0.2836 - auc_1: 0.6381 - f1_score: 0.2112 - val_loss: 3.3979 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1826 - val_f1_score: 0.0258\n",
      "Epoch 311/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7127 - categorical_accuracy: 0.2762 - auc_1: 0.6211 - f1_score: 0.2198 - val_loss: 3.4483 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1891 - val_f1_score: 0.0258\n",
      "Epoch 312/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7285 - categorical_accuracy: 0.2468 - auc_1: 0.6180 - f1_score: 0.1871 - val_loss: 3.2958 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1846 - val_f1_score: 0.0258\n",
      "Epoch 313/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7193 - categorical_accuracy: 0.2634 - auc_1: 0.6227 - f1_score: 0.1920 - val_loss: 3.4016 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1843 - val_f1_score: 0.0152\n",
      "Epoch 314/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7109 - categorical_accuracy: 0.2762 - auc_1: 0.6281 - f1_score: 0.2129 - val_loss: 3.3523 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1832 - val_f1_score: 0.0258\n",
      "Epoch 315/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7049 - categorical_accuracy: 0.2689 - auc_1: 0.6266 - f1_score: 0.2077 - val_loss: 3.2676 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1852 - val_f1_score: 0.0258\n",
      "Epoch 316/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.6991 - categorical_accuracy: 0.2652 - auc_1: 0.6280 - f1_score: 0.1921 - val_loss: 3.3626 - val_categorical_accuracy: 0.0515 - val_auc_1: 0.1900 - val_f1_score: 0.0289\n",
      "Epoch 317/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7072 - categorical_accuracy: 0.2560 - auc_1: 0.6350 - f1_score: 0.2056 - val_loss: 3.2672 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1887 - val_f1_score: 0.0258\n",
      "Epoch 318/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7032 - categorical_accuracy: 0.2726 - auc_1: 0.6374 - f1_score: 0.2068 - val_loss: 3.2464 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1866 - val_f1_score: 0.0258\n",
      "Epoch 319/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7084 - categorical_accuracy: 0.2578 - auc_1: 0.6231 - f1_score: 0.1999 - val_loss: 3.3312 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1837 - val_f1_score: 0.0258\n",
      "Epoch 320/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7152 - categorical_accuracy: 0.2486 - auc_1: 0.6248 - f1_score: 0.1825 - val_loss: 3.3754 - val_categorical_accuracy: 0.0515 - val_auc_1: 0.1872 - val_f1_score: 0.0289\n",
      "Epoch 321/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7122 - categorical_accuracy: 0.2781 - auc_1: 0.6243 - f1_score: 0.2217 - val_loss: 3.2906 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1856 - val_f1_score: 0.0258\n",
      "Epoch 322/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7146 - categorical_accuracy: 0.2689 - auc_1: 0.6362 - f1_score: 0.2104 - val_loss: 3.2732 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1852 - val_f1_score: 0.0258\n",
      "Epoch 323/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.6995 - categorical_accuracy: 0.2560 - auc_1: 0.6307 - f1_score: 0.2073 - val_loss: 3.2372 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1824 - val_f1_score: 0.0258\n",
      "Epoch 324/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.6935 - categorical_accuracy: 0.2873 - auc_1: 0.6337 - f1_score: 0.2255 - val_loss: 3.2456 - val_categorical_accuracy: 0.0515 - val_auc_1: 0.1864 - val_f1_score: 0.0289\n",
      "Epoch 325/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.6971 - categorical_accuracy: 0.2744 - auc_1: 0.6219 - f1_score: 0.2167 - val_loss: 3.2357 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1865 - val_f1_score: 0.0258\n",
      "Epoch 326/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7099 - categorical_accuracy: 0.2597 - auc_1: 0.6328 - f1_score: 0.1986 - val_loss: 3.3118 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1918 - val_f1_score: 0.0258\n",
      "Epoch 327/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7081 - categorical_accuracy: 0.2634 - auc_1: 0.6233 - f1_score: 0.2085 - val_loss: 3.2495 - val_categorical_accuracy: 0.0515 - val_auc_1: 0.1884 - val_f1_score: 0.0289\n",
      "Epoch 328/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.6999 - categorical_accuracy: 0.2634 - auc_1: 0.6331 - f1_score: 0.2040 - val_loss: 3.2469 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1850 - val_f1_score: 0.0175\n",
      "Epoch 329/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7007 - categorical_accuracy: 0.2799 - auc_1: 0.6232 - f1_score: 0.2087 - val_loss: 3.4274 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1857 - val_f1_score: 0.0258\n",
      "Epoch 330/500\n",
      "17/17 [==============================] - 1s 54ms/step - loss: 1.7029 - categorical_accuracy: 0.2726 - auc_1: 0.6256 - f1_score: 0.2110 - val_loss: 3.3198 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1832 - val_f1_score: 0.0258\n",
      "Epoch 331/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7142 - categorical_accuracy: 0.2707 - auc_1: 0.6098 - f1_score: 0.1995 - val_loss: 3.2841 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1882 - val_f1_score: 0.0121\n",
      "Epoch 332/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7005 - categorical_accuracy: 0.2670 - auc_1: 0.6360 - f1_score: 0.2087 - val_loss: 3.3773 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1848 - val_f1_score: 0.0258\n",
      "Epoch 333/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7062 - categorical_accuracy: 0.2744 - auc_1: 0.6335 - f1_score: 0.2160 - val_loss: 3.3478 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1807 - val_f1_score: 0.0258\n",
      "Epoch 334/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.6954 - categorical_accuracy: 0.2744 - auc_1: 0.6348 - f1_score: 0.2147 - val_loss: 3.3567 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1814 - val_f1_score: 0.0258\n",
      "Epoch 335/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.6922 - categorical_accuracy: 0.2652 - auc_1: 0.6290 - f1_score: 0.2149 - val_loss: 3.2168 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1787 - val_f1_score: 0.0258\n",
      "Epoch 336/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7166 - categorical_accuracy: 0.2634 - auc_1: 0.6157 - f1_score: 0.1956 - val_loss: 3.3633 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1841 - val_f1_score: 0.0258\n",
      "Epoch 337/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7099 - categorical_accuracy: 0.2762 - auc_1: 0.6237 - f1_score: 0.2152 - val_loss: 3.2665 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1850 - val_f1_score: 0.0206\n",
      "Epoch 338/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7007 - categorical_accuracy: 0.2615 - auc_1: 0.6335 - f1_score: 0.1972 - val_loss: 3.3438 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1858 - val_f1_score: 0.0258\n",
      "Epoch 339/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7059 - categorical_accuracy: 0.2818 - auc_1: 0.6176 - f1_score: 0.2207 - val_loss: 3.2019 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1869 - val_f1_score: 0.0258\n",
      "Epoch 340/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7098 - categorical_accuracy: 0.2523 - auc_1: 0.6154 - f1_score: 0.2029 - val_loss: 3.3024 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1868 - val_f1_score: 0.0258\n",
      "Epoch 341/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.6959 - categorical_accuracy: 0.2560 - auc_1: 0.6299 - f1_score: 0.2051 - val_loss: 3.2982 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1906 - val_f1_score: 0.0227\n",
      "Epoch 342/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7237 - categorical_accuracy: 0.2284 - auc_1: 0.6287 - f1_score: 0.1801 - val_loss: 3.2840 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1847 - val_f1_score: 0.0258\n",
      "Epoch 343/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7190 - categorical_accuracy: 0.2505 - auc_1: 0.6245 - f1_score: 0.1948 - val_loss: 3.3727 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1847 - val_f1_score: 0.0258\n",
      "Epoch 344/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7085 - categorical_accuracy: 0.2560 - auc_1: 0.6300 - f1_score: 0.1813 - val_loss: 3.2126 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1901 - val_f1_score: 0.0258\n",
      "Epoch 345/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7012 - categorical_accuracy: 0.2578 - auc_1: 0.6234 - f1_score: 0.2012 - val_loss: 3.3617 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1857 - val_f1_score: 0.0152\n",
      "Epoch 346/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7030 - categorical_accuracy: 0.2541 - auc_1: 0.6167 - f1_score: 0.1983 - val_loss: 3.2200 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1871 - val_f1_score: 0.0258\n",
      "Epoch 347/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.6974 - categorical_accuracy: 0.2781 - auc_1: 0.6318 - f1_score: 0.2082 - val_loss: 3.3421 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1862 - val_f1_score: 0.0258\n",
      "Epoch 348/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7099 - categorical_accuracy: 0.2744 - auc_1: 0.6212 - f1_score: 0.2128 - val_loss: 3.3828 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1857 - val_f1_score: 0.0258\n",
      "Epoch 349/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7242 - categorical_accuracy: 0.2523 - auc_1: 0.6245 - f1_score: 0.2010 - val_loss: 3.4489 - val_categorical_accuracy: 0.0588 - val_auc_1: 0.1832 - val_f1_score: 0.0384\n",
      "Epoch 350/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7108 - categorical_accuracy: 0.2726 - auc_1: 0.6245 - f1_score: 0.1946 - val_loss: 3.3716 - val_categorical_accuracy: 0.0147 - val_auc_1: 0.1847 - val_f1_score: 0.0065\n",
      "Epoch 351/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7120 - categorical_accuracy: 0.2449 - auc_1: 0.6157 - f1_score: 0.1927 - val_loss: 3.2887 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1836 - val_f1_score: 0.0258\n",
      "Epoch 352/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7068 - categorical_accuracy: 0.2468 - auc_1: 0.6300 - f1_score: 0.1993 - val_loss: 3.3242 - val_categorical_accuracy: 0.0515 - val_auc_1: 0.1865 - val_f1_score: 0.0289\n",
      "Epoch 353/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7046 - categorical_accuracy: 0.2634 - auc_1: 0.6192 - f1_score: 0.2130 - val_loss: 3.3257 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1831 - val_f1_score: 0.0258\n",
      "Epoch 354/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7131 - categorical_accuracy: 0.2689 - auc_1: 0.6145 - f1_score: 0.2027 - val_loss: 3.2151 - val_categorical_accuracy: 0.0735 - val_auc_1: 0.1855 - val_f1_score: 0.0459\n",
      "Epoch 355/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7122 - categorical_accuracy: 0.2523 - auc_1: 0.6177 - f1_score: 0.2101 - val_loss: 3.3127 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1849 - val_f1_score: 0.0227\n",
      "Epoch 356/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7054 - categorical_accuracy: 0.2560 - auc_1: 0.6338 - f1_score: 0.1939 - val_loss: 3.3868 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1834 - val_f1_score: 0.0152\n",
      "Epoch 357/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7272 - categorical_accuracy: 0.2634 - auc_1: 0.6203 - f1_score: 0.1989 - val_loss: 3.4231 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1858 - val_f1_score: 0.0258\n",
      "Epoch 358/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7082 - categorical_accuracy: 0.2689 - auc_1: 0.6357 - f1_score: 0.2093 - val_loss: 3.2881 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1842 - val_f1_score: 0.0227\n",
      "Epoch 359/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7067 - categorical_accuracy: 0.2505 - auc_1: 0.6109 - f1_score: 0.1826 - val_loss: 3.3862 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1840 - val_f1_score: 0.0152\n",
      "Epoch 360/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.6987 - categorical_accuracy: 0.2781 - auc_1: 0.6154 - f1_score: 0.2144 - val_loss: 3.3877 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1856 - val_f1_score: 0.0258\n",
      "Epoch 361/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.6963 - categorical_accuracy: 0.2707 - auc_1: 0.6277 - f1_score: 0.2090 - val_loss: 3.3748 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1868 - val_f1_score: 0.0258\n",
      "Epoch 362/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7009 - categorical_accuracy: 0.2762 - auc_1: 0.6191 - f1_score: 0.2158 - val_loss: 3.3016 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1850 - val_f1_score: 0.0227\n",
      "Epoch 363/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7062 - categorical_accuracy: 0.2707 - auc_1: 0.6315 - f1_score: 0.2073 - val_loss: 3.3627 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1869 - val_f1_score: 0.0277\n",
      "Epoch 364/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7220 - categorical_accuracy: 0.2541 - auc_1: 0.6171 - f1_score: 0.1918 - val_loss: 3.4706 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1873 - val_f1_score: 0.0227\n",
      "Epoch 365/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.6985 - categorical_accuracy: 0.2634 - auc_1: 0.6304 - f1_score: 0.2131 - val_loss: 3.3498 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1830 - val_f1_score: 0.0175\n",
      "Epoch 366/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7185 - categorical_accuracy: 0.2670 - auc_1: 0.6213 - f1_score: 0.1984 - val_loss: 3.4183 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1783 - val_f1_score: 0.0175\n",
      "Epoch 367/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7110 - categorical_accuracy: 0.2597 - auc_1: 0.6139 - f1_score: 0.2038 - val_loss: 3.3935 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1831 - val_f1_score: 0.0227\n",
      "Epoch 368/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.6980 - categorical_accuracy: 0.2652 - auc_1: 0.6186 - f1_score: 0.2089 - val_loss: 3.3221 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1797 - val_f1_score: 0.0227\n",
      "Epoch 369/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7126 - categorical_accuracy: 0.2468 - auc_1: 0.6324 - f1_score: 0.1929 - val_loss: 3.3189 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1862 - val_f1_score: 0.0227\n",
      "Epoch 370/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.6900 - categorical_accuracy: 0.2799 - auc_1: 0.6329 - f1_score: 0.2166 - val_loss: 3.3286 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1848 - val_f1_score: 0.0258\n",
      "Epoch 371/500\n",
      "17/17 [==============================] - 1s 69ms/step - loss: 1.7160 - categorical_accuracy: 0.2505 - auc_1: 0.6117 - f1_score: 0.1911 - val_loss: 3.2973 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1909 - val_f1_score: 0.0175\n",
      "Epoch 372/500\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 1.7128 - categorical_accuracy: 0.2670 - auc_1: 0.6341 - f1_score: 0.2006 - val_loss: 3.2445 - val_categorical_accuracy: 0.0735 - val_auc_1: 0.1893 - val_f1_score: 0.0459\n",
      "Epoch 373/500\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 1.7222 - categorical_accuracy: 0.2689 - auc_1: 0.6223 - f1_score: 0.2051 - val_loss: 3.3875 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1840 - val_f1_score: 0.0206\n",
      "Epoch 374/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7113 - categorical_accuracy: 0.2726 - auc_1: 0.6245 - f1_score: 0.2075 - val_loss: 3.2403 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1859 - val_f1_score: 0.0258\n",
      "Epoch 375/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.6987 - categorical_accuracy: 0.2744 - auc_1: 0.6264 - f1_score: 0.2142 - val_loss: 3.3510 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1860 - val_f1_score: 0.0258\n",
      "Epoch 376/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.6981 - categorical_accuracy: 0.2726 - auc_1: 0.6158 - f1_score: 0.2058 - val_loss: 3.5068 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1867 - val_f1_score: 0.0227\n",
      "Epoch 377/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.6997 - categorical_accuracy: 0.2707 - auc_1: 0.6159 - f1_score: 0.2084 - val_loss: 3.4021 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1892 - val_f1_score: 0.0227\n",
      "Epoch 378/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7052 - categorical_accuracy: 0.2726 - auc_1: 0.6270 - f1_score: 0.2104 - val_loss: 3.2532 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1825 - val_f1_score: 0.0258\n",
      "Epoch 379/500\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 1.7054 - categorical_accuracy: 0.2707 - auc_1: 0.6266 - f1_score: 0.2005 - val_loss: 3.2567 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1882 - val_f1_score: 0.0227\n",
      "Epoch 380/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7179 - categorical_accuracy: 0.2431 - auc_1: 0.6242 - f1_score: 0.2070 - val_loss: 3.3517 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1912 - val_f1_score: 0.0227\n",
      "Epoch 381/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7106 - categorical_accuracy: 0.2781 - auc_1: 0.6181 - f1_score: 0.2134 - val_loss: 3.4667 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1865 - val_f1_score: 0.0227\n",
      "Epoch 382/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7122 - categorical_accuracy: 0.2523 - auc_1: 0.6301 - f1_score: 0.1953 - val_loss: 3.3308 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1829 - val_f1_score: 0.0227\n",
      "Epoch 383/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7003 - categorical_accuracy: 0.2634 - auc_1: 0.6293 - f1_score: 0.2059 - val_loss: 3.4141 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1880 - val_f1_score: 0.0195\n",
      "Epoch 384/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7048 - categorical_accuracy: 0.2762 - auc_1: 0.6315 - f1_score: 0.2042 - val_loss: 3.4465 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1844 - val_f1_score: 0.0258\n",
      "Epoch 385/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7037 - categorical_accuracy: 0.2726 - auc_1: 0.6147 - f1_score: 0.2133 - val_loss: 3.3759 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1814 - val_f1_score: 0.0227\n",
      "Epoch 386/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.6984 - categorical_accuracy: 0.2707 - auc_1: 0.6259 - f1_score: 0.2118 - val_loss: 3.4186 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1849 - val_f1_score: 0.0258\n",
      "Epoch 387/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7036 - categorical_accuracy: 0.2726 - auc_1: 0.6278 - f1_score: 0.2221 - val_loss: 3.3755 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1839 - val_f1_score: 0.0258\n",
      "Epoch 388/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.6953 - categorical_accuracy: 0.2744 - auc_1: 0.6251 - f1_score: 0.2104 - val_loss: 3.2871 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1851 - val_f1_score: 0.0258\n",
      "Epoch 389/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7063 - categorical_accuracy: 0.2762 - auc_1: 0.6246 - f1_score: 0.2166 - val_loss: 3.2807 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1833 - val_f1_score: 0.0258\n",
      "Epoch 390/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7007 - categorical_accuracy: 0.2541 - auc_1: 0.6265 - f1_score: 0.2011 - val_loss: 3.3844 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1864 - val_f1_score: 0.0195\n",
      "Epoch 391/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.6912 - categorical_accuracy: 0.2836 - auc_1: 0.6332 - f1_score: 0.2310 - val_loss: 3.4669 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1825 - val_f1_score: 0.0227\n",
      "Epoch 392/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7132 - categorical_accuracy: 0.2578 - auc_1: 0.6263 - f1_score: 0.2051 - val_loss: 3.2660 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1863 - val_f1_score: 0.0227\n",
      "Epoch 393/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.6959 - categorical_accuracy: 0.2726 - auc_1: 0.6369 - f1_score: 0.2092 - val_loss: 3.3866 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1821 - val_f1_score: 0.0227\n",
      "Epoch 394/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7090 - categorical_accuracy: 0.2486 - auc_1: 0.6313 - f1_score: 0.1992 - val_loss: 3.2603 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1832 - val_f1_score: 0.0227\n",
      "Epoch 395/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7058 - categorical_accuracy: 0.2689 - auc_1: 0.6349 - f1_score: 0.2011 - val_loss: 3.3925 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1861 - val_f1_score: 0.0227\n",
      "Epoch 396/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7118 - categorical_accuracy: 0.2615 - auc_1: 0.6241 - f1_score: 0.2116 - val_loss: 3.3985 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1860 - val_f1_score: 0.0227\n",
      "Epoch 397/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7029 - categorical_accuracy: 0.2744 - auc_1: 0.6315 - f1_score: 0.2182 - val_loss: 3.3014 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1845 - val_f1_score: 0.0258\n",
      "Epoch 398/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7028 - categorical_accuracy: 0.2744 - auc_1: 0.6298 - f1_score: 0.2197 - val_loss: 3.3635 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1834 - val_f1_score: 0.0227\n",
      "Epoch 399/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.6918 - categorical_accuracy: 0.2799 - auc_1: 0.6233 - f1_score: 0.2101 - val_loss: 3.4289 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1866 - val_f1_score: 0.0258\n",
      "Epoch 400/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7011 - categorical_accuracy: 0.2670 - auc_1: 0.6217 - f1_score: 0.2061 - val_loss: 3.3636 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1872 - val_f1_score: 0.0227\n",
      "Epoch 401/500\n",
      "17/17 [==============================] - 1s 54ms/step - loss: 1.6945 - categorical_accuracy: 0.2744 - auc_1: 0.6363 - f1_score: 0.2100 - val_loss: 3.4091 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1839 - val_f1_score: 0.0175\n",
      "Epoch 402/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.6980 - categorical_accuracy: 0.2652 - auc_1: 0.6301 - f1_score: 0.2029 - val_loss: 3.3504 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1897 - val_f1_score: 0.0227\n",
      "Epoch 403/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.6970 - categorical_accuracy: 0.2818 - auc_1: 0.6282 - f1_score: 0.2165 - val_loss: 3.4404 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1879 - val_f1_score: 0.0258\n",
      "Epoch 404/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7234 - categorical_accuracy: 0.2192 - auc_1: 0.6215 - f1_score: 0.1950 - val_loss: 3.3227 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1857 - val_f1_score: 0.0227\n",
      "Epoch 405/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.6999 - categorical_accuracy: 0.2762 - auc_1: 0.6308 - f1_score: 0.2069 - val_loss: 3.4289 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1849 - val_f1_score: 0.0227\n",
      "Epoch 406/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7037 - categorical_accuracy: 0.2744 - auc_1: 0.6318 - f1_score: 0.2076 - val_loss: 3.3301 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1847 - val_f1_score: 0.0227\n",
      "Epoch 407/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7029 - categorical_accuracy: 0.2707 - auc_1: 0.6279 - f1_score: 0.2087 - val_loss: 3.4740 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1841 - val_f1_score: 0.0227\n",
      "Epoch 408/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7038 - categorical_accuracy: 0.2560 - auc_1: 0.6217 - f1_score: 0.1937 - val_loss: 3.3515 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1846 - val_f1_score: 0.0227\n",
      "Epoch 409/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.6972 - categorical_accuracy: 0.2744 - auc_1: 0.6290 - f1_score: 0.2135 - val_loss: 3.4361 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1772 - val_f1_score: 0.0227\n",
      "Epoch 410/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.6951 - categorical_accuracy: 0.2689 - auc_1: 0.6247 - f1_score: 0.2045 - val_loss: 3.4185 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1811 - val_f1_score: 0.0227\n",
      "Epoch 411/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7046 - categorical_accuracy: 0.2744 - auc_1: 0.6385 - f1_score: 0.2091 - val_loss: 3.3682 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1833 - val_f1_score: 0.0227\n",
      "Epoch 412/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7106 - categorical_accuracy: 0.2615 - auc_1: 0.6303 - f1_score: 0.1987 - val_loss: 3.4119 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1841 - val_f1_score: 0.0258\n",
      "Epoch 413/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7060 - categorical_accuracy: 0.2707 - auc_1: 0.6241 - f1_score: 0.2054 - val_loss: 3.2835 - val_categorical_accuracy: 0.0515 - val_auc_1: 0.1819 - val_f1_score: 0.0308\n",
      "Epoch 414/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7138 - categorical_accuracy: 0.2689 - auc_1: 0.6144 - f1_score: 0.1964 - val_loss: 3.5330 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1850 - val_f1_score: 0.0096\n",
      "Epoch 415/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.6986 - categorical_accuracy: 0.2652 - auc_1: 0.6318 - f1_score: 0.2075 - val_loss: 3.3072 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1858 - val_f1_score: 0.0258\n",
      "Epoch 416/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7156 - categorical_accuracy: 0.2689 - auc_1: 0.6260 - f1_score: 0.2058 - val_loss: 3.5685 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1801 - val_f1_score: 0.0175\n",
      "Epoch 417/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7080 - categorical_accuracy: 0.2578 - auc_1: 0.6153 - f1_score: 0.2096 - val_loss: 3.4077 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1850 - val_f1_score: 0.0121\n",
      "Epoch 418/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7098 - categorical_accuracy: 0.2578 - auc_1: 0.6214 - f1_score: 0.2013 - val_loss: 3.4763 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1871 - val_f1_score: 0.0227\n",
      "Epoch 419/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7065 - categorical_accuracy: 0.2726 - auc_1: 0.6302 - f1_score: 0.2052 - val_loss: 3.4979 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1869 - val_f1_score: 0.0258\n",
      "Epoch 420/500\n",
      "17/17 [==============================] - 1s 54ms/step - loss: 1.7028 - categorical_accuracy: 0.2670 - auc_1: 0.6286 - f1_score: 0.2166 - val_loss: 3.3090 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1868 - val_f1_score: 0.0258\n",
      "Epoch 421/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.6978 - categorical_accuracy: 0.2615 - auc_1: 0.6359 - f1_score: 0.2060 - val_loss: 3.4740 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1829 - val_f1_score: 0.0258\n",
      "Epoch 422/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7032 - categorical_accuracy: 0.2597 - auc_1: 0.6339 - f1_score: 0.2097 - val_loss: 3.3061 - val_categorical_accuracy: 0.0515 - val_auc_1: 0.1871 - val_f1_score: 0.0325\n",
      "Epoch 423/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.6970 - categorical_accuracy: 0.2634 - auc_1: 0.6316 - f1_score: 0.2004 - val_loss: 3.5032 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1850 - val_f1_score: 0.0227\n",
      "Epoch 424/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7037 - categorical_accuracy: 0.2762 - auc_1: 0.6226 - f1_score: 0.2108 - val_loss: 3.3354 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1831 - val_f1_score: 0.0227\n",
      "Epoch 425/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7061 - categorical_accuracy: 0.2634 - auc_1: 0.6279 - f1_score: 0.2157 - val_loss: 3.4083 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1845 - val_f1_score: 0.0258\n",
      "Epoch 426/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7072 - categorical_accuracy: 0.2744 - auc_1: 0.6200 - f1_score: 0.2156 - val_loss: 3.3167 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1903 - val_f1_score: 0.0258\n",
      "Epoch 427/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7143 - categorical_accuracy: 0.2689 - auc_1: 0.6204 - f1_score: 0.2021 - val_loss: 3.3820 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1892 - val_f1_score: 0.0258\n",
      "Epoch 428/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7050 - categorical_accuracy: 0.2449 - auc_1: 0.6349 - f1_score: 0.2005 - val_loss: 3.4263 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1849 - val_f1_score: 0.0258\n",
      "Epoch 429/500\n",
      "17/17 [==============================] - 1s 54ms/step - loss: 1.7118 - categorical_accuracy: 0.2413 - auc_1: 0.6157 - f1_score: 0.1823 - val_loss: 3.4990 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1869 - val_f1_score: 0.0227\n",
      "Epoch 430/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 56ms/step - loss: 1.6996 - categorical_accuracy: 0.2486 - auc_1: 0.6325 - f1_score: 0.1951 - val_loss: 3.3353 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1799 - val_f1_score: 0.0227\n",
      "Epoch 431/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7042 - categorical_accuracy: 0.2762 - auc_1: 0.6282 - f1_score: 0.2136 - val_loss: 3.3255 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1874 - val_f1_score: 0.0227\n",
      "Epoch 432/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7183 - categorical_accuracy: 0.2505 - auc_1: 0.6268 - f1_score: 0.2017 - val_loss: 3.4605 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1849 - val_f1_score: 0.0227\n",
      "Epoch 433/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7098 - categorical_accuracy: 0.2818 - auc_1: 0.6208 - f1_score: 0.2224 - val_loss: 3.3521 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1832 - val_f1_score: 0.0227\n",
      "Epoch 434/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7075 - categorical_accuracy: 0.2781 - auc_1: 0.6274 - f1_score: 0.2150 - val_loss: 3.4170 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1831 - val_f1_score: 0.0227\n",
      "Epoch 435/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.6954 - categorical_accuracy: 0.2652 - auc_1: 0.6333 - f1_score: 0.2157 - val_loss: 3.4104 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1891 - val_f1_score: 0.0227\n",
      "Epoch 436/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7124 - categorical_accuracy: 0.2818 - auc_1: 0.6144 - f1_score: 0.2176 - val_loss: 3.4443 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1849 - val_f1_score: 0.0258\n",
      "Epoch 437/500\n",
      "17/17 [==============================] - 1s 54ms/step - loss: 1.7089 - categorical_accuracy: 0.2781 - auc_1: 0.6249 - f1_score: 0.2131 - val_loss: 3.5147 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1832 - val_f1_score: 0.0227\n",
      "Epoch 438/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7054 - categorical_accuracy: 0.2762 - auc_1: 0.6241 - f1_score: 0.2139 - val_loss: 3.3996 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1844 - val_f1_score: 0.0227\n",
      "Epoch 439/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7043 - categorical_accuracy: 0.2799 - auc_1: 0.6132 - f1_score: 0.2149 - val_loss: 3.3207 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1864 - val_f1_score: 0.0258\n",
      "Epoch 440/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7112 - categorical_accuracy: 0.2762 - auc_1: 0.6197 - f1_score: 0.2112 - val_loss: 3.2982 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1881 - val_f1_score: 0.0277\n",
      "Epoch 441/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7004 - categorical_accuracy: 0.2394 - auc_1: 0.6266 - f1_score: 0.2070 - val_loss: 3.4665 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1814 - val_f1_score: 0.0258\n",
      "Epoch 442/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7055 - categorical_accuracy: 0.2670 - auc_1: 0.6322 - f1_score: 0.2083 - val_loss: 3.4649 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1844 - val_f1_score: 0.0195\n",
      "Epoch 443/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7107 - categorical_accuracy: 0.2726 - auc_1: 0.6167 - f1_score: 0.2021 - val_loss: 3.3746 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1846 - val_f1_score: 0.0227\n",
      "Epoch 444/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7095 - categorical_accuracy: 0.2541 - auc_1: 0.6259 - f1_score: 0.2022 - val_loss: 3.4260 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1835 - val_f1_score: 0.0227\n",
      "Epoch 445/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.6989 - categorical_accuracy: 0.2634 - auc_1: 0.6295 - f1_score: 0.1914 - val_loss: 3.3789 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1834 - val_f1_score: 0.0227\n",
      "Epoch 446/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7110 - categorical_accuracy: 0.2523 - auc_1: 0.6273 - f1_score: 0.2067 - val_loss: 3.4417 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1867 - val_f1_score: 0.0227\n",
      "Epoch 447/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7128 - categorical_accuracy: 0.2615 - auc_1: 0.6250 - f1_score: 0.2048 - val_loss: 3.3263 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1853 - val_f1_score: 0.0227\n",
      "Epoch 448/500\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 1.7061 - categorical_accuracy: 0.2523 - auc_1: 0.6305 - f1_score: 0.2005 - val_loss: 3.4067 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1832 - val_f1_score: 0.0175\n",
      "Epoch 449/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7035 - categorical_accuracy: 0.2689 - auc_1: 0.6270 - f1_score: 0.2051 - val_loss: 3.4337 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1807 - val_f1_score: 0.0227\n",
      "Epoch 450/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7022 - categorical_accuracy: 0.2652 - auc_1: 0.6240 - f1_score: 0.2083 - val_loss: 3.4090 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1849 - val_f1_score: 0.0258\n",
      "Epoch 451/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7105 - categorical_accuracy: 0.2670 - auc_1: 0.6275 - f1_score: 0.2030 - val_loss: 3.4441 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1822 - val_f1_score: 0.0258\n",
      "Epoch 452/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7101 - categorical_accuracy: 0.2652 - auc_1: 0.6213 - f1_score: 0.2053 - val_loss: 3.3283 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1822 - val_f1_score: 0.0227\n",
      "Epoch 453/500\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 1.7116 - categorical_accuracy: 0.2652 - auc_1: 0.6302 - f1_score: 0.2066 - val_loss: 3.4335 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1842 - val_f1_score: 0.0175\n",
      "Epoch 454/500\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 1.6980 - categorical_accuracy: 0.2781 - auc_1: 0.6234 - f1_score: 0.2140 - val_loss: 3.4181 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1816 - val_f1_score: 0.0175\n",
      "Epoch 455/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7022 - categorical_accuracy: 0.2670 - auc_1: 0.6286 - f1_score: 0.2080 - val_loss: 3.4596 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1872 - val_f1_score: 0.0175\n",
      "Epoch 456/500\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 1.6957 - categorical_accuracy: 0.2578 - auc_1: 0.6237 - f1_score: 0.1951 - val_loss: 3.4563 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1877 - val_f1_score: 0.0227\n",
      "Epoch 457/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.6964 - categorical_accuracy: 0.2468 - auc_1: 0.6239 - f1_score: 0.1971 - val_loss: 3.2914 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1870 - val_f1_score: 0.0206\n",
      "Epoch 458/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7033 - categorical_accuracy: 0.2781 - auc_1: 0.6237 - f1_score: 0.2188 - val_loss: 3.4240 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1829 - val_f1_score: 0.0227\n",
      "Epoch 459/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7045 - categorical_accuracy: 0.2597 - auc_1: 0.6231 - f1_score: 0.2050 - val_loss: 3.3950 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1865 - val_f1_score: 0.0227\n",
      "Epoch 460/500\n",
      "17/17 [==============================] - 1s 54ms/step - loss: 1.7021 - categorical_accuracy: 0.2689 - auc_1: 0.6304 - f1_score: 0.2072 - val_loss: 3.4027 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1846 - val_f1_score: 0.0227\n",
      "Epoch 461/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.6996 - categorical_accuracy: 0.2707 - auc_1: 0.6292 - f1_score: 0.2163 - val_loss: 3.4573 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1849 - val_f1_score: 0.0258\n",
      "Epoch 462/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.6965 - categorical_accuracy: 0.2560 - auc_1: 0.6322 - f1_score: 0.2065 - val_loss: 3.3921 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1826 - val_f1_score: 0.0258\n",
      "Epoch 463/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 59ms/step - loss: 1.6923 - categorical_accuracy: 0.2799 - auc_1: 0.6320 - f1_score: 0.2178 - val_loss: 3.3913 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1886 - val_f1_score: 0.0258\n",
      "Epoch 464/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.6979 - categorical_accuracy: 0.2726 - auc_1: 0.6178 - f1_score: 0.2115 - val_loss: 3.4970 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1774 - val_f1_score: 0.0227\n",
      "Epoch 465/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7082 - categorical_accuracy: 0.2634 - auc_1: 0.6221 - f1_score: 0.2078 - val_loss: 3.4340 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1823 - val_f1_score: 0.0175\n",
      "Epoch 466/500\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.7029 - categorical_accuracy: 0.2744 - auc_1: 0.6178 - f1_score: 0.205 - 1s 57ms/step - loss: 1.7029 - categorical_accuracy: 0.2744 - auc_1: 0.6178 - f1_score: 0.2058 - val_loss: 3.3878 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1838 - val_f1_score: 0.0227\n",
      "Epoch 467/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7243 - categorical_accuracy: 0.2726 - auc_1: 0.6126 - f1_score: 0.2100 - val_loss: 3.3931 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1856 - val_f1_score: 0.0227\n",
      "Epoch 468/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7008 - categorical_accuracy: 0.2597 - auc_1: 0.6287 - f1_score: 0.2084 - val_loss: 3.4459 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1862 - val_f1_score: 0.0227\n",
      "Epoch 469/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.6952 - categorical_accuracy: 0.2597 - auc_1: 0.6371 - f1_score: 0.2003 - val_loss: 3.4703 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1872 - val_f1_score: 0.0258\n",
      "Epoch 470/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7082 - categorical_accuracy: 0.2891 - auc_1: 0.6328 - f1_score: 0.2241 - val_loss: 3.4355 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1864 - val_f1_score: 0.0258\n",
      "Epoch 471/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7086 - categorical_accuracy: 0.2634 - auc_1: 0.6219 - f1_score: 0.2069 - val_loss: 3.5592 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1855 - val_f1_score: 0.0227\n",
      "Epoch 472/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7083 - categorical_accuracy: 0.2726 - auc_1: 0.6230 - f1_score: 0.2098 - val_loss: 3.3303 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1826 - val_f1_score: 0.0227\n",
      "Epoch 473/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7104 - categorical_accuracy: 0.2578 - auc_1: 0.6099 - f1_score: 0.2054 - val_loss: 3.2968 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1829 - val_f1_score: 0.0175\n",
      "Epoch 474/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7104 - categorical_accuracy: 0.2689 - auc_1: 0.6158 - f1_score: 0.2042 - val_loss: 3.4709 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1811 - val_f1_score: 0.0175\n",
      "Epoch 475/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7029 - categorical_accuracy: 0.2670 - auc_1: 0.6231 - f1_score: 0.2035 - val_loss: 3.3643 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1854 - val_f1_score: 0.0227\n",
      "Epoch 476/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7033 - categorical_accuracy: 0.2707 - auc_1: 0.6224 - f1_score: 0.2025 - val_loss: 3.3177 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1834 - val_f1_score: 0.0227\n",
      "Epoch 477/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7122 - categorical_accuracy: 0.2781 - auc_1: 0.6124 - f1_score: 0.2171 - val_loss: 3.4299 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1801 - val_f1_score: 0.0227\n",
      "Epoch 478/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7027 - categorical_accuracy: 0.2486 - auc_1: 0.6225 - f1_score: 0.2091 - val_loss: 3.4142 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1836 - val_f1_score: 0.0121\n",
      "Epoch 479/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7094 - categorical_accuracy: 0.2744 - auc_1: 0.6128 - f1_score: 0.2027 - val_loss: 3.3966 - val_categorical_accuracy: 0.0294 - val_auc_1: 0.1882 - val_f1_score: 0.0175\n",
      "Epoch 480/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7136 - categorical_accuracy: 0.2670 - auc_1: 0.6332 - f1_score: 0.1959 - val_loss: 3.4361 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1844 - val_f1_score: 0.0258\n",
      "Epoch 481/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.6946 - categorical_accuracy: 0.2486 - auc_1: 0.6394 - f1_score: 0.1878 - val_loss: 3.4926 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1926 - val_f1_score: 0.0227\n",
      "Epoch 482/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7171 - categorical_accuracy: 0.2210 - auc_1: 0.6109 - f1_score: 0.1824 - val_loss: 3.4077 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1838 - val_f1_score: 0.0258\n",
      "Epoch 483/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7017 - categorical_accuracy: 0.2670 - auc_1: 0.6308 - f1_score: 0.2147 - val_loss: 3.3626 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1881 - val_f1_score: 0.0227\n",
      "Epoch 484/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7058 - categorical_accuracy: 0.2670 - auc_1: 0.6343 - f1_score: 0.2057 - val_loss: 3.3623 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1872 - val_f1_score: 0.0258\n",
      "Epoch 485/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7064 - categorical_accuracy: 0.2597 - auc_1: 0.6277 - f1_score: 0.2036 - val_loss: 3.4582 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1891 - val_f1_score: 0.0258\n",
      "Epoch 486/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.6958 - categorical_accuracy: 0.2818 - auc_1: 0.6243 - f1_score: 0.2208 - val_loss: 3.4801 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1832 - val_f1_score: 0.0227\n",
      "Epoch 487/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7045 - categorical_accuracy: 0.2707 - auc_1: 0.6220 - f1_score: 0.2084 - val_loss: 3.3096 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1850 - val_f1_score: 0.0206\n",
      "Epoch 488/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7018 - categorical_accuracy: 0.2670 - auc_1: 0.6262 - f1_score: 0.2103 - val_loss: 3.4139 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1796 - val_f1_score: 0.0227\n",
      "Epoch 489/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7115 - categorical_accuracy: 0.2634 - auc_1: 0.6239 - f1_score: 0.2068 - val_loss: 3.5662 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1812 - val_f1_score: 0.0227\n",
      "Epoch 490/500\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 1.7083 - categorical_accuracy: 0.2541 - auc_1: 0.6176 - f1_score: 0.2045 - val_loss: 3.4764 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1852 - val_f1_score: 0.0227\n",
      "Epoch 491/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7034 - categorical_accuracy: 0.2818 - auc_1: 0.6251 - f1_score: 0.2119 - val_loss: 3.4487 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1851 - val_f1_score: 0.0258\n",
      "Epoch 492/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7042 - categorical_accuracy: 0.2707 - auc_1: 0.6312 - f1_score: 0.2140 - val_loss: 3.3716 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1856 - val_f1_score: 0.0258\n",
      "Epoch 493/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7119 - categorical_accuracy: 0.2726 - auc_1: 0.6236 - f1_score: 0.2112 - val_loss: 3.3553 - val_categorical_accuracy: 0.0221 - val_auc_1: 0.1864 - val_f1_score: 0.0121\n",
      "Epoch 494/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7199 - categorical_accuracy: 0.2413 - auc_1: 0.6187 - f1_score: 0.1791 - val_loss: 3.4056 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1800 - val_f1_score: 0.0258\n",
      "Epoch 495/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7073 - categorical_accuracy: 0.2707 - auc_1: 0.6227 - f1_score: 0.2191 - val_loss: 3.3302 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1867 - val_f1_score: 0.0258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7155 - categorical_accuracy: 0.2744 - auc_1: 0.6091 - f1_score: 0.2128 - val_loss: 3.5548 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1847 - val_f1_score: 0.0258\n",
      "Epoch 497/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7217 - categorical_accuracy: 0.2376 - auc_1: 0.6147 - f1_score: 0.1955 - val_loss: 3.3188 - val_categorical_accuracy: 0.0441 - val_auc_1: 0.1847 - val_f1_score: 0.0258\n",
      "Epoch 498/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.7104 - categorical_accuracy: 0.2670 - auc_1: 0.6177 - f1_score: 0.2009 - val_loss: 3.4288 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1845 - val_f1_score: 0.0227\n",
      "Epoch 499/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7003 - categorical_accuracy: 0.2505 - auc_1: 0.6316 - f1_score: 0.2014 - val_loss: 3.4165 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1857 - val_f1_score: 0.0206\n",
      "Epoch 500/500\n",
      "17/17 [==============================] - 1s 50ms/step - loss: 1.7059 - categorical_accuracy: 0.2670 - auc_1: 0.6182 - f1_score: 0.2061 - val_loss: 3.3657 - val_categorical_accuracy: 0.0368 - val_auc_1: 0.1838 - val_f1_score: 0.0227\n"
     ]
    }
   ],
   "source": [
    "if bi_class == 0:\n",
    "    full_model.compile(optimizer=Adam(lr=0.05), loss='categorical_crossentropy', metrics=[keras.metrics.CategoricalAccuracy(), keras.metrics.AUC(multi_label=True), tfa.metrics.F1Score(num_classes=num_classes)])\n",
    "    hist = full_model.fit(x=np.array(X_train).transpose([0,1,2,3]), y=np.array(Y_train).transpose([0,1]), batch_size=None, validation_split=0.2, epochs=500)\n",
    "else:\n",
    "    full_model.compile(optimizer=Adam(lr=0.05), loss='binary_crossentropy', metrics=['accuracy', keras.metrics.AUC()])\n",
    "    hist = full_model.fit(x=np.array(X_train).transpose([0,1,2,3]), y=np.array(Y_train).transpose([0,1]), batch_size=None, validation_split=0.2, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display acc, loss\n",
    "if bi_class == 0:\n",
    "    fig, loss_ax = plt.subplots()\n",
    "\n",
    "    acc_ax = loss_ax.twinx()\n",
    "\n",
    "    loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "\n",
    "    acc_ax.plot(hist.history['categorical_accuracy'], 'b', label='train acc')\n",
    "\n",
    "    loss_ax.set_xlabel('epoch')\n",
    "    loss_ax.set_ylabel('loss')\n",
    "    acc_ax.set_ylabel('accuray')\n",
    "\n",
    "    loss_ax.legend(loc='upper left')\n",
    "    acc_ax.legend(loc='lower left')\n",
    "\n",
    "    plt.show()\n",
    "else:\n",
    "    fig, loss_ax = plt.subplots()\n",
    "\n",
    "    acc_ax = loss_ax.twinx()\n",
    "\n",
    "    loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "\n",
    "    acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "\n",
    "    loss_ax.set_xlabel('epoch')\n",
    "    loss_ax.set_ylabel('loss')\n",
    "    acc_ax.set_ylabel('accuray')\n",
    "\n",
    "    loss_ax.legend(loc='upper left')\n",
    "    acc_ax.legend(loc='lower left')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Test AUC:  0.4868759290226682\n"
     ]
    }
   ],
   "source": [
    "predictions = full_model.predict(np.array(X_test).transpose([0,1,2,3]))\n",
    "\n",
    "if bi_class==0:\n",
    "    auc = roc_auc_score(Y_test, predictions, multi_class='raise')\n",
    "    print('Multiclass Test AUC: ', auc)\n",
    "else:\n",
    "    auc = roc_auc_score(Y_test, predictions)\n",
    "    print('Test AUC: ', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.,  5.,  0.,  7., 46.,  1.,  0.])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency = np.zeros(len(Y_test[0]))\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    frequency[np.argmax(predictions[i])] +=1\n",
    "\n",
    "frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.  8. 23. 21.  9.  4.  5.]\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(Y_test, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 2.2258 - categorical_accuracy: 0.1370 - auc_1: 0.4812 - f1_score: 0.1243\n",
      "\n",
      "Accuracy: 0.13698630034923553\n"
     ]
    }
   ],
   "source": [
    "if bi_class == 0:\n",
    "    test_loss, test_acc, test_auc, test_F1 = full_model.evaluate(np.array(X_test).transpose([0,1,2,3]),  np.array(Y_test).transpose([0,1]), verbose=2)\n",
    "    print('\\nAccuracy:', test_acc)\n",
    "else:\n",
    "    test_loss, test_acc, test_auc = full_model.evaluate(np.array(X_test).transpose([0,1,2,3]),  np.array(Y_test).transpose([0,1]), verbose=2)\n",
    "    print('\\nAccuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ###Visualize Latent Space###\n",
    "\n",
    "# x_test_encoded = encoder.predict(np.array(X_test).transpose([0,1,2,3]), batch_size=1)\n",
    "# plt.figure(figsize=(6, 6))\n",
    "# plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=Y_test)\n",
    "# plt.colorbar()\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
