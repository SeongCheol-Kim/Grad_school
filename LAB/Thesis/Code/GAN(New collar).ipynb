{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트 해볼 것  \n",
    "https://flonelin.wordpress.com/2019/12/14/regularization-in-deep-learning/  \n",
    "\n",
    "\n",
    "activation - gap - bn - dropout  \n",
    "activation - bn - dropout - gap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 1939572040513638982,\n",
       " name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 18155261465793276349\n",
       " physical_device_desc: \"device: XLA_CPU device\",\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 3129973147\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 17249188117991423719\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\",\n",
       " name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 17510258188163265145\n",
       " physical_device_desc: \"device: XLA_GPU device\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os, sys\n",
    "from os.path import join, dirname\n",
    "\n",
    "import datetime, time\n",
    "import csv\n",
    "from glob import glob\n",
    "import chardet\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, MaxAbsScaler, MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Conv2D, SimpleRNN, LSTM, GRU, Reshape, RepeatVector, Conv2DTranspose, Conv1D, Conv1DTranspose, ConvLSTM2D\n",
    "from tensorflow.keras.layers import MaxPooling1D, MaxPooling2D, Bidirectional, TimeDistributed,  Attention, BatchNormalization, GlobalAveragePooling1D, Dropout, GlobalMaxPool1D\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.optimizers import Adadelta, RMSprop,SGD,Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "\n",
    "from IPython.display import SVG\n",
    "\n",
    "import imblearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(tf.__version__)\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7                           # {\"0\" : \"Playing\", \"1\" : \"Talking\", \"2\" : \"Petting\", \"3\" : \"TV / Radio\", \"4\" : \"Eating / Cooking\", \"5\" : \"Moved It\", \"6\" : \"None of the above\", \"7\" : \"Other\"}\n",
    "time_offset = 10                           # 5초 단위 window: 50, 10초 단위 window: 90, 15초 단위 window: 128\n",
    "window_size = 50\n",
    "overlap_ratio = 0.5\n",
    "bi_class = 6                              # Binary Classification (1 : Playing or not, 2 : Talking or not, 3 : Petting or not, 4: TV / Radio or not, 5 : Eating / Cooking or not, 6 : Moved It or not)\n",
    "cross_val = 0\n",
    "rand_st=2\n",
    "mode = 0                                 # Split data {0: Didn't split, 1: US only, 2: Korea only, 3: train with US and test with Korea 4: train with Korea and test with US}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fname = '../Data/Preprocessed(new)/preprocessed_data(New collar_2).csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_fname)\n",
    "data = data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iaq = data['iaq']\n",
    "iaq_cat = []\n",
    "\n",
    "for num in iaq:\n",
    "    if num < 50 and num >=0:\n",
    "        iaq_cat.append('Good')\n",
    "    elif num >= 50 and num < 100:\n",
    "        iaq_cat.append('Average')\n",
    "    elif num >= 100 and num < 150:\n",
    "        iaq_cat.append('Little bad')\n",
    "    elif num >= 150 and num < 200:\n",
    "        iaq_cat.append('Bad')\n",
    "    elif num >= 200 and num < 300:\n",
    "        iaq_cat.append('Worse')\n",
    "    elif num >= 300 and num <= 500:\n",
    "        iaq_cat.append('Very bad')\n",
    "    else:\n",
    "        print(num)\n",
    "data['iaq_cat'] = iaq_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data,pd.get_dummies(data['sound category'])],axis=1)         # Onehot encode sound category\n",
    "data = pd.concat([data,pd.get_dummies(data['orientation_cat'])],axis=1)        # Onehot encode orientation category\n",
    "data = pd.concat([data,pd.get_dummies(data['iaq_cat'])],axis=1)                # Onehot encode iaq category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rowID list\n",
    "rowID_list = np.array(data['RowID'].drop_duplicates())\n",
    "data = data.to_records(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# data['pressure'] = scaler.fit_transform(data['pressure'].reshape(-1,1)).reshape(-1)\n",
    "data['gasResistance'] = scaler.fit_transform(data['gasResistance'].reshape(-1,1)).reshape(-1)\n",
    "data['staticIaq'] = scaler.fit_transform(data['staticIaq'].reshape(-1,1)).reshape(-1)\n",
    "data['co2Equivalent'] = scaler.fit_transform(data['co2Equivalent'].reshape(-1,1)).reshape(-1)\n",
    "data['breathVocEquivalent'] = scaler.fit_transform(data['breathVocEquivalent'].reshape(-1,1)).reshape(-1)\n",
    "data['audioLevel'] = scaler.fit_transform(data['audioLevel'].reshape(-1,1)).reshape(-1)\n",
    "data['rawTemp'] = scaler.fit_transform(data['rawTemp'].reshape(-1,1)).reshape(-1)\n",
    "data['rawHumidity'] = scaler.fit_transform(data['rawHumidity'].reshape(-1,1)).reshape(-1)\n",
    "data['pressure'] = scaler.fit_transform(data['pressure'].reshape(-1,1)).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split US and Korea\n",
    "us_rowIDs = []\n",
    "korea_rowIDs = []\n",
    "\n",
    "if mode != 0:\n",
    "    for rowid in rowID_list:\n",
    "    #     print(rowid, rowid[0])\n",
    "        if rowid[0] == '1':\n",
    "            korea_rowIDs.append(rowid)\n",
    "        else:\n",
    "            us_rowIDs.append(rowid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_col_name = ['accX', 'accY', 'accZ', 'chord', 'orientation', 'ir', 'full', 'iaq', 'iaqAccuracy', 'rawTemp',\n",
    "#                     'pressure', 'rawHumidity', 'gasResistance', 'compGasAccuracy', 'gasPercentageAccuracy', 'temperature', \n",
    "#                     'humidity', 'staticIaq', 'statIaqAccuracy', 'co2Equivalent', 'co2Accuracy', 'breathVocEquivalent', \n",
    "#                     'breathVocAccuracy', 'audioLevel', 'Loud', 'Moderate', 'Quiet']\n",
    "feature_col_name = ['accX', 'accY', 'accZ', 'arc', 'full', 'iaq', 'rawTemp',\n",
    "                    'pressure', 'rawHumidity', 'gasResistance', 'staticIaq', 'co2Equivalent', 'breathVocEquivalent', \n",
    "                    'audioLevel', 'Loud', 'Moderate', 'Quiet', 'Landscape Left Back', 'Landscape Left Front', 'Landscape Right Back',\n",
    "                    'Landscape Right Front', 'Portrait Down Back', 'Portrait Down Front', 'Portrait Up Back', \n",
    "                    'Portrait Up Front', 'Average', 'Bad', 'Good', 'Little bad', 'Very bad', 'Worse']\n",
    "target_col_name = ['Modality_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_num = len(feature_col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "us_X = []\n",
    "korea_X = []\n",
    "\n",
    "Y = []\n",
    "us_Y = []\n",
    "korea_Y = []\n",
    "\n",
    "\n",
    "if mode != 0:\n",
    "    for rowID in us_rowIDs:\n",
    "        #Split raw data by rowID & split X, Y data\n",
    "        tmp_data = data[data['RowID'] == rowID]\n",
    "        feature = tmp_data[feature_col_name]\n",
    "        feature = np.array(feature.tolist())\n",
    "        target = tmp_data[target_col_name][0][0]\n",
    "        target = np.array(target.tolist())\n",
    "        us_X.append(feature)\n",
    "        us_Y.append(target)\n",
    "    \n",
    "    for rowID in korea_rowIDs:\n",
    "        #Split raw data by rowID & split X, Y data\n",
    "        tmp_data = data[data['RowID'] == rowID]\n",
    "        feature = tmp_data[feature_col_name]\n",
    "        feature = np.array(feature.tolist())\n",
    "        target = tmp_data[target_col_name][0][0]\n",
    "        target = np.array(target.tolist())\n",
    "        korea_X.append(feature)\n",
    "        korea_Y.append(target)\n",
    "\n",
    "else:\n",
    "    for rowID in rowID_list:\n",
    "        #Split raw data by rowID & split X, Y data\n",
    "        tmp_data = data[data['RowID'] == rowID]\n",
    "        feature = tmp_data[feature_col_name]\n",
    "        feature = np.array(feature.tolist())\n",
    "        target = tmp_data[target_col_name][0][0]\n",
    "        target = np.array(target.tolist())\n",
    "        X.append(feature)\n",
    "        Y.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bi_class != 0:\n",
    "    #Transit multi classification to binary classification\n",
    "    if mode != 0:\n",
    "        for idx in range(len(us_Y)):\n",
    "            if us_Y[idx] == bi_class-1:\n",
    "                us_Y[idx]=1\n",
    "            else:\n",
    "                us_Y[idx]=0\n",
    "                \n",
    "        for idx in range(len(korea_Y)):\n",
    "            if korea_Y[idx] == bi_class-1:\n",
    "                korea_Y[idx]=1\n",
    "            else:\n",
    "                korea_Y[idx]=0\n",
    "    else:\n",
    "        for idx in range(len(Y)):\n",
    "            if Y[idx] == bi_class-1:\n",
    "                Y[idx]=1\n",
    "            else:\n",
    "                Y[idx]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_preprocess(X, window_size, overlap_ratio):\n",
    "    #Transform data shape using the set time window\n",
    "    processed_X = []\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        tmp_X = X[i]\n",
    "        tmp = []\n",
    "        start_row = 0\n",
    "        end_row = start_row + window_size\n",
    "        \n",
    "        if len(tmp_X)%int(window_size*overlap_ratio) == 0:\n",
    "            for j in range(len(tmp_X)//int(window_size*overlap_ratio)-1):\n",
    "                tmp.append(tmp_X[int(start_row):int(end_row)])\n",
    "                start_row += (window_size*overlap_ratio)\n",
    "                end_row += (window_size*overlap_ratio)\n",
    "        else:\n",
    "            for j in range(len(tmp_X)//int(window_size*overlap_ratio)+1):\n",
    "                if end_row > len(tmp_X):\n",
    "                    \n",
    "                    tmp.append(tmp_X[-window_size:])\n",
    "                    start_row += (window_size*overlap_ratio)\n",
    "                    end_row += (window_size*overlap_ratio)\n",
    "                    break\n",
    "                else:\n",
    "                    \n",
    "                    tmp.append(tmp_X[int(start_row):int(end_row)])\n",
    "                    start_row += (window_size*overlap_ratio)\n",
    "                    end_row += (window_size*overlap_ratio)\n",
    "        processed_X.append(tmp)\n",
    "        \n",
    "    return processed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode != 0:\n",
    "    us_X = X_preprocess(us_X, window_size, overlap_ratio)        ### preprocess with input shape\n",
    "    korea_X = X_preprocess(korea_X, window_size, overlap_ratio)\n",
    "    if bi_class == 0:\n",
    "        ### onehot encode Y\n",
    "        us_Y = np.eye(num_classes)[us_Y]\n",
    "        korea_Y = np.eye(num_classes)[korea_Y]\n",
    "    else: \n",
    "        us_Y = np.eye(2)[us_Y]\n",
    "        korea_Y = np.eye(2)[korea_Y]\n",
    "\n",
    "else:    \n",
    "    X = X_preprocess(X, window_size, overlap_ratio)        ### preprocess with input shape\n",
    "    if bi_class == 0:\n",
    "        ### onehot encode Y\n",
    "        Y = np.eye(num_classes)[Y]\n",
    "    else: Y = np.eye(2)[Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample X Data size\n",
    "\n",
    "def subsample(X, min_us_len, min_korea_len):\n",
    "    sampled_X = []\n",
    "    addon = 0\n",
    "    \n",
    "    if min_korea_len > min_us_len:\n",
    "        if np.array(X).shape[1] == min_us_len:\n",
    "            return X\n",
    "        else:\n",
    "            interval = min_korea_len / min_us_len\n",
    "            quotient = int(np.modf(interval)[1])\n",
    "            remainder = np.modf(interval)[0]\n",
    "\n",
    "            for i in range(len(X)):\n",
    "                temp_X = []\n",
    "                for j in range(min_us_len):\n",
    "                    if addon >= 1:\n",
    "                        temp_X.append(X[i][j*quotient + 1])\n",
    "                        addon = 0\n",
    "                        addon += remainder\n",
    "                    else:\n",
    "                        temp_X.append(X[i][j*quotient])\n",
    "                        addon += remainder\n",
    "\n",
    "                sampled_X.append(temp_X)\n",
    "            \n",
    "    else:\n",
    "        if np.array(X).shape[1] == min_korea_len:\n",
    "            return X\n",
    "        else:\n",
    "            interval = min_us_len / min_korea_len\n",
    "            quotient = int(np.modf(interval)[1])\n",
    "            remainder = np.modf(interval)[0]\n",
    "\n",
    "            for i in range(len(X)):\n",
    "                temp_X = []\n",
    "                for j in range(min_korea_len):\n",
    "                    if addon >= 1:\n",
    "                        temp_X.append(X[i][j*quotient + 1])\n",
    "                        addon = 0\n",
    "                        addon += remainder\n",
    "                    else:\n",
    "                        temp_X.append(X[i][j*quotient])\n",
    "                        addon += remainder\n",
    "\n",
    "            sampled_X.append(temp_X)\n",
    "                    \n",
    "    return sampled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit to minimum length\n",
    "\n",
    "min_len = 99999999\n",
    "min_us_len = 99999999\n",
    "min_korea_len = 99999999\n",
    "min_X = []\n",
    "min_us_X = []\n",
    "min_korea_X = []\n",
    "\n",
    "if mode == 0:\n",
    "#     print('Start mode 0\\n')\n",
    "    for x in X:\n",
    "        if len(x) < min_len:\n",
    "            min_len = len(x)\n",
    "#     print(min_len)\n",
    "\n",
    "    for x in X:\n",
    "        min_X.append(x[:min_len])\n",
    "\n",
    "else:\n",
    "    for x in us_X:\n",
    "        if len(x) < min_us_len:\n",
    "            min_us_len = len(x)\n",
    "            \n",
    "    for x in korea_X:\n",
    "        if len(x) < min_korea_len:\n",
    "            min_korea_len = len(x)\n",
    "            \n",
    "    if mode == 1:\n",
    "        for x in us_X:\n",
    "            min_us_X.append(x[:min_us_len])\n",
    "        for x in korea_X:\n",
    "            min_korea_X.append(x[:min_korea_len])\n",
    "        \n",
    "    elif mode == 2:\n",
    "        min_korea_len = 60\n",
    "        for x in us_X:\n",
    "            min_us_X.append(x[:min_us_len])\n",
    "        for x in korea_X:\n",
    "            min_korea_X.append(x[:min_korea_len])\n",
    "        \n",
    "    else:\n",
    "        if min_korea_len < min_us_len:\n",
    "            min_len = min_korea_len\n",
    "        else: min_len = min_us_len\n",
    "\n",
    "        for x in us_X:\n",
    "            min_us_X.append(x[:min_len])\n",
    "\n",
    "        for x in korea_X:\n",
    "            min_korea_X.append(x[:min_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop duplicate\n",
    "\n",
    "if bi_class != 0:\n",
    "    \n",
    "    target_list = []\n",
    "    us_target_list = []\n",
    "    korea_target_list = []\n",
    "    del_list = []\n",
    "    us_del_list = []\n",
    "    korea_del_list = []\n",
    "    \n",
    "    if mode == 0:\n",
    "        for i in range(len(Y)):\n",
    "            if Y[i][1] == 1:\n",
    "                target_list.append(i)\n",
    "\n",
    "        for i in target_list:\n",
    "            for j in range(len(min_X)):\n",
    "                if j in target_list:\n",
    "                    pass\n",
    "                else:\n",
    "                    if np.array_equal(np.array(min_X[i]), np.array(min_X[j])):\n",
    "                        if j not in del_list:\n",
    "                            del_list.append(j)\n",
    "        X = []\n",
    "        Target = []\n",
    "\n",
    "        for i in range(len(Y)):\n",
    "            if i not in del_list:\n",
    "                X.append(min_X[i])\n",
    "                Target.append(Y[i])\n",
    "                \n",
    "    else:\n",
    "        for i in range(len(us_Y)):\n",
    "            if us_Y[i][1] == 1:\n",
    "                us_target_list.append(i)\n",
    "\n",
    "        for i in us_target_list:\n",
    "            for j in range(len(min_us_X)):\n",
    "                if j in us_target_list:\n",
    "                    pass\n",
    "                else:\n",
    "                    if np.array_equal(np.array(min_us_X[i]), np.array(min_us_X[j])):\n",
    "                        if j not in us_del_list:\n",
    "                            us_del_list.append(j)\n",
    "                            \n",
    "        for i in range(len(korea_Y)):\n",
    "            if korea_Y[i][1] == 1:\n",
    "                korea_target_list.append(i)\n",
    "\n",
    "        for i in korea_target_list:\n",
    "            for j in range(len(min_korea_X)):\n",
    "                if j in korea_target_list:\n",
    "                    pass\n",
    "                else:\n",
    "                    if np.array_equal(np.array(min_korea_X[i]), np.array(min_korea_X[j])):\n",
    "                        if j not in korea_del_list:\n",
    "                            korea_del_list.append(j)\n",
    "        \n",
    "        us_X = []\n",
    "        us_Target = []\n",
    "        korea_X = []\n",
    "        korea_Target = []\n",
    "\n",
    "        for i in range(len(us_Y)):\n",
    "            if i not in us_del_list:\n",
    "                us_X.append(min_us_X[i])\n",
    "                us_Target.append(us_Y[i])\n",
    "                \n",
    "        for i in range(len(korea_Y)):\n",
    "            if i not in korea_del_list:\n",
    "                korea_X.append(min_korea_X[i])\n",
    "                korea_Target.append(korea_Y[i])\n",
    "\n",
    "else:\n",
    "    target_list = []\n",
    "    us_target_list = []\n",
    "    korea_target_list = []\n",
    "    del_list = []\n",
    "    us_del_list = []\n",
    "    korea_del_list = []\n",
    "    \n",
    "    if mode == 0:\n",
    "        X = min_X\n",
    "        Target = Y\n",
    "\n",
    "    else:\n",
    "        for i in range(len(us_Y)):\n",
    "            if us_Y[i][1] == 1:\n",
    "                us_target_list.append(i)\n",
    "\n",
    "        for i in us_target_list:\n",
    "            for j in range(len(min_us_X)):\n",
    "                if j in us_target_list:\n",
    "                    pass\n",
    "                else:\n",
    "                    if np.array_equal(np.array(min_us_X[i]), np.array(min_us_X[j])):\n",
    "                        if j not in us_del_list:\n",
    "                            us_del_list.append(j)\n",
    "\n",
    "        for i in range(len(korea_Y)):\n",
    "            if korea_Y[i][1] == 1:\n",
    "                korea_target_list.append(i)\n",
    "\n",
    "        for i in korea_target_list:\n",
    "            for j in range(len(min_korea_X)):\n",
    "                if j in korea_target_list:\n",
    "                    pass\n",
    "                else:\n",
    "                    if np.array_equal(np.array(min_korea_X[i]), np.array(min_korea_X[j])):\n",
    "                        if j not in korea_del_list:\n",
    "                            korea_del_list.append(j)\n",
    "\n",
    "        us_X = []\n",
    "        us_Target = []\n",
    "        korea_X = []\n",
    "        korea_Target = []\n",
    "\n",
    "        for i in range(len(us_Y)):\n",
    "            if i not in us_del_list:\n",
    "                us_X.append(min_us_X[i])\n",
    "                us_Target.append(us_Y[i])\n",
    "\n",
    "        for i in range(len(korea_Y)):\n",
    "            if i not in korea_del_list:\n",
    "                korea_X.append(min_korea_X[i])\n",
    "                korea_Target.append(korea_Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 0:\n",
    "#     X = subsample(X, min_us_len, min_korea_len)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Target, test_size=0.2)\n",
    "    \n",
    "elif mode == 1:\n",
    "    us_X = subsample(us_X, min_us_len, min_korea_len)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(us_X, us_Target, test_size=0.2)\n",
    "\n",
    "elif mode == 2:\n",
    "    korea_X = subsample(korea_X, min_us_len, min_korea_len)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(korea_X, korea_Target, test_size=0.2)\n",
    "\n",
    "elif mode == 3:\n",
    "    X_train = subsample(us_X, min_us_len, min_korea_len)\n",
    "    X_test = subsample(korea_X, min_us_len, min_korea_len)\n",
    "    Y_train = us_Target \n",
    "    Y_test = korea_Target\n",
    "\n",
    "else:\n",
    "    X_train = subsample(korea_X, min_us_len, min_korea_len)\n",
    "    X_test = subsample(us_X, min_us_len, min_korea_len)\n",
    "    Y_train = korea_Target\n",
    "    Y_test = us_Target "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------\n",
    "### End Setup, separate model sections\n",
    "-----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative Replay #1 - GAN\n",
    "- https://keras.io/examples/generative/dcgan_overriding_train_step/\n",
    "- https://towardsdatascience.com/writing-your-first-generative-adversarial-network-with-keras-2d16fd8d4889\n",
    "- https://www.tensorflow.org/tutorials/generative/dcgan\n",
    "- https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-a-1-dimensional-function-from-scratch-in-keras/\n",
    "- https://www.kaggle.com/function9/bidirectional-lstm-gan-music-generation\n",
    "- https://wiki.pathmind.com/generative-adversarial-network-gan\n",
    "- https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=chunjein&logNo=221589624838  \n",
    "    \n",
    "http://www.smartdesignlab.org/DL/%EC%8B%A0%EA%B8%B0%EC%88%A0/GAN_keras.html - 참고 필요  \n",
    "http://www.smartdesignlab.org/DL/GAN_tf2.html  \n",
    "https://deep-eye.tistory.com/63  \n",
    "https://velog.io/@hyebbly/Deep-Learning-Loss-%EC%A0%95%EB%A6%AC-1-GAN-loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sckim\\.conda\\envs\\grad\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "### Data Setup ###\n",
    "\n",
    "#Rebalance the data\n",
    "if bi_class == 0:\n",
    "    sm = imblearn.over_sampling.SMOTE()\n",
    "    X_shape = np.array(X_train).shape\n",
    "    Y_shape = np.array(Y_train).shape\n",
    "    new_X_train = np.array(X_train).reshape(X_shape[0], X_shape[1]*X_shape[2]*X_shape[3])\n",
    "    Y_train = np.array(Y_train).astype('float64')\n",
    "    X_train, Y_train = sm.fit_resample(new_X_train, Y_train)\n",
    "    temp = X_train.shape\n",
    "    X_train = X_train.reshape([temp[0], X_shape[1], X_shape[2], X_shape[3]])\n",
    "    Y_train = Y_train.reshape(temp[0], Y_shape[1])\n",
    "\n",
    "else:\n",
    "    sm = imblearn.over_sampling.SMOTE()         # random state do not set\n",
    "    origin_shape = np.array(X_train).shape\n",
    "    new_X_train = np.array(X_train).reshape(origin_shape[0], origin_shape[1]*origin_shape[2]*origin_shape[3])\n",
    "    Y_train = np.array(Y_train).astype('float64')\n",
    "    X_train, Y_train = sm.fit_resample(new_X_train, Y_train)\n",
    "    temp = X_train.shape\n",
    "    X_train = X_train.reshape([temp[0], origin_shape[1], origin_shape[2], origin_shape[3]])\n",
    "    Y_train = np.eye(2)[Y_train.reshape(temp[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 276, 50, 31)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model(input_shape, feature_num=feature_num):\n",
    "    \n",
    "    gen = Dense(feature_num, use_bias=False, name='gen_Dense1')(input_shape)\n",
    "    \n",
    "#     gen = BatchNormalization(momentum=0.8, name='gen_BM1')(gen)\n",
    "    gen = RepeatVector(276)(gen)\n",
    "    gen = layers.LeakyReLU(alpha=0.2, name='gen_activ1')(gen)\n",
    "    gen = GRU(units=50, activation='tanh', recurrent_activation='sigmoid',return_sequences=True, name='gen_rnn1')(gen)\n",
    "#     gen = BatchNormalization(momentum=0.8, name='gen_BM2')(gen)\n",
    "    gen = tf.expand_dims(gen, -1)\n",
    "#     gen = Reshape((576,24,1), name='gen_reshape1')(gen)\n",
    "    gen_output = Conv2DTranspose(feature_num, 1, padding=\"same\", activation='relu', name='gen_conv1')(gen)\n",
    "    \n",
    "    model = Model(inputs=input_shape, outputs=gen_output, name='Generator')          \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 31)]              0         \n",
      "_________________________________________________________________\n",
      "gen_Dense1 (Dense)           (None, 31)                961       \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 276, 31)           0         \n",
      "_________________________________________________________________\n",
      "gen_activ1 (LeakyReLU)       (None, 276, 31)           0         \n",
      "_________________________________________________________________\n",
      "gen_rnn1 (GRU)               (None, 276, 50)           12450     \n",
      "_________________________________________________________________\n",
      "tf_op_layer_ExpandDims (Tens [(None, 276, 50, 1)]      0         \n",
      "_________________________________________________________________\n",
      "gen_conv1 (Conv2DTranspose)  (None, 276, 50, 31)       62        \n",
      "=================================================================\n",
      "Total params: 13,473\n",
      "Trainable params: 13,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 276, 50, 31)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 노이즈 만들어서 generator에 넣은 후 나오는 이미지 출력 (확인용)\n",
    "\n",
    "g_input_shape = keras.Input(shape=(31,))\n",
    "generator = make_generator_model(g_input_shape)\n",
    "generator.summary()\n",
    "\n",
    "noise = tf.random.normal([1, 31])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "np.array(generated_image[:, :, :, :]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://velog.io/@byu0hyun/%EB%94%A5%EB%9F%AC%EB%8B%9D-CNN-Conv2D-Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model(input_shape, RNN_unit=200, feature_num = feature_num):\n",
    "#     print(input_shape.shape[0])\n",
    "    rnn_input = Reshape((input_shape.shape[1], input_shape.shape[2]*input_shape.shape[3]), name='reshape1')(input_shape)\n",
    "    disc = GRU(units=RNN_unit, activation='tanh', recurrent_activation='sigmoid', return_sequences=True, name='disc_rnn1')(rnn_input)\n",
    "#     disc = LSTM(units=RNN_unit, activation='tanh', recurrent_activation='sigmoid', return_sequences=True, name='disc_rnn2')(disc)\n",
    "#     disc = LSTM(units=RNN_unit, activation='tanh', recurrent_activation='sigmoid', return_sequences=True, kernel_regularizer='l1', name='disc_rnn2')(disc)\n",
    "    disc = BatchNormalization(name='disc_BM1')(disc)\n",
    "    disc = Conv1D(64, 8, padding='same', name='disc_conv1')(disc)\n",
    "#     disc = Conv1D(128, 8, padding='same', name='disc_conv2')(disc)\n",
    "#     disc = GlobalMaxPool1D()(disc)\n",
    "    disc = GlobalAveragePooling1D()(disc)\n",
    "    disc = BatchNormalization(name='disc_BM2')(disc)\n",
    "    disc = layers.LeakyReLU(alpha=0.2, name='disc_activ1')(disc)\n",
    "#     disc = Dropout(0.2)(disc)\n",
    "    \n",
    "\n",
    "    return disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_disc_output(discriminator):\n",
    "\n",
    "    discriminator_output = Dense(1, activation='sigmoid')(discriminator)\n",
    "    \n",
    "    return discriminator_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 276, 50, 31)]     0         \n",
      "_________________________________________________________________\n",
      "reshape1 (Reshape)           (None, 276, 1550)         0         \n",
      "_________________________________________________________________\n",
      "disc_rnn1 (GRU)              (None, 276, 200)          1051200   \n",
      "_________________________________________________________________\n",
      "disc_BM1 (BatchNormalization (None, 276, 200)          800       \n",
      "_________________________________________________________________\n",
      "disc_conv1 (Conv1D)          (None, 276, 64)           102464    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "disc_BM2 (BatchNormalization (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "disc_activ1 (LeakyReLU)      (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,154,785\n",
      "Trainable params: 1,154,257\n",
      "Non-trainable params: 528\n",
      "_________________________________________________________________\n",
      "tf.Tensor([[0.5294397]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# image를 discriminator에 넣었을 때 판별값이 나옴 (예시. 확인용)\n",
    "input_shape = np.array(X_train[0]).shape\n",
    "feature_input = keras.Input(shape=input_shape)\n",
    "\n",
    "discriminator = Model(inputs=feature_input, outputs=make_disc_output(make_discriminator_model(feature_input)), name='Discriminator')\n",
    "discriminator.summary()\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(0.0005, 0.5)\n",
    "\n",
    "generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 31)]              0         \n",
      "_________________________________________________________________\n",
      "Generator (Functional)       (None, 276, 50, 31)       13473     \n",
      "_________________________________________________________________\n",
      "Discriminator (Functional)   (None, 1)                 1154785   \n",
      "=================================================================\n",
      "Total params: 1,168,258\n",
      "Trainable params: 13,473\n",
      "Non-trainable params: 1,154,785\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Combined Model\n",
    "# 랜덤으로 만든 이미지로부터 학습해서 새로운 이미지를 만들어내는 generator의 데이터를 discriminator가 분류. \n",
    "\n",
    "g_input_shape = keras.Input(shape=(31,))\n",
    "# noise = tf.random.normal([64, feature_num])\n",
    "\n",
    "fake_input = generator(g_input_shape)\n",
    "\n",
    "\n",
    "# 모델을 합쳐서 학습하기 때문에 발란스 때문에 discriminator는 학습을 꺼둠. 우리는 generator만 학습\n",
    "discriminator.trainable = False\n",
    "\n",
    "# discriminator에 이미지를 입력으로 넣어서 진짜이미지인지 가짜이미지인지 판별\n",
    "valid = discriminator(fake_input)\n",
    "\n",
    "# generator와 discriminator 모델 합침. (노이즈가 인풋으로 들어가서 판별결과가 아웃풋으로 나오게)\n",
    "# discriminator를 속이도록 generator를 학습\n",
    "combined = Model(g_input_shape, valid)\n",
    "combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "combined.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameter 설정 \n",
    "EPOCHS = 500\n",
    "noise_dim = feature_num\n",
    "num_examples_to_generate = 16\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# 데이터 배치를 만들고 섞습니다.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(np.array(X_train).transpose([0,1,2,3])).shuffle(len(X_train)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs, batch_size=BATCH_SIZE):\n",
    "    history = []\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        print ('Epoch {} '.format(epoch + 1))\n",
    "        \n",
    "        e_g_loss = 0\n",
    "        e_d_loss = 0\n",
    "        \n",
    "        for data_batch in dataset:\n",
    "#             train_step(data_batch)\n",
    "        \n",
    "#             # batch_size만큼 이미지와 라벨을 랜덤으로 뽑음\n",
    "#             idx = np.random.randint(0, dataset.shape[0], batch_size)\n",
    "#             inputs = dataset[idx]\n",
    "\n",
    "            noise = tf.random.normal([len(data_batch), feature_num])\n",
    "            valid = np.ones((len(data_batch), 1))\n",
    "            fake = np.zeros((len(data_batch), 1))\n",
    "    #         history = []\n",
    "\n",
    "             # Sample noise 생성(batch_size만큼)\n",
    "            noise = np.random.normal(0, 1, (len(data_batch), 31))\n",
    "\n",
    "            # noise를 generator에 넣어서 fake image 이미지 생성\n",
    "            gen_inputs = generator.predict(noise)\n",
    "\n",
    "            # discriminator를 학습함. 진짜 이미지는 1이 나오게, 가짜 이미지는 0이 나오게\n",
    "            # discriminator가 이미지를 판별한 값과 valid와 fake가 \n",
    "            # 각각 같이 들어가서 binary_crossentropy으로 계산되어 업데이트함.\n",
    "            d_loss_real = discriminator.train_on_batch(data_batch, valid)\n",
    "            d_loss_fake = discriminator.train_on_batch(gen_inputs, fake)\n",
    "\n",
    "            # real을 넣었을 때와 fake를 넣었을 때의 discriminator의 loss값과 accracy값의 평균을 구함.\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            e_d_loss = d_loss\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            # noise 생성\n",
    "    #         noise = np.random.normal(0, 1, (batch_size, feature_num))\n",
    "            noise = tf.random.normal([len(data_batch), noise_dim])\n",
    "\n",
    "            # noise가 들어가서 discriminator가 real image라고 판단하도록 generator를 학습\n",
    "            g_loss = combined.train_on_batch(noise, valid)\n",
    "            e_g_loss = g_loss\n",
    "\n",
    "        history.append([e_d_loss, e_g_loss])\n",
    "        print(\"D loss: %f, G loss: %f\" % (d_loss, g_loss))\n",
    "    \n",
    "        # print (' 에포크 {} 에서 걸린 시간은 {} 초 입니다'.format(epoch +1, time.time()-start))\n",
    "        print ('Runtime: {} sec'.format(time.time()-start))\n",
    "        \n",
    "    # Display D_loss, G_loss\n",
    "    \n",
    "    fig, ax = plt.subplots(2, figsize = (10,10))\n",
    "    ax[0].plot(list(zip(*history))[0], 'y', label='D_loss')\n",
    "    ax[0].set_xlabel('Time')\n",
    "    ax[0].set_ylabel('loss')\n",
    "    ax[0].set_title(\"D_loss\")\n",
    "    ax[0].legend(loc='upper left')\n",
    "    \n",
    "    \n",
    "    ax[1].plot(list(zip(*history))[1], 'b', label='G_loss')\n",
    "    ax[1].set_xlabel('Time')\n",
    "    ax[1].set_ylabel('loss')\n",
    "    ax[1].set_title(\"G_loss\")\n",
    "    ax[1].legend(loc='upper left')\n",
    "    \n",
    "#     fig, loss_ax = plt.subplots()\n",
    "\n",
    "#     acc_ax = loss_ax.twinx()\n",
    "\n",
    "#     loss_ax.plot(list(zip(*history))[0], 'y', label='D_loss')\n",
    "\n",
    "#     acc_ax.plot(list(zip(*history))[1], 'b', label='G_loss')\n",
    "\n",
    "#     loss_ax.set_xlabel('epoch')\n",
    "#     loss_ax.set_ylabel('D_loss')\n",
    "#     acc_ax.set_ylabel('G_loss')\n",
    "\n",
    "#     loss_ax.legend(loc='upper left')\n",
    "#     acc_ax.legend(loc='upper right')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \n",
      "D loss: 0.617651, G loss: 0.664708\n",
      "Runtime: 18.723504304885864 sec\n",
      "Epoch 2 \n",
      "D loss: 0.605815, G loss: 0.571508\n",
      "Runtime: 7.575970411300659 sec\n",
      "Epoch 3 \n",
      "D loss: 0.592991, G loss: 0.539836\n",
      "Runtime: 7.670622825622559 sec\n",
      "Epoch 4 \n",
      "D loss: 0.626960, G loss: 0.347163\n",
      "Runtime: 7.703887701034546 sec\n",
      "Epoch 5 \n",
      "D loss: 0.581301, G loss: 0.201936\n",
      "Runtime: 7.592510223388672 sec\n",
      "Epoch 6 \n",
      "D loss: 0.593182, G loss: 0.140257\n",
      "Runtime: 7.5500876903533936 sec\n",
      "Epoch 7 \n",
      "D loss: 0.583063, G loss: 0.153010\n",
      "Runtime: 7.8887269496917725 sec\n",
      "Epoch 8 \n",
      "D loss: 0.655201, G loss: 0.108337\n",
      "Runtime: 7.615651607513428 sec\n",
      "Epoch 9 \n",
      "D loss: 0.585211, G loss: 0.227518\n",
      "Runtime: 7.499051809310913 sec\n",
      "Epoch 10 \n",
      "D loss: 0.604373, G loss: 0.127380\n",
      "Runtime: 7.637843132019043 sec\n",
      "Epoch 11 \n",
      "D loss: 0.559025, G loss: 0.013072\n",
      "Runtime: 7.722620487213135 sec\n",
      "Epoch 12 \n",
      "D loss: 0.636879, G loss: 0.034710\n",
      "Runtime: 8.273183584213257 sec\n",
      "Epoch 13 \n",
      "D loss: 0.577415, G loss: 0.015018\n",
      "Runtime: 7.599886417388916 sec\n",
      "Epoch 14 \n",
      "D loss: 0.619803, G loss: 0.000390\n",
      "Runtime: 7.488431453704834 sec\n",
      "Epoch 15 \n",
      "D loss: 0.480115, G loss: 0.000568\n",
      "Runtime: 7.660233974456787 sec\n",
      "Epoch 16 \n",
      "D loss: 0.470815, G loss: 0.000386\n",
      "Runtime: 8.007140398025513 sec\n",
      "Epoch 17 \n",
      "D loss: 0.520065, G loss: 0.000060\n",
      "Runtime: 7.454030990600586 sec\n",
      "Epoch 18 \n",
      "D loss: 0.476800, G loss: 0.000053\n",
      "Runtime: 7.595172882080078 sec\n",
      "Epoch 19 \n",
      "D loss: 0.527268, G loss: 0.000074\n",
      "Runtime: 7.3802714347839355 sec\n",
      "Epoch 20 \n",
      "D loss: 0.623158, G loss: 0.000012\n",
      "Runtime: 7.421733140945435 sec\n",
      "Epoch 21 \n",
      "D loss: 0.661789, G loss: 0.000012\n",
      "Runtime: 7.455822944641113 sec\n",
      "Epoch 22 \n",
      "D loss: 0.537471, G loss: 0.000020\n",
      "Runtime: 7.601734161376953 sec\n",
      "Epoch 23 \n",
      "D loss: 0.541819, G loss: 0.000012\n",
      "Runtime: 7.516278505325317 sec\n",
      "Epoch 24 \n",
      "D loss: 0.505482, G loss: 0.000008\n",
      "Runtime: 7.522493362426758 sec\n",
      "Epoch 25 \n",
      "D loss: 0.576469, G loss: 0.000003\n",
      "Runtime: 7.528958082199097 sec\n",
      "Epoch 26 \n",
      "D loss: 0.693655, G loss: 0.000002\n",
      "Runtime: 7.522449493408203 sec\n",
      "Epoch 27 \n",
      "D loss: 0.524692, G loss: 0.000003\n",
      "Runtime: 7.674099445343018 sec\n",
      "Epoch 28 \n",
      "D loss: 0.484541, G loss: 0.000001\n",
      "Runtime: 7.793256759643555 sec\n",
      "Epoch 29 \n",
      "D loss: 0.507931, G loss: 0.000000\n",
      "Runtime: 8.373725414276123 sec\n",
      "Epoch 30 \n",
      "D loss: 0.556029, G loss: 0.000000\n",
      "Runtime: 7.828800439834595 sec\n",
      "Epoch 31 \n",
      "D loss: 0.395951, G loss: 0.000000\n",
      "Runtime: 7.726351976394653 sec\n",
      "Epoch 32 \n",
      "D loss: 0.408865, G loss: 0.000068\n",
      "Runtime: 7.802650690078735 sec\n",
      "Epoch 33 \n",
      "D loss: 0.694937, G loss: 0.000165\n",
      "Runtime: 8.333203077316284 sec\n",
      "Epoch 34 \n",
      "D loss: 0.772082, G loss: 0.000088\n",
      "Runtime: 7.852226257324219 sec\n",
      "Epoch 35 \n",
      "D loss: 0.604984, G loss: 0.000000\n",
      "Runtime: 7.9757184982299805 sec\n",
      "Epoch 36 \n",
      "D loss: 0.697556, G loss: 0.029795\n",
      "Runtime: 7.740406036376953 sec\n",
      "Epoch 37 \n",
      "D loss: 0.845451, G loss: 0.000106\n",
      "Runtime: 7.585760593414307 sec\n",
      "Epoch 38 \n",
      "D loss: 0.581779, G loss: 0.000020\n",
      "Runtime: 8.256836652755737 sec\n",
      "Epoch 39 \n",
      "D loss: 0.709112, G loss: 0.000003\n",
      "Runtime: 7.439258337020874 sec\n",
      "Epoch 40 \n",
      "D loss: 0.565759, G loss: 0.000000\n",
      "Runtime: 7.801941633224487 sec\n",
      "Epoch 41 \n",
      "D loss: 0.399255, G loss: 0.000000\n",
      "Runtime: 7.414175987243652 sec\n",
      "Epoch 42 \n",
      "D loss: 0.719981, G loss: 0.000000\n",
      "Runtime: 7.412854909896851 sec\n",
      "Epoch 43 \n",
      "D loss: 0.775031, G loss: 0.000000\n",
      "Runtime: 7.441503524780273 sec\n",
      "Epoch 44 \n",
      "D loss: 0.325757, G loss: 0.000000\n",
      "Runtime: 7.564733266830444 sec\n",
      "Epoch 45 \n",
      "D loss: 0.432739, G loss: 0.000000\n",
      "Runtime: 7.588029623031616 sec\n",
      "Epoch 46 \n",
      "D loss: 0.675690, G loss: 0.000000\n",
      "Runtime: 7.828978776931763 sec\n",
      "Epoch 47 \n",
      "D loss: 0.707193, G loss: 0.000000\n",
      "Runtime: 7.9808642864227295 sec\n",
      "Epoch 48 \n",
      "D loss: 0.602182, G loss: 0.000000\n",
      "Runtime: 7.971553564071655 sec\n",
      "Epoch 49 \n",
      "D loss: 0.621410, G loss: 0.000000\n",
      "Runtime: 8.02870488166809 sec\n",
      "Epoch 50 \n",
      "D loss: 0.603296, G loss: 0.000000\n",
      "Runtime: 7.840011119842529 sec\n",
      "Epoch 51 \n",
      "D loss: 0.438582, G loss: 0.000000\n",
      "Runtime: 8.02557110786438 sec\n",
      "Epoch 52 \n",
      "D loss: 0.308538, G loss: 0.000000\n",
      "Runtime: 7.911077260971069 sec\n",
      "Epoch 53 \n",
      "D loss: 0.556026, G loss: 0.000000\n",
      "Runtime: 7.373214483261108 sec\n",
      "Epoch 54 \n",
      "D loss: 0.280937, G loss: 0.000000\n",
      "Runtime: 7.334550619125366 sec\n",
      "Epoch 55 \n",
      "D loss: 0.292896, G loss: 0.000000\n",
      "Runtime: 7.330517053604126 sec\n",
      "Epoch 56 \n",
      "D loss: 0.455649, G loss: 0.000000\n",
      "Runtime: 7.287586688995361 sec\n",
      "Epoch 57 \n",
      "D loss: 0.304406, G loss: 0.000000\n",
      "Runtime: 7.35051155090332 sec\n",
      "Epoch 58 \n",
      "D loss: 0.651618, G loss: 0.000000\n",
      "Runtime: 7.317375183105469 sec\n",
      "Epoch 59 \n",
      "D loss: 0.493433, G loss: 0.000000\n",
      "Runtime: 7.33181619644165 sec\n",
      "Epoch 60 \n",
      "D loss: 0.315885, G loss: 0.000000\n",
      "Runtime: 7.362896680831909 sec\n",
      "Epoch 61 \n",
      "D loss: 0.619472, G loss: 0.000000\n",
      "Runtime: 7.341978311538696 sec\n",
      "Epoch 62 \n",
      "D loss: 0.262865, G loss: 0.000000\n",
      "Runtime: 7.309021234512329 sec\n",
      "Epoch 63 \n",
      "D loss: 0.331294, G loss: 0.000000\n",
      "Runtime: 7.4269163608551025 sec\n",
      "Epoch 64 \n",
      "D loss: 0.547733, G loss: 0.000000\n",
      "Runtime: 7.442951440811157 sec\n",
      "Epoch 65 \n",
      "D loss: 0.271946, G loss: 0.000000\n",
      "Runtime: 7.299399137496948 sec\n",
      "Epoch 66 \n",
      "D loss: 0.446768, G loss: 0.000000\n",
      "Runtime: 7.357470750808716 sec\n",
      "Epoch 67 \n",
      "D loss: 0.636489, G loss: 0.000000\n",
      "Runtime: 7.3151469230651855 sec\n",
      "Epoch 68 \n",
      "D loss: 0.471468, G loss: 0.000000\n",
      "Runtime: 7.357472896575928 sec\n",
      "Epoch 69 \n",
      "D loss: 0.618961, G loss: 0.000000\n",
      "Runtime: 7.410823106765747 sec\n",
      "Epoch 70 \n",
      "D loss: 0.272166, G loss: 0.000000\n",
      "Runtime: 7.356945514678955 sec\n",
      "Epoch 71 \n",
      "D loss: 0.294160, G loss: 0.000000\n",
      "Runtime: 7.36899995803833 sec\n",
      "Epoch 72 \n",
      "D loss: 0.315821, G loss: 0.000000\n",
      "Runtime: 7.325819730758667 sec\n",
      "Epoch 73 \n",
      "D loss: 0.484831, G loss: 0.000000\n",
      "Runtime: 7.310654163360596 sec\n",
      "Epoch 74 \n",
      "D loss: 0.255738, G loss: 0.000000\n",
      "Runtime: 7.394479513168335 sec\n",
      "Epoch 75 \n",
      "D loss: 0.502689, G loss: 0.000000\n",
      "Runtime: 7.709894418716431 sec\n",
      "Epoch 76 \n",
      "D loss: 0.287634, G loss: 0.000000\n",
      "Runtime: 7.2832932472229 sec\n",
      "Epoch 77 \n",
      "D loss: 0.421777, G loss: 0.000000\n",
      "Runtime: 7.400315046310425 sec\n",
      "Epoch 78 \n",
      "D loss: 0.269982, G loss: 0.000000\n",
      "Runtime: 7.875393629074097 sec\n",
      "Epoch 79 \n",
      "D loss: 0.145371, G loss: 0.000000\n",
      "Runtime: 7.344451189041138 sec\n",
      "Epoch 80 \n",
      "D loss: 0.308029, G loss: 0.000000\n",
      "Runtime: 7.628892421722412 sec\n",
      "Epoch 81 \n",
      "D loss: 0.477617, G loss: 0.000000\n",
      "Runtime: 7.540048360824585 sec\n",
      "Epoch 82 \n",
      "D loss: 0.401602, G loss: 0.000000\n",
      "Runtime: 7.474283933639526 sec\n",
      "Epoch 83 \n",
      "D loss: 0.529362, G loss: 0.000000\n",
      "Runtime: 7.370065927505493 sec\n",
      "Epoch 84 \n",
      "D loss: 0.248192, G loss: 0.000000\n",
      "Runtime: 7.361504077911377 sec\n",
      "Epoch 85 \n",
      "D loss: 0.476882, G loss: 0.000000\n",
      "Runtime: 7.962279319763184 sec\n",
      "Epoch 86 \n",
      "D loss: 0.563260, G loss: 0.000000\n",
      "Runtime: 7.938933372497559 sec\n",
      "Epoch 87 \n",
      "D loss: 0.292741, G loss: 0.000000\n",
      "Runtime: 7.473377704620361 sec\n",
      "Epoch 88 \n",
      "D loss: 0.201797, G loss: 0.000000\n",
      "Runtime: 7.302066802978516 sec\n",
      "Epoch 89 \n",
      "D loss: 0.270126, G loss: 0.000000\n",
      "Runtime: 7.680047988891602 sec\n",
      "Epoch 90 \n",
      "D loss: 0.498659, G loss: 0.000000\n",
      "Runtime: 7.636137962341309 sec\n",
      "Epoch 91 \n",
      "D loss: 0.302510, G loss: 0.000000\n",
      "Runtime: 7.6970155239105225 sec\n",
      "Epoch 92 \n",
      "D loss: 0.453829, G loss: 0.000000\n",
      "Runtime: 7.701406002044678 sec\n",
      "Epoch 93 \n",
      "D loss: 0.207157, G loss: 0.000000\n",
      "Runtime: 7.542937278747559 sec\n",
      "Epoch 94 \n",
      "D loss: 0.311037, G loss: 0.000000\n",
      "Runtime: 7.57782506942749 sec\n",
      "Epoch 95 \n",
      "D loss: 0.530057, G loss: 0.000000\n",
      "Runtime: 7.515201568603516 sec\n",
      "Epoch 96 \n",
      "D loss: 0.464340, G loss: 0.000000\n",
      "Runtime: 7.496744394302368 sec\n",
      "Epoch 97 \n",
      "D loss: 0.656360, G loss: 0.000000\n",
      "Runtime: 7.550500392913818 sec\n",
      "Epoch 98 \n",
      "D loss: 0.307584, G loss: 0.000000\n",
      "Runtime: 7.442120790481567 sec\n",
      "Epoch 99 \n",
      "D loss: 0.214649, G loss: 0.000000\n",
      "Runtime: 7.9319703578948975 sec\n",
      "Epoch 100 \n",
      "D loss: 0.276620, G loss: 0.000000\n",
      "Runtime: 8.091043949127197 sec\n",
      "Epoch 101 \n",
      "D loss: 0.650935, G loss: 0.000000\n",
      "Runtime: 7.48783802986145 sec\n",
      "Epoch 102 \n",
      "D loss: 0.603802, G loss: 0.000000\n",
      "Runtime: 7.958370923995972 sec\n",
      "Epoch 103 \n",
      "D loss: 0.582328, G loss: 0.000000\n",
      "Runtime: 7.549906969070435 sec\n",
      "Epoch 104 \n",
      "D loss: 0.125963, G loss: 0.000000\n",
      "Runtime: 7.597083806991577 sec\n",
      "Epoch 105 \n",
      "D loss: 0.114878, G loss: 0.000000\n",
      "Runtime: 7.7223289012908936 sec\n",
      "Epoch 106 \n",
      "D loss: 0.371138, G loss: 0.000000\n",
      "Runtime: 7.841442584991455 sec\n",
      "Epoch 107 \n",
      "D loss: 0.163194, G loss: 0.000000\n",
      "Runtime: 7.315331220626831 sec\n",
      "Epoch 108 \n",
      "D loss: 0.143191, G loss: 0.000000\n",
      "Runtime: 7.561416864395142 sec\n",
      "Epoch 109 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D loss: 0.227909, G loss: 0.000000\n",
      "Runtime: 8.048150062561035 sec\n",
      "Epoch 110 \n",
      "D loss: 0.186807, G loss: 0.000000\n",
      "Runtime: 7.999083518981934 sec\n",
      "Epoch 111 \n",
      "D loss: 0.099150, G loss: 0.000000\n",
      "Runtime: 7.7778098583221436 sec\n",
      "Epoch 112 \n",
      "D loss: 0.333960, G loss: 0.000000\n",
      "Runtime: 7.538572788238525 sec\n",
      "Epoch 113 \n",
      "D loss: 0.469545, G loss: 0.000000\n",
      "Runtime: 7.659038782119751 sec\n",
      "Epoch 114 \n",
      "D loss: 0.142619, G loss: 0.000000\n",
      "Runtime: 7.617876291275024 sec\n",
      "Epoch 115 \n",
      "D loss: 0.263973, G loss: 0.000000\n",
      "Runtime: 7.535585165023804 sec\n",
      "Epoch 116 \n",
      "D loss: 0.235538, G loss: 0.000000\n",
      "Runtime: 7.7282044887542725 sec\n",
      "Epoch 117 \n",
      "D loss: 0.521885, G loss: 0.000000\n",
      "Runtime: 7.63857102394104 sec\n",
      "Epoch 118 \n",
      "D loss: 0.216799, G loss: 0.000000\n",
      "Runtime: 7.68387770652771 sec\n",
      "Epoch 119 \n",
      "D loss: 0.219862, G loss: 0.000000\n",
      "Runtime: 7.532737970352173 sec\n",
      "Epoch 120 \n",
      "D loss: 0.149254, G loss: 0.000000\n",
      "Runtime: 7.688509464263916 sec\n",
      "Epoch 121 \n",
      "D loss: 0.411836, G loss: 0.000000\n",
      "Runtime: 7.765485763549805 sec\n",
      "Epoch 122 \n",
      "D loss: 0.792593, G loss: 0.000000\n",
      "Runtime: 7.571227073669434 sec\n",
      "Epoch 123 \n",
      "D loss: 0.182240, G loss: 0.000000\n",
      "Runtime: 7.309944152832031 sec\n",
      "Epoch 124 \n",
      "D loss: 0.195450, G loss: 0.000000\n",
      "Runtime: 7.342251300811768 sec\n",
      "Epoch 125 \n",
      "D loss: 0.082524, G loss: 0.000000\n",
      "Runtime: 7.553877353668213 sec\n",
      "Epoch 126 \n",
      "D loss: 0.123733, G loss: 0.000000\n",
      "Runtime: 8.013848066329956 sec\n",
      "Epoch 127 \n",
      "D loss: 0.078452, G loss: 0.000000\n",
      "Runtime: 7.399169445037842 sec\n",
      "Epoch 128 \n",
      "D loss: 0.101045, G loss: 0.000000\n",
      "Runtime: 7.588089227676392 sec\n",
      "Epoch 129 \n",
      "D loss: 0.323003, G loss: 0.000000\n",
      "Runtime: 7.613770246505737 sec\n",
      "Epoch 130 \n",
      "D loss: 0.581914, G loss: 0.000000\n",
      "Runtime: 7.462718486785889 sec\n",
      "Epoch 131 \n",
      "D loss: 0.233394, G loss: 0.000000\n",
      "Runtime: 7.494580268859863 sec\n",
      "Epoch 132 \n",
      "D loss: 0.423728, G loss: 0.000000\n",
      "Runtime: 8.43319034576416 sec\n",
      "Epoch 133 \n",
      "D loss: 0.109933, G loss: 0.000000\n",
      "Runtime: 8.047587156295776 sec\n",
      "Epoch 134 \n",
      "D loss: 0.229416, G loss: 0.000000\n",
      "Runtime: 7.643712282180786 sec\n",
      "Epoch 135 \n",
      "D loss: 0.499438, G loss: 0.000000\n",
      "Runtime: 7.581247091293335 sec\n",
      "Epoch 136 \n",
      "D loss: 0.213994, G loss: 0.000000\n",
      "Runtime: 7.452147006988525 sec\n",
      "Epoch 137 \n",
      "D loss: 0.339425, G loss: 0.000000\n",
      "Runtime: 7.3943190574646 sec\n",
      "Epoch 138 \n",
      "D loss: 0.122512, G loss: 0.000000\n",
      "Runtime: 7.446021556854248 sec\n",
      "Epoch 139 \n",
      "D loss: 0.191840, G loss: 0.000000\n",
      "Runtime: 7.4323859214782715 sec\n",
      "Epoch 140 \n",
      "D loss: 0.326772, G loss: 0.000000\n",
      "Runtime: 7.995185613632202 sec\n",
      "Epoch 141 \n",
      "D loss: 0.072949, G loss: 0.000000\n",
      "Runtime: 8.094352722167969 sec\n",
      "Epoch 142 \n",
      "D loss: 0.720430, G loss: 0.000000\n",
      "Runtime: 7.573709964752197 sec\n",
      "Epoch 143 \n",
      "D loss: 0.441526, G loss: 0.000000\n",
      "Runtime: 7.676904201507568 sec\n",
      "Epoch 144 \n",
      "D loss: 0.560979, G loss: 0.000000\n",
      "Runtime: 7.875141620635986 sec\n",
      "Epoch 145 \n",
      "D loss: 0.135832, G loss: 0.000000\n",
      "Runtime: 7.3142499923706055 sec\n",
      "Epoch 146 \n",
      "D loss: 0.054571, G loss: 0.000000\n",
      "Runtime: 7.425621509552002 sec\n",
      "Epoch 147 \n",
      "D loss: 0.250762, G loss: 0.000000\n",
      "Runtime: 7.78730583190918 sec\n",
      "Epoch 148 \n",
      "D loss: 0.174412, G loss: 0.000000\n",
      "Runtime: 7.703344345092773 sec\n",
      "Epoch 149 \n",
      "D loss: 0.075461, G loss: 0.000000\n",
      "Runtime: 7.724599838256836 sec\n",
      "Epoch 150 \n",
      "D loss: 0.111666, G loss: 0.000000\n",
      "Runtime: 7.508986234664917 sec\n",
      "Epoch 151 \n",
      "D loss: 0.178388, G loss: 0.000000\n",
      "Runtime: 7.458149433135986 sec\n",
      "Epoch 152 \n",
      "D loss: 0.204046, G loss: 0.000000\n",
      "Runtime: 7.443989515304565 sec\n",
      "Epoch 153 \n",
      "D loss: 0.101867, G loss: 0.000000\n",
      "Runtime: 7.353996276855469 sec\n",
      "Epoch 154 \n",
      "D loss: 0.302292, G loss: 0.000000\n",
      "Runtime: 7.313339471817017 sec\n",
      "Epoch 155 \n",
      "D loss: 0.517105, G loss: 0.000000\n",
      "Runtime: 7.34750509262085 sec\n",
      "Epoch 156 \n",
      "D loss: 0.348793, G loss: 0.000000\n",
      "Runtime: 7.335609436035156 sec\n",
      "Epoch 157 \n",
      "D loss: 0.189113, G loss: 0.000000\n",
      "Runtime: 7.275686979293823 sec\n",
      "Epoch 158 \n",
      "D loss: 0.160077, G loss: 0.000000\n",
      "Runtime: 7.292518615722656 sec\n",
      "Epoch 159 \n",
      "D loss: 0.449207, G loss: 0.000000\n",
      "Runtime: 7.36042594909668 sec\n",
      "Epoch 160 \n",
      "D loss: 0.476033, G loss: 0.000000\n",
      "Runtime: 7.4419543743133545 sec\n",
      "Epoch 161 \n",
      "D loss: 0.424012, G loss: 0.000000\n",
      "Runtime: 7.6858811378479 sec\n",
      "Epoch 162 \n",
      "D loss: 0.292789, G loss: 0.000000\n",
      "Runtime: 7.493024826049805 sec\n",
      "Epoch 163 \n",
      "D loss: 0.200781, G loss: 0.000000\n",
      "Runtime: 7.333919525146484 sec\n",
      "Epoch 164 \n",
      "D loss: 0.099092, G loss: 0.000000\n",
      "Runtime: 7.403112888336182 sec\n",
      "Epoch 165 \n",
      "D loss: 0.125757, G loss: 0.000000\n",
      "Runtime: 7.382167339324951 sec\n",
      "Epoch 166 \n",
      "D loss: 0.037402, G loss: 0.000000\n",
      "Runtime: 7.294660806655884 sec\n",
      "Epoch 167 \n",
      "D loss: 0.074571, G loss: 0.000000\n",
      "Runtime: 7.37265419960022 sec\n",
      "Epoch 168 \n",
      "D loss: 0.091402, G loss: 0.000000\n",
      "Runtime: 7.445286512374878 sec\n",
      "Epoch 169 \n",
      "D loss: 0.107327, G loss: 0.000000\n",
      "Runtime: 7.484954595565796 sec\n",
      "Epoch 170 \n",
      "D loss: 0.092534, G loss: 0.000000\n",
      "Runtime: 7.757363319396973 sec\n",
      "Epoch 171 \n",
      "D loss: 0.154461, G loss: 0.000000\n",
      "Runtime: 8.171724081039429 sec\n",
      "Epoch 172 \n",
      "D loss: 0.062005, G loss: 0.000000\n",
      "Runtime: 7.596120357513428 sec\n",
      "Epoch 173 \n",
      "D loss: 0.587973, G loss: 0.000000\n",
      "Runtime: 7.593553781509399 sec\n",
      "Epoch 174 \n",
      "D loss: 0.050054, G loss: 0.000000\n",
      "Runtime: 7.6154491901397705 sec\n",
      "Epoch 175 \n",
      "D loss: 0.051331, G loss: 0.000000\n",
      "Runtime: 7.904951572418213 sec\n",
      "Epoch 176 \n",
      "D loss: 0.306221, G loss: 0.000000\n",
      "Runtime: 7.414438009262085 sec\n",
      "Epoch 177 \n",
      "D loss: 0.180876, G loss: 0.000000\n",
      "Runtime: 7.407629013061523 sec\n",
      "Epoch 178 \n",
      "D loss: 0.409397, G loss: 0.000000\n",
      "Runtime: 7.350232124328613 sec\n",
      "Epoch 179 \n",
      "D loss: 0.155305, G loss: 0.000000\n",
      "Runtime: 7.459314346313477 sec\n",
      "Epoch 180 \n",
      "D loss: 0.164853, G loss: 0.000000\n",
      "Runtime: 7.356039762496948 sec\n",
      "Epoch 181 \n",
      "D loss: 0.070376, G loss: 0.000000\n",
      "Runtime: 7.363736629486084 sec\n",
      "Epoch 182 \n",
      "D loss: 0.096121, G loss: 0.000000\n",
      "Runtime: 7.444604158401489 sec\n",
      "Epoch 183 \n",
      "D loss: 0.027631, G loss: 0.000000\n",
      "Runtime: 7.32072639465332 sec\n",
      "Epoch 184 \n",
      "D loss: 0.384737, G loss: 0.000000\n",
      "Runtime: 7.5974040031433105 sec\n",
      "Epoch 185 \n",
      "D loss: 0.310436, G loss: 0.000000\n",
      "Runtime: 7.461270809173584 sec\n",
      "Epoch 186 \n",
      "D loss: 0.058619, G loss: 0.000000\n",
      "Runtime: 7.6835691928863525 sec\n",
      "Epoch 187 \n",
      "D loss: 0.146282, G loss: 0.000000\n",
      "Runtime: 7.415314435958862 sec\n",
      "Epoch 188 \n",
      "D loss: 0.428034, G loss: 0.000000\n",
      "Runtime: 7.584071159362793 sec\n",
      "Epoch 189 \n",
      "D loss: 0.785775, G loss: 0.000000\n",
      "Runtime: 7.420353412628174 sec\n",
      "Epoch 190 \n",
      "D loss: 0.115053, G loss: 0.000000\n",
      "Runtime: 7.393933057785034 sec\n",
      "Epoch 191 \n",
      "D loss: 0.132377, G loss: 0.000000\n",
      "Runtime: 7.410051584243774 sec\n",
      "Epoch 192 \n",
      "D loss: 0.196705, G loss: 0.000000\n",
      "Runtime: 7.439042091369629 sec\n",
      "Epoch 193 \n",
      "D loss: 0.384157, G loss: 0.000000\n",
      "Runtime: 7.437880277633667 sec\n",
      "Epoch 194 \n",
      "D loss: 0.073155, G loss: 0.000000\n",
      "Runtime: 7.500256299972534 sec\n",
      "Epoch 195 \n",
      "D loss: 0.190536, G loss: 0.000000\n",
      "Runtime: 7.3941426277160645 sec\n",
      "Epoch 196 \n",
      "D loss: 0.315117, G loss: 0.000000\n",
      "Runtime: 7.374161720275879 sec\n",
      "Epoch 197 \n",
      "D loss: 0.050463, G loss: 0.000000\n",
      "Runtime: 7.387083053588867 sec\n",
      "Epoch 198 \n",
      "D loss: 0.084836, G loss: 0.000000\n",
      "Runtime: 7.359869480133057 sec\n",
      "Epoch 199 \n",
      "D loss: 0.093295, G loss: 0.000000\n",
      "Runtime: 7.358147859573364 sec\n",
      "Epoch 200 \n",
      "D loss: 0.163506, G loss: 0.000000\n",
      "Runtime: 7.291015625 sec\n",
      "Epoch 201 \n",
      "D loss: 0.042123, G loss: 0.000000\n",
      "Runtime: 7.411378860473633 sec\n",
      "Epoch 202 \n",
      "D loss: 0.168850, G loss: 0.000000\n",
      "Runtime: 7.973942995071411 sec\n",
      "Epoch 203 \n",
      "D loss: 0.390517, G loss: 0.000000\n",
      "Runtime: 7.489073276519775 sec\n",
      "Epoch 204 \n",
      "D loss: 0.260701, G loss: 0.000000\n",
      "Runtime: 7.344156980514526 sec\n",
      "Epoch 205 \n",
      "D loss: 0.674076, G loss: 0.000000\n",
      "Runtime: 7.414201498031616 sec\n",
      "Epoch 206 \n",
      "D loss: 0.196440, G loss: 0.000000\n",
      "Runtime: 7.410383224487305 sec\n",
      "Epoch 207 \n",
      "D loss: 0.076782, G loss: 0.000000\n",
      "Runtime: 7.437467336654663 sec\n",
      "Epoch 208 \n",
      "D loss: 0.110549, G loss: 0.000000\n",
      "Runtime: 7.498900413513184 sec\n",
      "Epoch 209 \n",
      "D loss: 0.029005, G loss: 0.000000\n",
      "Runtime: 7.540208101272583 sec\n",
      "Epoch 210 \n",
      "D loss: 0.099963, G loss: 0.000000\n",
      "Runtime: 7.584031820297241 sec\n",
      "Epoch 211 \n",
      "D loss: 0.223135, G loss: 0.000000\n",
      "Runtime: 7.607637166976929 sec\n",
      "Epoch 212 \n",
      "D loss: 0.047240, G loss: 0.000000\n",
      "Runtime: 7.5546863079071045 sec\n",
      "Epoch 213 \n",
      "D loss: 0.113806, G loss: 0.000000\n",
      "Runtime: 7.534135341644287 sec\n",
      "Epoch 214 \n",
      "D loss: 0.040401, G loss: 0.000000\n",
      "Runtime: 7.506399869918823 sec\n",
      "Epoch 215 \n",
      "D loss: 0.152779, G loss: 0.000000\n",
      "Runtime: 7.434251546859741 sec\n",
      "Epoch 216 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D loss: 0.070582, G loss: 0.000000\n",
      "Runtime: 7.505725145339966 sec\n",
      "Epoch 217 \n",
      "D loss: 0.273299, G loss: 0.000000\n",
      "Runtime: 7.547732591629028 sec\n",
      "Epoch 218 \n",
      "D loss: 0.027758, G loss: 0.000000\n",
      "Runtime: 7.425504922866821 sec\n",
      "Epoch 219 \n",
      "D loss: 0.067864, G loss: 0.000000\n",
      "Runtime: 7.411661148071289 sec\n",
      "Epoch 220 \n",
      "D loss: 0.113077, G loss: 0.000000\n",
      "Runtime: 7.421828746795654 sec\n",
      "Epoch 221 \n",
      "D loss: 0.080700, G loss: 0.000000\n",
      "Runtime: 7.62818717956543 sec\n",
      "Epoch 222 \n",
      "D loss: 0.107309, G loss: 0.000000\n",
      "Runtime: 7.492060422897339 sec\n",
      "Epoch 223 \n",
      "D loss: 0.074309, G loss: 0.000000\n",
      "Runtime: 7.362537622451782 sec\n",
      "Epoch 224 \n",
      "D loss: 0.169365, G loss: 0.000000\n",
      "Runtime: 7.400204420089722 sec\n",
      "Epoch 225 \n",
      "D loss: 0.657096, G loss: 0.000000\n",
      "Runtime: 7.5280373096466064 sec\n",
      "Epoch 226 \n",
      "D loss: 0.034568, G loss: 0.000000\n",
      "Runtime: 7.447983264923096 sec\n",
      "Epoch 227 \n",
      "D loss: 0.080935, G loss: 0.000000\n",
      "Runtime: 7.41758131980896 sec\n",
      "Epoch 228 \n",
      "D loss: 0.153310, G loss: 0.000000\n",
      "Runtime: 7.626945495605469 sec\n",
      "Epoch 229 \n",
      "D loss: 0.220156, G loss: 0.000000\n",
      "Runtime: 8.07242751121521 sec\n",
      "Epoch 230 \n",
      "D loss: 0.044747, G loss: 0.000000\n",
      "Runtime: 7.585704326629639 sec\n",
      "Epoch 231 \n",
      "D loss: 0.357487, G loss: 0.000000\n",
      "Runtime: 7.454582929611206 sec\n",
      "Epoch 232 \n",
      "D loss: 0.066925, G loss: 0.000000\n",
      "Runtime: 7.441366195678711 sec\n",
      "Epoch 233 \n",
      "D loss: 0.059626, G loss: 0.000000\n",
      "Runtime: 8.201462984085083 sec\n",
      "Epoch 234 \n",
      "D loss: 0.153805, G loss: 0.000000\n",
      "Runtime: 7.427273273468018 sec\n",
      "Epoch 235 \n",
      "D loss: 0.058947, G loss: 0.000000\n",
      "Runtime: 7.387082576751709 sec\n",
      "Epoch 236 \n",
      "D loss: 0.085055, G loss: 0.000000\n",
      "Runtime: 7.385349988937378 sec\n",
      "Epoch 237 \n",
      "D loss: 0.215253, G loss: 0.000000\n",
      "Runtime: 7.526355266571045 sec\n",
      "Epoch 238 \n",
      "D loss: 0.134434, G loss: 0.000000\n",
      "Runtime: 7.807609796524048 sec\n",
      "Epoch 239 \n",
      "D loss: 0.095822, G loss: 0.000000\n",
      "Runtime: 7.387106895446777 sec\n",
      "Epoch 240 \n",
      "D loss: 0.357866, G loss: 0.000000\n",
      "Runtime: 7.319395065307617 sec\n",
      "Epoch 241 \n",
      "D loss: 0.140733, G loss: 0.000000\n",
      "Runtime: 7.368829011917114 sec\n",
      "Epoch 242 \n",
      "D loss: 0.043443, G loss: 0.000000\n",
      "Runtime: 7.358652114868164 sec\n",
      "Epoch 243 \n",
      "D loss: 0.199217, G loss: 0.000000\n",
      "Runtime: 7.421420335769653 sec\n",
      "Epoch 244 \n",
      "D loss: 0.021385, G loss: 0.000000\n",
      "Runtime: 7.279653549194336 sec\n",
      "Epoch 245 \n",
      "D loss: 0.407951, G loss: 0.000000\n",
      "Runtime: 7.393707275390625 sec\n",
      "Epoch 246 \n",
      "D loss: 0.038166, G loss: 0.000000\n",
      "Runtime: 7.3478686809539795 sec\n",
      "Epoch 247 \n",
      "D loss: 0.870757, G loss: 0.000000\n",
      "Runtime: 7.321911573410034 sec\n",
      "Epoch 248 \n",
      "D loss: 0.142707, G loss: 0.000000\n",
      "Runtime: 7.375885725021362 sec\n",
      "Epoch 249 \n",
      "D loss: 0.106097, G loss: 0.000000\n",
      "Runtime: 7.473573207855225 sec\n",
      "Epoch 250 \n",
      "D loss: 0.054225, G loss: 0.000000\n",
      "Runtime: 7.549806833267212 sec\n",
      "Epoch 251 \n",
      "D loss: 0.013067, G loss: 0.000000\n",
      "Runtime: 7.4405741691589355 sec\n",
      "Epoch 252 \n",
      "D loss: 0.057096, G loss: 0.000000\n",
      "Runtime: 7.393042325973511 sec\n",
      "Epoch 253 \n",
      "D loss: 0.254122, G loss: 0.000000\n",
      "Runtime: 7.354793310165405 sec\n",
      "Epoch 254 \n",
      "D loss: 0.182362, G loss: 0.000000\n",
      "Runtime: 7.369484901428223 sec\n",
      "Epoch 255 \n",
      "D loss: 0.191445, G loss: 0.000000\n",
      "Runtime: 7.288065195083618 sec\n",
      "Epoch 256 \n",
      "D loss: 0.057105, G loss: 0.000000\n",
      "Runtime: 7.388775825500488 sec\n",
      "Epoch 257 \n",
      "D loss: 0.024506, G loss: 0.000000\n",
      "Runtime: 7.333271265029907 sec\n",
      "Epoch 258 \n",
      "D loss: 0.288664, G loss: 0.000000\n",
      "Runtime: 7.396305084228516 sec\n",
      "Epoch 259 \n",
      "D loss: 0.083325, G loss: 0.000000\n",
      "Runtime: 7.382357358932495 sec\n",
      "Epoch 260 \n",
      "D loss: 0.242428, G loss: 0.000000\n",
      "Runtime: 7.311915159225464 sec\n",
      "Epoch 261 \n",
      "D loss: 0.020299, G loss: 0.000000\n",
      "Runtime: 7.385130167007446 sec\n",
      "Epoch 262 \n",
      "D loss: 0.086750, G loss: 0.000000\n",
      "Runtime: 7.3187806606292725 sec\n",
      "Epoch 263 \n",
      "D loss: 0.020329, G loss: 0.000000\n",
      "Runtime: 7.344048500061035 sec\n",
      "Epoch 264 \n",
      "D loss: 0.019217, G loss: 0.000000\n",
      "Runtime: 7.848966598510742 sec\n",
      "Epoch 265 \n",
      "D loss: 0.065750, G loss: 0.000000\n",
      "Runtime: 7.334506988525391 sec\n",
      "Epoch 266 \n",
      "D loss: 0.205607, G loss: 0.000000\n",
      "Runtime: 7.3283586502075195 sec\n",
      "Epoch 267 \n",
      "D loss: 0.045754, G loss: 0.000000\n",
      "Runtime: 7.327892780303955 sec\n",
      "Epoch 268 \n",
      "D loss: 0.024324, G loss: 0.000000\n",
      "Runtime: 7.353740692138672 sec\n",
      "Epoch 269 \n",
      "D loss: 0.108196, G loss: 0.000000\n",
      "Runtime: 7.385089159011841 sec\n",
      "Epoch 270 \n",
      "D loss: 0.019711, G loss: 0.000000\n",
      "Runtime: 7.3006086349487305 sec\n",
      "Epoch 271 \n",
      "D loss: 0.343944, G loss: 0.000000\n",
      "Runtime: 7.435736656188965 sec\n",
      "Epoch 272 \n",
      "D loss: 0.031011, G loss: 0.000000\n",
      "Runtime: 7.289448261260986 sec\n",
      "Epoch 273 \n",
      "D loss: 0.109656, G loss: 0.000000\n",
      "Runtime: 7.371719598770142 sec\n",
      "Epoch 274 \n",
      "D loss: 0.288111, G loss: 0.000000\n",
      "Runtime: 7.373842239379883 sec\n",
      "Epoch 275 \n",
      "D loss: 0.082055, G loss: 0.000000\n",
      "Runtime: 7.2964928150177 sec\n",
      "Epoch 276 \n",
      "D loss: 0.044713, G loss: 0.000000\n",
      "Runtime: 7.414753198623657 sec\n",
      "Epoch 277 \n",
      "D loss: 0.344012, G loss: 0.000000\n",
      "Runtime: 7.45691180229187 sec\n",
      "Epoch 278 \n",
      "D loss: 0.164421, G loss: 0.000000\n",
      "Runtime: 7.666980028152466 sec\n",
      "Epoch 279 \n",
      "D loss: 0.024245, G loss: 0.000000\n",
      "Runtime: 7.523797988891602 sec\n",
      "Epoch 280 \n",
      "D loss: 0.016106, G loss: 0.000000\n",
      "Runtime: 7.640746831893921 sec\n",
      "Epoch 281 \n",
      "D loss: 0.012076, G loss: 0.000000\n",
      "Runtime: 7.333696365356445 sec\n",
      "Epoch 282 \n",
      "D loss: 0.032079, G loss: 0.000000\n",
      "Runtime: 7.377748012542725 sec\n",
      "Epoch 283 \n",
      "D loss: 0.331613, G loss: 0.000000\n",
      "Runtime: 7.398045778274536 sec\n",
      "Epoch 284 \n",
      "D loss: 0.085894, G loss: 0.000000\n",
      "Runtime: 7.412707328796387 sec\n",
      "Epoch 285 \n",
      "D loss: 0.019034, G loss: 0.000000\n",
      "Runtime: 7.299279451370239 sec\n",
      "Epoch 286 \n",
      "D loss: 0.038728, G loss: 0.000000\n",
      "Runtime: 7.383796215057373 sec\n",
      "Epoch 287 \n",
      "D loss: 0.091593, G loss: 0.000000\n",
      "Runtime: 7.415057420730591 sec\n",
      "Epoch 288 \n",
      "D loss: 0.034161, G loss: 0.000000\n",
      "Runtime: 7.417617082595825 sec\n",
      "Epoch 289 \n",
      "D loss: 0.023275, G loss: 0.000000\n",
      "Runtime: 7.388232231140137 sec\n",
      "Epoch 290 \n",
      "D loss: 0.093939, G loss: 0.000000\n",
      "Runtime: 7.447306156158447 sec\n",
      "Epoch 291 \n",
      "D loss: 0.127648, G loss: 0.000000\n",
      "Runtime: 7.564728498458862 sec\n",
      "Epoch 292 \n",
      "D loss: 0.039018, G loss: 0.000000\n",
      "Runtime: 7.638076066970825 sec\n",
      "Epoch 293 \n",
      "D loss: 0.094009, G loss: 0.000000\n",
      "Runtime: 7.45682168006897 sec\n",
      "Epoch 294 \n",
      "D loss: 0.027032, G loss: 0.000000\n",
      "Runtime: 7.440268039703369 sec\n",
      "Epoch 295 \n",
      "D loss: 0.018928, G loss: 0.000000\n",
      "Runtime: 7.872172594070435 sec\n",
      "Epoch 296 \n",
      "D loss: 0.048459, G loss: 0.000000\n",
      "Runtime: 7.46204137802124 sec\n",
      "Epoch 297 \n",
      "D loss: 0.090506, G loss: 0.000000\n",
      "Runtime: 7.29979681968689 sec\n",
      "Epoch 298 \n",
      "D loss: 0.439640, G loss: 0.000000\n",
      "Runtime: 7.406539440155029 sec\n",
      "Epoch 299 \n",
      "D loss: 0.074031, G loss: 0.000000\n",
      "Runtime: 7.380550146102905 sec\n",
      "Epoch 300 \n",
      "D loss: 0.108034, G loss: 0.000000\n",
      "Runtime: 7.350726127624512 sec\n",
      "Epoch 301 \n",
      "D loss: 0.015553, G loss: 0.000000\n",
      "Runtime: 7.40247917175293 sec\n",
      "Epoch 302 \n",
      "D loss: 0.018173, G loss: 0.000000\n",
      "Runtime: 7.404722690582275 sec\n",
      "Epoch 303 \n",
      "D loss: 0.016819, G loss: 0.000000\n",
      "Runtime: 7.406792879104614 sec\n",
      "Epoch 304 \n",
      "D loss: 0.026750, G loss: 0.000000\n",
      "Runtime: 7.3641743659973145 sec\n",
      "Epoch 305 \n",
      "D loss: 0.083513, G loss: 0.000000\n",
      "Runtime: 7.387817859649658 sec\n",
      "Epoch 306 \n",
      "D loss: 0.053342, G loss: 0.000000\n",
      "Runtime: 7.437791347503662 sec\n",
      "Epoch 307 \n",
      "D loss: 0.063995, G loss: 0.000000\n",
      "Runtime: 7.35710597038269 sec\n",
      "Epoch 308 \n",
      "D loss: 0.011061, G loss: 0.000000\n",
      "Runtime: 7.377346515655518 sec\n",
      "Epoch 309 \n",
      "D loss: 0.016443, G loss: 0.000000\n",
      "Runtime: 7.4332945346832275 sec\n",
      "Epoch 310 \n",
      "D loss: 0.260955, G loss: 0.000000\n",
      "Runtime: 7.35977840423584 sec\n",
      "Epoch 311 \n",
      "D loss: 0.021377, G loss: 0.000000\n",
      "Runtime: 7.344888925552368 sec\n",
      "Epoch 312 \n",
      "D loss: 0.066523, G loss: 0.000000\n",
      "Runtime: 7.886516571044922 sec\n",
      "Epoch 313 \n",
      "D loss: 0.200561, G loss: 0.000000\n",
      "Runtime: 7.571261405944824 sec\n",
      "Epoch 314 \n",
      "D loss: 0.135369, G loss: 0.000000\n",
      "Runtime: 7.6223180294036865 sec\n",
      "Epoch 315 \n",
      "D loss: 0.123927, G loss: 0.000000\n",
      "Runtime: 9.591548442840576 sec\n",
      "Epoch 316 \n",
      "D loss: 0.018961, G loss: 0.000000\n",
      "Runtime: 9.007328748703003 sec\n",
      "Epoch 317 \n",
      "D loss: 0.281140, G loss: 0.000000\n",
      "Runtime: 8.334475755691528 sec\n",
      "Epoch 318 \n",
      "D loss: 0.040389, G loss: 0.000000\n",
      "Runtime: 8.356229305267334 sec\n",
      "Epoch 319 \n",
      "D loss: 0.161685, G loss: 0.000000\n",
      "Runtime: 8.237404584884644 sec\n",
      "Epoch 320 \n",
      "D loss: 0.019284, G loss: 0.000000\n",
      "Runtime: 8.21583604812622 sec\n",
      "Epoch 321 \n",
      "D loss: 0.015184, G loss: 0.000000\n",
      "Runtime: 8.28133225440979 sec\n",
      "Epoch 322 \n",
      "D loss: 0.017343, G loss: 0.000000\n",
      "Runtime: 8.29355263710022 sec\n",
      "Epoch 323 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D loss: 0.169867, G loss: 0.000000\n",
      "Runtime: 8.2286958694458 sec\n",
      "Epoch 324 \n",
      "D loss: 0.397370, G loss: 0.000000\n",
      "Runtime: 8.22379446029663 sec\n",
      "Epoch 325 \n",
      "D loss: 0.386855, G loss: 0.000000\n",
      "Runtime: 8.547491312026978 sec\n",
      "Epoch 326 \n",
      "D loss: 0.014555, G loss: 0.000000\n",
      "Runtime: 8.786919832229614 sec\n",
      "Epoch 327 \n",
      "D loss: 0.021100, G loss: 0.000000\n",
      "Runtime: 8.28653621673584 sec\n",
      "Epoch 328 \n",
      "D loss: 0.045257, G loss: 0.000000\n",
      "Runtime: 8.516305923461914 sec\n",
      "Epoch 329 \n",
      "D loss: 0.035715, G loss: 0.000000\n",
      "Runtime: 8.746442317962646 sec\n",
      "Epoch 330 \n",
      "D loss: 0.010803, G loss: 0.000000\n",
      "Runtime: 8.677185297012329 sec\n",
      "Epoch 331 \n",
      "D loss: 0.007732, G loss: 0.000000\n",
      "Runtime: 8.41763949394226 sec\n",
      "Epoch 332 \n",
      "D loss: 0.106150, G loss: 0.000000\n",
      "Runtime: 8.395476579666138 sec\n",
      "Epoch 333 \n",
      "D loss: 0.015027, G loss: 0.000000\n",
      "Runtime: 8.260476112365723 sec\n",
      "Epoch 334 \n",
      "D loss: 0.513366, G loss: 0.000000\n",
      "Runtime: 8.287329196929932 sec\n",
      "Epoch 335 \n",
      "D loss: 0.070797, G loss: 0.000000\n",
      "Runtime: 8.477478742599487 sec\n",
      "Epoch 336 \n",
      "D loss: 0.136336, G loss: 0.000000\n",
      "Runtime: 8.505317687988281 sec\n",
      "Epoch 337 \n",
      "D loss: 0.055949, G loss: 0.000000\n",
      "Runtime: 8.32405710220337 sec\n",
      "Epoch 338 \n",
      "D loss: 0.038009, G loss: 0.000000\n",
      "Runtime: 8.542789459228516 sec\n",
      "Epoch 339 \n",
      "D loss: 0.015934, G loss: 0.000000\n",
      "Runtime: 8.39932370185852 sec\n",
      "Epoch 340 \n",
      "D loss: 0.147549, G loss: 0.000000\n",
      "Runtime: 8.406280517578125 sec\n",
      "Epoch 341 \n",
      "D loss: 0.015732, G loss: 0.000000\n",
      "Runtime: 8.359347343444824 sec\n",
      "Epoch 342 \n",
      "D loss: 0.008956, G loss: 0.000000\n",
      "Runtime: 8.310806512832642 sec\n",
      "Epoch 343 \n",
      "D loss: 0.150564, G loss: 0.000000\n",
      "Runtime: 8.334678649902344 sec\n",
      "Epoch 344 \n",
      "D loss: 0.063811, G loss: 0.000000\n",
      "Runtime: 8.441287517547607 sec\n",
      "Epoch 345 \n",
      "D loss: 0.034082, G loss: 0.000000\n",
      "Runtime: 8.337408542633057 sec\n",
      "Epoch 346 \n",
      "D loss: 0.156362, G loss: 0.000000\n",
      "Runtime: 8.75631308555603 sec\n",
      "Epoch 347 \n",
      "D loss: 0.071047, G loss: 0.000000\n",
      "Runtime: 8.276089429855347 sec\n",
      "Epoch 348 \n",
      "D loss: 0.161402, G loss: 0.000000\n",
      "Runtime: 8.357267618179321 sec\n",
      "Epoch 349 \n",
      "D loss: 0.036623, G loss: 0.000000\n",
      "Runtime: 8.498117208480835 sec\n",
      "Epoch 350 \n",
      "D loss: 0.340605, G loss: 0.000000\n",
      "Runtime: 8.399407625198364 sec\n",
      "Epoch 351 \n",
      "D loss: 0.034269, G loss: 0.000000\n",
      "Runtime: 8.370282411575317 sec\n",
      "Epoch 352 \n",
      "D loss: 0.020410, G loss: 0.000000\n",
      "Runtime: 8.276917695999146 sec\n",
      "Epoch 353 \n",
      "D loss: 0.169926, G loss: 0.000000\n",
      "Runtime: 8.225877285003662 sec\n",
      "Epoch 354 \n",
      "D loss: 0.292262, G loss: 0.000000\n",
      "Runtime: 8.240783929824829 sec\n",
      "Epoch 355 \n",
      "D loss: 0.369936, G loss: 0.000000\n",
      "Runtime: 8.189204216003418 sec\n",
      "Epoch 356 \n",
      "D loss: 0.014554, G loss: 0.000000\n",
      "Runtime: 8.450389385223389 sec\n",
      "Epoch 357 \n",
      "D loss: 0.117453, G loss: 0.000000\n",
      "Runtime: 8.828701257705688 sec\n",
      "Epoch 358 \n",
      "D loss: 0.040451, G loss: 0.000000\n",
      "Runtime: 8.09313702583313 sec\n",
      "Epoch 359 \n",
      "D loss: 0.023866, G loss: 0.000000\n",
      "Runtime: 8.290926456451416 sec\n",
      "Epoch 360 \n",
      "D loss: 0.013701, G loss: 0.000000\n",
      "Runtime: 8.253520011901855 sec\n",
      "Epoch 361 \n",
      "D loss: 0.039528, G loss: 0.000000\n",
      "Runtime: 8.19675326347351 sec\n",
      "Epoch 362 \n",
      "D loss: 0.013115, G loss: 0.000000\n",
      "Runtime: 8.162360668182373 sec\n",
      "Epoch 363 \n",
      "D loss: 0.216457, G loss: 0.000000\n",
      "Runtime: 8.278702735900879 sec\n",
      "Epoch 364 \n",
      "D loss: 0.007848, G loss: 0.000000\n",
      "Runtime: 8.419987678527832 sec\n",
      "Epoch 365 \n",
      "D loss: 0.044466, G loss: 0.000000\n",
      "Runtime: 8.490994691848755 sec\n",
      "Epoch 366 \n",
      "D loss: 0.122262, G loss: 0.000000\n",
      "Runtime: 8.609128713607788 sec\n",
      "Epoch 367 \n",
      "D loss: 0.022145, G loss: 0.000000\n",
      "Runtime: 8.469833612442017 sec\n",
      "Epoch 368 \n",
      "D loss: 0.062947, G loss: 0.000000\n",
      "Runtime: 8.28883671760559 sec\n",
      "Epoch 369 \n",
      "D loss: 0.018741, G loss: 0.000000\n",
      "Runtime: 8.27734923362732 sec\n",
      "Epoch 370 \n",
      "D loss: 0.066197, G loss: 0.000000\n",
      "Runtime: 8.308685064315796 sec\n",
      "Epoch 371 \n",
      "D loss: 0.241917, G loss: 0.000000\n",
      "Runtime: 8.187636852264404 sec\n",
      "Epoch 372 \n",
      "D loss: 0.048179, G loss: 0.000000\n",
      "Runtime: 8.293990850448608 sec\n",
      "Epoch 373 \n",
      "D loss: 0.009495, G loss: 0.000000\n",
      "Runtime: 8.409541368484497 sec\n",
      "Epoch 374 \n",
      "D loss: 0.035820, G loss: 0.000000\n",
      "Runtime: 8.244455814361572 sec\n",
      "Epoch 375 \n",
      "D loss: 0.042001, G loss: 0.000000\n",
      "Runtime: 8.64574408531189 sec\n",
      "Epoch 376 \n",
      "D loss: 0.314110, G loss: 0.000000\n",
      "Runtime: 8.3835129737854 sec\n",
      "Epoch 377 \n",
      "D loss: 0.107768, G loss: 0.000000\n",
      "Runtime: 8.233707427978516 sec\n",
      "Epoch 378 \n",
      "D loss: 0.017006, G loss: 0.000000\n",
      "Runtime: 8.41858720779419 sec\n",
      "Epoch 379 \n",
      "D loss: 0.013273, G loss: 0.000000\n",
      "Runtime: 8.421840190887451 sec\n",
      "Epoch 380 \n",
      "D loss: 0.348833, G loss: 0.000000\n",
      "Runtime: 8.243274450302124 sec\n",
      "Epoch 381 \n",
      "D loss: 0.095180, G loss: 0.000000\n",
      "Runtime: 8.491081476211548 sec\n",
      "Epoch 382 \n",
      "D loss: 0.022880, G loss: 0.000000\n",
      "Runtime: 8.333510398864746 sec\n",
      "Epoch 383 \n",
      "D loss: 0.069030, G loss: 0.000000\n",
      "Runtime: 8.639427423477173 sec\n",
      "Epoch 384 \n",
      "D loss: 0.005668, G loss: 0.000000\n",
      "Runtime: 8.355699300765991 sec\n",
      "Epoch 385 \n",
      "D loss: 0.037691, G loss: 0.000000\n",
      "Runtime: 8.358223676681519 sec\n",
      "Epoch 386 \n",
      "D loss: 0.029817, G loss: 0.000000\n",
      "Runtime: 8.439231872558594 sec\n",
      "Epoch 387 \n",
      "D loss: 0.009287, G loss: 0.000000\n",
      "Runtime: 8.22031283378601 sec\n",
      "Epoch 388 \n",
      "D loss: 0.034809, G loss: 0.000000\n",
      "Runtime: 8.802315711975098 sec\n",
      "Epoch 389 \n",
      "D loss: 0.212406, G loss: 0.000000\n",
      "Runtime: 8.339305877685547 sec\n",
      "Epoch 390 \n",
      "D loss: 0.569010, G loss: 0.000000\n",
      "Runtime: 8.473273992538452 sec\n",
      "Epoch 391 \n",
      "D loss: 0.022351, G loss: 0.000000\n",
      "Runtime: 8.248125791549683 sec\n",
      "Epoch 392 \n",
      "D loss: 0.022819, G loss: 0.000000\n",
      "Runtime: 8.255413293838501 sec\n",
      "Epoch 393 \n",
      "D loss: 0.095463, G loss: 0.000000\n",
      "Runtime: 8.184884786605835 sec\n",
      "Epoch 394 \n",
      "D loss: 0.304634, G loss: 0.000000\n",
      "Runtime: 8.40124249458313 sec\n",
      "Epoch 395 \n",
      "D loss: 0.006975, G loss: 0.000000\n",
      "Runtime: 8.233262300491333 sec\n",
      "Epoch 396 \n",
      "D loss: 0.165156, G loss: 0.000000\n",
      "Runtime: 8.438186407089233 sec\n",
      "Epoch 397 \n",
      "D loss: 0.059046, G loss: 0.000000\n",
      "Runtime: 8.38825535774231 sec\n",
      "Epoch 398 \n",
      "D loss: 0.054176, G loss: 0.000000\n",
      "Runtime: 8.154318571090698 sec\n",
      "Epoch 399 \n",
      "D loss: 0.018435, G loss: 0.000000\n",
      "Runtime: 8.45702576637268 sec\n",
      "Epoch 400 \n",
      "D loss: 0.057477, G loss: 0.000000\n",
      "Runtime: 7.713139533996582 sec\n",
      "Epoch 401 \n",
      "D loss: 0.014416, G loss: 0.000000\n",
      "Runtime: 7.711893320083618 sec\n",
      "Epoch 402 \n",
      "D loss: 0.032907, G loss: 0.000000\n",
      "Runtime: 7.813425779342651 sec\n",
      "Epoch 403 \n",
      "D loss: 0.003033, G loss: 0.000000\n",
      "Runtime: 7.67674994468689 sec\n",
      "Epoch 404 \n",
      "D loss: 0.065530, G loss: 0.000000\n",
      "Runtime: 7.576138496398926 sec\n",
      "Epoch 405 \n",
      "D loss: 0.026586, G loss: 0.000000\n",
      "Runtime: 7.634401559829712 sec\n",
      "Epoch 406 \n",
      "D loss: 0.061349, G loss: 0.000000\n",
      "Runtime: 7.512921333312988 sec\n",
      "Epoch 407 \n",
      "D loss: 0.006438, G loss: 0.000000\n",
      "Runtime: 7.447794675827026 sec\n",
      "Epoch 408 \n",
      "D loss: 0.008228, G loss: 0.000000\n",
      "Runtime: 7.436509132385254 sec\n",
      "Epoch 409 \n",
      "D loss: 0.006116, G loss: 0.000000\n",
      "Runtime: 7.248415231704712 sec\n",
      "Epoch 410 \n",
      "D loss: 0.033994, G loss: 0.000000\n",
      "Runtime: 7.396099805831909 sec\n",
      "Epoch 411 \n",
      "D loss: 0.006166, G loss: 0.000000\n",
      "Runtime: 7.369150876998901 sec\n",
      "Epoch 412 \n",
      "D loss: 0.005114, G loss: 0.000000\n",
      "Runtime: 7.357469797134399 sec\n",
      "Epoch 413 \n",
      "D loss: 0.012441, G loss: 0.000000\n",
      "Runtime: 7.28374981880188 sec\n",
      "Epoch 414 \n",
      "D loss: 0.060409, G loss: 0.000000\n",
      "Runtime: 7.35789155960083 sec\n",
      "Epoch 415 \n",
      "D loss: 0.009337, G loss: 0.000000\n",
      "Runtime: 7.378852128982544 sec\n",
      "Epoch 416 \n",
      "D loss: 0.022484, G loss: 0.000000\n",
      "Runtime: 7.408707857131958 sec\n",
      "Epoch 417 \n",
      "D loss: 0.009120, G loss: 0.000000\n",
      "Runtime: 7.298764944076538 sec\n",
      "Epoch 418 \n",
      "D loss: 0.016504, G loss: 0.000000\n",
      "Runtime: 7.411107063293457 sec\n",
      "Epoch 419 \n",
      "D loss: 0.018562, G loss: 0.000000\n",
      "Runtime: 7.97745680809021 sec\n",
      "Epoch 420 \n",
      "D loss: 0.012543, G loss: 0.000000\n",
      "Runtime: 7.382316827774048 sec\n",
      "Epoch 421 \n",
      "D loss: 0.085800, G loss: 0.000000\n",
      "Runtime: 7.3017377853393555 sec\n",
      "Epoch 422 \n",
      "D loss: 0.008517, G loss: 0.000000\n",
      "Runtime: 7.439214706420898 sec\n",
      "Epoch 423 \n",
      "D loss: 0.017298, G loss: 0.000000\n",
      "Runtime: 7.343710899353027 sec\n",
      "Epoch 424 \n",
      "D loss: 0.046698, G loss: 0.000000\n",
      "Runtime: 8.050100088119507 sec\n",
      "Epoch 425 \n",
      "D loss: 0.010563, G loss: 0.000000\n",
      "Runtime: 8.405857563018799 sec\n",
      "Epoch 426 \n",
      "D loss: 0.091205, G loss: 0.000000\n",
      "Runtime: 8.224388837814331 sec\n",
      "Epoch 427 \n",
      "D loss: 0.004490, G loss: 0.000000\n",
      "Runtime: 8.179296970367432 sec\n",
      "Epoch 428 \n",
      "D loss: 0.022572, G loss: 0.000000\n",
      "Runtime: 8.21004843711853 sec\n",
      "Epoch 429 \n",
      "D loss: 0.843986, G loss: 0.000000\n",
      "Runtime: 8.275688171386719 sec\n",
      "Epoch 430 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D loss: 0.056233, G loss: 0.000000\n",
      "Runtime: 8.079274415969849 sec\n",
      "Epoch 431 \n",
      "D loss: 0.054654, G loss: 0.000000\n",
      "Runtime: 8.135852813720703 sec\n",
      "Epoch 432 \n",
      "D loss: 0.033158, G loss: 0.000000\n",
      "Runtime: 8.197063207626343 sec\n",
      "Epoch 433 \n",
      "D loss: 0.034758, G loss: 0.000000\n",
      "Runtime: 8.129900693893433 sec\n",
      "Epoch 434 \n",
      "D loss: 0.133804, G loss: 0.000000\n",
      "Runtime: 8.139867305755615 sec\n",
      "Epoch 435 \n",
      "D loss: 0.173683, G loss: 0.000000\n",
      "Runtime: 8.324730396270752 sec\n",
      "Epoch 436 \n",
      "D loss: 0.008210, G loss: 0.000000\n",
      "Runtime: 8.205647230148315 sec\n",
      "Epoch 437 \n",
      "D loss: 0.007784, G loss: 0.000000\n",
      "Runtime: 8.457895278930664 sec\n",
      "Epoch 438 \n",
      "D loss: 0.019174, G loss: 0.000000\n",
      "Runtime: 8.46771788597107 sec\n",
      "Epoch 439 \n",
      "D loss: 0.027065, G loss: 0.000000\n",
      "Runtime: 8.546318769454956 sec\n",
      "Epoch 440 \n",
      "D loss: 0.078935, G loss: 0.000000\n",
      "Runtime: 8.485247135162354 sec\n",
      "Epoch 441 \n",
      "D loss: 0.012767, G loss: 0.000000\n",
      "Runtime: 8.38861632347107 sec\n",
      "Epoch 442 \n",
      "D loss: 0.018856, G loss: 0.000000\n",
      "Runtime: 8.455402612686157 sec\n",
      "Epoch 443 \n",
      "D loss: 0.015469, G loss: 0.000000\n",
      "Runtime: 8.12451958656311 sec\n",
      "Epoch 444 \n",
      "D loss: 0.004612, G loss: 0.000000\n",
      "Runtime: 8.263196229934692 sec\n",
      "Epoch 445 \n",
      "D loss: 0.027163, G loss: 0.000000\n",
      "Runtime: 8.357472658157349 sec\n",
      "Epoch 446 \n",
      "D loss: 0.023550, G loss: 0.000000\n",
      "Runtime: 8.499676942825317 sec\n",
      "Epoch 447 \n",
      "D loss: 0.008414, G loss: 0.000000\n",
      "Runtime: 8.20831561088562 sec\n",
      "Epoch 448 \n",
      "D loss: 0.049911, G loss: 0.000000\n",
      "Runtime: 9.164602041244507 sec\n",
      "Epoch 449 \n",
      "D loss: 0.006912, G loss: 0.000000\n",
      "Runtime: 9.30695629119873 sec\n",
      "Epoch 450 \n",
      "D loss: 0.198358, G loss: 0.000000\n",
      "Runtime: 9.392788648605347 sec\n",
      "Epoch 451 \n",
      "D loss: 0.052539, G loss: 0.000000\n",
      "Runtime: 8.630022764205933 sec\n",
      "Epoch 452 \n",
      "D loss: 0.004814, G loss: 0.000000\n",
      "Runtime: 8.620415210723877 sec\n",
      "Epoch 453 \n",
      "D loss: 0.068034, G loss: 0.000000\n",
      "Runtime: 8.627044439315796 sec\n",
      "Epoch 454 \n",
      "D loss: 0.042988, G loss: 0.000000\n",
      "Runtime: 8.564789056777954 sec\n",
      "Epoch 455 \n",
      "D loss: 0.139361, G loss: 0.000000\n",
      "Runtime: 8.94991159439087 sec\n",
      "Epoch 456 \n",
      "D loss: 0.005594, G loss: 0.000000\n",
      "Runtime: 8.780279397964478 sec\n",
      "Epoch 457 \n",
      "D loss: 0.002222, G loss: 0.000000\n",
      "Runtime: 8.469428777694702 sec\n",
      "Epoch 458 \n",
      "D loss: 0.004138, G loss: 0.000000\n",
      "Runtime: 8.236246824264526 sec\n",
      "Epoch 459 \n",
      "D loss: 0.097798, G loss: 0.000000\n",
      "Runtime: 8.198633670806885 sec\n",
      "Epoch 460 \n",
      "D loss: 0.008711, G loss: 0.000000\n",
      "Runtime: 8.201969861984253 sec\n",
      "Epoch 461 \n",
      "D loss: 0.013602, G loss: 0.000000\n",
      "Runtime: 8.168564796447754 sec\n",
      "Epoch 462 \n",
      "D loss: 0.006495, G loss: 0.000000\n",
      "Runtime: 8.286644697189331 sec\n",
      "Epoch 463 \n",
      "D loss: 0.007356, G loss: 0.000000\n",
      "Runtime: 8.211877584457397 sec\n",
      "Epoch 464 \n",
      "D loss: 0.097437, G loss: 0.000000\n",
      "Runtime: 8.33234715461731 sec\n",
      "Epoch 465 \n",
      "D loss: 0.278702, G loss: 0.000000\n",
      "Runtime: 8.343718767166138 sec\n",
      "Epoch 466 \n",
      "D loss: 0.275272, G loss: 0.000000\n",
      "Runtime: 8.671458005905151 sec\n",
      "Epoch 467 \n",
      "D loss: 0.018128, G loss: 0.000000\n",
      "Runtime: 8.474669694900513 sec\n",
      "Epoch 468 \n",
      "D loss: 0.007074, G loss: 0.000000\n",
      "Runtime: 8.65943193435669 sec\n",
      "Epoch 469 \n",
      "D loss: 0.004817, G loss: 0.000000\n",
      "Runtime: 8.503051280975342 sec\n",
      "Epoch 470 \n",
      "D loss: 0.044433, G loss: 0.000000\n",
      "Runtime: 8.246011972427368 sec\n",
      "Epoch 471 \n",
      "D loss: 0.021791, G loss: 0.000000\n",
      "Runtime: 8.1890709400177 sec\n",
      "Epoch 472 \n",
      "D loss: 0.032397, G loss: 0.000000\n",
      "Runtime: 8.32619309425354 sec\n",
      "Epoch 473 \n",
      "D loss: 0.056911, G loss: 0.000000\n",
      "Runtime: 8.2227303981781 sec\n",
      "Epoch 474 \n",
      "D loss: 0.011681, G loss: 0.000000\n",
      "Runtime: 8.338674068450928 sec\n",
      "Epoch 475 \n",
      "D loss: 0.032832, G loss: 0.000000\n",
      "Runtime: 8.570642232894897 sec\n",
      "Epoch 476 \n",
      "D loss: 0.032560, G loss: 0.000000\n",
      "Runtime: 8.47627592086792 sec\n",
      "Epoch 477 \n",
      "D loss: 0.025396, G loss: 0.000000\n",
      "Runtime: 8.53652811050415 sec\n",
      "Epoch 478 \n",
      "D loss: 0.005594, G loss: 0.000000\n",
      "Runtime: 8.236133098602295 sec\n",
      "Epoch 479 \n",
      "D loss: 0.153385, G loss: 0.000000\n",
      "Runtime: 8.164907932281494 sec\n",
      "Epoch 480 \n",
      "D loss: 0.035959, G loss: 0.000000\n",
      "Runtime: 8.40380859375 sec\n",
      "Epoch 481 \n",
      "D loss: 0.088478, G loss: 0.000000\n",
      "Runtime: 8.93812084197998 sec\n",
      "Epoch 482 \n",
      "D loss: 0.009704, G loss: 0.000000\n",
      "Runtime: 8.576106786727905 sec\n",
      "Epoch 483 \n",
      "D loss: 0.025772, G loss: 0.000000\n",
      "Runtime: 8.313722610473633 sec\n",
      "Epoch 484 \n",
      "D loss: 0.008676, G loss: 0.000000\n",
      "Runtime: 8.482803344726562 sec\n",
      "Epoch 485 \n",
      "D loss: 0.004167, G loss: 0.000000\n",
      "Runtime: 8.198542356491089 sec\n",
      "Epoch 486 \n",
      "D loss: 0.138639, G loss: 0.000000\n",
      "Runtime: 8.297785997390747 sec\n",
      "Epoch 487 \n",
      "D loss: 0.062483, G loss: 0.000000\n",
      "Runtime: 8.240686655044556 sec\n",
      "Epoch 488 \n",
      "D loss: 0.022857, G loss: 0.000000\n",
      "Runtime: 8.331178903579712 sec\n",
      "Epoch 489 \n",
      "D loss: 0.031290, G loss: 0.000000\n",
      "Runtime: 8.174830913543701 sec\n",
      "Epoch 490 \n",
      "D loss: 0.064763, G loss: 0.000000\n",
      "Runtime: 8.199607610702515 sec\n",
      "Epoch 491 \n",
      "D loss: 0.007841, G loss: 0.000000\n",
      "Runtime: 8.279410600662231 sec\n",
      "Epoch 492 \n",
      "D loss: 0.023757, G loss: 0.000000\n",
      "Runtime: 8.230041980743408 sec\n",
      "Epoch 493 \n",
      "D loss: 0.005978, G loss: 0.000000\n",
      "Runtime: 8.164061069488525 sec\n",
      "Epoch 494 \n",
      "D loss: 0.007614, G loss: 0.000000\n",
      "Runtime: 8.342812299728394 sec\n",
      "Epoch 495 \n",
      "D loss: 0.012611, G loss: 0.000000\n",
      "Runtime: 8.241493940353394 sec\n",
      "Epoch 496 \n",
      "D loss: 0.011878, G loss: 0.000000\n",
      "Runtime: 8.285577058792114 sec\n",
      "Epoch 497 \n",
      "D loss: 0.020979, G loss: 0.000000\n",
      "Runtime: 8.482118606567383 sec\n",
      "Epoch 498 \n",
      "D loss: 0.028565, G loss: 0.000000\n",
      "Runtime: 8.365742921829224 sec\n",
      "Epoch 499 \n",
      "D loss: 0.015655, G loss: 0.000000\n",
      "Runtime: 8.438404560089111 sec\n",
      "Epoch 500 \n",
      "D loss: 0.007270, G loss: 0.000000\n",
      "Runtime: 8.302010774612427 sec\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1h 11min 8s\n",
      "Wall time: 1h 5min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc(discriminator, bi_class, num_classes):\n",
    "\n",
    "#     den = Dense(64, activation='relu')(discriminator)\n",
    "#     den = tf.keras.layers.LeakyReLU()(den)\n",
    "    den = Dense(32)(discriminator)\n",
    "    den = tf.keras.layers.LeakyReLU()(den)\n",
    "    den = BatchNormalization()(den)\n",
    "#     den = Dropout(0.5)(den)\n",
    "#     den = Dense(16)(den)\n",
    "#     den = tf.keras.layers.LeakyReLU()(den)\n",
    "    \n",
    "    \n",
    "    if bi_class == 0:\n",
    "        den = Dense(num_classes, activation='softmax')(den)\n",
    "    else:\n",
    "        den = Dense(2, activation='softmax')(den)\n",
    "#     den = BatchNormalization()(den)\n",
    "#     den = tf.keras.layers.LeakyReLU()(den)\n",
    "#     den = Dense(7)(den)\n",
    "#     den = BatchNormalization()(den)\n",
    "#     out = tf.keras.activations.softmax(den)\n",
    "    \n",
    "    return den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Classification_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 276, 50, 31)]     0         \n",
      "_________________________________________________________________\n",
      "reshape1 (Reshape)           (None, 276, 1550)         0         \n",
      "_________________________________________________________________\n",
      "disc_rnn1 (GRU)              (None, 276, 200)          1051200   \n",
      "_________________________________________________________________\n",
      "disc_BM1 (BatchNormalization (None, 276, 200)          800       \n",
      "_________________________________________________________________\n",
      "disc_conv1 (Conv1D)          (None, 276, 64)           102464    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "disc_BM2 (BatchNormalization (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "disc_activ1 (LeakyReLU)      (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 1,156,994\n",
      "Trainable params: 1,156,402\n",
      "Non-trainable params: 592\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "disc = make_discriminator_model(feature_input)\n",
    "full_model = Model(feature_input,fc(disc, bi_class, num_classes), name=\"Classification_model\")\n",
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l1,l2 in zip(full_model.layers[:8], discriminator.layers[:8]):\n",
    "    l1.set_weights(l2.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in full_model.layers[:8]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.8325 - accuracy: 0.5802 - auc: 0.5929 - val_loss: 0.0966 - val_accuracy: 0.9596 - val_auc: 0.9984\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.6666 - accuracy: 0.6539 - auc: 0.6815 - val_loss: 2.9995e-06 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.6336 - accuracy: 0.6896 - auc: 0.7294 - val_loss: 5.7528e-07 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.6801 - accuracy: 0.6234 - auc: 0.6569 - val_loss: 7.0493e-04 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.6285 - accuracy: 0.6565 - auc: 0.7169 - val_loss: 4.5061e-04 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.6338 - accuracy: 0.6997 - auc: 0.7346 - val_loss: 4.4736e-04 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.6127 - accuracy: 0.6794 - auc: 0.7342 - val_loss: 2.9299e-04 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.6300 - accuracy: 0.6641 - auc: 0.7271 - val_loss: 0.0080 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.6185 - accuracy: 0.6718 - auc: 0.7310 - val_loss: 0.0056 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5934 - accuracy: 0.6768 - auc: 0.7500 - val_loss: 0.0073 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.6054 - accuracy: 0.6896 - auc: 0.7504 - val_loss: 0.0138 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.5927 - accuracy: 0.6768 - auc: 0.7571 - val_loss: 0.0315 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 1s 71ms/step - loss: 0.6007 - accuracy: 0.6896 - auc: 0.7472 - val_loss: 0.0413 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.6303 - accuracy: 0.6743 - auc: 0.7206 - val_loss: 0.0491 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.5865 - accuracy: 0.6947 - auc: 0.7638 - val_loss: 0.0126 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.5752 - accuracy: 0.7074 - auc: 0.7757 - val_loss: 0.0320 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.5937 - accuracy: 0.7023 - auc: 0.7486 - val_loss: 0.1366 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.5957 - accuracy: 0.6947 - auc: 0.7519 - val_loss: 0.1815 - val_accuracy: 0.9899 - val_auc: 0.9995\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.5851 - accuracy: 0.7125 - auc: 0.7633 - val_loss: 0.0923 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.5874 - accuracy: 0.6947 - auc: 0.7564 - val_loss: 0.1136 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.5604 - accuracy: 0.7074 - auc: 0.7844 - val_loss: 0.0770 - val_accuracy: 0.9697 - val_auc: 0.9991\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.5885 - accuracy: 0.6667 - auc: 0.7534 - val_loss: 0.0931 - val_accuracy: 0.9899 - val_auc: 0.9999\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.6019 - accuracy: 0.6692 - auc: 0.7427 - val_loss: 0.1305 - val_accuracy: 0.9697 - val_auc: 0.9991\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.5605 - accuracy: 0.6921 - auc: 0.7850 - val_loss: 0.1337 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.5688 - accuracy: 0.7176 - auc: 0.7734 - val_loss: 0.2657 - val_accuracy: 0.9596 - val_auc: 0.9607\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.5884 - accuracy: 0.7023 - auc: 0.7718 - val_loss: 0.2768 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.5721 - accuracy: 0.6972 - auc: 0.7717 - val_loss: 0.1912 - val_accuracy: 0.9596 - val_auc: 0.9754\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.5937 - accuracy: 0.6870 - auc: 0.7675 - val_loss: 0.3979 - val_accuracy: 0.9495 - val_auc: 0.9928\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.5694 - accuracy: 0.6794 - auc: 0.7694 - val_loss: 0.4179 - val_accuracy: 0.9091 - val_auc: 0.9549\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.5598 - accuracy: 0.6947 - auc: 0.7814 - val_loss: 0.5696 - val_accuracy: 0.5859 - val_auc: 0.7384\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.5574 - accuracy: 0.7099 - auc: 0.7921 - val_loss: 0.3506 - val_accuracy: 0.8283 - val_auc: 0.9495\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.5563 - accuracy: 0.6972 - auc: 0.7870 - val_loss: 0.5840 - val_accuracy: 0.6566 - val_auc: 0.7265\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.5784 - accuracy: 0.7074 - auc: 0.7739 - val_loss: 0.4370 - val_accuracy: 0.8687 - val_auc: 0.9069\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.5566 - accuracy: 0.7125 - auc: 0.7844 - val_loss: 0.4476 - val_accuracy: 0.8586 - val_auc: 0.8728\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.6052 - accuracy: 0.7150 - auc: 0.7566 - val_loss: 0.5514 - val_accuracy: 0.7273 - val_auc: 0.8081\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.5914 - accuracy: 0.7023 - auc: 0.7577 - val_loss: 0.2478 - val_accuracy: 0.9899 - val_auc: 0.9985\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.5735 - accuracy: 0.7074 - auc: 0.7708 - val_loss: 0.4739 - val_accuracy: 0.7576 - val_auc: 0.8739\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.5386 - accuracy: 0.7303 - auc: 0.8054 - val_loss: 0.8704 - val_accuracy: 0.4444 - val_auc: 0.3608\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.5745 - accuracy: 0.6819 - auc: 0.7666 - val_loss: 0.6548 - val_accuracy: 0.4949 - val_auc: 0.6610\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.5368 - accuracy: 0.7226 - auc: 0.7997 - val_loss: 0.8840 - val_accuracy: 0.3838 - val_auc: 0.4339\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.5469 - accuracy: 0.7125 - auc: 0.7968 - val_loss: 0.8373 - val_accuracy: 0.3737 - val_auc: 0.4515\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.5595 - accuracy: 0.7048 - auc: 0.7843 - val_loss: 0.7928 - val_accuracy: 0.4444 - val_auc: 0.4881\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.5594 - accuracy: 0.6997 - auc: 0.7825 - val_loss: 0.8181 - val_accuracy: 0.3636 - val_auc: 0.4846\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.5329 - accuracy: 0.7201 - auc: 0.8072 - val_loss: 1.2263 - val_accuracy: 0.3131 - val_auc: 0.2141\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.5279 - accuracy: 0.7252 - auc: 0.8154 - val_loss: 0.8907 - val_accuracy: 0.4444 - val_auc: 0.3838\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.5336 - accuracy: 0.7023 - auc: 0.8018 - val_loss: 1.7017 - val_accuracy: 0.1010 - val_auc: 0.0533\n",
      "Epoch 47/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 54ms/step - loss: 0.5646 - accuracy: 0.7099 - auc: 0.7846 - val_loss: 0.8961 - val_accuracy: 0.4343 - val_auc: 0.3382\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.5618 - accuracy: 0.6921 - auc: 0.7861 - val_loss: 1.5531 - val_accuracy: 0.0707 - val_auc: 0.0301\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.5662 - accuracy: 0.6896 - auc: 0.7779 - val_loss: 0.6364 - val_accuracy: 0.6566 - val_auc: 0.6863\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.5468 - accuracy: 0.6972 - auc: 0.7950 - val_loss: 0.4303 - val_accuracy: 0.8384 - val_auc: 0.9163\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.5731 - accuracy: 0.7201 - auc: 0.7734 - val_loss: 0.9741 - val_accuracy: 0.3939 - val_auc: 0.2936\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.5581 - accuracy: 0.7125 - auc: 0.7876 - val_loss: 0.7961 - val_accuracy: 0.3939 - val_auc: 0.4627\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.5339 - accuracy: 0.7303 - auc: 0.8052 - val_loss: 0.7350 - val_accuracy: 0.4545 - val_auc: 0.5581\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.5171 - accuracy: 0.7430 - auc: 0.8229 - val_loss: 0.9733 - val_accuracy: 0.4242 - val_auc: 0.3108\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.6479 - accuracy: 0.6819 - auc: 0.7423 - val_loss: 0.8016 - val_accuracy: 0.4444 - val_auc: 0.3257\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.5751 - accuracy: 0.6896 - auc: 0.7687 - val_loss: 0.3380 - val_accuracy: 0.8788 - val_auc: 0.9621\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.5347 - accuracy: 0.7099 - auc: 0.8056 - val_loss: 0.2304 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.5380 - accuracy: 0.7557 - auc: 0.8111 - val_loss: 0.6072 - val_accuracy: 0.5455 - val_auc: 0.6822\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.5314 - accuracy: 0.7303 - auc: 0.8090 - val_loss: 0.4932 - val_accuracy: 0.6768 - val_auc: 0.8412\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.5486 - accuracy: 0.7328 - auc: 0.7980 - val_loss: 0.2919 - val_accuracy: 0.9192 - val_auc: 0.9858\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.5308 - accuracy: 0.7150 - auc: 0.8130 - val_loss: 0.2447 - val_accuracy: 0.9091 - val_auc: 0.9898\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.5213 - accuracy: 0.7328 - auc: 0.8218 - val_loss: 0.2722 - val_accuracy: 0.9899 - val_auc: 0.9963\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.5081 - accuracy: 0.7481 - auc: 0.8292 - val_loss: 0.8633 - val_accuracy: 0.4040 - val_auc: 0.4450\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5337 - accuracy: 0.7506 - auc: 0.8099 - val_loss: 0.4476 - val_accuracy: 0.7980 - val_auc: 0.8850\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.5249 - accuracy: 0.7303 - auc: 0.8117 - val_loss: 1.2828 - val_accuracy: 0.3737 - val_auc: 0.2393\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.5405 - accuracy: 0.7150 - auc: 0.7947 - val_loss: 0.9170 - val_accuracy: 0.5253 - val_auc: 0.5731\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5368 - accuracy: 0.7201 - auc: 0.8072 - val_loss: 1.0221 - val_accuracy: 0.3434 - val_auc: 0.3446\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4987 - accuracy: 0.7354 - auc: 0.8309 - val_loss: 0.5981 - val_accuracy: 0.8182 - val_auc: 0.7933\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.5120 - accuracy: 0.7354 - auc: 0.8229 - val_loss: 0.6951 - val_accuracy: 0.7677 - val_auc: 0.7464\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.5399 - accuracy: 0.7074 - auc: 0.8010 - val_loss: 0.8711 - val_accuracy: 0.4545 - val_auc: 0.4986\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.5714 - accuracy: 0.7201 - auc: 0.7764 - val_loss: 0.8151 - val_accuracy: 0.4545 - val_auc: 0.4570\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 1s 79ms/step - loss: 0.5272 - accuracy: 0.7252 - auc: 0.8076 - val_loss: 0.9304 - val_accuracy: 0.4242 - val_auc: 0.3846\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 1s 79ms/step - loss: 0.4905 - accuracy: 0.7659 - auc: 0.8420 - val_loss: 1.0109 - val_accuracy: 0.4949 - val_auc: 0.3851\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 1s 70ms/step - loss: 0.5099 - accuracy: 0.7354 - auc: 0.8270 - val_loss: 1.2964 - val_accuracy: 0.2424 - val_auc: 0.0985\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 1s 72ms/step - loss: 0.5111 - accuracy: 0.7430 - auc: 0.8263 - val_loss: 2.0943 - val_accuracy: 0.0303 - val_auc: 0.0122\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 1s 72ms/step - loss: 0.5628 - accuracy: 0.7150 - auc: 0.7801 - val_loss: 0.9195 - val_accuracy: 0.4444 - val_auc: 0.3400\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.5051 - accuracy: 0.7506 - auc: 0.8307 - val_loss: 0.9476 - val_accuracy: 0.4242 - val_auc: 0.4337\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.6223 - accuracy: 0.7125 - auc: 0.7814 - val_loss: 0.4578 - val_accuracy: 0.7980 - val_auc: 0.8756\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.5658 - accuracy: 0.6870 - auc: 0.7740 - val_loss: 0.2650 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.5225 - accuracy: 0.7328 - auc: 0.8203 - val_loss: 0.1453 - val_accuracy: 0.9697 - val_auc: 0.9991\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 1s 72ms/step - loss: 0.5501 - accuracy: 0.7328 - auc: 0.8031 - val_loss: 0.4390 - val_accuracy: 0.8384 - val_auc: 0.9020\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.5192 - accuracy: 0.7354 - auc: 0.8214 - val_loss: 0.3342 - val_accuracy: 0.8788 - val_auc: 0.9438\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.5252 - accuracy: 0.7379 - auc: 0.8209 - val_loss: 0.1569 - val_accuracy: 0.9899 - val_auc: 0.9985\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5072 - accuracy: 0.7455 - auc: 0.8294 - val_loss: 0.4693 - val_accuracy: 0.7980 - val_auc: 0.8746\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.5132 - accuracy: 0.7659 - auc: 0.8294 - val_loss: 0.6951 - val_accuracy: 0.5657 - val_auc: 0.6350\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.5078 - accuracy: 0.7405 - auc: 0.8275 - val_loss: 0.2285 - val_accuracy: 0.9899 - val_auc: 0.9991\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.5273 - accuracy: 0.7837 - auc: 0.8303 - val_loss: 0.6557 - val_accuracy: 0.5253 - val_auc: 0.6536\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.5051 - accuracy: 0.7379 - auc: 0.8282 - val_loss: 1.0611 - val_accuracy: 0.4343 - val_auc: 0.3247\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.5185 - accuracy: 0.7583 - auc: 0.8361 - val_loss: 1.1328 - val_accuracy: 0.3838 - val_auc: 0.3233\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5200 - accuracy: 0.7328 - auc: 0.8191 - val_loss: 0.8779 - val_accuracy: 0.4444 - val_auc: 0.4934\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 1s 71ms/step - loss: 0.5530 - accuracy: 0.7506 - auc: 0.8109 - val_loss: 0.3614 - val_accuracy: 0.8384 - val_auc: 0.9403\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5084 - accuracy: 0.7430 - auc: 0.8303 - val_loss: 0.5622 - val_accuracy: 0.6364 - val_auc: 0.7517\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.5079 - accuracy: 0.7430 - auc: 0.8325 - val_loss: 0.8457 - val_accuracy: 0.4545 - val_auc: 0.4325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5048 - accuracy: 0.7379 - auc: 0.8312 - val_loss: 1.3048 - val_accuracy: 0.2626 - val_auc: 0.1702\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5126 - accuracy: 0.7405 - auc: 0.8283 - val_loss: 0.7988 - val_accuracy: 0.4343 - val_auc: 0.4803\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.5155 - accuracy: 0.7074 - auc: 0.8219 - val_loss: 0.7279 - val_accuracy: 0.4848 - val_auc: 0.5730\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.4952 - accuracy: 0.7583 - auc: 0.8400 - val_loss: 1.6858 - val_accuracy: 0.0707 - val_auc: 0.0244\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.5251 - accuracy: 0.7608 - auc: 0.8187 - val_loss: 1.2326 - val_accuracy: 0.3333 - val_auc: 0.1642\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.5228 - accuracy: 0.7303 - auc: 0.8211 - val_loss: 1.0332 - val_accuracy: 0.3535 - val_auc: 0.3623\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4992 - accuracy: 0.7557 - auc: 0.8391 - val_loss: 0.8180 - val_accuracy: 0.4646 - val_auc: 0.5004\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.5025 - accuracy: 0.7583 - auc: 0.8362 - val_loss: 1.1292 - val_accuracy: 0.3737 - val_auc: 0.2443\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.5482 - accuracy: 0.7074 - auc: 0.7962 - val_loss: 0.6147 - val_accuracy: 0.6364 - val_auc: 0.6992\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.5262 - accuracy: 0.7481 - auc: 0.8163 - val_loss: 0.1875 - val_accuracy: 0.9899 - val_auc: 0.9999\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4940 - accuracy: 0.7735 - auc: 0.8458 - val_loss: 0.0907 - val_accuracy: 1.0000 - val_auc: 0.9999\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4940 - accuracy: 0.7532 - auc: 0.8376 - val_loss: 0.1608 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5015 - accuracy: 0.7506 - auc: 0.8425 - val_loss: 0.0599 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5080 - accuracy: 0.7226 - auc: 0.8275 - val_loss: 0.0850 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.5402 - accuracy: 0.7405 - auc: 0.8195 - val_loss: 0.2601 - val_accuracy: 0.9798 - val_auc: 0.9996\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5467 - accuracy: 0.7226 - auc: 0.7993 - val_loss: 0.1823 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5359 - accuracy: 0.7226 - auc: 0.8076 - val_loss: 0.0539 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.5032 - accuracy: 0.7634 - auc: 0.8308 - val_loss: 0.1336 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.5098 - accuracy: 0.7328 - auc: 0.8237 - val_loss: 0.3157 - val_accuracy: 0.9091 - val_auc: 0.9840\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4981 - accuracy: 0.7506 - auc: 0.8365 - val_loss: 0.2731 - val_accuracy: 0.9091 - val_auc: 0.9902\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4862 - accuracy: 0.7786 - auc: 0.8439 - val_loss: 0.5658 - val_accuracy: 0.6162 - val_auc: 0.7558\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4943 - accuracy: 0.7761 - auc: 0.8457 - val_loss: 0.4326 - val_accuracy: 0.8283 - val_auc: 0.8981\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.5069 - accuracy: 0.7277 - auc: 0.8238 - val_loss: 0.5775 - val_accuracy: 0.5859 - val_auc: 0.7243\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.5044 - accuracy: 0.7583 - auc: 0.8318 - val_loss: 0.6819 - val_accuracy: 0.5253 - val_auc: 0.6267\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4812 - accuracy: 0.7913 - auc: 0.8574 - val_loss: 0.5009 - val_accuracy: 0.7071 - val_auc: 0.8226\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.5080 - accuracy: 0.7430 - auc: 0.8296 - val_loss: 1.3828 - val_accuracy: 0.2222 - val_auc: 0.0942\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4805 - accuracy: 0.7761 - auc: 0.8519 - val_loss: 1.1918 - val_accuracy: 0.3434 - val_auc: 0.2141\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.5127 - accuracy: 0.7583 - auc: 0.8386 - val_loss: 1.0277 - val_accuracy: 0.3838 - val_auc: 0.2604\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4832 - accuracy: 0.7710 - auc: 0.8521 - val_loss: 1.4923 - val_accuracy: 0.2121 - val_auc: 0.0958\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4730 - accuracy: 0.7710 - auc: 0.8546 - val_loss: 0.9897 - val_accuracy: 0.3838 - val_auc: 0.3942\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4805 - accuracy: 0.7659 - auc: 0.8509 - val_loss: 0.9665 - val_accuracy: 0.4242 - val_auc: 0.4566\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.5145 - accuracy: 0.7455 - auc: 0.8253 - val_loss: 1.2149 - val_accuracy: 0.2727 - val_auc: 0.1314\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4971 - accuracy: 0.7761 - auc: 0.8456 - val_loss: 1.4102 - val_accuracy: 0.3030 - val_auc: 0.1218\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.5023 - accuracy: 0.7710 - auc: 0.8411 - val_loss: 1.8362 - val_accuracy: 0.1919 - val_auc: 0.0719\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.5242 - accuracy: 0.7557 - auc: 0.8221 - val_loss: 0.6510 - val_accuracy: 0.5657 - val_auc: 0.6810\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.5293 - accuracy: 0.7405 - auc: 0.8125 - val_loss: 0.5626 - val_accuracy: 0.6667 - val_auc: 0.7596\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.5039 - accuracy: 0.7506 - auc: 0.8288 - val_loss: 0.9743 - val_accuracy: 0.4545 - val_auc: 0.3981\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.5228 - accuracy: 0.7481 - auc: 0.8275 - val_loss: 0.8761 - val_accuracy: 0.4545 - val_auc: 0.4769\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.5008 - accuracy: 0.7506 - auc: 0.8349 - val_loss: 0.7468 - val_accuracy: 0.4747 - val_auc: 0.5633\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4952 - accuracy: 0.7557 - auc: 0.8443 - val_loss: 0.5323 - val_accuracy: 0.6364 - val_auc: 0.7895\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4693 - accuracy: 0.7710 - auc: 0.8526 - val_loss: 0.6712 - val_accuracy: 0.5960 - val_auc: 0.6801\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.5191 - accuracy: 0.7430 - auc: 0.8296 - val_loss: 0.7389 - val_accuracy: 0.5152 - val_auc: 0.6405\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.5067 - accuracy: 0.7583 - auc: 0.8368 - val_loss: 0.8577 - val_accuracy: 0.4646 - val_auc: 0.4605\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.5077 - accuracy: 0.7608 - auc: 0.8336 - val_loss: 0.7487 - val_accuracy: 0.5051 - val_auc: 0.5720\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4835 - accuracy: 0.7735 - auc: 0.8478 - val_loss: 0.8549 - val_accuracy: 0.4646 - val_auc: 0.4345\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4841 - accuracy: 0.7812 - auc: 0.8486 - val_loss: 1.0323 - val_accuracy: 0.4545 - val_auc: 0.4615\n",
      "Epoch 140/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5191 - accuracy: 0.7277 - auc: 0.8232 - val_loss: 0.9926 - val_accuracy: 0.4242 - val_auc: 0.3288\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5047 - accuracy: 0.7761 - auc: 0.8388 - val_loss: 1.3103 - val_accuracy: 0.2727 - val_auc: 0.1028\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4845 - accuracy: 0.7608 - auc: 0.8439 - val_loss: 0.8962 - val_accuracy: 0.4444 - val_auc: 0.4588\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.5052 - accuracy: 0.7557 - auc: 0.8362 - val_loss: 0.3346 - val_accuracy: 0.8788 - val_auc: 0.9318\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.5018 - accuracy: 0.7634 - auc: 0.8365 - val_loss: 0.6543 - val_accuracy: 0.5657 - val_auc: 0.6873\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.5003 - accuracy: 0.7430 - auc: 0.8335 - val_loss: 0.3204 - val_accuracy: 0.8990 - val_auc: 0.9762\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.5029 - accuracy: 0.7532 - auc: 0.8308 - val_loss: 0.6731 - val_accuracy: 0.5657 - val_auc: 0.6582\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4978 - accuracy: 0.7379 - auc: 0.8341 - val_loss: 0.3284 - val_accuracy: 0.8788 - val_auc: 0.9451\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.4937 - accuracy: 0.7608 - auc: 0.8417 - val_loss: 0.4478 - val_accuracy: 0.8283 - val_auc: 0.8752\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5103 - accuracy: 0.7583 - auc: 0.8229 - val_loss: 0.2256 - val_accuracy: 0.9899 - val_auc: 0.9976\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5143 - accuracy: 0.7201 - auc: 0.8285 - val_loss: 0.3523 - val_accuracy: 0.9091 - val_auc: 0.9425\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4977 - accuracy: 0.7328 - auc: 0.8321 - val_loss: 0.3606 - val_accuracy: 0.8384 - val_auc: 0.9541\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5225 - accuracy: 0.7455 - auc: 0.8271 - val_loss: 0.4904 - val_accuracy: 0.7778 - val_auc: 0.8375\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.5427 - accuracy: 0.7277 - auc: 0.8012 - val_loss: 0.3204 - val_accuracy: 0.9091 - val_auc: 0.9752\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.5086 - accuracy: 0.7557 - auc: 0.8311 - val_loss: 0.3478 - val_accuracy: 0.8384 - val_auc: 0.9239\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4915 - accuracy: 0.7379 - auc: 0.8418 - val_loss: 0.3887 - val_accuracy: 0.8182 - val_auc: 0.9051\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.5342 - accuracy: 0.7405 - auc: 0.8123 - val_loss: 0.9643 - val_accuracy: 0.4242 - val_auc: 0.3375\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.5150 - accuracy: 0.7532 - auc: 0.8273 - val_loss: 0.5225 - val_accuracy: 0.7374 - val_auc: 0.8014\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.5071 - accuracy: 0.7557 - auc: 0.8354 - val_loss: 0.2293 - val_accuracy: 0.9899 - val_auc: 0.9994\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4760 - accuracy: 0.7379 - auc: 0.8489 - val_loss: 0.8321 - val_accuracy: 0.5051 - val_auc: 0.5997\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5074 - accuracy: 0.7761 - auc: 0.8388 - val_loss: 0.3845 - val_accuracy: 0.8788 - val_auc: 0.9367\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.5174 - accuracy: 0.7506 - auc: 0.8234 - val_loss: 0.3424 - val_accuracy: 0.8990 - val_auc: 0.9445\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.5278 - accuracy: 0.7354 - auc: 0.8194 - val_loss: 1.2520 - val_accuracy: 0.4141 - val_auc: 0.3164\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5390 - accuracy: 0.7252 - auc: 0.8069 - val_loss: 1.3113 - val_accuracy: 0.2828 - val_auc: 0.1415\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.5324 - accuracy: 0.7277 - auc: 0.8128 - val_loss: 0.4310 - val_accuracy: 0.7374 - val_auc: 0.8756\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.5002 - accuracy: 0.7557 - auc: 0.8410 - val_loss: 0.6209 - val_accuracy: 0.5960 - val_auc: 0.7131\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5196 - accuracy: 0.7277 - auc: 0.8190 - val_loss: 1.5932 - val_accuracy: 0.2020 - val_auc: 0.0887\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4858 - accuracy: 0.7506 - auc: 0.8476 - val_loss: 0.6979 - val_accuracy: 0.5051 - val_auc: 0.6128\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.5304 - accuracy: 0.7430 - auc: 0.8093 - val_loss: 1.7815 - val_accuracy: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.5119 - accuracy: 0.7532 - auc: 0.8271 - val_loss: 2.1417 - val_accuracy: 0.0303 - val_auc: 0.0401\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4972 - accuracy: 0.7659 - auc: 0.8415 - val_loss: 0.2548 - val_accuracy: 0.9293 - val_auc: 0.9948\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.4790 - accuracy: 0.7659 - auc: 0.8511 - val_loss: 0.3260 - val_accuracy: 0.9091 - val_auc: 0.9540\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4725 - accuracy: 0.7634 - auc: 0.8543 - val_loss: 0.4097 - val_accuracy: 0.8081 - val_auc: 0.9013\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.5163 - accuracy: 0.7481 - auc: 0.8230 - val_loss: 0.3847 - val_accuracy: 0.8687 - val_auc: 0.9162\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.5190 - accuracy: 0.7557 - auc: 0.8210 - val_loss: 0.8369 - val_accuracy: 0.5051 - val_auc: 0.4648\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4880 - accuracy: 0.7735 - auc: 0.8434 - val_loss: 0.2962 - val_accuracy: 0.9192 - val_auc: 0.9731\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.4938 - accuracy: 0.7659 - auc: 0.8434 - val_loss: 0.3444 - val_accuracy: 0.8182 - val_auc: 0.9377\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.5206 - accuracy: 0.7684 - auc: 0.8285 - val_loss: 0.3699 - val_accuracy: 0.8889 - val_auc: 0.9429\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.5071 - accuracy: 0.7506 - auc: 0.8285 - val_loss: 0.5325 - val_accuracy: 0.8081 - val_auc: 0.8135\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.5127 - accuracy: 0.7532 - auc: 0.8288 - val_loss: 0.3545 - val_accuracy: 0.8283 - val_auc: 0.9415\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.5363 - accuracy: 0.7303 - auc: 0.8093 - val_loss: 0.5688 - val_accuracy: 0.6970 - val_auc: 0.7612\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.5106 - accuracy: 0.7583 - auc: 0.8330 - val_loss: 0.4791 - val_accuracy: 0.7778 - val_auc: 0.8599\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5174 - accuracy: 0.7455 - auc: 0.8288 - val_loss: 0.3883 - val_accuracy: 0.8081 - val_auc: 0.9045\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4913 - accuracy: 0.7837 - auc: 0.8525 - val_loss: 1.0297 - val_accuracy: 0.3939 - val_auc: 0.2904\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.5105 - accuracy: 0.7710 - auc: 0.8294 - val_loss: 0.8231 - val_accuracy: 0.4848 - val_auc: 0.4688\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.5083 - accuracy: 0.7684 - auc: 0.8363 - val_loss: 0.5846 - val_accuracy: 0.5960 - val_auc: 0.7315\n",
      "Epoch 186/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4906 - accuracy: 0.7786 - auc: 0.8429 - val_loss: 0.4336 - val_accuracy: 0.8586 - val_auc: 0.9069\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4687 - accuracy: 0.7761 - auc: 0.8573 - val_loss: 0.2445 - val_accuracy: 0.9293 - val_auc: 0.9934\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5038 - accuracy: 0.7557 - auc: 0.8410 - val_loss: 0.6115 - val_accuracy: 0.5758 - val_auc: 0.7107\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4729 - accuracy: 0.7837 - auc: 0.8586 - val_loss: 1.0475 - val_accuracy: 0.4040 - val_auc: 0.3228\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4939 - accuracy: 0.7455 - auc: 0.8377 - val_loss: 1.1610 - val_accuracy: 0.3535 - val_auc: 0.2113\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4940 - accuracy: 0.7608 - auc: 0.8395 - val_loss: 1.2547 - val_accuracy: 0.3434 - val_auc: 0.1708\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4851 - accuracy: 0.7684 - auc: 0.8486 - val_loss: 1.8836 - val_accuracy: 0.0303 - val_auc: 0.0056\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4806 - accuracy: 0.7608 - auc: 0.8503 - val_loss: 0.5556 - val_accuracy: 0.6061 - val_auc: 0.7699\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4852 - accuracy: 0.8041 - auc: 0.8598 - val_loss: 0.4956 - val_accuracy: 0.7071 - val_auc: 0.8238\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.4971 - accuracy: 0.7684 - auc: 0.8414 - val_loss: 0.4414 - val_accuracy: 0.7374 - val_auc: 0.8923\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4973 - accuracy: 0.7684 - auc: 0.8395 - val_loss: 0.5323 - val_accuracy: 0.6869 - val_auc: 0.7904\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.4657 - accuracy: 0.8066 - auc: 0.8678 - val_loss: 0.5580 - val_accuracy: 0.6667 - val_auc: 0.7737\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4671 - accuracy: 0.7863 - auc: 0.8578 - val_loss: 0.5049 - val_accuracy: 0.7374 - val_auc: 0.8213\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4898 - accuracy: 0.7812 - auc: 0.8462 - val_loss: 0.5328 - val_accuracy: 0.7374 - val_auc: 0.8041\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4866 - accuracy: 0.7659 - auc: 0.8464 - val_loss: 0.5473 - val_accuracy: 0.6162 - val_auc: 0.7868\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4863 - accuracy: 0.7761 - auc: 0.8473 - val_loss: 0.5592 - val_accuracy: 0.6465 - val_auc: 0.7791\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.5090 - accuracy: 0.7583 - auc: 0.8335 - val_loss: 0.6270 - val_accuracy: 0.5960 - val_auc: 0.6925\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4668 - accuracy: 0.7888 - auc: 0.8625 - val_loss: 0.3572 - val_accuracy: 0.8889 - val_auc: 0.9407\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4722 - accuracy: 0.7913 - auc: 0.8571 - val_loss: 0.2776 - val_accuracy: 0.9394 - val_auc: 0.9777\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4774 - accuracy: 0.7735 - auc: 0.8541 - val_loss: 0.1664 - val_accuracy: 0.9899 - val_auc: 0.9999\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4920 - accuracy: 0.7710 - auc: 0.8437 - val_loss: 0.1581 - val_accuracy: 0.9899 - val_auc: 0.9974\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4780 - accuracy: 0.7532 - auc: 0.8524 - val_loss: 0.3081 - val_accuracy: 0.9091 - val_auc: 0.9539\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.5167 - accuracy: 0.7608 - auc: 0.8324 - val_loss: 0.6525 - val_accuracy: 0.7980 - val_auc: 0.7506\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.5123 - accuracy: 0.7430 - auc: 0.8306 - val_loss: 1.2257 - val_accuracy: 0.3131 - val_auc: 0.1988\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4984 - accuracy: 0.7659 - auc: 0.8409 - val_loss: 1.5413 - val_accuracy: 0.1717 - val_auc: 0.0740\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4899 - accuracy: 0.7583 - auc: 0.8421 - val_loss: 1.6960 - val_accuracy: 0.1818 - val_auc: 0.0632\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.5002 - accuracy: 0.7786 - auc: 0.8411 - val_loss: 0.6640 - val_accuracy: 0.5253 - val_auc: 0.6601\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.4864 - accuracy: 0.7761 - auc: 0.8433 - val_loss: 1.7990 - val_accuracy: 0.0606 - val_auc: 0.0487\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4851 - accuracy: 0.7634 - auc: 0.8470 - val_loss: 0.9962 - val_accuracy: 0.4444 - val_auc: 0.4387\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.4608 - accuracy: 0.7837 - auc: 0.8621 - val_loss: 0.7600 - val_accuracy: 0.5152 - val_auc: 0.5579\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4909 - accuracy: 0.7837 - auc: 0.8449 - val_loss: 0.4260 - val_accuracy: 0.8788 - val_auc: 0.9002\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4724 - accuracy: 0.7812 - auc: 0.8573 - val_loss: 0.3200 - val_accuracy: 0.9192 - val_auc: 0.9585\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4970 - accuracy: 0.7684 - auc: 0.8371 - val_loss: 0.4743 - val_accuracy: 0.8182 - val_auc: 0.8694\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4735 - accuracy: 0.7964 - auc: 0.8589 - val_loss: 0.5027 - val_accuracy: 0.7576 - val_auc: 0.8356\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4712 - accuracy: 0.7812 - auc: 0.8586 - val_loss: 0.2699 - val_accuracy: 0.8990 - val_auc: 0.9785\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.4862 - accuracy: 0.7506 - auc: 0.8442 - val_loss: 0.8552 - val_accuracy: 0.4444 - val_auc: 0.4996\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4781 - accuracy: 0.7684 - auc: 0.8542 - val_loss: 0.2786 - val_accuracy: 0.9192 - val_auc: 0.9908\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4656 - accuracy: 0.7710 - auc: 0.8616 - val_loss: 0.4398 - val_accuracy: 0.7374 - val_auc: 0.8846\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.4858 - accuracy: 0.7812 - auc: 0.8573 - val_loss: 0.9698 - val_accuracy: 0.4343 - val_auc: 0.4461\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5350 - accuracy: 0.7455 - auc: 0.8227 - val_loss: 0.2933 - val_accuracy: 0.9293 - val_auc: 0.9929\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5103 - accuracy: 0.7532 - auc: 0.8289 - val_loss: 0.1719 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4685 - accuracy: 0.7684 - auc: 0.8596 - val_loss: 0.1163 - val_accuracy: 0.9899 - val_auc: 0.9999\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4665 - accuracy: 0.7913 - auc: 0.8600 - val_loss: 0.4896 - val_accuracy: 0.6566 - val_auc: 0.8230\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.4833 - accuracy: 0.7735 - auc: 0.8539 - val_loss: 0.6692 - val_accuracy: 0.5859 - val_auc: 0.6580\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4747 - accuracy: 0.7710 - auc: 0.8540 - val_loss: 0.3213 - val_accuracy: 0.8889 - val_auc: 0.9725\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4769 - accuracy: 0.7837 - auc: 0.8551 - val_loss: 0.4218 - val_accuracy: 0.7475 - val_auc: 0.8915\n",
      "Epoch 232/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4778 - accuracy: 0.7684 - auc: 0.8482 - val_loss: 0.5845 - val_accuracy: 0.5859 - val_auc: 0.7406\n",
      "Epoch 233/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4747 - accuracy: 0.7710 - auc: 0.8561 - val_loss: 0.3775 - val_accuracy: 0.8788 - val_auc: 0.9326\n",
      "Epoch 234/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4606 - accuracy: 0.7990 - auc: 0.8622 - val_loss: 0.6668 - val_accuracy: 0.6263 - val_auc: 0.6809\n",
      "Epoch 235/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4790 - accuracy: 0.7786 - auc: 0.8536 - val_loss: 0.3177 - val_accuracy: 0.8990 - val_auc: 0.9503\n",
      "Epoch 236/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.4801 - accuracy: 0.7481 - auc: 0.8509 - val_loss: 0.5632 - val_accuracy: 0.6869 - val_auc: 0.7759\n",
      "Epoch 237/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5405 - accuracy: 0.7201 - auc: 0.8045 - val_loss: 0.3529 - val_accuracy: 0.8990 - val_auc: 0.9625\n",
      "Epoch 238/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.5149 - accuracy: 0.7430 - auc: 0.8285 - val_loss: 0.4776 - val_accuracy: 0.7980 - val_auc: 0.8592\n",
      "Epoch 239/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4908 - accuracy: 0.7710 - auc: 0.8407 - val_loss: 0.4057 - val_accuracy: 0.8081 - val_auc: 0.9001\n",
      "Epoch 240/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4683 - accuracy: 0.7532 - auc: 0.8564 - val_loss: 0.9786 - val_accuracy: 0.4848 - val_auc: 0.4374\n",
      "Epoch 241/1000\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.4746 - accuracy: 0.7888 - auc: 0.8635 - val_loss: 0.7049 - val_accuracy: 0.6364 - val_auc: 0.6515\n",
      "Epoch 242/1000\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.4937 - accuracy: 0.7455 - auc: 0.8361 - val_loss: 0.1354 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 243/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.4892 - accuracy: 0.7684 - auc: 0.8448 - val_loss: 0.1056 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 244/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.5129 - accuracy: 0.7506 - auc: 0.8282 - val_loss: 0.2238 - val_accuracy: 0.9798 - val_auc: 0.9976\n",
      "Epoch 245/1000\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.5550 - accuracy: 0.7074 - auc: 0.7951 - val_loss: 0.6878 - val_accuracy: 0.6061 - val_auc: 0.6528\n",
      "Epoch 246/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4886 - accuracy: 0.7608 - auc: 0.8412 - val_loss: 2.9044 - val_accuracy: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 247/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5045 - accuracy: 0.7379 - auc: 0.8417 - val_loss: 2.2130 - val_accuracy: 0.1010 - val_auc: 0.0590\n",
      "Epoch 248/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4765 - accuracy: 0.7837 - auc: 0.8532 - val_loss: 0.7791 - val_accuracy: 0.5455 - val_auc: 0.5792\n",
      "Epoch 249/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4852 - accuracy: 0.7659 - auc: 0.8476 - val_loss: 0.4899 - val_accuracy: 0.7172 - val_auc: 0.8308\n",
      "Epoch 250/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.4900 - accuracy: 0.7557 - auc: 0.8448 - val_loss: 0.1542 - val_accuracy: 0.9798 - val_auc: 0.9985\n",
      "Epoch 251/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.5139 - accuracy: 0.7430 - auc: 0.8310 - val_loss: 0.2899 - val_accuracy: 0.8990 - val_auc: 0.9850\n",
      "Epoch 252/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4971 - accuracy: 0.7481 - auc: 0.8423 - val_loss: 0.2808 - val_accuracy: 0.9293 - val_auc: 0.9829\n",
      "Epoch 253/1000\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.4986 - accuracy: 0.7735 - auc: 0.8473 - val_loss: 0.6383 - val_accuracy: 0.6263 - val_auc: 0.7092\n",
      "Epoch 254/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4681 - accuracy: 0.7761 - auc: 0.8566 - val_loss: 0.6507 - val_accuracy: 0.6263 - val_auc: 0.7108\n",
      "Epoch 255/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4965 - accuracy: 0.7557 - auc: 0.8368 - val_loss: 1.0223 - val_accuracy: 0.3434 - val_auc: 0.2512\n",
      "Epoch 256/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.5062 - accuracy: 0.7557 - auc: 0.8316 - val_loss: 1.8491 - val_accuracy: 0.1111 - val_auc: 0.0320\n",
      "Epoch 257/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4908 - accuracy: 0.7634 - auc: 0.8442 - val_loss: 2.0468 - val_accuracy: 0.0505 - val_auc: 0.0118\n",
      "Epoch 258/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.4949 - accuracy: 0.7634 - auc: 0.8426 - val_loss: 1.1834 - val_accuracy: 0.3838 - val_auc: 0.2800\n",
      "Epoch 259/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.4771 - accuracy: 0.7990 - auc: 0.8610 - val_loss: 0.7199 - val_accuracy: 0.5253 - val_auc: 0.6372\n",
      "Epoch 260/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4878 - accuracy: 0.7506 - auc: 0.8443 - val_loss: 1.7019 - val_accuracy: 0.0202 - val_auc: 0.0070\n",
      "Epoch 261/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4662 - accuracy: 0.7837 - auc: 0.8626 - val_loss: 1.7737 - val_accuracy: 0.0404 - val_auc: 0.0122\n",
      "Epoch 262/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4754 - accuracy: 0.7812 - auc: 0.8570 - val_loss: 0.6944 - val_accuracy: 0.5253 - val_auc: 0.6564\n",
      "Epoch 263/1000\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.5020 - accuracy: 0.7303 - auc: 0.8295 - val_loss: 0.8971 - val_accuracy: 0.4646 - val_auc: 0.3651\n",
      "Epoch 264/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4707 - accuracy: 0.7837 - auc: 0.8593 - val_loss: 0.4917 - val_accuracy: 0.8182 - val_auc: 0.8477\n",
      "Epoch 265/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.4578 - accuracy: 0.8117 - auc: 0.8701 - val_loss: 0.4192 - val_accuracy: 0.8485 - val_auc: 0.8883\n",
      "Epoch 266/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4921 - accuracy: 0.7557 - auc: 0.8401 - val_loss: 0.7661 - val_accuracy: 0.5455 - val_auc: 0.5563\n",
      "Epoch 267/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.5044 - accuracy: 0.7557 - auc: 0.8382 - val_loss: 0.6220 - val_accuracy: 0.5960 - val_auc: 0.7215\n",
      "Epoch 268/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.5089 - accuracy: 0.7659 - auc: 0.8384 - val_loss: 0.1677 - val_accuracy: 0.9394 - val_auc: 0.9904\n",
      "Epoch 269/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4866 - accuracy: 0.7659 - auc: 0.8476 - val_loss: 0.1119 - val_accuracy: 0.9495 - val_auc: 0.9965\n",
      "Epoch 270/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5244 - accuracy: 0.7506 - auc: 0.8171 - val_loss: 0.1544 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 271/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4808 - accuracy: 0.7634 - auc: 0.8526 - val_loss: 0.2122 - val_accuracy: 0.9394 - val_auc: 0.9941\n",
      "Epoch 272/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4847 - accuracy: 0.7735 - auc: 0.8515 - val_loss: 0.3722 - val_accuracy: 0.8687 - val_auc: 0.9297\n",
      "Epoch 273/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4855 - accuracy: 0.7634 - auc: 0.8478 - val_loss: 0.1328 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 274/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4882 - accuracy: 0.7786 - auc: 0.8474 - val_loss: 0.6662 - val_accuracy: 0.6061 - val_auc: 0.6372\n",
      "Epoch 275/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4835 - accuracy: 0.7710 - auc: 0.8486 - val_loss: 0.3691 - val_accuracy: 0.8788 - val_auc: 0.9276\n",
      "Epoch 276/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.4629 - accuracy: 0.7863 - auc: 0.8663 - val_loss: 0.9072 - val_accuracy: 0.5455 - val_auc: 0.4742\n",
      "Epoch 277/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5826 - accuracy: 0.6972 - auc: 0.7608 - val_loss: 1.3760 - val_accuracy: 0.0707 - val_auc: 0.0178\n",
      "Epoch 278/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 62ms/step - loss: 0.5625 - accuracy: 0.7125 - auc: 0.7802 - val_loss: 0.1686 - val_accuracy: 0.9899 - val_auc: 0.9997\n",
      "Epoch 279/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4807 - accuracy: 0.7761 - auc: 0.8469 - val_loss: 0.0777 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 280/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.5023 - accuracy: 0.7735 - auc: 0.8444 - val_loss: 0.2032 - val_accuracy: 0.9394 - val_auc: 0.9957\n",
      "Epoch 281/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4678 - accuracy: 0.7634 - auc: 0.8594 - val_loss: 0.2977 - val_accuracy: 0.8788 - val_auc: 0.9457\n",
      "Epoch 282/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.5176 - accuracy: 0.7303 - auc: 0.8305 - val_loss: 0.1234 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 283/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.5042 - accuracy: 0.7481 - auc: 0.8427 - val_loss: 0.2431 - val_accuracy: 0.9293 - val_auc: 0.9949\n",
      "Epoch 284/1000\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.5050 - accuracy: 0.7710 - auc: 0.8390 - val_loss: 0.4870 - val_accuracy: 0.7374 - val_auc: 0.8795\n",
      "Epoch 285/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.5080 - accuracy: 0.7557 - auc: 0.8259 - val_loss: 0.0891 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 286/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.5123 - accuracy: 0.7303 - auc: 0.8244 - val_loss: 0.1338 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 287/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4999 - accuracy: 0.7506 - auc: 0.8326 - val_loss: 0.1678 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 288/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4771 - accuracy: 0.7405 - auc: 0.8509 - val_loss: 0.4180 - val_accuracy: 0.8687 - val_auc: 0.9175\n",
      "Epoch 289/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4860 - accuracy: 0.7608 - auc: 0.8486 - val_loss: 0.5459 - val_accuracy: 0.6566 - val_auc: 0.7904\n",
      "Epoch 290/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4854 - accuracy: 0.7583 - auc: 0.8449 - val_loss: 0.9377 - val_accuracy: 0.4141 - val_auc: 0.3812\n",
      "Epoch 291/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4780 - accuracy: 0.7684 - auc: 0.8525 - val_loss: 1.2646 - val_accuracy: 0.1515 - val_auc: 0.1666\n",
      "Epoch 292/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4917 - accuracy: 0.7735 - auc: 0.8452 - val_loss: 1.2409 - val_accuracy: 0.3030 - val_auc: 0.1501\n",
      "Epoch 293/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4771 - accuracy: 0.7735 - auc: 0.8517 - val_loss: 1.2290 - val_accuracy: 0.2020 - val_auc: 0.0780\n",
      "Epoch 294/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4640 - accuracy: 0.7837 - auc: 0.8617 - val_loss: 1.3767 - val_accuracy: 0.2525 - val_auc: 0.1398\n",
      "Epoch 295/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4700 - accuracy: 0.7735 - auc: 0.8615 - val_loss: 1.1785 - val_accuracy: 0.3939 - val_auc: 0.3019\n",
      "Epoch 296/1000\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.4951 - accuracy: 0.7684 - auc: 0.8457 - val_loss: 0.8970 - val_accuracy: 0.4040 - val_auc: 0.4065\n",
      "Epoch 297/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4997 - accuracy: 0.7608 - auc: 0.8379 - val_loss: 0.9552 - val_accuracy: 0.3232 - val_auc: 0.2145\n",
      "Epoch 298/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4726 - accuracy: 0.7761 - auc: 0.8609 - val_loss: 1.0631 - val_accuracy: 0.3737 - val_auc: 0.3172\n",
      "Epoch 299/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4645 - accuracy: 0.7888 - auc: 0.8641 - val_loss: 1.1487 - val_accuracy: 0.3131 - val_auc: 0.2201\n",
      "Epoch 300/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4649 - accuracy: 0.7964 - auc: 0.8633 - val_loss: 0.9017 - val_accuracy: 0.4444 - val_auc: 0.3645\n",
      "Epoch 301/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4980 - accuracy: 0.7481 - auc: 0.8356 - val_loss: 0.6592 - val_accuracy: 0.5758 - val_auc: 0.6696\n",
      "Epoch 302/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.5105 - accuracy: 0.7735 - auc: 0.8396 - val_loss: 0.3652 - val_accuracy: 0.8586 - val_auc: 0.9352\n",
      "Epoch 303/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.4662 - accuracy: 0.7888 - auc: 0.8622 - val_loss: 1.0402 - val_accuracy: 0.4242 - val_auc: 0.2992\n",
      "Epoch 304/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.5131 - accuracy: 0.7684 - auc: 0.8327 - val_loss: 0.9469 - val_accuracy: 0.3939 - val_auc: 0.3831\n",
      "Epoch 305/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.4723 - accuracy: 0.7812 - auc: 0.8583 - val_loss: 0.8432 - val_accuracy: 0.5152 - val_auc: 0.5010\n",
      "Epoch 306/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4715 - accuracy: 0.7761 - auc: 0.8544 - val_loss: 0.8007 - val_accuracy: 0.5051 - val_auc: 0.5435\n",
      "Epoch 307/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4764 - accuracy: 0.7634 - auc: 0.8514 - val_loss: 0.6754 - val_accuracy: 0.5859 - val_auc: 0.6674\n",
      "Epoch 308/1000\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.5105 - accuracy: 0.7379 - auc: 0.8309 - val_loss: 0.7479 - val_accuracy: 0.5758 - val_auc: 0.5775\n",
      "Epoch 309/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4711 - accuracy: 0.7710 - auc: 0.8558 - val_loss: 0.6738 - val_accuracy: 0.6263 - val_auc: 0.6973\n",
      "Epoch 310/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4723 - accuracy: 0.7710 - auc: 0.8578 - val_loss: 0.6408 - val_accuracy: 0.6263 - val_auc: 0.7195\n",
      "Epoch 311/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4920 - accuracy: 0.7735 - auc: 0.8470 - val_loss: 0.4620 - val_accuracy: 0.7374 - val_auc: 0.8625\n",
      "Epoch 312/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4646 - accuracy: 0.8015 - auc: 0.8648 - val_loss: 0.1418 - val_accuracy: 0.9899 - val_auc: 0.9973\n",
      "Epoch 313/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4980 - accuracy: 0.7557 - auc: 0.8396 - val_loss: 0.2857 - val_accuracy: 0.9192 - val_auc: 0.9865\n",
      "Epoch 314/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4731 - accuracy: 0.7913 - auc: 0.8614 - val_loss: 0.8627 - val_accuracy: 0.5152 - val_auc: 0.4854\n",
      "Epoch 315/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4857 - accuracy: 0.7710 - auc: 0.8464 - val_loss: 0.3530 - val_accuracy: 0.8889 - val_auc: 0.9284\n",
      "Epoch 316/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.5108 - accuracy: 0.7379 - auc: 0.8324 - val_loss: 1.0369 - val_accuracy: 0.3838 - val_auc: 0.2730\n",
      "Epoch 317/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.4719 - accuracy: 0.7608 - auc: 0.8559 - val_loss: 0.5050 - val_accuracy: 0.7172 - val_auc: 0.8298\n",
      "Epoch 318/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4461 - accuracy: 0.7990 - auc: 0.8748 - val_loss: 0.8471 - val_accuracy: 0.4747 - val_auc: 0.5522\n",
      "Epoch 319/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.5019 - accuracy: 0.7481 - auc: 0.8377 - val_loss: 0.9533 - val_accuracy: 0.4343 - val_auc: 0.3729\n",
      "Epoch 320/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4659 - accuracy: 0.7710 - auc: 0.8624 - val_loss: 0.8805 - val_accuracy: 0.5152 - val_auc: 0.5314\n",
      "Epoch 321/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4642 - accuracy: 0.7964 - auc: 0.8684 - val_loss: 0.6196 - val_accuracy: 0.7273 - val_auc: 0.7313\n",
      "Epoch 322/1000\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.4816 - accuracy: 0.7710 - auc: 0.8474 - val_loss: 0.2418 - val_accuracy: 0.8788 - val_auc: 0.9796\n",
      "Epoch 323/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4791 - accuracy: 0.7812 - auc: 0.8539 - val_loss: 0.2750 - val_accuracy: 0.9091 - val_auc: 0.9758\n",
      "Epoch 324/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4650 - accuracy: 0.7761 - auc: 0.8620 - val_loss: 0.2881 - val_accuracy: 0.8889 - val_auc: 0.9646\n",
      "Epoch 325/1000\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.5146 - accuracy: 0.7405 - auc: 0.8275 - val_loss: 0.3804 - val_accuracy: 0.8788 - val_auc: 0.9321\n",
      "Epoch 326/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4801 - accuracy: 0.7812 - auc: 0.8527 - val_loss: 0.5652 - val_accuracy: 0.7071 - val_auc: 0.7786\n",
      "Epoch 327/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4596 - accuracy: 0.7812 - auc: 0.8641 - val_loss: 0.1398 - val_accuracy: 0.9899 - val_auc: 0.9972\n",
      "Epoch 328/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4918 - accuracy: 0.7684 - auc: 0.8405 - val_loss: 0.3874 - val_accuracy: 0.8788 - val_auc: 0.9213\n",
      "Epoch 329/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4797 - accuracy: 0.7863 - auc: 0.8560 - val_loss: 0.5134 - val_accuracy: 0.6768 - val_auc: 0.8233\n",
      "Epoch 330/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.4717 - accuracy: 0.7735 - auc: 0.8555 - val_loss: 1.2694 - val_accuracy: 0.3434 - val_auc: 0.2899\n",
      "Epoch 331/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4939 - accuracy: 0.7735 - auc: 0.8441 - val_loss: 0.3478 - val_accuracy: 0.8485 - val_auc: 0.9566\n",
      "Epoch 332/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4865 - accuracy: 0.7634 - auc: 0.8437 - val_loss: 0.5158 - val_accuracy: 0.7980 - val_auc: 0.8207\n",
      "Epoch 333/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4911 - accuracy: 0.7455 - auc: 0.8424 - val_loss: 0.7566 - val_accuracy: 0.5556 - val_auc: 0.5959\n",
      "Epoch 334/1000\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.4913 - accuracy: 0.7328 - auc: 0.8376 - val_loss: 0.8809 - val_accuracy: 0.4949 - val_auc: 0.4959\n",
      "Epoch 335/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4823 - accuracy: 0.7837 - auc: 0.8543 - val_loss: 0.4131 - val_accuracy: 0.8081 - val_auc: 0.8930\n",
      "Epoch 336/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4878 - accuracy: 0.7608 - auc: 0.8440 - val_loss: 0.6352 - val_accuracy: 0.6364 - val_auc: 0.7213\n",
      "Epoch 337/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4892 - accuracy: 0.7812 - auc: 0.8495 - val_loss: 0.5639 - val_accuracy: 0.6263 - val_auc: 0.7681\n",
      "Epoch 338/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4787 - accuracy: 0.7710 - auc: 0.8533 - val_loss: 0.1329 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 339/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4541 - accuracy: 0.7913 - auc: 0.8701 - val_loss: 0.1312 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 340/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4665 - accuracy: 0.7913 - auc: 0.8674 - val_loss: 0.2339 - val_accuracy: 0.9293 - val_auc: 0.9895\n",
      "Epoch 341/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4633 - accuracy: 0.7634 - auc: 0.8591 - val_loss: 0.9758 - val_accuracy: 0.4444 - val_auc: 0.3692\n",
      "Epoch 342/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4954 - accuracy: 0.7455 - auc: 0.8414 - val_loss: 0.7648 - val_accuracy: 0.5253 - val_auc: 0.5344\n",
      "Epoch 343/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4766 - accuracy: 0.7863 - auc: 0.8575 - val_loss: 0.9594 - val_accuracy: 0.4444 - val_auc: 0.4478\n",
      "Epoch 344/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4786 - accuracy: 0.7964 - auc: 0.8611 - val_loss: 0.5732 - val_accuracy: 0.6364 - val_auc: 0.7775\n",
      "Epoch 345/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4852 - accuracy: 0.7837 - auc: 0.8503 - val_loss: 0.9262 - val_accuracy: 0.4242 - val_auc: 0.3494\n",
      "Epoch 346/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.4752 - accuracy: 0.7939 - auc: 0.8554 - val_loss: 0.3257 - val_accuracy: 0.8687 - val_auc: 0.9483\n",
      "Epoch 347/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4636 - accuracy: 0.8066 - auc: 0.8637 - val_loss: 0.3805 - val_accuracy: 0.8687 - val_auc: 0.9324\n",
      "Epoch 348/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4574 - accuracy: 0.8092 - auc: 0.8697 - val_loss: 0.1822 - val_accuracy: 0.9697 - val_auc: 0.9962\n",
      "Epoch 349/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4605 - accuracy: 0.7735 - auc: 0.8641 - val_loss: 0.4934 - val_accuracy: 0.7374 - val_auc: 0.8405\n",
      "Epoch 350/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4955 - accuracy: 0.7684 - auc: 0.8426 - val_loss: 0.6819 - val_accuracy: 0.5556 - val_auc: 0.6665\n",
      "Epoch 351/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4581 - accuracy: 0.7939 - auc: 0.8689 - val_loss: 1.9826 - val_accuracy: 0.1010 - val_auc: 0.0504\n",
      "Epoch 352/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.4679 - accuracy: 0.7786 - auc: 0.8593 - val_loss: 1.4508 - val_accuracy: 0.2222 - val_auc: 0.0718\n",
      "Epoch 353/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4787 - accuracy: 0.7939 - auc: 0.8483 - val_loss: 0.7689 - val_accuracy: 0.5253 - val_auc: 0.5849\n",
      "Epoch 354/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.5069 - accuracy: 0.7608 - auc: 0.8354 - val_loss: 2.0352 - val_accuracy: 0.1212 - val_auc: 0.0944\n",
      "Epoch 355/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4861 - accuracy: 0.7863 - auc: 0.8500 - val_loss: 0.3484 - val_accuracy: 0.8485 - val_auc: 0.9371\n",
      "Epoch 356/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4652 - accuracy: 0.7939 - auc: 0.8623 - val_loss: 0.4679 - val_accuracy: 0.7172 - val_auc: 0.8554\n",
      "Epoch 357/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4564 - accuracy: 0.7684 - auc: 0.8660 - val_loss: 0.2497 - val_accuracy: 0.9091 - val_auc: 0.9809\n",
      "Epoch 358/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4855 - accuracy: 0.7812 - auc: 0.8507 - val_loss: 0.1756 - val_accuracy: 0.9192 - val_auc: 0.9884\n",
      "Epoch 359/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.5114 - accuracy: 0.7608 - auc: 0.8277 - val_loss: 0.6716 - val_accuracy: 0.5758 - val_auc: 0.6663\n",
      "Epoch 360/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4685 - accuracy: 0.7786 - auc: 0.8600 - val_loss: 0.2821 - val_accuracy: 0.8990 - val_auc: 0.9707\n",
      "Epoch 361/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4772 - accuracy: 0.7735 - auc: 0.8546 - val_loss: 0.8186 - val_accuracy: 0.4949 - val_auc: 0.5356\n",
      "Epoch 362/1000\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.4493 - accuracy: 0.8142 - auc: 0.8716 - val_loss: 1.7096 - val_accuracy: 0.1313 - val_auc: 0.0806\n",
      "Epoch 363/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4679 - accuracy: 0.7837 - auc: 0.8591 - val_loss: 0.5019 - val_accuracy: 0.7475 - val_auc: 0.8396\n",
      "Epoch 364/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4728 - accuracy: 0.7608 - auc: 0.8531 - val_loss: 0.4946 - val_accuracy: 0.7374 - val_auc: 0.8390\n",
      "Epoch 365/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4602 - accuracy: 0.7913 - auc: 0.8691 - val_loss: 1.1506 - val_accuracy: 0.3838 - val_auc: 0.2967\n",
      "Epoch 366/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4535 - accuracy: 0.7837 - auc: 0.8703 - val_loss: 0.4168 - val_accuracy: 0.8485 - val_auc: 0.8958\n",
      "Epoch 367/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4750 - accuracy: 0.7913 - auc: 0.8550 - val_loss: 0.4615 - val_accuracy: 0.7273 - val_auc: 0.8645\n",
      "Epoch 368/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4579 - accuracy: 0.8015 - auc: 0.8743 - val_loss: 1.1202 - val_accuracy: 0.4242 - val_auc: 0.3852\n",
      "Epoch 369/1000\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.4832 - accuracy: 0.7837 - auc: 0.8555 - val_loss: 0.2989 - val_accuracy: 0.9091 - val_auc: 0.9658\n",
      "Epoch 370/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4620 - accuracy: 0.7786 - auc: 0.8617 - val_loss: 0.4259 - val_accuracy: 0.7980 - val_auc: 0.8841\n",
      "Epoch 371/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.5221 - accuracy: 0.7532 - auc: 0.8318 - val_loss: 0.4439 - val_accuracy: 0.8182 - val_auc: 0.8674\n",
      "Epoch 372/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4954 - accuracy: 0.7786 - auc: 0.8489 - val_loss: 0.6491 - val_accuracy: 0.6364 - val_auc: 0.6811\n",
      "Epoch 373/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4889 - accuracy: 0.7735 - auc: 0.8436 - val_loss: 0.4223 - val_accuracy: 0.7677 - val_auc: 0.8901\n",
      "Epoch 374/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4626 - accuracy: 0.7659 - auc: 0.8649 - val_loss: 0.4266 - val_accuracy: 0.8485 - val_auc: 0.8856\n",
      "Epoch 375/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4661 - accuracy: 0.7990 - auc: 0.8690 - val_loss: 1.2996 - val_accuracy: 0.2828 - val_auc: 0.2072\n",
      "Epoch 376/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4867 - accuracy: 0.7506 - auc: 0.8457 - val_loss: 0.3839 - val_accuracy: 0.8990 - val_auc: 0.9248\n",
      "Epoch 377/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.4538 - accuracy: 0.7939 - auc: 0.8730 - val_loss: 0.3708 - val_accuracy: 0.8889 - val_auc: 0.9185\n",
      "Epoch 378/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4746 - accuracy: 0.7888 - auc: 0.8596 - val_loss: 1.0788 - val_accuracy: 0.4141 - val_auc: 0.3349\n",
      "Epoch 379/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4658 - accuracy: 0.7939 - auc: 0.8638 - val_loss: 0.3906 - val_accuracy: 0.8586 - val_auc: 0.9305\n",
      "Epoch 380/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4706 - accuracy: 0.7786 - auc: 0.8571 - val_loss: 0.3563 - val_accuracy: 0.7576 - val_auc: 0.9283\n",
      "Epoch 381/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.5030 - accuracy: 0.7634 - auc: 0.8382 - val_loss: 0.6014 - val_accuracy: 0.8182 - val_auc: 0.8275\n",
      "Epoch 382/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.5029 - accuracy: 0.7506 - auc: 0.8374 - val_loss: 0.1783 - val_accuracy: 0.9596 - val_auc: 0.9805\n",
      "Epoch 383/1000\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.4765 - accuracy: 0.7964 - auc: 0.8609 - val_loss: 0.1083 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 384/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.4824 - accuracy: 0.7786 - auc: 0.8501 - val_loss: 0.7290 - val_accuracy: 0.6263 - val_auc: 0.6019\n",
      "Epoch 385/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4830 - accuracy: 0.7659 - auc: 0.8471 - val_loss: 0.3116 - val_accuracy: 0.8889 - val_auc: 0.9625\n",
      "Epoch 386/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4715 - accuracy: 0.7684 - auc: 0.8527 - val_loss: 0.2094 - val_accuracy: 0.9293 - val_auc: 0.9862\n",
      "Epoch 387/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4981 - accuracy: 0.7761 - auc: 0.8406 - val_loss: 0.4077 - val_accuracy: 0.8586 - val_auc: 0.9283\n",
      "Epoch 388/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.4797 - accuracy: 0.7939 - auc: 0.8588 - val_loss: 1.2832 - val_accuracy: 0.3434 - val_auc: 0.2475\n",
      "Epoch 389/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.4742 - accuracy: 0.7761 - auc: 0.8581 - val_loss: 0.6830 - val_accuracy: 0.6667 - val_auc: 0.6387\n",
      "Epoch 390/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4671 - accuracy: 0.7990 - auc: 0.8555 - val_loss: 0.5238 - val_accuracy: 0.7071 - val_auc: 0.8074\n",
      "Epoch 391/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4610 - accuracy: 0.7735 - auc: 0.8613 - val_loss: 0.6879 - val_accuracy: 0.5960 - val_auc: 0.6571\n",
      "Epoch 392/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.4724 - accuracy: 0.7761 - auc: 0.8578 - val_loss: 1.2961 - val_accuracy: 0.2828 - val_auc: 0.2475\n",
      "Epoch 393/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.5370 - accuracy: 0.7583 - auc: 0.8257 - val_loss: 0.5298 - val_accuracy: 0.7273 - val_auc: 0.8054\n",
      "Epoch 394/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.4667 - accuracy: 0.7939 - auc: 0.8618 - val_loss: 0.3391 - val_accuracy: 0.8687 - val_auc: 0.9361\n",
      "Epoch 395/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4916 - accuracy: 0.7913 - auc: 0.8471 - val_loss: 0.3628 - val_accuracy: 0.8586 - val_auc: 0.9364\n",
      "Epoch 396/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4807 - accuracy: 0.7684 - auc: 0.8489 - val_loss: 0.8288 - val_accuracy: 0.4848 - val_auc: 0.5075\n",
      "Epoch 397/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.5004 - accuracy: 0.7608 - auc: 0.8437 - val_loss: 0.6117 - val_accuracy: 0.6869 - val_auc: 0.7526\n",
      "Epoch 398/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4916 - accuracy: 0.7659 - auc: 0.8425 - val_loss: 0.7189 - val_accuracy: 0.5758 - val_auc: 0.6068\n",
      "Epoch 399/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4548 - accuracy: 0.7990 - auc: 0.8709 - val_loss: 1.0069 - val_accuracy: 0.4444 - val_auc: 0.3495\n",
      "Epoch 400/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4857 - accuracy: 0.7761 - auc: 0.8518 - val_loss: 1.0109 - val_accuracy: 0.3939 - val_auc: 0.3344\n",
      "Epoch 401/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4679 - accuracy: 0.7837 - auc: 0.8563 - val_loss: 1.3804 - val_accuracy: 0.3131 - val_auc: 0.1621\n",
      "Epoch 402/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.4747 - accuracy: 0.7837 - auc: 0.8552 - val_loss: 1.0763 - val_accuracy: 0.3737 - val_auc: 0.2888\n",
      "Epoch 403/1000\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.5119 - accuracy: 0.7455 - auc: 0.8273 - val_loss: 0.2913 - val_accuracy: 0.9192 - val_auc: 0.9697\n",
      "Epoch 404/1000\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.4936 - accuracy: 0.7506 - auc: 0.8411 - val_loss: 0.2598 - val_accuracy: 0.9091 - val_auc: 0.9734\n",
      "Epoch 405/1000\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.5000 - accuracy: 0.7735 - auc: 0.8388 - val_loss: 0.9124 - val_accuracy: 0.4646 - val_auc: 0.4107\n",
      "Epoch 406/1000\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.4615 - accuracy: 0.8092 - auc: 0.8646 - val_loss: 1.0316 - val_accuracy: 0.4141 - val_auc: 0.3488\n",
      "Epoch 407/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.5095 - accuracy: 0.7608 - auc: 0.8337 - val_loss: 0.3201 - val_accuracy: 0.9192 - val_auc: 0.9703\n",
      "Epoch 408/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4801 - accuracy: 0.7710 - auc: 0.8520 - val_loss: 0.2319 - val_accuracy: 0.8990 - val_auc: 0.9851\n",
      "Epoch 409/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5120 - accuracy: 0.7684 - auc: 0.8357 - val_loss: 0.3075 - val_accuracy: 0.8889 - val_auc: 0.9565\n",
      "Epoch 410/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.4869 - accuracy: 0.7583 - auc: 0.8466 - val_loss: 0.1229 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 411/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.4701 - accuracy: 0.7939 - auc: 0.8630 - val_loss: 0.2095 - val_accuracy: 0.9293 - val_auc: 0.9915\n",
      "Epoch 412/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4884 - accuracy: 0.7455 - auc: 0.8410 - val_loss: 0.6700 - val_accuracy: 0.5859 - val_auc: 0.6587\n",
      "Epoch 413/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4722 - accuracy: 0.7761 - auc: 0.8566 - val_loss: 0.8433 - val_accuracy: 0.5051 - val_auc: 0.6013\n",
      "Epoch 414/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.5546 - accuracy: 0.7557 - auc: 0.8269 - val_loss: 0.7053 - val_accuracy: 0.8182 - val_auc: 0.7957\n",
      "Epoch 415/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.5480 - accuracy: 0.7405 - auc: 0.8094 - val_loss: 0.3770 - val_accuracy: 0.8889 - val_auc: 0.9354\n",
      "Epoch 416/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 62ms/step - loss: 0.5074 - accuracy: 0.7328 - auc: 0.8328 - val_loss: 0.1737 - val_accuracy: 0.9293 - val_auc: 0.9946\n",
      "Epoch 417/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4897 - accuracy: 0.7761 - auc: 0.8512 - val_loss: 0.0582 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 418/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4764 - accuracy: 0.7761 - auc: 0.8572 - val_loss: 0.0792 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 419/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4399 - accuracy: 0.7964 - auc: 0.8772 - val_loss: 0.2154 - val_accuracy: 0.8687 - val_auc: 0.9743\n",
      "Epoch 420/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4998 - accuracy: 0.7761 - auc: 0.8509 - val_loss: 0.8263 - val_accuracy: 0.5051 - val_auc: 0.5280\n",
      "Epoch 421/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4891 - accuracy: 0.7710 - auc: 0.8470 - val_loss: 0.8175 - val_accuracy: 0.5051 - val_auc: 0.5351\n",
      "Epoch 422/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4606 - accuracy: 0.7710 - auc: 0.8643 - val_loss: 1.3184 - val_accuracy: 0.3131 - val_auc: 0.1773\n",
      "Epoch 423/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4677 - accuracy: 0.7710 - auc: 0.8630 - val_loss: 0.5776 - val_accuracy: 0.6667 - val_auc: 0.7698\n",
      "Epoch 424/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.5130 - accuracy: 0.7328 - auc: 0.8296 - val_loss: 0.4066 - val_accuracy: 0.8586 - val_auc: 0.9086\n",
      "Epoch 425/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4866 - accuracy: 0.7659 - auc: 0.8490 - val_loss: 0.1445 - val_accuracy: 0.9293 - val_auc: 0.9950\n",
      "Epoch 426/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.5312 - accuracy: 0.7455 - auc: 0.8275 - val_loss: 0.6019 - val_accuracy: 0.6667 - val_auc: 0.7190\n",
      "Epoch 427/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.5044 - accuracy: 0.7455 - auc: 0.8288 - val_loss: 0.5109 - val_accuracy: 0.7273 - val_auc: 0.8357\n",
      "Epoch 428/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4705 - accuracy: 0.7888 - auc: 0.8583 - val_loss: 0.3245 - val_accuracy: 0.8990 - val_auc: 0.9445\n",
      "Epoch 429/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4405 - accuracy: 0.8041 - auc: 0.8804 - val_loss: 0.5119 - val_accuracy: 0.6970 - val_auc: 0.8190\n",
      "Epoch 430/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4414 - accuracy: 0.7990 - auc: 0.8780 - val_loss: 0.6780 - val_accuracy: 0.6162 - val_auc: 0.6618\n",
      "Epoch 431/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4643 - accuracy: 0.7837 - auc: 0.8636 - val_loss: 0.3947 - val_accuracy: 0.8788 - val_auc: 0.9098\n",
      "Epoch 432/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5057 - accuracy: 0.7634 - auc: 0.8391 - val_loss: 0.4640 - val_accuracy: 0.8485 - val_auc: 0.8965\n",
      "Epoch 433/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4656 - accuracy: 0.7888 - auc: 0.8630 - val_loss: 0.4158 - val_accuracy: 0.7576 - val_auc: 0.8946\n",
      "Epoch 434/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.4638 - accuracy: 0.8066 - auc: 0.8684 - val_loss: 0.4015 - val_accuracy: 0.7374 - val_auc: 0.9016\n",
      "Epoch 435/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.4734 - accuracy: 0.7532 - auc: 0.8555 - val_loss: 0.4858 - val_accuracy: 0.8182 - val_auc: 0.8508\n",
      "Epoch 436/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4580 - accuracy: 0.7939 - auc: 0.8688 - val_loss: 0.5733 - val_accuracy: 0.6970 - val_auc: 0.7696\n",
      "Epoch 437/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4943 - accuracy: 0.7684 - auc: 0.8388 - val_loss: 0.2673 - val_accuracy: 0.9192 - val_auc: 0.9892\n",
      "Epoch 438/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.4780 - accuracy: 0.7604 - auc: 0.85 - 1s 60ms/step - loss: 0.4916 - accuracy: 0.7557 - auc: 0.8531 - val_loss: 0.2541 - val_accuracy: 0.9192 - val_auc: 0.9834\n",
      "Epoch 439/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4695 - accuracy: 0.7888 - auc: 0.8619 - val_loss: 0.8910 - val_accuracy: 0.4747 - val_auc: 0.4029\n",
      "Epoch 440/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4540 - accuracy: 0.7786 - auc: 0.8703 - val_loss: 0.9801 - val_accuracy: 0.4848 - val_auc: 0.3980\n",
      "Epoch 441/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4984 - accuracy: 0.8015 - auc: 0.8491 - val_loss: 1.1582 - val_accuracy: 0.3939 - val_auc: 0.2549\n",
      "Epoch 442/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.5365 - accuracy: 0.7379 - auc: 0.8140 - val_loss: 1.1411 - val_accuracy: 0.1515 - val_auc: 0.2207\n",
      "Epoch 443/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.5441 - accuracy: 0.7583 - auc: 0.8054 - val_loss: 0.7451 - val_accuracy: 0.5051 - val_auc: 0.6048\n",
      "Epoch 444/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4647 - accuracy: 0.7735 - auc: 0.8640 - val_loss: 0.5071 - val_accuracy: 0.7172 - val_auc: 0.8341\n",
      "Epoch 445/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4715 - accuracy: 0.7837 - auc: 0.8613 - val_loss: 0.2383 - val_accuracy: 0.8889 - val_auc: 0.9850\n",
      "Epoch 446/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.5150 - accuracy: 0.7659 - auc: 0.8364 - val_loss: 0.5684 - val_accuracy: 0.6970 - val_auc: 0.7755\n",
      "Epoch 447/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5222 - accuracy: 0.7252 - auc: 0.8182 - val_loss: 0.2592 - val_accuracy: 0.9394 - val_auc: 0.9912\n",
      "Epoch 448/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4734 - accuracy: 0.7761 - auc: 0.8566 - val_loss: 0.2248 - val_accuracy: 0.9192 - val_auc: 0.9839\n",
      "Epoch 449/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.6146 - accuracy: 0.7150 - auc: 0.7847 - val_loss: 0.4054 - val_accuracy: 0.8182 - val_auc: 0.9179\n",
      "Epoch 450/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.5862 - accuracy: 0.6921 - auc: 0.7604 - val_loss: 0.0842 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 451/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5744 - accuracy: 0.6947 - auc: 0.7775 - val_loss: 0.0116 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 452/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.5134 - accuracy: 0.7430 - auc: 0.8281 - val_loss: 0.0806 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 453/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.5094 - accuracy: 0.7481 - auc: 0.8311 - val_loss: 0.5850 - val_accuracy: 0.6465 - val_auc: 0.7639\n",
      "Epoch 454/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.4813 - accuracy: 0.7786 - auc: 0.8519 - val_loss: 0.2740 - val_accuracy: 0.9192 - val_auc: 0.9855\n",
      "Epoch 455/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5029 - accuracy: 0.7608 - auc: 0.8408 - val_loss: 0.3858 - val_accuracy: 0.8889 - val_auc: 0.9326\n",
      "Epoch 456/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.5108 - accuracy: 0.7659 - auc: 0.8373 - val_loss: 0.8320 - val_accuracy: 0.4141 - val_auc: 0.4160\n",
      "Epoch 457/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4781 - accuracy: 0.7913 - auc: 0.8556 - val_loss: 0.6703 - val_accuracy: 0.6263 - val_auc: 0.6891\n",
      "Epoch 458/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.5029 - accuracy: 0.7659 - auc: 0.8400 - val_loss: 0.2297 - val_accuracy: 0.9192 - val_auc: 0.9895\n",
      "Epoch 459/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.4693 - accuracy: 0.7812 - auc: 0.8552 - val_loss: 0.7891 - val_accuracy: 0.5253 - val_auc: 0.5413\n",
      "Epoch 460/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.5034 - accuracy: 0.7735 - auc: 0.8527 - val_loss: 0.5201 - val_accuracy: 0.6970 - val_auc: 0.8144\n",
      "Epoch 461/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4729 - accuracy: 0.7837 - auc: 0.8596 - val_loss: 0.3630 - val_accuracy: 0.8687 - val_auc: 0.9294\n",
      "Epoch 462/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4863 - accuracy: 0.7761 - auc: 0.8478 - val_loss: 0.3289 - val_accuracy: 0.9091 - val_auc: 0.9557\n",
      "Epoch 463/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4928 - accuracy: 0.7634 - auc: 0.8476 - val_loss: 0.3004 - val_accuracy: 0.9192 - val_auc: 0.9692\n",
      "Epoch 464/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4766 - accuracy: 0.7863 - auc: 0.8549 - val_loss: 0.4993 - val_accuracy: 0.6869 - val_auc: 0.8318\n",
      "Epoch 465/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4918 - accuracy: 0.7710 - auc: 0.8478 - val_loss: 0.4406 - val_accuracy: 0.8384 - val_auc: 0.9058\n",
      "Epoch 466/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.4583 - accuracy: 0.7761 - auc: 0.8677 - val_loss: 0.4040 - val_accuracy: 0.8283 - val_auc: 0.9036\n",
      "Epoch 467/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.4720 - accuracy: 0.7634 - auc: 0.8605 - val_loss: 0.5066 - val_accuracy: 0.7576 - val_auc: 0.8303\n",
      "Epoch 468/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4578 - accuracy: 0.7812 - auc: 0.8661 - val_loss: 1.0033 - val_accuracy: 0.4444 - val_auc: 0.3545\n",
      "Epoch 469/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4689 - accuracy: 0.7837 - auc: 0.8638 - val_loss: 0.5154 - val_accuracy: 0.7374 - val_auc: 0.8186\n",
      "Epoch 470/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4661 - accuracy: 0.7761 - auc: 0.8640 - val_loss: 0.8361 - val_accuracy: 0.4848 - val_auc: 0.4719\n",
      "Epoch 471/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4808 - accuracy: 0.7710 - auc: 0.8534 - val_loss: 0.3633 - val_accuracy: 0.8889 - val_auc: 0.9465\n",
      "Epoch 472/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4694 - accuracy: 0.7557 - auc: 0.8538 - val_loss: 0.5572 - val_accuracy: 0.7071 - val_auc: 0.7854\n",
      "Epoch 473/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4601 - accuracy: 0.7964 - auc: 0.8685 - val_loss: 0.7704 - val_accuracy: 0.5051 - val_auc: 0.5607\n",
      "Epoch 474/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.4512 - accuracy: 0.7913 - auc: 0.8724 - val_loss: 0.9723 - val_accuracy: 0.4040 - val_auc: 0.3931\n",
      "Epoch 475/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4762 - accuracy: 0.7634 - auc: 0.8530 - val_loss: 0.5495 - val_accuracy: 0.6970 - val_auc: 0.7900\n",
      "Epoch 476/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.5011 - accuracy: 0.7455 - auc: 0.83 - 1s 63ms/step - loss: 0.5011 - accuracy: 0.7455 - auc: 0.8332 - val_loss: 0.5480 - val_accuracy: 0.6465 - val_auc: 0.7848\n",
      "Epoch 477/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4760 - accuracy: 0.7888 - auc: 0.8534 - val_loss: 0.5772 - val_accuracy: 0.7071 - val_auc: 0.7670\n",
      "Epoch 478/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.4916 - accuracy: 0.7354 - auc: 0.8419 - val_loss: 0.6208 - val_accuracy: 0.6162 - val_auc: 0.7081\n",
      "Epoch 479/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.5039 - accuracy: 0.7379 - auc: 0.8338 - val_loss: 0.5849 - val_accuracy: 0.6768 - val_auc: 0.7543\n",
      "Epoch 480/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4500 - accuracy: 0.7888 - auc: 0.8728 - val_loss: 0.7193 - val_accuracy: 0.5758 - val_auc: 0.6269\n",
      "Epoch 481/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.4972 - accuracy: 0.7583 - auc: 0.8367 - val_loss: 0.8529 - val_accuracy: 0.4545 - val_auc: 0.5125\n",
      "Epoch 482/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4647 - accuracy: 0.7786 - auc: 0.8642 - val_loss: 0.9217 - val_accuracy: 0.4848 - val_auc: 0.4599\n",
      "Epoch 483/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4604 - accuracy: 0.7761 - auc: 0.8653 - val_loss: 0.9140 - val_accuracy: 0.4242 - val_auc: 0.4117\n",
      "Epoch 484/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4785 - accuracy: 0.7990 - auc: 0.8541 - val_loss: 0.7722 - val_accuracy: 0.5455 - val_auc: 0.5715\n",
      "Epoch 485/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4751 - accuracy: 0.7608 - auc: 0.8534 - val_loss: 0.6574 - val_accuracy: 0.5657 - val_auc: 0.6708\n",
      "Epoch 486/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.4618 - accuracy: 0.7888 - auc: 0.8663 - val_loss: 1.1172 - val_accuracy: 0.4141 - val_auc: 0.3271\n",
      "Epoch 487/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.4684 - accuracy: 0.7863 - auc: 0.8626 - val_loss: 0.9985 - val_accuracy: 0.4040 - val_auc: 0.3579\n",
      "Epoch 488/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4450 - accuracy: 0.7837 - auc: 0.8769 - val_loss: 0.7741 - val_accuracy: 0.5657 - val_auc: 0.5939\n",
      "Epoch 489/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4677 - accuracy: 0.7786 - auc: 0.8595 - val_loss: 0.6864 - val_accuracy: 0.6465 - val_auc: 0.6603\n",
      "Epoch 490/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.4315 - accuracy: 0.8041 - auc: 0.8850 - val_loss: 0.3283 - val_accuracy: 0.8889 - val_auc: 0.9435\n",
      "Epoch 491/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4664 - accuracy: 0.7913 - auc: 0.8637 - val_loss: 0.5645 - val_accuracy: 0.6970 - val_auc: 0.7761\n",
      "Epoch 492/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.5596 - accuracy: 0.7761 - auc: 0.8214 - val_loss: 0.4819 - val_accuracy: 0.8283 - val_auc: 0.8455\n",
      "Epoch 493/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.5214 - accuracy: 0.7328 - auc: 0.8337 - val_loss: 0.3583 - val_accuracy: 0.8586 - val_auc: 0.9391\n",
      "Epoch 494/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.4551 - accuracy: 0.7964 - auc: 0.8713 - val_loss: 0.2995 - val_accuracy: 0.8586 - val_auc: 0.9494\n",
      "Epoch 495/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4793 - accuracy: 0.7684 - auc: 0.8554 - val_loss: 0.4203 - val_accuracy: 0.7374 - val_auc: 0.8884\n",
      "Epoch 496/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4966 - accuracy: 0.7710 - auc: 0.8394 - val_loss: 0.4591 - val_accuracy: 0.7778 - val_auc: 0.8753\n",
      "Epoch 497/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4840 - accuracy: 0.7659 - auc: 0.8468 - val_loss: 0.6876 - val_accuracy: 0.5960 - val_auc: 0.6376\n",
      "Epoch 498/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4765 - accuracy: 0.7557 - auc: 0.8535 - val_loss: 0.3927 - val_accuracy: 0.8586 - val_auc: 0.9131\n",
      "Epoch 499/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.5030 - accuracy: 0.7557 - auc: 0.8330 - val_loss: 0.4201 - val_accuracy: 0.8182 - val_auc: 0.9109\n",
      "Epoch 500/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4634 - accuracy: 0.7710 - auc: 0.8610 - val_loss: 0.6528 - val_accuracy: 0.6061 - val_auc: 0.6943\n",
      "Epoch 501/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4636 - accuracy: 0.7761 - auc: 0.8630 - val_loss: 0.4762 - val_accuracy: 0.7273 - val_auc: 0.8521\n",
      "Epoch 502/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4722 - accuracy: 0.7710 - auc: 0.8569 - val_loss: 1.0444 - val_accuracy: 0.4141 - val_auc: 0.3764\n",
      "Epoch 503/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4726 - accuracy: 0.7481 - auc: 0.8500 - val_loss: 1.6403 - val_accuracy: 0.2626 - val_auc: 0.1220\n",
      "Epoch 504/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.5257 - accuracy: 0.7430 - auc: 0.8347 - val_loss: 0.9341 - val_accuracy: 0.5253 - val_auc: 0.5171\n",
      "Epoch 505/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.4855 - accuracy: 0.7837 - auc: 0.8539 - val_loss: 2.7393 - val_accuracy: 0.0303 - val_auc: 0.0283\n",
      "Epoch 506/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4519 - accuracy: 0.7659 - auc: 0.8667 - val_loss: 0.7904 - val_accuracy: 0.6263 - val_auc: 0.5831\n",
      "Epoch 507/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4540 - accuracy: 0.7761 - auc: 0.8706 - val_loss: 1.3107 - val_accuracy: 0.3434 - val_auc: 0.2183\n",
      "Epoch 508/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 60ms/step - loss: 0.4528 - accuracy: 0.7837 - auc: 0.8711 - val_loss: 1.8257 - val_accuracy: 0.1313 - val_auc: 0.1048\n",
      "Epoch 509/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4872 - accuracy: 0.7786 - auc: 0.8516 - val_loss: 0.3483 - val_accuracy: 0.8384 - val_auc: 0.9230\n",
      "Epoch 510/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5001 - accuracy: 0.7608 - auc: 0.8375 - val_loss: 0.3019 - val_accuracy: 0.9091 - val_auc: 0.9834\n",
      "Epoch 511/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4528 - accuracy: 0.7964 - auc: 0.8711 - val_loss: 0.4875 - val_accuracy: 0.7879 - val_auc: 0.8405\n",
      "Epoch 512/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4523 - accuracy: 0.7888 - auc: 0.8684 - val_loss: 0.3343 - val_accuracy: 0.8990 - val_auc: 0.9484\n",
      "Epoch 513/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4792 - accuracy: 0.7684 - auc: 0.8516 - val_loss: 0.6063 - val_accuracy: 0.6768 - val_auc: 0.7324\n",
      "Epoch 514/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4475 - accuracy: 0.7710 - auc: 0.8718 - val_loss: 0.2582 - val_accuracy: 0.8586 - val_auc: 0.9692\n",
      "Epoch 515/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4535 - accuracy: 0.8015 - auc: 0.8721 - val_loss: 0.4938 - val_accuracy: 0.7071 - val_auc: 0.8345\n",
      "Epoch 516/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4757 - accuracy: 0.7634 - auc: 0.8591 - val_loss: 0.5932 - val_accuracy: 0.6667 - val_auc: 0.7537\n",
      "Epoch 517/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.4852 - accuracy: 0.7761 - auc: 0.8505 - val_loss: 0.3581 - val_accuracy: 0.8788 - val_auc: 0.9383\n",
      "Epoch 518/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.4835 - accuracy: 0.7735 - auc: 0.8485 - val_loss: 1.0171 - val_accuracy: 0.4343 - val_auc: 0.4185\n",
      "Epoch 519/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4971 - accuracy: 0.7684 - auc: 0.8463 - val_loss: 0.4311 - val_accuracy: 0.7374 - val_auc: 0.8857\n",
      "Epoch 520/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4562 - accuracy: 0.7888 - auc: 0.8676 - val_loss: 0.2669 - val_accuracy: 0.9091 - val_auc: 0.9684\n",
      "Epoch 521/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4631 - accuracy: 0.7684 - auc: 0.8586 - val_loss: 0.3689 - val_accuracy: 0.8485 - val_auc: 0.9129\n",
      "Epoch 522/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4868 - accuracy: 0.7837 - auc: 0.8584 - val_loss: 0.4545 - val_accuracy: 0.7879 - val_auc: 0.8676\n",
      "Epoch 523/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4991 - accuracy: 0.7684 - auc: 0.8349 - val_loss: 0.5158 - val_accuracy: 0.7374 - val_auc: 0.8579\n",
      "Epoch 524/1000\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.4792 - accuracy: 0.8015 - auc: 0.8543 - val_loss: 0.8151 - val_accuracy: 0.5253 - val_auc: 0.6091\n",
      "Epoch 525/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4544 - accuracy: 0.7939 - auc: 0.8732 - val_loss: 0.1270 - val_accuracy: 0.9899 - val_auc: 0.9989\n",
      "Epoch 526/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4552 - accuracy: 0.7990 - auc: 0.8705 - val_loss: 0.1307 - val_accuracy: 0.9899 - val_auc: 0.9999\n",
      "Epoch 527/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4757 - accuracy: 0.7837 - auc: 0.8563 - val_loss: 0.5145 - val_accuracy: 0.7980 - val_auc: 0.8272\n",
      "Epoch 528/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4920 - accuracy: 0.7634 - auc: 0.8446 - val_loss: 0.5955 - val_accuracy: 0.6566 - val_auc: 0.7485\n",
      "Epoch 529/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.5039 - accuracy: 0.7328 - auc: 0.8307 - val_loss: 0.4106 - val_accuracy: 0.8788 - val_auc: 0.9155\n",
      "Epoch 530/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4781 - accuracy: 0.7634 - auc: 0.8485 - val_loss: 0.5421 - val_accuracy: 0.7273 - val_auc: 0.7950\n",
      "Epoch 531/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4763 - accuracy: 0.7710 - auc: 0.8543 - val_loss: 0.2935 - val_accuracy: 0.8485 - val_auc: 0.9596\n",
      "Epoch 532/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4575 - accuracy: 0.7710 - auc: 0.8636 - val_loss: 1.3144 - val_accuracy: 0.3131 - val_auc: 0.2771\n",
      "Epoch 533/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4962 - accuracy: 0.7939 - auc: 0.8458 - val_loss: 0.9416 - val_accuracy: 0.4141 - val_auc: 0.4138\n",
      "Epoch 534/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4761 - accuracy: 0.7583 - auc: 0.8493 - val_loss: 0.9287 - val_accuracy: 0.4343 - val_auc: 0.3730\n",
      "Epoch 535/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4572 - accuracy: 0.7888 - auc: 0.8653 - val_loss: 1.2200 - val_accuracy: 0.3333 - val_auc: 0.2152\n",
      "Epoch 536/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4628 - accuracy: 0.7837 - auc: 0.8614 - val_loss: 0.8930 - val_accuracy: 0.4848 - val_auc: 0.4439\n",
      "Epoch 537/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.4623 - accuracy: 0.7812 - auc: 0.8590 - val_loss: 0.8866 - val_accuracy: 0.4848 - val_auc: 0.4629\n",
      "Epoch 538/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4547 - accuracy: 0.7837 - auc: 0.8681 - val_loss: 0.9060 - val_accuracy: 0.4444 - val_auc: 0.4232\n",
      "Epoch 539/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4447 - accuracy: 0.8117 - auc: 0.8785 - val_loss: 1.1218 - val_accuracy: 0.3636 - val_auc: 0.2837\n",
      "Epoch 540/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.4891 - accuracy: 0.7786 - auc: 0.8423 - val_loss: 1.0284 - val_accuracy: 0.4242 - val_auc: 0.3671\n",
      "Epoch 541/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.4821 - accuracy: 0.7710 - auc: 0.8497 - val_loss: 0.2595 - val_accuracy: 0.9091 - val_auc: 0.9820\n",
      "Epoch 542/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4608 - accuracy: 0.7913 - auc: 0.8669 - val_loss: 0.8994 - val_accuracy: 0.5253 - val_auc: 0.5203\n",
      "Epoch 543/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4806 - accuracy: 0.7888 - auc: 0.8613 - val_loss: 0.5308 - val_accuracy: 0.7172 - val_auc: 0.8205\n",
      "Epoch 544/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.4520 - accuracy: 0.7964 - auc: 0.8730 - val_loss: 0.4768 - val_accuracy: 0.7980 - val_auc: 0.8535\n",
      "Epoch 545/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4802 - accuracy: 0.7710 - auc: 0.8543 - val_loss: 1.2609 - val_accuracy: 0.1717 - val_auc: 0.1927\n",
      "Epoch 546/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4795 - accuracy: 0.7837 - auc: 0.8562 - val_loss: 1.5739 - val_accuracy: 0.0606 - val_auc: 0.0506\n",
      "Epoch 547/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.5014 - accuracy: 0.7684 - auc: 0.8413 - val_loss: 0.8003 - val_accuracy: 0.5657 - val_auc: 0.5456\n",
      "Epoch 548/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4681 - accuracy: 0.7684 - auc: 0.8562 - val_loss: 0.4133 - val_accuracy: 0.7778 - val_auc: 0.9149\n",
      "Epoch 549/1000\n",
      "13/13 [==============================] - 1s 75ms/step - loss: 0.4665 - accuracy: 0.7684 - auc: 0.8585 - val_loss: 0.2810 - val_accuracy: 0.8990 - val_auc: 0.9745\n",
      "Epoch 550/1000\n",
      "13/13 [==============================] - 1s 70ms/step - loss: 0.4570 - accuracy: 0.7659 - auc: 0.8635 - val_loss: 0.2907 - val_accuracy: 0.8889 - val_auc: 0.9719\n",
      "Epoch 551/1000\n",
      "13/13 [==============================] - 1s 71ms/step - loss: 0.4755 - accuracy: 0.7761 - auc: 0.8499 - val_loss: 0.4405 - val_accuracy: 0.7475 - val_auc: 0.8765\n",
      "Epoch 552/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4696 - accuracy: 0.7659 - auc: 0.8596 - val_loss: 0.0706 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 553/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4613 - accuracy: 0.7837 - auc: 0.8643 - val_loss: 0.4192 - val_accuracy: 0.7475 - val_auc: 0.9006\n",
      "Epoch 554/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4435 - accuracy: 0.7964 - auc: 0.8738 - val_loss: 0.4183 - val_accuracy: 0.7475 - val_auc: 0.8856\n",
      "Epoch 555/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4488 - accuracy: 0.7964 - auc: 0.8748 - val_loss: 0.1895 - val_accuracy: 0.9394 - val_auc: 0.9922\n",
      "Epoch 556/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4447 - accuracy: 0.8041 - auc: 0.8769 - val_loss: 0.5299 - val_accuracy: 0.6869 - val_auc: 0.8135\n",
      "Epoch 557/1000\n",
      "13/13 [==============================] - 1s 71ms/step - loss: 0.4755 - accuracy: 0.7634 - auc: 0.8573 - val_loss: 0.4570 - val_accuracy: 0.8081 - val_auc: 0.8701\n",
      "Epoch 558/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.4669 - accuracy: 0.7659 - auc: 0.8578 - val_loss: 0.3545 - val_accuracy: 0.8485 - val_auc: 0.9340\n",
      "Epoch 559/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.4726 - accuracy: 0.7761 - auc: 0.8587 - val_loss: 0.2350 - val_accuracy: 0.9394 - val_auc: 0.9902\n",
      "Epoch 560/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4446 - accuracy: 0.7939 - auc: 0.8778 - val_loss: 0.5535 - val_accuracy: 0.6768 - val_auc: 0.7941\n",
      "Epoch 561/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4624 - accuracy: 0.7837 - auc: 0.8684 - val_loss: 0.4317 - val_accuracy: 0.7879 - val_auc: 0.8818\n",
      "Epoch 562/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4389 - accuracy: 0.7990 - auc: 0.8769 - val_loss: 0.5298 - val_accuracy: 0.6970 - val_auc: 0.8127\n",
      "Epoch 563/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4884 - accuracy: 0.7735 - auc: 0.8530 - val_loss: 0.3509 - val_accuracy: 0.8788 - val_auc: 0.9350\n",
      "Epoch 564/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4776 - accuracy: 0.7837 - auc: 0.8590 - val_loss: 0.4412 - val_accuracy: 0.8384 - val_auc: 0.8813\n",
      "Epoch 565/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4623 - accuracy: 0.8142 - auc: 0.8679 - val_loss: 1.5282 - val_accuracy: 0.1010 - val_auc: 0.0596\n",
      "Epoch 566/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4975 - accuracy: 0.7608 - auc: 0.8402 - val_loss: 0.2000 - val_accuracy: 0.9394 - val_auc: 0.9944\n",
      "Epoch 567/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.4519 - accuracy: 0.8142 - auc: 0.8736 - val_loss: 0.4037 - val_accuracy: 0.7677 - val_auc: 0.9029\n",
      "Epoch 568/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.5349 - accuracy: 0.7684 - auc: 0.8338 - val_loss: 0.3448 - val_accuracy: 0.8889 - val_auc: 0.9316\n",
      "Epoch 569/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.4857 - accuracy: 0.7583 - auc: 0.8505 - val_loss: 0.4434 - val_accuracy: 0.7475 - val_auc: 0.8729\n",
      "Epoch 570/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4861 - accuracy: 0.7735 - auc: 0.8445 - val_loss: 0.4161 - val_accuracy: 0.8586 - val_auc: 0.9046\n",
      "Epoch 571/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4626 - accuracy: 0.7913 - auc: 0.8668 - val_loss: 0.5678 - val_accuracy: 0.7071 - val_auc: 0.7709\n",
      "Epoch 572/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.5046 - accuracy: 0.7532 - auc: 0.8368 - val_loss: 0.4506 - val_accuracy: 0.7374 - val_auc: 0.8809\n",
      "Epoch 573/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.5000 - accuracy: 0.7506 - auc: 0.8330 - val_loss: 0.5013 - val_accuracy: 0.7879 - val_auc: 0.8497\n",
      "Epoch 574/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4736 - accuracy: 0.7888 - auc: 0.8589 - val_loss: 0.3748 - val_accuracy: 0.8485 - val_auc: 0.9182\n",
      "Epoch 575/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4789 - accuracy: 0.7735 - auc: 0.8551 - val_loss: 0.2288 - val_accuracy: 0.8889 - val_auc: 0.9811\n",
      "Epoch 576/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4875 - accuracy: 0.7532 - auc: 0.8441 - val_loss: 0.2412 - val_accuracy: 0.9293 - val_auc: 0.9923\n",
      "Epoch 577/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.4975 - accuracy: 0.7532 - auc: 0.8387 - val_loss: 0.2854 - val_accuracy: 0.9091 - val_auc: 0.9696\n",
      "Epoch 578/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4600 - accuracy: 0.7786 - auc: 0.8646 - val_loss: 0.4839 - val_accuracy: 0.7273 - val_auc: 0.8450\n",
      "Epoch 579/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.5048 - accuracy: 0.7583 - auc: 0.8400 - val_loss: 0.1048 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 580/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4947 - accuracy: 0.7863 - auc: 0.8412 - val_loss: 0.1762 - val_accuracy: 0.9394 - val_auc: 0.9906\n",
      "Epoch 581/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.5045 - accuracy: 0.7684 - auc: 0.8365 - val_loss: 0.2036 - val_accuracy: 0.9394 - val_auc: 0.9901\n",
      "Epoch 582/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4977 - accuracy: 0.7608 - auc: 0.8285 - val_loss: 0.4659 - val_accuracy: 0.7273 - val_auc: 0.8729\n",
      "Epoch 583/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4708 - accuracy: 0.7863 - auc: 0.8607 - val_loss: 0.4088 - val_accuracy: 0.8485 - val_auc: 0.9057\n",
      "Epoch 584/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4566 - accuracy: 0.7634 - auc: 0.8671 - val_loss: 0.4269 - val_accuracy: 0.8081 - val_auc: 0.8866\n",
      "Epoch 585/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.4422 - accuracy: 0.7812 - auc: 0.8772 - val_loss: 0.4855 - val_accuracy: 0.6869 - val_auc: 0.8415\n",
      "Epoch 586/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.4643 - accuracy: 0.7837 - auc: 0.8617 - val_loss: 0.5650 - val_accuracy: 0.7475 - val_auc: 0.7920\n",
      "Epoch 587/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4563 - accuracy: 0.7863 - auc: 0.8677 - val_loss: 0.6008 - val_accuracy: 0.6768 - val_auc: 0.7432\n",
      "Epoch 588/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4864 - accuracy: 0.7684 - auc: 0.8556 - val_loss: 0.4192 - val_accuracy: 0.8182 - val_auc: 0.8857\n",
      "Epoch 589/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4634 - accuracy: 0.7837 - auc: 0.8635 - val_loss: 0.3931 - val_accuracy: 0.8586 - val_auc: 0.9248\n",
      "Epoch 590/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4818 - accuracy: 0.7837 - auc: 0.8495 - val_loss: 0.4416 - val_accuracy: 0.7374 - val_auc: 0.9029\n",
      "Epoch 591/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4917 - accuracy: 0.7761 - auc: 0.8531 - val_loss: 0.6671 - val_accuracy: 0.6162 - val_auc: 0.6605\n",
      "Epoch 592/1000\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.4696 - accuracy: 0.7939 - auc: 0.8625 - val_loss: 0.7383 - val_accuracy: 0.5556 - val_auc: 0.6381\n",
      "Epoch 593/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4724 - accuracy: 0.7608 - auc: 0.8577 - val_loss: 0.9936 - val_accuracy: 0.4747 - val_auc: 0.3709\n",
      "Epoch 594/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4816 - accuracy: 0.7761 - auc: 0.8517 - val_loss: 0.6755 - val_accuracy: 0.6162 - val_auc: 0.6555\n",
      "Epoch 595/1000\n",
      "13/13 [==============================] - 1s 71ms/step - loss: 0.4402 - accuracy: 0.7837 - auc: 0.8772 - val_loss: 0.2999 - val_accuracy: 0.8788 - val_auc: 0.9545\n",
      "Epoch 596/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.4809 - accuracy: 0.7710 - auc: 0.8507 - val_loss: 0.4059 - val_accuracy: 0.8283 - val_auc: 0.8896\n",
      "Epoch 597/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4756 - accuracy: 0.7990 - auc: 0.8556 - val_loss: 0.6783 - val_accuracy: 0.6364 - val_auc: 0.6548\n",
      "Epoch 598/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4511 - accuracy: 0.8142 - auc: 0.8723 - val_loss: 0.4693 - val_accuracy: 0.7879 - val_auc: 0.8546\n",
      "Epoch 599/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4676 - accuracy: 0.7786 - auc: 0.8592 - val_loss: 0.6546 - val_accuracy: 0.5859 - val_auc: 0.6900\n",
      "Epoch 600/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4737 - accuracy: 0.7913 - auc: 0.8566 - val_loss: 0.7043 - val_accuracy: 0.5960 - val_auc: 0.6351\n",
      "Epoch 601/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4686 - accuracy: 0.7888 - auc: 0.8616 - val_loss: 0.5828 - val_accuracy: 0.6364 - val_auc: 0.7657\n",
      "Epoch 602/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4771 - accuracy: 0.7659 - auc: 0.8568 - val_loss: 0.8923 - val_accuracy: 0.5354 - val_auc: 0.4815\n",
      "Epoch 603/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4617 - accuracy: 0.7786 - auc: 0.8633 - val_loss: 0.7977 - val_accuracy: 0.5859 - val_auc: 0.5537\n",
      "Epoch 604/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4866 - accuracy: 0.7532 - auc: 0.8432 - val_loss: 0.2460 - val_accuracy: 0.9091 - val_auc: 0.9852\n",
      "Epoch 605/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.4544 - accuracy: 0.7888 - auc: 0.8714 - val_loss: 0.5555 - val_accuracy: 0.7475 - val_auc: 0.8051\n",
      "Epoch 606/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4608 - accuracy: 0.7786 - auc: 0.8623 - val_loss: 1.3189 - val_accuracy: 0.3737 - val_auc: 0.1973\n",
      "Epoch 607/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4819 - accuracy: 0.7684 - auc: 0.8511 - val_loss: 1.0855 - val_accuracy: 0.4242 - val_auc: 0.4068\n",
      "Epoch 608/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.5132 - accuracy: 0.7634 - auc: 0.8309 - val_loss: 1.3041 - val_accuracy: 0.2626 - val_auc: 0.1141\n",
      "Epoch 609/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4534 - accuracy: 0.7837 - auc: 0.8675 - val_loss: 1.1715 - val_accuracy: 0.3939 - val_auc: 0.2546\n",
      "Epoch 610/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4634 - accuracy: 0.7761 - auc: 0.8617 - val_loss: 0.6094 - val_accuracy: 0.7071 - val_auc: 0.7333\n",
      "Epoch 611/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4801 - accuracy: 0.7863 - auc: 0.8583 - val_loss: 0.1780 - val_accuracy: 0.9798 - val_auc: 0.9945\n",
      "Epoch 612/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4918 - accuracy: 0.7812 - auc: 0.8471 - val_loss: 0.5772 - val_accuracy: 0.6364 - val_auc: 0.7468\n",
      "Epoch 613/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4658 - accuracy: 0.7939 - auc: 0.8637 - val_loss: 0.3671 - val_accuracy: 0.7677 - val_auc: 0.9248\n",
      "Epoch 614/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.5007 - accuracy: 0.7532 - auc: 0.8418 - val_loss: 0.0975 - val_accuracy: 1.0000 - val_auc: 0.9999\n",
      "Epoch 615/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.4615 - accuracy: 0.7863 - auc: 0.8596 - val_loss: 0.1233 - val_accuracy: 0.9899 - val_auc: 0.9999\n",
      "Epoch 616/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4830 - accuracy: 0.7786 - auc: 0.8520 - val_loss: 0.3596 - val_accuracy: 0.7879 - val_auc: 0.9271\n",
      "Epoch 617/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4569 - accuracy: 0.7863 - auc: 0.8638 - val_loss: 0.1876 - val_accuracy: 0.9293 - val_auc: 0.9943\n",
      "Epoch 618/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4605 - accuracy: 0.7990 - auc: 0.8679 - val_loss: 0.2394 - val_accuracy: 0.9293 - val_auc: 0.9895\n",
      "Epoch 619/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4829 - accuracy: 0.7583 - auc: 0.8450 - val_loss: 0.0737 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 620/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4560 - accuracy: 0.8066 - auc: 0.8712 - val_loss: 0.2086 - val_accuracy: 0.9091 - val_auc: 0.9864\n",
      "Epoch 621/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4662 - accuracy: 0.8041 - auc: 0.8639 - val_loss: 0.6864 - val_accuracy: 0.6263 - val_auc: 0.6263\n",
      "Epoch 622/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4933 - accuracy: 0.7583 - auc: 0.8401 - val_loss: 0.1994 - val_accuracy: 0.9192 - val_auc: 0.9935\n",
      "Epoch 623/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4648 - accuracy: 0.7913 - auc: 0.8664 - val_loss: 0.5870 - val_accuracy: 0.6263 - val_auc: 0.7529\n",
      "Epoch 624/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4745 - accuracy: 0.7684 - auc: 0.8520 - val_loss: 0.3332 - val_accuracy: 0.8990 - val_auc: 0.9678\n",
      "Epoch 625/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4594 - accuracy: 0.7812 - auc: 0.8624 - val_loss: 0.2375 - val_accuracy: 0.9091 - val_auc: 0.9846\n",
      "Epoch 626/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4549 - accuracy: 0.7990 - auc: 0.8679 - val_loss: 0.5159 - val_accuracy: 0.6869 - val_auc: 0.8265\n",
      "Epoch 627/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4415 - accuracy: 0.8015 - auc: 0.8781 - val_loss: 0.5471 - val_accuracy: 0.6768 - val_auc: 0.7979\n",
      "Epoch 628/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.4518 - accuracy: 0.7913 - auc: 0.8733 - val_loss: 0.4745 - val_accuracy: 0.7172 - val_auc: 0.8540\n",
      "Epoch 629/1000\n",
      "13/13 [==============================] - 1s 70ms/step - loss: 0.4611 - accuracy: 0.7888 - auc: 0.8610 - val_loss: 0.5423 - val_accuracy: 0.6566 - val_auc: 0.7952\n",
      "Epoch 630/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4771 - accuracy: 0.7761 - auc: 0.8554 - val_loss: 0.2259 - val_accuracy: 0.9798 - val_auc: 0.9933\n",
      "Epoch 631/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.4525 - accuracy: 0.7710 - auc: 0.8691 - val_loss: 0.4874 - val_accuracy: 0.7273 - val_auc: 0.8437\n",
      "Epoch 632/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.4684 - accuracy: 0.7684 - auc: 0.8602 - val_loss: 0.6078 - val_accuracy: 0.6869 - val_auc: 0.7311\n",
      "Epoch 633/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4684 - accuracy: 0.7608 - auc: 0.8547 - val_loss: 0.2700 - val_accuracy: 0.9596 - val_auc: 0.9895\n",
      "Epoch 634/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4694 - accuracy: 0.7634 - auc: 0.8570 - val_loss: 0.5901 - val_accuracy: 0.6162 - val_auc: 0.7516\n",
      "Epoch 635/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.4610 - accuracy: 0.7735 - auc: 0.8633 - val_loss: 0.7864 - val_accuracy: 0.6061 - val_auc: 0.5324\n",
      "Epoch 636/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4580 - accuracy: 0.8041 - auc: 0.8685 - val_loss: 0.5661 - val_accuracy: 0.7576 - val_auc: 0.7894\n",
      "Epoch 637/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4645 - accuracy: 0.7710 - auc: 0.8619 - val_loss: 0.9095 - val_accuracy: 0.4848 - val_auc: 0.4662\n",
      "Epoch 638/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4476 - accuracy: 0.8168 - auc: 0.8758 - val_loss: 0.4589 - val_accuracy: 0.7879 - val_auc: 0.8607\n",
      "Epoch 639/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4550 - accuracy: 0.7863 - auc: 0.8694 - val_loss: 0.7566 - val_accuracy: 0.5556 - val_auc: 0.6093\n",
      "Epoch 640/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4528 - accuracy: 0.7939 - auc: 0.8712 - val_loss: 1.2556 - val_accuracy: 0.3939 - val_auc: 0.2595\n",
      "Epoch 641/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4797 - accuracy: 0.7913 - auc: 0.8610 - val_loss: 0.5134 - val_accuracy: 0.7374 - val_auc: 0.8236\n",
      "Epoch 642/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4947 - accuracy: 0.7583 - auc: 0.8385 - val_loss: 0.9455 - val_accuracy: 0.4343 - val_auc: 0.3946\n",
      "Epoch 643/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.4546 - accuracy: 0.7863 - auc: 0.8664 - val_loss: 1.3204 - val_accuracy: 0.2626 - val_auc: 0.1800\n",
      "Epoch 644/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4656 - accuracy: 0.7888 - auc: 0.8627 - val_loss: 0.8194 - val_accuracy: 0.6364 - val_auc: 0.6674\n",
      "Epoch 645/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4836 - accuracy: 0.7761 - auc: 0.8518 - val_loss: 1.0624 - val_accuracy: 0.4242 - val_auc: 0.3859\n",
      "Epoch 646/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4776 - accuracy: 0.7888 - auc: 0.8580 - val_loss: 0.7751 - val_accuracy: 0.6061 - val_auc: 0.6447\n",
      "Epoch 647/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4774 - accuracy: 0.7888 - auc: 0.8515 - val_loss: 0.4231 - val_accuracy: 0.8485 - val_auc: 0.8907\n",
      "Epoch 648/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4795 - accuracy: 0.7964 - auc: 0.8585 - val_loss: 0.2141 - val_accuracy: 0.8990 - val_auc: 0.9800\n",
      "Epoch 649/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4730 - accuracy: 0.7863 - auc: 0.8548 - val_loss: 0.2931 - val_accuracy: 0.8990 - val_auc: 0.9730\n",
      "Epoch 650/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4487 - accuracy: 0.7990 - auc: 0.8727 - val_loss: 0.5368 - val_accuracy: 0.7273 - val_auc: 0.8042\n",
      "Epoch 651/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4395 - accuracy: 0.7964 - auc: 0.8765 - val_loss: 0.1250 - val_accuracy: 0.9798 - val_auc: 0.9987\n",
      "Epoch 652/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4782 - accuracy: 0.7557 - auc: 0.8493 - val_loss: 0.6001 - val_accuracy: 0.6263 - val_auc: 0.7416\n",
      "Epoch 653/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4608 - accuracy: 0.8015 - auc: 0.8702 - val_loss: 0.6595 - val_accuracy: 0.6263 - val_auc: 0.7075\n",
      "Epoch 654/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4963 - accuracy: 0.7557 - auc: 0.8450 - val_loss: 0.5014 - val_accuracy: 0.7879 - val_auc: 0.8470\n",
      "Epoch 655/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4739 - accuracy: 0.7608 - auc: 0.8531 - val_loss: 0.2600 - val_accuracy: 0.8990 - val_auc: 0.9752\n",
      "Epoch 656/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4904 - accuracy: 0.7837 - auc: 0.8593 - val_loss: 0.3358 - val_accuracy: 0.8384 - val_auc: 0.9282\n",
      "Epoch 657/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.5055 - accuracy: 0.7634 - auc: 0.8381 - val_loss: 0.5502 - val_accuracy: 0.7475 - val_auc: 0.8073\n",
      "Epoch 658/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4718 - accuracy: 0.7761 - auc: 0.8588 - val_loss: 0.3592 - val_accuracy: 0.8384 - val_auc: 0.9205\n",
      "Epoch 659/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4762 - accuracy: 0.7608 - auc: 0.8483 - val_loss: 0.9128 - val_accuracy: 0.5051 - val_auc: 0.5337\n",
      "Epoch 660/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4964 - accuracy: 0.7786 - auc: 0.8489 - val_loss: 0.5212 - val_accuracy: 0.6768 - val_auc: 0.8177\n",
      "Epoch 661/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4729 - accuracy: 0.7735 - auc: 0.8551 - val_loss: 0.3247 - val_accuracy: 0.8788 - val_auc: 0.9435\n",
      "Epoch 662/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4822 - accuracy: 0.7684 - auc: 0.8527 - val_loss: 0.4246 - val_accuracy: 0.7778 - val_auc: 0.8877\n",
      "Epoch 663/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4493 - accuracy: 0.7939 - auc: 0.8683 - val_loss: 0.5747 - val_accuracy: 0.6566 - val_auc: 0.7747\n",
      "Epoch 664/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4625 - accuracy: 0.7684 - auc: 0.8686 - val_loss: 0.8776 - val_accuracy: 0.5859 - val_auc: 0.5084\n",
      "Epoch 665/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4588 - accuracy: 0.7913 - auc: 0.8653 - val_loss: 0.9728 - val_accuracy: 0.4646 - val_auc: 0.3549\n",
      "Epoch 666/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4629 - accuracy: 0.7684 - auc: 0.8610 - val_loss: 1.0700 - val_accuracy: 0.4242 - val_auc: 0.3189\n",
      "Epoch 667/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4715 - accuracy: 0.7812 - auc: 0.8639 - val_loss: 0.5321 - val_accuracy: 0.6869 - val_auc: 0.8082\n",
      "Epoch 668/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4649 - accuracy: 0.7735 - auc: 0.8602 - val_loss: 1.3814 - val_accuracy: 0.2121 - val_auc: 0.1339\n",
      "Epoch 669/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.4659 - accuracy: 0.7964 - auc: 0.8615 - val_loss: 0.3476 - val_accuracy: 0.8889 - val_auc: 0.9372\n",
      "Epoch 670/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4797 - accuracy: 0.7761 - auc: 0.8567 - val_loss: 0.6158 - val_accuracy: 0.6667 - val_auc: 0.7249\n",
      "Epoch 671/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4769 - accuracy: 0.8066 - auc: 0.8611 - val_loss: 0.5211 - val_accuracy: 0.7778 - val_auc: 0.8190\n",
      "Epoch 672/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4590 - accuracy: 0.8066 - auc: 0.8667 - val_loss: 0.1762 - val_accuracy: 0.9798 - val_auc: 0.9935\n",
      "Epoch 673/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4877 - accuracy: 0.7761 - auc: 0.8474 - val_loss: 0.2742 - val_accuracy: 0.8990 - val_auc: 0.9564\n",
      "Epoch 674/1000\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.4868 - accuracy: 0.7990 - auc: 0.8513 - val_loss: 0.3102 - val_accuracy: 0.9091 - val_auc: 0.9528\n",
      "Epoch 675/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4490 - accuracy: 0.7863 - auc: 0.8723 - val_loss: 0.1945 - val_accuracy: 0.9293 - val_auc: 0.9936\n",
      "Epoch 676/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4756 - accuracy: 0.7735 - auc: 0.8492 - val_loss: 0.2989 - val_accuracy: 0.9091 - val_auc: 0.9599\n",
      "Epoch 677/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.4567 - accuracy: 0.7786 - auc: 0.8638 - val_loss: 0.6067 - val_accuracy: 0.6162 - val_auc: 0.7310\n",
      "Epoch 678/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.4575 - accuracy: 0.7786 - auc: 0.8693 - val_loss: 0.7202 - val_accuracy: 0.6566 - val_auc: 0.6551\n",
      "Epoch 679/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.4641 - accuracy: 0.7634 - auc: 0.8592 - val_loss: 0.6354 - val_accuracy: 0.6768 - val_auc: 0.7057\n",
      "Epoch 680/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4573 - accuracy: 0.7990 - auc: 0.8674 - val_loss: 0.7650 - val_accuracy: 0.5556 - val_auc: 0.6043\n",
      "Epoch 681/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4777 - accuracy: 0.7735 - auc: 0.8553 - val_loss: 0.9874 - val_accuracy: 0.4646 - val_auc: 0.4042\n",
      "Epoch 682/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.4559 - accuracy: 0.8015 - auc: 0.8761 - val_loss: 0.7277 - val_accuracy: 0.5657 - val_auc: 0.6309\n",
      "Epoch 683/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4987 - accuracy: 0.7684 - auc: 0.8411 - val_loss: 0.7569 - val_accuracy: 0.5253 - val_auc: 0.6063\n",
      "Epoch 684/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4766 - accuracy: 0.7786 - auc: 0.8575 - val_loss: 1.1714 - val_accuracy: 0.3737 - val_auc: 0.2278\n",
      "Epoch 685/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4496 - accuracy: 0.8015 - auc: 0.8741 - val_loss: 0.7065 - val_accuracy: 0.5960 - val_auc: 0.6717\n",
      "Epoch 686/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4554 - accuracy: 0.8015 - auc: 0.8682 - val_loss: 0.8618 - val_accuracy: 0.5455 - val_auc: 0.5341\n",
      "Epoch 687/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4772 - accuracy: 0.7659 - auc: 0.8528 - val_loss: 0.4681 - val_accuracy: 0.7475 - val_auc: 0.8621\n",
      "Epoch 688/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4964 - accuracy: 0.7506 - auc: 0.8380 - val_loss: 0.5810 - val_accuracy: 0.6465 - val_auc: 0.7605\n",
      "Epoch 689/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4677 - accuracy: 0.7888 - auc: 0.8586 - val_loss: 0.7201 - val_accuracy: 0.6162 - val_auc: 0.6337\n",
      "Epoch 690/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.5029 - accuracy: 0.7557 - auc: 0.8386 - val_loss: 1.9680 - val_accuracy: 0.0303 - val_auc: 0.0484\n",
      "Epoch 691/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4951 - accuracy: 0.7481 - auc: 0.8397 - val_loss: 0.8136 - val_accuracy: 0.5960 - val_auc: 0.5538\n",
      "Epoch 692/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 53ms/step - loss: 0.4711 - accuracy: 0.7812 - auc: 0.8621 - val_loss: 0.5516 - val_accuracy: 0.6970 - val_auc: 0.8016\n",
      "Epoch 693/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4615 - accuracy: 0.7964 - auc: 0.8633 - val_loss: 0.4429 - val_accuracy: 0.7980 - val_auc: 0.8845\n",
      "Epoch 694/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4675 - accuracy: 0.7557 - auc: 0.8567 - val_loss: 0.5750 - val_accuracy: 0.6768 - val_auc: 0.7681\n",
      "Epoch 695/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.5098 - accuracy: 0.7532 - auc: 0.8304 - val_loss: 0.8626 - val_accuracy: 0.5253 - val_auc: 0.4743\n",
      "Epoch 696/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4959 - accuracy: 0.7710 - auc: 0.8464 - val_loss: 0.4766 - val_accuracy: 0.8081 - val_auc: 0.8636\n",
      "Epoch 697/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4717 - accuracy: 0.7659 - auc: 0.8570 - val_loss: 0.1434 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 698/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4597 - accuracy: 0.7761 - auc: 0.8646 - val_loss: 0.1133 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 699/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4695 - accuracy: 0.7863 - auc: 0.8551 - val_loss: 0.2343 - val_accuracy: 0.9798 - val_auc: 0.9971\n",
      "Epoch 700/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.4435 - accuracy: 0.7812 - auc: 0.8772 - val_loss: 0.4313 - val_accuracy: 0.7980 - val_auc: 0.8926\n",
      "Epoch 701/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4617 - accuracy: 0.7659 - auc: 0.8616 - val_loss: 0.3324 - val_accuracy: 0.8586 - val_auc: 0.9536\n",
      "Epoch 702/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4474 - accuracy: 0.7964 - auc: 0.8736 - val_loss: 0.4241 - val_accuracy: 0.8182 - val_auc: 0.8957\n",
      "Epoch 703/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4380 - accuracy: 0.8015 - auc: 0.8806 - val_loss: 0.4117 - val_accuracy: 0.7677 - val_auc: 0.9007\n",
      "Epoch 704/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.4668 - accuracy: 0.7761 - auc: 0.8602 - val_loss: 0.2587 - val_accuracy: 0.9192 - val_auc: 0.9860\n",
      "Epoch 705/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4769 - accuracy: 0.7583 - auc: 0.8509 - val_loss: 0.4980 - val_accuracy: 0.7071 - val_auc: 0.8293\n",
      "Epoch 706/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4585 - accuracy: 0.8015 - auc: 0.8667 - val_loss: 0.4061 - val_accuracy: 0.8586 - val_auc: 0.8995\n",
      "Epoch 707/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4459 - accuracy: 0.8142 - auc: 0.8762 - val_loss: 0.5455 - val_accuracy: 0.7778 - val_auc: 0.8147\n",
      "Epoch 708/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4528 - accuracy: 0.7990 - auc: 0.8729 - val_loss: 0.6902 - val_accuracy: 0.6061 - val_auc: 0.6675\n",
      "Epoch 709/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4620 - accuracy: 0.7888 - auc: 0.8669 - val_loss: 0.4867 - val_accuracy: 0.7980 - val_auc: 0.8414\n",
      "Epoch 710/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4715 - accuracy: 0.7837 - auc: 0.8600 - val_loss: 0.7841 - val_accuracy: 0.5051 - val_auc: 0.5444\n",
      "Epoch 711/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4587 - accuracy: 0.7888 - auc: 0.8635 - val_loss: 0.2407 - val_accuracy: 0.9091 - val_auc: 0.9767\n",
      "Epoch 712/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4945 - accuracy: 0.7837 - auc: 0.8459 - val_loss: 0.8433 - val_accuracy: 0.5051 - val_auc: 0.4971\n",
      "Epoch 713/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4787 - accuracy: 0.7786 - auc: 0.8531 - val_loss: 0.4620 - val_accuracy: 0.7374 - val_auc: 0.8749\n",
      "Epoch 714/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4665 - accuracy: 0.7786 - auc: 0.8576 - val_loss: 0.4082 - val_accuracy: 0.8283 - val_auc: 0.9052\n",
      "Epoch 715/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4427 - accuracy: 0.8041 - auc: 0.8737 - val_loss: 0.5412 - val_accuracy: 0.6869 - val_auc: 0.8047\n",
      "Epoch 716/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.4344 - accuracy: 0.8066 - auc: 0.8821 - val_loss: 0.9256 - val_accuracy: 0.4747 - val_auc: 0.4875\n",
      "Epoch 717/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.4703 - accuracy: 0.7913 - auc: 0.8652 - val_loss: 0.5518 - val_accuracy: 0.7071 - val_auc: 0.7838\n",
      "Epoch 718/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4470 - accuracy: 0.7913 - auc: 0.8761 - val_loss: 0.4729 - val_accuracy: 0.7677 - val_auc: 0.8619\n",
      "Epoch 719/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4529 - accuracy: 0.7939 - auc: 0.8706 - val_loss: 0.7035 - val_accuracy: 0.6566 - val_auc: 0.6317\n",
      "Epoch 720/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4808 - accuracy: 0.7634 - auc: 0.8497 - val_loss: 0.3462 - val_accuracy: 0.8485 - val_auc: 0.9492\n",
      "Epoch 721/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4564 - accuracy: 0.8142 - auc: 0.8699 - val_loss: 0.4074 - val_accuracy: 0.8586 - val_auc: 0.9071\n",
      "Epoch 722/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4601 - accuracy: 0.7786 - auc: 0.8635 - val_loss: 0.1440 - val_accuracy: 0.9899 - val_auc: 0.9995\n",
      "Epoch 723/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4658 - accuracy: 0.7583 - auc: 0.8616 - val_loss: 0.3749 - val_accuracy: 0.8889 - val_auc: 0.9265\n",
      "Epoch 724/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4459 - accuracy: 0.8066 - auc: 0.8777 - val_loss: 0.2237 - val_accuracy: 0.8990 - val_auc: 0.9840\n",
      "Epoch 725/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.4671 - accuracy: 0.7659 - auc: 0.8579 - val_loss: 0.5168 - val_accuracy: 0.7172 - val_auc: 0.8297\n",
      "Epoch 726/1000\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 0.4544 - accuracy: 0.8041 - auc: 0.8671 - val_loss: 0.4582 - val_accuracy: 0.7273 - val_auc: 0.8645\n",
      "Epoch 727/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4509 - accuracy: 0.7964 - auc: 0.8738 - val_loss: 0.6566 - val_accuracy: 0.6162 - val_auc: 0.6913\n",
      "Epoch 728/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4891 - accuracy: 0.7659 - auc: 0.8481 - val_loss: 0.5220 - val_accuracy: 0.6869 - val_auc: 0.8267\n",
      "Epoch 729/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4859 - accuracy: 0.7583 - auc: 0.8524 - val_loss: 0.7191 - val_accuracy: 0.5859 - val_auc: 0.6490\n",
      "Epoch 730/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.5477 - accuracy: 0.7379 - auc: 0.8079 - val_loss: 0.3990 - val_accuracy: 0.8889 - val_auc: 0.9637\n",
      "Epoch 731/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.5251 - accuracy: 0.7099 - auc: 0.8103 - val_loss: 0.0861 - val_accuracy: 0.9899 - val_auc: 0.9995\n",
      "Epoch 732/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4911 - accuracy: 0.7659 - auc: 0.8480 - val_loss: 0.4383 - val_accuracy: 0.7980 - val_auc: 0.8834\n",
      "Epoch 733/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.4589 - accuracy: 0.7913 - auc: 0.8664 - val_loss: 0.1950 - val_accuracy: 0.9192 - val_auc: 0.9898\n",
      "Epoch 734/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.4771 - accuracy: 0.7863 - auc: 0.8586 - val_loss: 0.2175 - val_accuracy: 0.9293 - val_auc: 0.9917\n",
      "Epoch 735/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4908 - accuracy: 0.7812 - auc: 0.8498 - val_loss: 0.2481 - val_accuracy: 0.9394 - val_auc: 0.9942\n",
      "Epoch 736/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4771 - accuracy: 0.7964 - auc: 0.8613 - val_loss: 0.3394 - val_accuracy: 0.8384 - val_auc: 0.9437\n",
      "Epoch 737/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4588 - accuracy: 0.7583 - auc: 0.8622 - val_loss: 0.1228 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 738/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 67ms/step - loss: 0.4569 - accuracy: 0.8117 - auc: 0.8730 - val_loss: 0.1465 - val_accuracy: 0.9899 - val_auc: 0.9997\n",
      "Epoch 739/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4548 - accuracy: 0.7863 - auc: 0.8673 - val_loss: 0.1335 - val_accuracy: 0.9596 - val_auc: 0.9946\n",
      "Epoch 740/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.5168 - accuracy: 0.7608 - auc: 0.8399 - val_loss: 0.9549 - val_accuracy: 0.4141 - val_auc: 0.3710\n",
      "Epoch 741/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.5172 - accuracy: 0.7430 - auc: 0.8241 - val_loss: 0.7570 - val_accuracy: 0.5556 - val_auc: 0.5837\n",
      "Epoch 742/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4700 - accuracy: 0.7990 - auc: 0.8600 - val_loss: 0.1392 - val_accuracy: 0.9899 - val_auc: 0.9999\n",
      "Epoch 743/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4687 - accuracy: 0.7786 - auc: 0.8611 - val_loss: 0.1961 - val_accuracy: 0.9192 - val_auc: 0.9897\n",
      "Epoch 744/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4604 - accuracy: 0.7939 - auc: 0.8635 - val_loss: 0.2152 - val_accuracy: 0.9293 - val_auc: 0.9846\n",
      "Epoch 745/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4611 - accuracy: 0.7837 - auc: 0.8690 - val_loss: 0.5666 - val_accuracy: 0.6566 - val_auc: 0.7719\n",
      "Epoch 746/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.4679 - accuracy: 0.7735 - auc: 0.8572 - val_loss: 0.4999 - val_accuracy: 0.7778 - val_auc: 0.8362\n",
      "Epoch 747/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4656 - accuracy: 0.7888 - auc: 0.8584 - val_loss: 1.1524 - val_accuracy: 0.1616 - val_auc: 0.2088\n",
      "Epoch 748/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.5020 - accuracy: 0.7735 - auc: 0.8388 - val_loss: 0.3128 - val_accuracy: 0.9091 - val_auc: 0.9845\n",
      "Epoch 749/1000\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.4544 - accuracy: 0.7913 - auc: 0.8686 - val_loss: 0.2786 - val_accuracy: 0.9091 - val_auc: 0.9731\n",
      "Epoch 750/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4657 - accuracy: 0.7837 - auc: 0.8601 - val_loss: 0.2553 - val_accuracy: 0.9192 - val_auc: 0.9848\n",
      "Epoch 751/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.4428 - accuracy: 0.8295 - auc: 0.8793 - val_loss: 0.7205 - val_accuracy: 0.5859 - val_auc: 0.6407\n",
      "Epoch 752/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4579 - accuracy: 0.7761 - auc: 0.8655 - val_loss: 0.4150 - val_accuracy: 0.8485 - val_auc: 0.8979\n",
      "Epoch 753/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4591 - accuracy: 0.7990 - auc: 0.8683 - val_loss: 1.4974 - val_accuracy: 0.1515 - val_auc: 0.1425\n",
      "Epoch 754/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4848 - accuracy: 0.7634 - auc: 0.8458 - val_loss: 0.7351 - val_accuracy: 0.6162 - val_auc: 0.5634\n",
      "Epoch 755/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4441 - accuracy: 0.8066 - auc: 0.8760 - val_loss: 0.4111 - val_accuracy: 0.8384 - val_auc: 0.9031\n",
      "Epoch 756/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4528 - accuracy: 0.8015 - auc: 0.8732 - val_loss: 0.8824 - val_accuracy: 0.5152 - val_auc: 0.4876\n",
      "Epoch 757/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4751 - accuracy: 0.7837 - auc: 0.8559 - val_loss: 0.8478 - val_accuracy: 0.5657 - val_auc: 0.4983\n",
      "Epoch 758/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4882 - accuracy: 0.7761 - auc: 0.8507 - val_loss: 1.4285 - val_accuracy: 0.2929 - val_auc: 0.1285\n",
      "Epoch 759/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4587 - accuracy: 0.8193 - auc: 0.8669 - val_loss: 0.8557 - val_accuracy: 0.5354 - val_auc: 0.4963\n",
      "Epoch 760/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4736 - accuracy: 0.7939 - auc: 0.8553 - val_loss: 0.4188 - val_accuracy: 0.8384 - val_auc: 0.9079\n",
      "Epoch 761/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4392 - accuracy: 0.7863 - auc: 0.8798 - val_loss: 0.3351 - val_accuracy: 0.8788 - val_auc: 0.9311\n",
      "Epoch 762/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4364 - accuracy: 0.8041 - auc: 0.8795 - val_loss: 0.4245 - val_accuracy: 0.8182 - val_auc: 0.8864\n",
      "Epoch 763/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4525 - accuracy: 0.7761 - auc: 0.8695 - val_loss: 0.5694 - val_accuracy: 0.6869 - val_auc: 0.7793\n",
      "Epoch 764/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4406 - accuracy: 0.8015 - auc: 0.8745 - val_loss: 0.2317 - val_accuracy: 0.9192 - val_auc: 0.9798\n",
      "Epoch 765/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4741 - accuracy: 0.7863 - auc: 0.8589 - val_loss: 1.0158 - val_accuracy: 0.3939 - val_auc: 0.3291\n",
      "Epoch 766/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4496 - accuracy: 0.7837 - auc: 0.8712 - val_loss: 0.8470 - val_accuracy: 0.4646 - val_auc: 0.4962\n",
      "Epoch 767/1000\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.4491 - accuracy: 0.7888 - auc: 0.8720 - val_loss: 0.6611 - val_accuracy: 0.6566 - val_auc: 0.6776\n",
      "Epoch 768/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.4954 - accuracy: 0.7684 - auc: 0.8451 - val_loss: 0.3596 - val_accuracy: 0.8788 - val_auc: 0.9437\n",
      "Epoch 769/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4400 - accuracy: 0.7812 - auc: 0.8770 - val_loss: 0.3966 - val_accuracy: 0.8687 - val_auc: 0.9180\n",
      "Epoch 770/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4843 - accuracy: 0.7710 - auc: 0.8514 - val_loss: 0.4780 - val_accuracy: 0.7273 - val_auc: 0.8657\n",
      "Epoch 771/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4401 - accuracy: 0.7786 - auc: 0.8809 - val_loss: 0.3948 - val_accuracy: 0.8485 - val_auc: 0.9247\n",
      "Epoch 772/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.4442 - accuracy: 0.7837 - auc: 0.8724 - val_loss: 0.1857 - val_accuracy: 0.9293 - val_auc: 0.9921\n",
      "Epoch 773/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.4547 - accuracy: 0.7863 - auc: 0.8681 - val_loss: 0.5359 - val_accuracy: 0.7172 - val_auc: 0.8135\n",
      "Epoch 774/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.4515 - accuracy: 0.7964 - auc: 0.8727 - val_loss: 1.1657 - val_accuracy: 0.3434 - val_auc: 0.2395\n",
      "Epoch 775/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4573 - accuracy: 0.7812 - auc: 0.8694 - val_loss: 0.3915 - val_accuracy: 0.8384 - val_auc: 0.9148\n",
      "Epoch 776/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4557 - accuracy: 0.7913 - auc: 0.8719 - val_loss: 0.6005 - val_accuracy: 0.6364 - val_auc: 0.7515\n",
      "Epoch 777/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4434 - accuracy: 0.7913 - auc: 0.8722 - val_loss: 0.9853 - val_accuracy: 0.4242 - val_auc: 0.3610\n",
      "Epoch 778/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4501 - accuracy: 0.7990 - auc: 0.8727 - val_loss: 1.0104 - val_accuracy: 0.4848 - val_auc: 0.3924\n",
      "Epoch 779/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4533 - accuracy: 0.7939 - auc: 0.8717 - val_loss: 1.6532 - val_accuracy: 0.1313 - val_auc: 0.0963\n",
      "Epoch 780/1000\n",
      "13/13 [==============================] - 1s 72ms/step - loss: 0.4762 - accuracy: 0.7913 - auc: 0.8585 - val_loss: 0.2109 - val_accuracy: 0.9394 - val_auc: 0.9936\n",
      "Epoch 781/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.4543 - accuracy: 0.7865 - auc: 0.86 - 1s 56ms/step - loss: 0.4485 - accuracy: 0.7888 - auc: 0.8728 - val_loss: 0.1286 - val_accuracy: 0.9899 - val_auc: 0.9985\n",
      "Epoch 782/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4640 - accuracy: 0.7812 - auc: 0.8643 - val_loss: 0.7173 - val_accuracy: 0.6162 - val_auc: 0.6662\n",
      "Epoch 783/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4265 - accuracy: 0.8092 - auc: 0.8846 - val_loss: 0.3376 - val_accuracy: 0.8889 - val_auc: 0.9418\n",
      "Epoch 784/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4680 - accuracy: 0.8015 - auc: 0.8627 - val_loss: 1.1027 - val_accuracy: 0.3737 - val_auc: 0.2484\n",
      "Epoch 785/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.5037 - accuracy: 0.7684 - auc: 0.8356 - val_loss: 1.4526 - val_accuracy: 0.3434 - val_auc: 0.1821\n",
      "Epoch 786/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4766 - accuracy: 0.7837 - auc: 0.8531 - val_loss: 0.9605 - val_accuracy: 0.5152 - val_auc: 0.5665\n",
      "Epoch 787/1000\n",
      "13/13 [==============================] - 1s 70ms/step - loss: 0.4935 - accuracy: 0.7735 - auc: 0.8505 - val_loss: 0.2438 - val_accuracy: 0.9091 - val_auc: 0.9806\n",
      "Epoch 788/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.4835 - accuracy: 0.7913 - auc: 0.8544 - val_loss: 0.4163 - val_accuracy: 0.7475 - val_auc: 0.9025\n",
      "Epoch 789/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4514 - accuracy: 0.7863 - auc: 0.8699 - val_loss: 0.2562 - val_accuracy: 0.9091 - val_auc: 0.9694\n",
      "Epoch 790/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.5193 - accuracy: 0.7659 - auc: 0.8410 - val_loss: 0.2575 - val_accuracy: 0.9091 - val_auc: 0.9893\n",
      "Epoch 791/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4769 - accuracy: 0.7863 - auc: 0.8612 - val_loss: 0.1519 - val_accuracy: 0.9596 - val_auc: 0.9984\n",
      "Epoch 792/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4434 - accuracy: 0.8142 - auc: 0.8782 - val_loss: 0.5103 - val_accuracy: 0.7172 - val_auc: 0.8341\n",
      "Epoch 793/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4808 - accuracy: 0.7761 - auc: 0.8574 - val_loss: 1.3009 - val_accuracy: 0.3838 - val_auc: 0.2500\n",
      "Epoch 794/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4609 - accuracy: 0.7939 - auc: 0.8713 - val_loss: 0.8605 - val_accuracy: 0.4646 - val_auc: 0.4922\n",
      "Epoch 795/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4631 - accuracy: 0.7761 - auc: 0.8626 - val_loss: 0.6283 - val_accuracy: 0.6970 - val_auc: 0.7149\n",
      "Epoch 796/1000\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.4475 - accuracy: 0.7990 - auc: 0.8727 - val_loss: 0.5681 - val_accuracy: 0.7374 - val_auc: 0.7848\n",
      "Epoch 797/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.4546 - accuracy: 0.7964 - auc: 0.8675 - val_loss: 0.8574 - val_accuracy: 0.5354 - val_auc: 0.5212\n",
      "Epoch 798/1000\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.4671 - accuracy: 0.7863 - auc: 0.8586 - val_loss: 0.3961 - val_accuracy: 0.8586 - val_auc: 0.9050\n",
      "Epoch 799/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4799 - accuracy: 0.7557 - auc: 0.8496 - val_loss: 0.4619 - val_accuracy: 0.7273 - val_auc: 0.8803\n",
      "Epoch 800/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4313 - accuracy: 0.7964 - auc: 0.8852 - val_loss: 0.1817 - val_accuracy: 0.9697 - val_auc: 0.9967\n",
      "Epoch 801/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4764 - accuracy: 0.7786 - auc: 0.8590 - val_loss: 0.5507 - val_accuracy: 0.7071 - val_auc: 0.7949\n",
      "Epoch 802/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.4633 - accuracy: 0.7863 - auc: 0.8641 - val_loss: 0.5151 - val_accuracy: 0.7576 - val_auc: 0.8286\n",
      "Epoch 803/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4793 - accuracy: 0.7863 - auc: 0.8505 - val_loss: 1.0766 - val_accuracy: 0.3838 - val_auc: 0.2636\n",
      "Epoch 804/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4345 - accuracy: 0.8092 - auc: 0.8799 - val_loss: 0.2290 - val_accuracy: 0.9091 - val_auc: 0.9815\n",
      "Epoch 805/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.5196 - accuracy: 0.7506 - auc: 0.8304 - val_loss: 0.5402 - val_accuracy: 0.6970 - val_auc: 0.8081\n",
      "Epoch 806/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4494 - accuracy: 0.7939 - auc: 0.8703 - val_loss: 1.3869 - val_accuracy: 0.3535 - val_auc: 0.1995\n",
      "Epoch 807/1000\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.4566 - accuracy: 0.7964 - auc: 0.8709 - val_loss: 1.0621 - val_accuracy: 0.4242 - val_auc: 0.3291\n",
      "Epoch 808/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4611 - accuracy: 0.7990 - auc: 0.8657 - val_loss: 0.6057 - val_accuracy: 0.6768 - val_auc: 0.7378\n",
      "Epoch 809/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4781 - accuracy: 0.8066 - auc: 0.8585 - val_loss: 0.5054 - val_accuracy: 0.7172 - val_auc: 0.8350\n",
      "Epoch 810/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4701 - accuracy: 0.7837 - auc: 0.8590 - val_loss: 0.4705 - val_accuracy: 0.7172 - val_auc: 0.8615\n",
      "Epoch 811/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.4514 - accuracy: 0.7735 - auc: 0.8685 - val_loss: 0.3227 - val_accuracy: 0.8788 - val_auc: 0.9431\n",
      "Epoch 812/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4625 - accuracy: 0.8168 - auc: 0.8695 - val_loss: 0.3469 - val_accuracy: 0.8283 - val_auc: 0.9381\n",
      "Epoch 813/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.4730 - accuracy: 0.7532 - auc: 0.8557 - val_loss: 0.6859 - val_accuracy: 0.6566 - val_auc: 0.6163\n",
      "Epoch 814/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4657 - accuracy: 0.7863 - auc: 0.8622 - val_loss: 0.1765 - val_accuracy: 0.9798 - val_auc: 0.9957\n",
      "Epoch 815/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4586 - accuracy: 0.8041 - auc: 0.8691 - val_loss: 0.4763 - val_accuracy: 0.7172 - val_auc: 0.8517\n",
      "Epoch 816/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4461 - accuracy: 0.7964 - auc: 0.8759 - val_loss: 0.3576 - val_accuracy: 0.8586 - val_auc: 0.9363\n",
      "Epoch 817/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4511 - accuracy: 0.7710 - auc: 0.8712 - val_loss: 0.3027 - val_accuracy: 0.8990 - val_auc: 0.9765\n",
      "Epoch 818/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4666 - accuracy: 0.7786 - auc: 0.8641 - val_loss: 0.1557 - val_accuracy: 0.9798 - val_auc: 0.9973\n",
      "Epoch 819/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4751 - accuracy: 0.7964 - auc: 0.8634 - val_loss: 0.2218 - val_accuracy: 0.9192 - val_auc: 0.9838\n",
      "Epoch 820/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4657 - accuracy: 0.7481 - auc: 0.8569 - val_loss: 0.4779 - val_accuracy: 0.7677 - val_auc: 0.8514\n",
      "Epoch 821/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4366 - accuracy: 0.7888 - auc: 0.8776 - val_loss: 0.7756 - val_accuracy: 0.5556 - val_auc: 0.5828\n",
      "Epoch 822/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4398 - accuracy: 0.8066 - auc: 0.8823 - val_loss: 0.6086 - val_accuracy: 0.6768 - val_auc: 0.7447\n",
      "Epoch 823/1000\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.4368 - accuracy: 0.7939 - auc: 0.8784 - val_loss: 0.5240 - val_accuracy: 0.7273 - val_auc: 0.8138\n",
      "Epoch 824/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4429 - accuracy: 0.8015 - auc: 0.8760 - val_loss: 0.8935 - val_accuracy: 0.5051 - val_auc: 0.4639\n",
      "Epoch 825/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4583 - accuracy: 0.8092 - auc: 0.8669 - val_loss: 1.1144 - val_accuracy: 0.3939 - val_auc: 0.2778\n",
      "Epoch 826/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4489 - accuracy: 0.7786 - auc: 0.8719 - val_loss: 0.6599 - val_accuracy: 0.5960 - val_auc: 0.6984\n",
      "Epoch 827/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4725 - accuracy: 0.7888 - auc: 0.8606 - val_loss: 0.6248 - val_accuracy: 0.6263 - val_auc: 0.7287\n",
      "Epoch 828/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4483 - accuracy: 0.7863 - auc: 0.8759 - val_loss: 0.5057 - val_accuracy: 0.7071 - val_auc: 0.8403\n",
      "Epoch 829/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4755 - accuracy: 0.7735 - auc: 0.8551 - val_loss: 0.6437 - val_accuracy: 0.6364 - val_auc: 0.6962\n",
      "Epoch 830/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 60ms/step - loss: 0.5200 - accuracy: 0.7506 - auc: 0.8182 - val_loss: 0.5618 - val_accuracy: 0.6768 - val_auc: 0.7806\n",
      "Epoch 831/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.4527 - accuracy: 0.7913 - auc: 0.8723 - val_loss: 0.8165 - val_accuracy: 0.6162 - val_auc: 0.5448\n",
      "Epoch 832/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.4468 - accuracy: 0.8041 - auc: 0.8776 - val_loss: 0.5445 - val_accuracy: 0.7071 - val_auc: 0.8028\n",
      "Epoch 833/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.4591 - accuracy: 0.7786 - auc: 0.8670 - val_loss: 0.7249 - val_accuracy: 0.6566 - val_auc: 0.6058\n",
      "Epoch 834/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4795 - accuracy: 0.7684 - auc: 0.8490 - val_loss: 0.3428 - val_accuracy: 0.8990 - val_auc: 0.9401\n",
      "Epoch 835/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4553 - accuracy: 0.8015 - auc: 0.8701 - val_loss: 0.8105 - val_accuracy: 0.4949 - val_auc: 0.5190\n",
      "Epoch 836/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4620 - accuracy: 0.7837 - auc: 0.8646 - val_loss: 1.1691 - val_accuracy: 0.3838 - val_auc: 0.2575\n",
      "Epoch 837/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.4395 - accuracy: 0.8041 - auc: 0.8791 - val_loss: 0.7555 - val_accuracy: 0.5758 - val_auc: 0.5911\n",
      "Epoch 838/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4639 - accuracy: 0.7863 - auc: 0.8608 - val_loss: 0.5713 - val_accuracy: 0.7071 - val_auc: 0.7757\n",
      "Epoch 839/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4512 - accuracy: 0.7939 - auc: 0.8721 - val_loss: 0.8927 - val_accuracy: 0.5253 - val_auc: 0.4743\n",
      "Epoch 840/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.4666 - accuracy: 0.7786 - auc: 0.8597 - val_loss: 0.7665 - val_accuracy: 0.5152 - val_auc: 0.5993\n",
      "Epoch 841/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4586 - accuracy: 0.7888 - auc: 0.8644 - val_loss: 1.1482 - val_accuracy: 0.4040 - val_auc: 0.2524\n",
      "Epoch 842/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4432 - accuracy: 0.8041 - auc: 0.8748 - val_loss: 0.7590 - val_accuracy: 0.5960 - val_auc: 0.6099\n",
      "Epoch 843/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.4565 - accuracy: 0.7891 - auc: 0.86 - 1s 59ms/step - loss: 0.4534 - accuracy: 0.7939 - auc: 0.8689 - val_loss: 0.2858 - val_accuracy: 0.8889 - val_auc: 0.9668\n",
      "Epoch 844/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4576 - accuracy: 0.7863 - auc: 0.8695 - val_loss: 0.4716 - val_accuracy: 0.7778 - val_auc: 0.8576\n",
      "Epoch 845/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4589 - accuracy: 0.7837 - auc: 0.8666 - val_loss: 0.5047 - val_accuracy: 0.7273 - val_auc: 0.8474\n",
      "Epoch 846/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4525 - accuracy: 0.7888 - auc: 0.8720 - val_loss: 0.4367 - val_accuracy: 0.8182 - val_auc: 0.8844\n",
      "Epoch 847/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4516 - accuracy: 0.7939 - auc: 0.8717 - val_loss: 0.6464 - val_accuracy: 0.6667 - val_auc: 0.6797\n",
      "Epoch 848/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.4670 - accuracy: 0.7913 - auc: 0.8583 - val_loss: 0.2099 - val_accuracy: 0.9394 - val_auc: 0.9905\n",
      "Epoch 849/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4492 - accuracy: 0.7888 - auc: 0.8758 - val_loss: 0.3509 - val_accuracy: 0.8687 - val_auc: 0.9441\n",
      "Epoch 850/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4335 - accuracy: 0.8193 - auc: 0.8848 - val_loss: 0.5232 - val_accuracy: 0.7071 - val_auc: 0.8227\n",
      "Epoch 851/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4393 - accuracy: 0.7837 - auc: 0.8777 - val_loss: 0.4021 - val_accuracy: 0.8384 - val_auc: 0.8964\n",
      "Epoch 852/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4494 - accuracy: 0.7888 - auc: 0.8716 - val_loss: 0.3205 - val_accuracy: 0.8788 - val_auc: 0.9442\n",
      "Epoch 853/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4733 - accuracy: 0.7786 - auc: 0.8613 - val_loss: 0.7286 - val_accuracy: 0.6061 - val_auc: 0.6370\n",
      "Epoch 854/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.4461 - accuracy: 0.7990 - auc: 0.8716 - val_loss: 1.8681 - val_accuracy: 0.0303 - val_auc: 0.0286\n",
      "Epoch 855/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4536 - accuracy: 0.8117 - auc: 0.8706 - val_loss: 0.6391 - val_accuracy: 0.6465 - val_auc: 0.7295\n",
      "Epoch 856/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4815 - accuracy: 0.7710 - auc: 0.8518 - val_loss: 0.3507 - val_accuracy: 0.8586 - val_auc: 0.9426\n",
      "Epoch 857/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4596 - accuracy: 0.7964 - auc: 0.8649 - val_loss: 0.1341 - val_accuracy: 0.9899 - val_auc: 0.9994\n",
      "Epoch 858/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4690 - accuracy: 0.7888 - auc: 0.8618 - val_loss: 0.1856 - val_accuracy: 0.9192 - val_auc: 0.9839\n",
      "Epoch 859/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.5008 - accuracy: 0.7812 - auc: 0.8541 - val_loss: 0.1671 - val_accuracy: 0.9899 - val_auc: 0.9968\n",
      "Epoch 860/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4647 - accuracy: 0.7964 - auc: 0.8652 - val_loss: 0.0785 - val_accuracy: 1.0000 - val_auc: 1.0000\n",
      "Epoch 861/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4675 - accuracy: 0.7405 - auc: 0.8517 - val_loss: 0.2617 - val_accuracy: 0.9192 - val_auc: 0.9748\n",
      "Epoch 862/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4655 - accuracy: 0.7888 - auc: 0.8629 - val_loss: 0.3714 - val_accuracy: 0.8182 - val_auc: 0.9230\n",
      "Epoch 863/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4364 - accuracy: 0.7863 - auc: 0.8785 - val_loss: 0.1976 - val_accuracy: 0.9293 - val_auc: 0.9900\n",
      "Epoch 864/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4373 - accuracy: 0.7913 - auc: 0.8759 - val_loss: 0.6989 - val_accuracy: 0.6667 - val_auc: 0.6590\n",
      "Epoch 865/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4823 - accuracy: 0.7659 - auc: 0.8578 - val_loss: 0.3505 - val_accuracy: 0.8485 - val_auc: 0.9369\n",
      "Epoch 866/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4645 - accuracy: 0.7837 - auc: 0.8635 - val_loss: 0.8526 - val_accuracy: 0.4545 - val_auc: 0.4777\n",
      "Epoch 867/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4609 - accuracy: 0.7812 - auc: 0.8621 - val_loss: 0.6460 - val_accuracy: 0.6667 - val_auc: 0.7063\n",
      "Epoch 868/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.5083 - accuracy: 0.7481 - auc: 0.8313 - val_loss: 0.5986 - val_accuracy: 0.6667 - val_auc: 0.7387\n",
      "Epoch 869/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4580 - accuracy: 0.8015 - auc: 0.8667 - val_loss: 0.1324 - val_accuracy: 0.9798 - val_auc: 0.9972\n",
      "Epoch 870/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.4674 - accuracy: 0.7964 - auc: 0.8663 - val_loss: 0.7296 - val_accuracy: 0.5657 - val_auc: 0.6483\n",
      "Epoch 871/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4306 - accuracy: 0.8117 - auc: 0.8840 - val_loss: 0.4835 - val_accuracy: 0.7374 - val_auc: 0.8480\n",
      "Epoch 872/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4248 - accuracy: 0.8142 - auc: 0.8876 - val_loss: 1.6838 - val_accuracy: 0.1818 - val_auc: 0.1146\n",
      "Epoch 873/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4857 - accuracy: 0.7761 - auc: 0.8525 - val_loss: 0.4165 - val_accuracy: 0.8283 - val_auc: 0.8883\n",
      "Epoch 874/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4521 - accuracy: 0.7888 - auc: 0.8700 - val_loss: 0.7267 - val_accuracy: 0.5859 - val_auc: 0.6268\n",
      "Epoch 875/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4708 - accuracy: 0.7710 - auc: 0.8571 - val_loss: 0.6066 - val_accuracy: 0.6768 - val_auc: 0.7372\n",
      "Epoch 876/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 53ms/step - loss: 0.4346 - accuracy: 0.8041 - auc: 0.8821 - val_loss: 0.3386 - val_accuracy: 0.8788 - val_auc: 0.9414\n",
      "Epoch 877/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4489 - accuracy: 0.7863 - auc: 0.8711 - val_loss: 0.2411 - val_accuracy: 0.8586 - val_auc: 0.9669\n",
      "Epoch 878/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4974 - accuracy: 0.7735 - auc: 0.8492 - val_loss: 0.6455 - val_accuracy: 0.6566 - val_auc: 0.6864\n",
      "Epoch 879/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4494 - accuracy: 0.8270 - auc: 0.8781 - val_loss: 0.6142 - val_accuracy: 0.6667 - val_auc: 0.7225\n",
      "Epoch 880/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4383 - accuracy: 0.7735 - auc: 0.8792 - val_loss: 0.1846 - val_accuracy: 0.9192 - val_auc: 0.9884\n",
      "Epoch 881/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4741 - accuracy: 0.7786 - auc: 0.8618 - val_loss: 0.5727 - val_accuracy: 0.6768 - val_auc: 0.7719\n",
      "Epoch 882/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4740 - accuracy: 0.7913 - auc: 0.8562 - val_loss: 0.4033 - val_accuracy: 0.8283 - val_auc: 0.9264\n",
      "Epoch 883/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4697 - accuracy: 0.7608 - auc: 0.8587 - val_loss: 0.3741 - val_accuracy: 0.8485 - val_auc: 0.9302\n",
      "Epoch 884/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4534 - accuracy: 0.8015 - auc: 0.8702 - val_loss: 0.4717 - val_accuracy: 0.7576 - val_auc: 0.8642\n",
      "Epoch 885/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.5019 - accuracy: 0.7583 - auc: 0.8402 - val_loss: 0.6834 - val_accuracy: 0.6162 - val_auc: 0.6706\n",
      "Epoch 886/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4769 - accuracy: 0.7786 - auc: 0.8561 - val_loss: 0.6133 - val_accuracy: 0.5960 - val_auc: 0.7137\n",
      "Epoch 887/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4655 - accuracy: 0.7837 - auc: 0.8632 - val_loss: 0.3303 - val_accuracy: 0.8687 - val_auc: 0.9586\n",
      "Epoch 888/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4470 - accuracy: 0.8041 - auc: 0.8771 - val_loss: 0.6859 - val_accuracy: 0.6061 - val_auc: 0.6792\n",
      "Epoch 889/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.4928 - accuracy: 0.7812 - auc: 0.8439 - val_loss: 0.1459 - val_accuracy: 0.9899 - val_auc: 0.9985\n",
      "Epoch 890/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4548 - accuracy: 0.7812 - auc: 0.8660 - val_loss: 0.2926 - val_accuracy: 0.8889 - val_auc: 0.9634\n",
      "Epoch 891/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.4385 - accuracy: 0.8015 - auc: 0.8758 - val_loss: 0.2642 - val_accuracy: 0.8788 - val_auc: 0.9717\n",
      "Epoch 892/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.5132 - accuracy: 0.7583 - auc: 0.8400 - val_loss: 0.7078 - val_accuracy: 0.6667 - val_auc: 0.6150\n",
      "Epoch 893/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4513 - accuracy: 0.7837 - auc: 0.8717 - val_loss: 0.5454 - val_accuracy: 0.7475 - val_auc: 0.8030\n",
      "Epoch 894/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4461 - accuracy: 0.8117 - auc: 0.8738 - val_loss: 0.8956 - val_accuracy: 0.5152 - val_auc: 0.5012\n",
      "Epoch 895/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.4928 - accuracy: 0.7837 - auc: 0.8593 - val_loss: 0.9666 - val_accuracy: 0.4848 - val_auc: 0.4200\n",
      "Epoch 896/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4654 - accuracy: 0.7888 - auc: 0.8580 - val_loss: 0.5017 - val_accuracy: 0.8081 - val_auc: 0.8426\n",
      "Epoch 897/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.5297 - accuracy: 0.7710 - auc: 0.8395 - val_loss: 0.7214 - val_accuracy: 0.5758 - val_auc: 0.6503\n",
      "Epoch 898/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4747 - accuracy: 0.7557 - auc: 0.8578 - val_loss: 0.7545 - val_accuracy: 0.5657 - val_auc: 0.5899\n",
      "Epoch 899/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4438 - accuracy: 0.7913 - auc: 0.8724 - val_loss: 0.4018 - val_accuracy: 0.7778 - val_auc: 0.9068\n",
      "Epoch 900/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.5275 - accuracy: 0.7455 - auc: 0.8248 - val_loss: 0.4117 - val_accuracy: 0.8182 - val_auc: 0.8900\n",
      "Epoch 901/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4694 - accuracy: 0.7786 - auc: 0.8633 - val_loss: 0.7820 - val_accuracy: 0.5859 - val_auc: 0.5475\n",
      "Epoch 902/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4833 - accuracy: 0.7863 - auc: 0.8460 - val_loss: 0.4982 - val_accuracy: 0.7172 - val_auc: 0.8424\n",
      "Epoch 903/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.5275 - accuracy: 0.7328 - auc: 0.8335 - val_loss: 0.4536 - val_accuracy: 0.7172 - val_auc: 0.8666\n",
      "Epoch 904/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4793 - accuracy: 0.7863 - auc: 0.8572 - val_loss: 0.7706 - val_accuracy: 0.5253 - val_auc: 0.5841\n",
      "Epoch 905/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4542 - accuracy: 0.7710 - auc: 0.8657 - val_loss: 1.3154 - val_accuracy: 0.3939 - val_auc: 0.2583\n",
      "Epoch 906/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.4558 - accuracy: 0.7786 - auc: 0.8701 - val_loss: 0.3055 - val_accuracy: 0.8889 - val_auc: 0.9683\n",
      "Epoch 907/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.4481 - accuracy: 0.8066 - auc: 0.8748 - val_loss: 0.1410 - val_accuracy: 0.9798 - val_auc: 0.9981\n",
      "Epoch 908/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4704 - accuracy: 0.7863 - auc: 0.8549 - val_loss: 0.4533 - val_accuracy: 0.7677 - val_auc: 0.8889\n",
      "Epoch 909/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4655 - accuracy: 0.8015 - auc: 0.8630 - val_loss: 0.9946 - val_accuracy: 0.4343 - val_auc: 0.3591\n",
      "Epoch 910/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4768 - accuracy: 0.7608 - auc: 0.8542 - val_loss: 0.5479 - val_accuracy: 0.7172 - val_auc: 0.7963\n",
      "Epoch 911/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4782 - accuracy: 0.7710 - auc: 0.8536 - val_loss: 0.9198 - val_accuracy: 0.5354 - val_auc: 0.4537\n",
      "Epoch 912/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4702 - accuracy: 0.7990 - auc: 0.8617 - val_loss: 0.5829 - val_accuracy: 0.6263 - val_auc: 0.7695\n",
      "Epoch 913/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4585 - accuracy: 0.7939 - auc: 0.8713 - val_loss: 0.5875 - val_accuracy: 0.6768 - val_auc: 0.7545\n",
      "Epoch 914/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4352 - accuracy: 0.8015 - auc: 0.8809 - val_loss: 0.3850 - val_accuracy: 0.8283 - val_auc: 0.9176\n",
      "Epoch 915/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4633 - accuracy: 0.7761 - auc: 0.8651 - val_loss: 0.4711 - val_accuracy: 0.7172 - val_auc: 0.8584\n",
      "Epoch 916/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4327 - accuracy: 0.8015 - auc: 0.8818 - val_loss: 0.3502 - val_accuracy: 0.8586 - val_auc: 0.9390\n",
      "Epoch 917/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4388 - accuracy: 0.7964 - auc: 0.8793 - val_loss: 0.5267 - val_accuracy: 0.7071 - val_auc: 0.8205\n",
      "Epoch 918/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4351 - accuracy: 0.7863 - auc: 0.8777 - val_loss: 0.4106 - val_accuracy: 0.8687 - val_auc: 0.9057\n",
      "Epoch 919/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4645 - accuracy: 0.7786 - auc: 0.8598 - val_loss: 0.7976 - val_accuracy: 0.5354 - val_auc: 0.5120\n",
      "Epoch 920/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4441 - accuracy: 0.8092 - auc: 0.8784 - val_loss: 0.6684 - val_accuracy: 0.6364 - val_auc: 0.6917\n",
      "Epoch 921/1000\n",
      "13/13 [==============================] - 1s 70ms/step - loss: 0.4503 - accuracy: 0.7761 - auc: 0.8713 - val_loss: 0.3378 - val_accuracy: 0.8788 - val_auc: 0.9433\n",
      "Epoch 922/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4894 - accuracy: 0.7812 - auc: 0.8481 - val_loss: 0.3649 - val_accuracy: 0.8788 - val_auc: 0.9373\n",
      "Epoch 923/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4926 - accuracy: 0.7863 - auc: 0.8418 - val_loss: 0.6036 - val_accuracy: 0.6869 - val_auc: 0.7288\n",
      "Epoch 924/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.4648 - accuracy: 0.7964 - auc: 0.8596 - val_loss: 0.2579 - val_accuracy: 0.8990 - val_auc: 0.9765\n",
      "Epoch 925/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4528 - accuracy: 0.7786 - auc: 0.8664 - val_loss: 0.4810 - val_accuracy: 0.7071 - val_auc: 0.8508\n",
      "Epoch 926/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4694 - accuracy: 0.7710 - auc: 0.8596 - val_loss: 0.4848 - val_accuracy: 0.7071 - val_auc: 0.8430\n",
      "Epoch 927/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.4557 - accuracy: 0.7812 - auc: 0.8662 - val_loss: 0.5153 - val_accuracy: 0.7172 - val_auc: 0.8236\n",
      "Epoch 928/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4806 - accuracy: 0.7710 - auc: 0.8493 - val_loss: 0.7747 - val_accuracy: 0.5354 - val_auc: 0.5893\n",
      "Epoch 929/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4836 - accuracy: 0.7608 - auc: 0.8584 - val_loss: 0.1846 - val_accuracy: 0.9293 - val_auc: 0.9916\n",
      "Epoch 930/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4699 - accuracy: 0.8015 - auc: 0.8642 - val_loss: 0.3305 - val_accuracy: 0.8182 - val_auc: 0.9405\n",
      "Epoch 931/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4829 - accuracy: 0.7659 - auc: 0.8453 - val_loss: 0.2190 - val_accuracy: 0.9293 - val_auc: 0.9932\n",
      "Epoch 932/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4492 - accuracy: 0.7786 - auc: 0.8730 - val_loss: 0.3975 - val_accuracy: 0.8081 - val_auc: 0.9075\n",
      "Epoch 933/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4607 - accuracy: 0.7990 - auc: 0.8637 - val_loss: 0.5263 - val_accuracy: 0.6768 - val_auc: 0.8164\n",
      "Epoch 934/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4436 - accuracy: 0.8015 - auc: 0.8782 - val_loss: 0.3648 - val_accuracy: 0.8586 - val_auc: 0.9330\n",
      "Epoch 935/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4403 - accuracy: 0.7888 - auc: 0.8768 - val_loss: 0.1893 - val_accuracy: 0.9192 - val_auc: 0.9906\n",
      "Epoch 936/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4750 - accuracy: 0.7964 - auc: 0.8615 - val_loss: 1.4588 - val_accuracy: 0.0606 - val_auc: 0.0551\n",
      "Epoch 937/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4560 - accuracy: 0.7837 - auc: 0.8658 - val_loss: 0.8790 - val_accuracy: 0.5253 - val_auc: 0.5261\n",
      "Epoch 938/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4867 - accuracy: 0.7583 - auc: 0.8505 - val_loss: 0.2525 - val_accuracy: 0.8990 - val_auc: 0.9741\n",
      "Epoch 939/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4469 - accuracy: 0.7939 - auc: 0.8739 - val_loss: 0.9421 - val_accuracy: 0.4949 - val_auc: 0.4082\n",
      "Epoch 940/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4515 - accuracy: 0.7939 - auc: 0.8688 - val_loss: 1.0164 - val_accuracy: 0.4747 - val_auc: 0.3828\n",
      "Epoch 941/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4394 - accuracy: 0.8015 - auc: 0.8804 - val_loss: 1.5115 - val_accuracy: 0.1717 - val_auc: 0.1452\n",
      "Epoch 942/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.4595 - accuracy: 0.7786 - auc: 0.8651 - val_loss: 1.0810 - val_accuracy: 0.4242 - val_auc: 0.3112\n",
      "Epoch 943/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4556 - accuracy: 0.7888 - auc: 0.8673 - val_loss: 1.1271 - val_accuracy: 0.4444 - val_auc: 0.3218\n",
      "Epoch 944/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.4553 - accuracy: 0.7659 - auc: 0.8682 - val_loss: 0.4575 - val_accuracy: 0.8081 - val_auc: 0.8722\n",
      "Epoch 945/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4700 - accuracy: 0.7735 - auc: 0.8558 - val_loss: 0.5713 - val_accuracy: 0.6970 - val_auc: 0.7755\n",
      "Epoch 946/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4291 - accuracy: 0.7863 - auc: 0.8835 - val_loss: 0.6010 - val_accuracy: 0.6465 - val_auc: 0.7551\n",
      "Epoch 947/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4690 - accuracy: 0.7837 - auc: 0.8595 - val_loss: 0.3221 - val_accuracy: 0.8687 - val_auc: 0.9442\n",
      "Epoch 948/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4685 - accuracy: 0.7837 - auc: 0.8634 - val_loss: 0.4616 - val_accuracy: 0.7778 - val_auc: 0.8697\n",
      "Epoch 949/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4689 - accuracy: 0.7837 - auc: 0.8661 - val_loss: 1.0074 - val_accuracy: 0.4747 - val_auc: 0.4011\n",
      "Epoch 950/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4581 - accuracy: 0.7786 - auc: 0.8679 - val_loss: 0.6280 - val_accuracy: 0.6465 - val_auc: 0.7083\n",
      "Epoch 951/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4463 - accuracy: 0.8117 - auc: 0.8760 - val_loss: 0.3651 - val_accuracy: 0.8687 - val_auc: 0.9236\n",
      "Epoch 952/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4543 - accuracy: 0.7837 - auc: 0.8686 - val_loss: 0.2201 - val_accuracy: 0.9091 - val_auc: 0.9819\n",
      "Epoch 953/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4524 - accuracy: 0.7863 - auc: 0.8681 - val_loss: 0.6557 - val_accuracy: 0.6667 - val_auc: 0.6902\n",
      "Epoch 954/1000\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.4474 - accuracy: 0.7939 - auc: 0.8735 - val_loss: 0.3598 - val_accuracy: 0.8283 - val_auc: 0.9314\n",
      "Epoch 955/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4581 - accuracy: 0.7964 - auc: 0.8696 - val_loss: 0.2584 - val_accuracy: 0.8889 - val_auc: 0.9778\n",
      "Epoch 956/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4439 - accuracy: 0.7939 - auc: 0.8764 - val_loss: 0.4949 - val_accuracy: 0.7071 - val_auc: 0.8445\n",
      "Epoch 957/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4428 - accuracy: 0.7964 - auc: 0.8776 - val_loss: 0.2978 - val_accuracy: 0.8788 - val_auc: 0.9569\n",
      "Epoch 958/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.4687 - accuracy: 0.8015 - auc: 0.8719 - val_loss: 0.2708 - val_accuracy: 0.8990 - val_auc: 0.9751\n",
      "Epoch 959/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4463 - accuracy: 0.7710 - auc: 0.8721 - val_loss: 0.3772 - val_accuracy: 0.8687 - val_auc: 0.9216\n",
      "Epoch 960/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4538 - accuracy: 0.8041 - auc: 0.8712 - val_loss: 0.5546 - val_accuracy: 0.7172 - val_auc: 0.7888\n",
      "Epoch 961/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4537 - accuracy: 0.7837 - auc: 0.8680 - val_loss: 0.4612 - val_accuracy: 0.7374 - val_auc: 0.8815\n",
      "Epoch 962/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4530 - accuracy: 0.7761 - auc: 0.8684 - val_loss: 0.2169 - val_accuracy: 0.8990 - val_auc: 0.9836\n",
      "Epoch 963/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4531 - accuracy: 0.7939 - auc: 0.8681 - val_loss: 0.3635 - val_accuracy: 0.8485 - val_auc: 0.9371\n",
      "Epoch 964/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4476 - accuracy: 0.7990 - auc: 0.8729 - val_loss: 0.7518 - val_accuracy: 0.6061 - val_auc: 0.5929\n",
      "Epoch 965/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.4761 - accuracy: 0.7888 - auc: 0.8621 - val_loss: 0.4550 - val_accuracy: 0.7879 - val_auc: 0.8751\n",
      "Epoch 966/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4547 - accuracy: 0.7888 - auc: 0.8663 - val_loss: 0.2464 - val_accuracy: 0.9091 - val_auc: 0.9784\n",
      "Epoch 967/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.4512 - accuracy: 0.7964 - auc: 0.8764 - val_loss: 0.7900 - val_accuracy: 0.5152 - val_auc: 0.5884\n",
      "Epoch 968/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4479 - accuracy: 0.7863 - auc: 0.8712 - val_loss: 0.4252 - val_accuracy: 0.8182 - val_auc: 0.8962\n",
      "Epoch 969/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4549 - accuracy: 0.7735 - auc: 0.8667 - val_loss: 0.3851 - val_accuracy: 0.8586 - val_auc: 0.9191\n",
      "Epoch 970/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4870 - accuracy: 0.7481 - auc: 0.8474 - val_loss: 0.2936 - val_accuracy: 0.8990 - val_auc: 0.9575\n",
      "Epoch 971/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4476 - accuracy: 0.8066 - auc: 0.8776 - val_loss: 0.2419 - val_accuracy: 0.9192 - val_auc: 0.9835\n",
      "Epoch 972/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4562 - accuracy: 0.7939 - auc: 0.8677 - val_loss: 0.4136 - val_accuracy: 0.7576 - val_auc: 0.9077\n",
      "Epoch 973/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4439 - accuracy: 0.8015 - auc: 0.8752 - val_loss: 0.7160 - val_accuracy: 0.6061 - val_auc: 0.6873\n",
      "Epoch 974/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.4534 - accuracy: 0.8015 - auc: 0.8703 - val_loss: 0.9841 - val_accuracy: 0.5152 - val_auc: 0.4171\n",
      "Epoch 975/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4495 - accuracy: 0.7710 - auc: 0.8707 - val_loss: 0.7777 - val_accuracy: 0.5758 - val_auc: 0.5879\n",
      "Epoch 976/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4569 - accuracy: 0.7863 - auc: 0.8650 - val_loss: 0.4981 - val_accuracy: 0.7071 - val_auc: 0.8359\n",
      "Epoch 977/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4308 - accuracy: 0.7913 - auc: 0.8835 - val_loss: 0.2296 - val_accuracy: 0.8990 - val_auc: 0.9786\n",
      "Epoch 978/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4506 - accuracy: 0.7913 - auc: 0.8739 - val_loss: 0.7347 - val_accuracy: 0.6768 - val_auc: 0.5968\n",
      "Epoch 979/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4516 - accuracy: 0.7786 - auc: 0.8676 - val_loss: 0.6460 - val_accuracy: 0.6768 - val_auc: 0.7329\n",
      "Epoch 980/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.5163 - accuracy: 0.7761 - auc: 0.8381 - val_loss: 0.7957 - val_accuracy: 0.4949 - val_auc: 0.4219\n",
      "Epoch 981/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.5714 - accuracy: 0.7379 - auc: 0.8044 - val_loss: 0.4287 - val_accuracy: 0.8586 - val_auc: 0.9176\n",
      "Epoch 982/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.4877 - accuracy: 0.7583 - auc: 0.8522 - val_loss: 0.4634 - val_accuracy: 0.7273 - val_auc: 0.8577\n",
      "Epoch 983/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4554 - accuracy: 0.7990 - auc: 0.8666 - val_loss: 1.1129 - val_accuracy: 0.3232 - val_auc: 0.2823\n",
      "Epoch 984/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4802 - accuracy: 0.7735 - auc: 0.8515 - val_loss: 0.8020 - val_accuracy: 0.5354 - val_auc: 0.5650\n",
      "Epoch 985/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4644 - accuracy: 0.7684 - auc: 0.8626 - val_loss: 0.4989 - val_accuracy: 0.7576 - val_auc: 0.8373\n",
      "Epoch 986/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4560 - accuracy: 0.7634 - auc: 0.8670 - val_loss: 0.5311 - val_accuracy: 0.7071 - val_auc: 0.8133\n",
      "Epoch 987/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4352 - accuracy: 0.7863 - auc: 0.8822 - val_loss: 0.4731 - val_accuracy: 0.7172 - val_auc: 0.8585\n",
      "Epoch 988/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4435 - accuracy: 0.7786 - auc: 0.8729 - val_loss: 0.5580 - val_accuracy: 0.7071 - val_auc: 0.7920\n",
      "Epoch 989/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.4481 - accuracy: 0.7939 - auc: 0.8730 - val_loss: 0.3160 - val_accuracy: 0.8586 - val_auc: 0.9510\n",
      "Epoch 990/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.4634 - accuracy: 0.7786 - auc: 0.8622 - val_loss: 0.4636 - val_accuracy: 0.7273 - val_auc: 0.8587\n",
      "Epoch 991/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4679 - accuracy: 0.7964 - auc: 0.8619 - val_loss: 0.5177 - val_accuracy: 0.7172 - val_auc: 0.8254\n",
      "Epoch 992/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4630 - accuracy: 0.7863 - auc: 0.8620 - val_loss: 0.1784 - val_accuracy: 0.9293 - val_auc: 0.9933\n",
      "Epoch 993/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4550 - accuracy: 0.7939 - auc: 0.8688 - val_loss: 0.2952 - val_accuracy: 0.8687 - val_auc: 0.9441\n",
      "Epoch 994/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4648 - accuracy: 0.7812 - auc: 0.8630 - val_loss: 0.1275 - val_accuracy: 0.9798 - val_auc: 0.9971\n",
      "Epoch 995/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4437 - accuracy: 0.8041 - auc: 0.8750 - val_loss: 1.0837 - val_accuracy: 0.4949 - val_auc: 0.4104\n",
      "Epoch 996/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4425 - accuracy: 0.7964 - auc: 0.8752 - val_loss: 0.2629 - val_accuracy: 0.8788 - val_auc: 0.9733\n",
      "Epoch 997/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.4311 - accuracy: 0.8015 - auc: 0.8822 - val_loss: 0.4710 - val_accuracy: 0.7273 - val_auc: 0.8682\n",
      "Epoch 998/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.4785 - accuracy: 0.7913 - auc: 0.8537 - val_loss: 0.3255 - val_accuracy: 0.8485 - val_auc: 0.9528\n",
      "Epoch 999/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.4505 - accuracy: 0.7913 - auc: 0.8728 - val_loss: 0.2587 - val_accuracy: 0.9091 - val_auc: 0.9725\n",
      "Epoch 1000/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.4622 - accuracy: 0.7837 - auc: 0.8605 - val_loss: 0.4388 - val_accuracy: 0.7879 - val_auc: 0.8930\n"
     ]
    }
   ],
   "source": [
    "if bi_class == 0:\n",
    "    full_model.compile(optimizer=Adam(lr=0.05), loss='categorical_crossentropy', metrics=[keras.metrics.CategoricalAccuracy(), keras.metrics.AUC(multi_label=True), tfa.metrics.F1Score(num_classes=num_classes)])\n",
    "    hist = full_model.fit(x=np.array(X_train).transpose([0,1,2,3]), y=np.array(Y_train).transpose([0,1]), batch_size=None, validation_split=0.2, epochs=1000)\n",
    "else:\n",
    "    full_model.compile(optimizer=Adam(lr=0.05), loss='binary_crossentropy', metrics=['accuracy', keras.metrics.AUC()])\n",
    "    hist = full_model.fit(x=np.array(X_train).transpose([0,1,2,3]), y=np.array(Y_train).transpose([0,1]), batch_size=None, validation_split=0.2, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display acc, loss\n",
    "if bi_class == 0:\n",
    "    fig, loss_ax = plt.subplots()\n",
    "\n",
    "    acc_ax = loss_ax.twinx()\n",
    "\n",
    "    loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "\n",
    "    acc_ax.plot(hist.history['categorical_accuracy'], 'b', label='train acc')\n",
    "\n",
    "    loss_ax.set_xlabel('epoch')\n",
    "    loss_ax.set_ylabel('loss')\n",
    "    acc_ax.set_ylabel('accuray')\n",
    "\n",
    "    loss_ax.legend(loc='upper left')\n",
    "    acc_ax.legend(loc='lower left')\n",
    "\n",
    "    plt.show()\n",
    "else:\n",
    "    fig, loss_ax = plt.subplots()\n",
    "\n",
    "    acc_ax = loss_ax.twinx()\n",
    "\n",
    "    loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "\n",
    "    acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "\n",
    "    loss_ax.set_xlabel('epoch')\n",
    "    loss_ax.set_ylabel('loss')\n",
    "    acc_ax.set_ylabel('accuray')\n",
    "\n",
    "    loss_ax.legend(loc='upper left')\n",
    "    acc_ax.legend(loc='lower left')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC:  0.480952380952381\n"
     ]
    }
   ],
   "source": [
    "predictions = full_model.predict(np.array(X_test).transpose([0,1,2,3]))\n",
    "\n",
    "if bi_class==0:\n",
    "    auc = roc_auc_score(Y_test, predictions, multi_class='raise')\n",
    "    print('Multiclass Test AUC: ', auc)\n",
    "else:\n",
    "    auc = roc_auc_score(Y_test, predictions)\n",
    "    print('Test AUC: ', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60.  7.]\n",
      "[53. 14.]\n"
     ]
    }
   ],
   "source": [
    "frequency = np.zeros(len(Y_test[0]))\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    frequency[np.argmax(predictions[i])] +=1\n",
    "    \n",
    "print(np.sum(Y_test, axis=0))\n",
    "print(frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 0.6722 - accuracy: 0.7164 - auc: 0.7483\n",
      "\n",
      "Accuracy: 0.7164179086685181\n"
     ]
    }
   ],
   "source": [
    "if bi_class == 0:\n",
    "    test_loss, test_acc, test_auc, test_F1 = full_model.evaluate(np.array(X_test).transpose([0,1,2,3]),  np.array(Y_test).transpose([0,1]), verbose=2)\n",
    "    print('\\nAccuracy:', test_acc)\n",
    "else:\n",
    "    test_loss, test_acc, test_auc = full_model.evaluate(np.array(X_test).transpose([0,1,2,3]),  np.array(Y_test).transpose([0,1]), verbose=2)\n",
    "    print('\\nAccuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
