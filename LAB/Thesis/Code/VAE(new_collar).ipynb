{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 3136607562160073353,\n",
       " name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 8377363359132279434\n",
       " physical_device_desc: \"device: XLA_CPU device\",\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 3129973147\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 11185231795476836962\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\",\n",
       " name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 467105377208401200\n",
       " physical_device_desc: \"device: XLA_GPU device\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os, sys\n",
    "from os.path import join, dirname\n",
    "\n",
    "import datetime, time\n",
    "import csv\n",
    "from glob import glob\n",
    "import chardet\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, MaxAbsScaler, MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Conv2D, SimpleRNN, LSTM, GRU, Reshape, RepeatVector, MaxPooling2D, Dropout, Bidirectional, Attention, BatchNormalization, Conv2DTranspose, TimeDistributed\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.optimizers import Adadelta, RMSprop,SGD,Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "\n",
    "import imblearn\n",
    "\n",
    "from IPython.display import SVG\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(tf.__version__)\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7                           # {\"0\" : \"Playing\", \"1\" : \"Talking\", \"2\" : \"Petting\", \"3\" : \"TV / Radio\", \"4\" : \"Eating / Cooking\", \"5\" : \"Moved It\", \"6\" : \"None of the above\", \"7\" : \"Other\"}\n",
    "time_offset = 10\n",
    "window_size = 50\n",
    "overlap_ratio = 0.5\n",
    "bi_class = 0                              # Binary Classification (1 : Playing or not, 2 : Talking or not, 3 : Petting or not, 4: TV / Radio or not, 5 : Eating / Cooking or not, 6 : Moved It or not)\n",
    "cross_val = 0\n",
    "rand_st=2\n",
    "mode = 0                                 # Split data {0: Didn't split, 1: US only, 2: Korea only, 3: train with US and test with Korea 4: train with Korea and test with US}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fname = '../Data/Preprocessed(new)/preprocessed_data(New collar_2).csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_fname)\n",
    "data = data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iaq = data['iaq']\n",
    "iaq_cat = []\n",
    "\n",
    "for num in iaq:\n",
    "    if num < 50 and num >=0:\n",
    "        iaq_cat.append('Good')\n",
    "    elif num >= 50 and num < 100:\n",
    "        iaq_cat.append('Average')\n",
    "    elif num >= 100 and num < 150:\n",
    "        iaq_cat.append('Little bad')\n",
    "    elif num >= 150 and num < 200:\n",
    "        iaq_cat.append('Bad')\n",
    "    elif num >= 200 and num < 300:\n",
    "        iaq_cat.append('Worse')\n",
    "    elif num >= 300 and num <= 500:\n",
    "        iaq_cat.append('Very bad')\n",
    "    else:\n",
    "        print(num)\n",
    "data['iaq_cat'] = iaq_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data,pd.get_dummies(data['sound category'])],axis=1)         # Onehot encode sound category\n",
    "data = pd.concat([data,pd.get_dummies(data['orientation_cat'])],axis=1)         # Onehot encode orientation category\n",
    "data = pd.concat([data,pd.get_dummies(data['iaq_cat'])],axis=1)         # Onehot encode iaq category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rowID list\n",
    "rowID_list = np.array(data['RowID'].drop_duplicates())\n",
    "data = data.to_records(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# data['pressure'] = scaler.fit_transform(data['pressure'].reshape(-1,1)).reshape(-1)\n",
    "data['gasResistance'] = scaler.fit_transform(data['gasResistance'].reshape(-1,1)).reshape(-1)\n",
    "data['staticIaq'] = scaler.fit_transform(data['staticIaq'].reshape(-1,1)).reshape(-1)\n",
    "data['co2Equivalent'] = scaler.fit_transform(data['co2Equivalent'].reshape(-1,1)).reshape(-1)\n",
    "data['breathVocEquivalent'] = scaler.fit_transform(data['breathVocEquivalent'].reshape(-1,1)).reshape(-1)\n",
    "data['audioLevel'] = scaler.fit_transform(data['audioLevel'].reshape(-1,1)).reshape(-1)\n",
    "data['rawTemp'] = scaler.fit_transform(data['rawTemp'].reshape(-1,1)).reshape(-1)\n",
    "data['rawHumidity'] = scaler.fit_transform(data['rawHumidity'].reshape(-1,1)).reshape(-1)\n",
    "data['pressure'] = scaler.fit_transform(data['pressure'].reshape(-1,1)).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split US and Korea\n",
    "us_rowIDs = []\n",
    "korea_rowIDs = []\n",
    "\n",
    "if mode != 0:\n",
    "    for rowid in rowID_list:\n",
    "    #     print(rowid, rowid[0])\n",
    "        if rowid[0] == '1':\n",
    "            korea_rowIDs.append(rowid)\n",
    "        else:\n",
    "            us_rowIDs.append(rowid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_col_name = ['accX', 'accY', 'accZ', 'chord', 'orientation', 'ir', 'full', 'iaq', 'iaqAccuracy', 'rawTemp',\n",
    "#                     'pressure', 'rawHumidity', 'gasResistance', 'compGasAccuracy', 'gasPercentageAccuracy', 'temperature', \n",
    "#                     'humidity', 'staticIaq', 'statIaqAccuracy', 'co2Equivalent', 'co2Accuracy', 'breathVocEquivalent', \n",
    "#                     'breathVocAccuracy', 'audioLevel', 'Loud', 'Moderate', 'Quiet']\n",
    "feature_col_name = ['accX', 'accY', 'accZ', 'chord', 'full', 'iaq', 'rawTemp',\n",
    "                    'pressure', 'rawHumidity', 'gasResistance', 'staticIaq', 'co2Equivalent', 'breathVocEquivalent', \n",
    "                    'audioLevel', 'Loud', 'Moderate', 'Quiet', 'Landscape Left Back', 'Landscape Left Front', 'Landscape Right Back',\n",
    "                    'Landscape Right Front', 'Portrait Down Back', 'Portrait Down Front', 'Portrait Up Back', \n",
    "                    'Portrait Up Front', 'Average', 'Bad', 'Good', 'Little bad', 'Very bad', 'Worse']\n",
    "target_col_name = ['Modality_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_num = len(feature_col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "us_X = []\n",
    "korea_X = []\n",
    "\n",
    "Y = []\n",
    "us_Y = []\n",
    "korea_Y = []\n",
    "\n",
    "\n",
    "if mode != 0:\n",
    "    for rowID in us_rowIDs:\n",
    "        #Split raw data by rowID & split X, Y data\n",
    "        tmp_data = data[data['RowID'] == rowID]\n",
    "        feature = tmp_data[feature_col_name]\n",
    "        feature = np.array(feature.tolist())\n",
    "        target = tmp_data[target_col_name][0][0]\n",
    "        target = np.array(target.tolist())\n",
    "        us_X.append(feature)\n",
    "        us_Y.append(target)\n",
    "    \n",
    "    for rowID in korea_rowIDs:\n",
    "        #Split raw data by rowID & split X, Y data\n",
    "        tmp_data = data[data['RowID'] == rowID]\n",
    "        feature = tmp_data[feature_col_name]\n",
    "        feature = np.array(feature.tolist())\n",
    "        target = tmp_data[target_col_name][0][0]\n",
    "        target = np.array(target.tolist())\n",
    "        korea_X.append(feature)\n",
    "        korea_Y.append(target)\n",
    "\n",
    "else:\n",
    "    for rowID in rowID_list:\n",
    "        #Split raw data by rowID & split X, Y data\n",
    "        tmp_data = data[data['RowID'] == rowID]\n",
    "        feature = tmp_data[feature_col_name]\n",
    "        feature = np.array(feature.tolist())\n",
    "        target = tmp_data[target_col_name][0][0]\n",
    "        target = np.array(target.tolist())\n",
    "        X.append(feature)\n",
    "        Y.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bi_class != 0:\n",
    "    #Transit multi classification to binary classification\n",
    "    if mode != 0:\n",
    "        for idx in range(len(us_Y)):\n",
    "            if us_Y[idx] == bi_class-1:\n",
    "                us_Y[idx]=1\n",
    "            else:\n",
    "                us_Y[idx]=0\n",
    "                \n",
    "        for idx in range(len(korea_Y)):\n",
    "            if korea_Y[idx] == bi_class-1:\n",
    "                korea_Y[idx]=1\n",
    "            else:\n",
    "                korea_Y[idx]=0\n",
    "    else:\n",
    "        for idx in range(len(Y)):\n",
    "            if Y[idx] == bi_class-1:\n",
    "                Y[idx]=1\n",
    "            else:\n",
    "                Y[idx]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_preprocess(X, window_size, overlap_ratio):\n",
    "    #Transform data shape using the set time window\n",
    "    processed_X = []\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        tmp_X = X[i]\n",
    "        tmp = []\n",
    "        start_row = 0\n",
    "        end_row = start_row + window_size\n",
    "        \n",
    "        if len(tmp_X)%int(window_size*overlap_ratio) == 0:\n",
    "            for j in range(len(tmp_X)//int(window_size*overlap_ratio)-1):\n",
    "                tmp.append(tmp_X[int(start_row):int(end_row)])\n",
    "                start_row += (window_size*overlap_ratio)\n",
    "                end_row += (window_size*overlap_ratio)\n",
    "        else:\n",
    "            for j in range(len(tmp_X)//int(window_size*overlap_ratio)+1):\n",
    "                if end_row > len(tmp_X):\n",
    "                    \n",
    "                    tmp.append(tmp_X[-window_size:])\n",
    "                    start_row += (window_size*overlap_ratio)\n",
    "                    end_row += (window_size*overlap_ratio)\n",
    "                    break\n",
    "                else:\n",
    "                    \n",
    "                    tmp.append(tmp_X[int(start_row):int(end_row)])\n",
    "                    start_row += (window_size*overlap_ratio)\n",
    "                    end_row += (window_size*overlap_ratio)\n",
    "        processed_X.append(tmp)\n",
    "        \n",
    "    return processed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode != 0:\n",
    "    us_X = X_preprocess(us_X, window_size, overlap_ratio)        ### preprocess with input shape\n",
    "    korea_X = X_preprocess(korea_X, window_size, overlap_ratio)\n",
    "    if bi_class == 0:\n",
    "        ### onehot encode Y\n",
    "        us_Y = np.eye(num_classes)[us_Y]\n",
    "        korea_Y = np.eye(num_classes)[korea_Y]\n",
    "    else: \n",
    "        us_Y = np.eye(2)[us_Y]\n",
    "        korea_Y = np.eye(2)[korea_Y]\n",
    "\n",
    "else:    \n",
    "    X = X_preprocess(X, window_size, overlap_ratio)        ### preprocess with input shape\n",
    "    if bi_class == 0:\n",
    "        ### onehot encode Y\n",
    "        Y = np.eye(num_classes)[Y]\n",
    "    else: Y = np.eye(2)[Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample X Data size\n",
    "\n",
    "def subsample(X, min_us_len, min_korea_len):\n",
    "    sampled_X = []\n",
    "    addon = 0\n",
    "    \n",
    "    if min_korea_len > min_us_len:\n",
    "        if np.array(X).shape[1] == min_us_len:\n",
    "            return X\n",
    "        else:\n",
    "            interval = min_korea_len / min_us_len\n",
    "            quotient = int(np.modf(interval)[1])\n",
    "            remainder = np.modf(interval)[0]\n",
    "\n",
    "            for i in range(len(X)):\n",
    "                temp_X = []\n",
    "                for j in range(min_us_len):\n",
    "                    if addon >= 1:\n",
    "                        temp_X.append(X[i][j*quotient + 1])\n",
    "                        addon = 0\n",
    "                        addon += remainder\n",
    "                    else:\n",
    "                        temp_X.append(X[i][j*quotient])\n",
    "                        addon += remainder\n",
    "\n",
    "                sampled_X.append(temp_X)\n",
    "            \n",
    "    else:\n",
    "        if np.array(X).shape[1] == min_korea_len:\n",
    "            return X\n",
    "        else:\n",
    "            interval = min_us_len / min_korea_len\n",
    "            quotient = int(np.modf(interval)[1])\n",
    "            remainder = np.modf(interval)[0]\n",
    "\n",
    "            for i in range(len(X)):\n",
    "                temp_X = []\n",
    "                for j in range(min_korea_len):\n",
    "                    if addon >= 1:\n",
    "                        temp_X.append(X[i][j*quotient + 1])\n",
    "                        addon = 0\n",
    "                        addon += remainder\n",
    "                    else:\n",
    "                        temp_X.append(X[i][j*quotient])\n",
    "                        addon += remainder\n",
    "\n",
    "            sampled_X.append(temp_X)\n",
    "                    \n",
    "    return sampled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit to minimum length\n",
    "\n",
    "min_len = 99999999\n",
    "min_us_len = 99999999\n",
    "min_korea_len = 99999999\n",
    "min_X = []\n",
    "min_us_X = []\n",
    "min_korea_X = []\n",
    "\n",
    "if mode == 0:\n",
    "#     print('Start mode 0\\n')\n",
    "    for x in X:\n",
    "        if len(x) < min_len:\n",
    "            min_len = len(x)\n",
    "#     print(min_len)\n",
    "\n",
    "    for x in X:\n",
    "        min_X.append(x[:min_len])\n",
    "\n",
    "else:\n",
    "    for x in us_X:\n",
    "        if len(x) < min_us_len:\n",
    "            min_us_len = len(x)\n",
    "            \n",
    "    for x in korea_X:\n",
    "        if len(x) < min_korea_len:\n",
    "            min_korea_len = len(x)\n",
    "            \n",
    "    if mode == 1:\n",
    "        for x in us_X:\n",
    "            min_us_X.append(x[:min_us_len])\n",
    "        for x in korea_X:\n",
    "            min_korea_X.append(x[:min_korea_len])\n",
    "        \n",
    "    elif mode == 2:\n",
    "        min_korea_len = 60\n",
    "        for x in us_X:\n",
    "            min_us_X.append(x[:min_us_len])\n",
    "        for x in korea_X:\n",
    "            min_korea_X.append(x[:min_korea_len])\n",
    "        \n",
    "    else:\n",
    "        if min_korea_len < min_us_len:\n",
    "            min_len = min_korea_len\n",
    "        else: min_len = min_us_len\n",
    "\n",
    "        for x in us_X:\n",
    "            min_us_X.append(x[:min_len])\n",
    "\n",
    "        for x in korea_X:\n",
    "            min_korea_X.append(x[:min_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop duplicate\n",
    "\n",
    "if bi_class != 0:\n",
    "    \n",
    "    target_list = []\n",
    "    us_target_list = []\n",
    "    korea_target_list = []\n",
    "    del_list = []\n",
    "    us_del_list = []\n",
    "    korea_del_list = []\n",
    "    \n",
    "    if mode == 0:\n",
    "        for i in range(len(Y)):\n",
    "            if Y[i][1] == 1:\n",
    "                target_list.append(i)\n",
    "\n",
    "        for i in target_list:\n",
    "            for j in range(len(min_X)):\n",
    "                if j in target_list:\n",
    "                    pass\n",
    "                else:\n",
    "                    if np.array_equal(np.array(min_X[i]), np.array(min_X[j])):\n",
    "                        if j not in del_list:\n",
    "                            del_list.append(j)\n",
    "        X = []\n",
    "        Target = []\n",
    "\n",
    "        for i in range(len(Y)):\n",
    "            if i not in del_list:\n",
    "                X.append(min_X[i])\n",
    "                Target.append(Y[i])\n",
    "                \n",
    "    else:\n",
    "        for i in range(len(us_Y)):\n",
    "            if us_Y[i][1] == 1:\n",
    "                us_target_list.append(i)\n",
    "\n",
    "        for i in us_target_list:\n",
    "            for j in range(len(min_us_X)):\n",
    "                if j in us_target_list:\n",
    "                    pass\n",
    "                else:\n",
    "                    if np.array_equal(np.array(min_us_X[i]), np.array(min_us_X[j])):\n",
    "                        if j not in us_del_list:\n",
    "                            us_del_list.append(j)\n",
    "                            \n",
    "        for i in range(len(korea_Y)):\n",
    "            if korea_Y[i][1] == 1:\n",
    "                korea_target_list.append(i)\n",
    "\n",
    "        for i in korea_target_list:\n",
    "            for j in range(len(min_korea_X)):\n",
    "                if j in korea_target_list:\n",
    "                    pass\n",
    "                else:\n",
    "                    if np.array_equal(np.array(min_korea_X[i]), np.array(min_korea_X[j])):\n",
    "                        if j not in korea_del_list:\n",
    "                            korea_del_list.append(j)\n",
    "        \n",
    "        us_X = []\n",
    "        us_Target = []\n",
    "        korea_X = []\n",
    "        korea_Target = []\n",
    "\n",
    "        for i in range(len(us_Y)):\n",
    "            if i not in us_del_list:\n",
    "                us_X.append(min_us_X[i])\n",
    "                us_Target.append(us_Y[i])\n",
    "                \n",
    "        for i in range(len(korea_Y)):\n",
    "            if i not in korea_del_list:\n",
    "                korea_X.append(min_korea_X[i])\n",
    "                korea_Target.append(korea_Y[i])\n",
    "\n",
    "else:\n",
    "    target_list = []\n",
    "    us_target_list = []\n",
    "    korea_target_list = []\n",
    "    del_list = []\n",
    "    us_del_list = []\n",
    "    korea_del_list = []\n",
    "    \n",
    "    if mode == 0:\n",
    "        X = min_X\n",
    "        Target = Y\n",
    "\n",
    "    else:\n",
    "        for i in range(len(us_Y)):\n",
    "            if us_Y[i][1] == 1:\n",
    "                us_target_list.append(i)\n",
    "\n",
    "        for i in us_target_list:\n",
    "            for j in range(len(min_us_X)):\n",
    "                if j in us_target_list:\n",
    "                    pass\n",
    "                else:\n",
    "                    if np.array_equal(np.array(min_us_X[i]), np.array(min_us_X[j])):\n",
    "                        if j not in us_del_list:\n",
    "                            us_del_list.append(j)\n",
    "\n",
    "        for i in range(len(korea_Y)):\n",
    "            if korea_Y[i][1] == 1:\n",
    "                korea_target_list.append(i)\n",
    "\n",
    "        for i in korea_target_list:\n",
    "            for j in range(len(min_korea_X)):\n",
    "                if j in korea_target_list:\n",
    "                    pass\n",
    "                else:\n",
    "                    if np.array_equal(np.array(min_korea_X[i]), np.array(min_korea_X[j])):\n",
    "                        if j not in korea_del_list:\n",
    "                            korea_del_list.append(j)\n",
    "\n",
    "        us_X = []\n",
    "        us_Target = []\n",
    "        korea_X = []\n",
    "        korea_Target = []\n",
    "\n",
    "        for i in range(len(us_Y)):\n",
    "            if i not in us_del_list:\n",
    "                us_X.append(min_us_X[i])\n",
    "                us_Target.append(us_Y[i])\n",
    "\n",
    "        for i in range(len(korea_Y)):\n",
    "            if i not in korea_del_list:\n",
    "                korea_X.append(min_korea_X[i])\n",
    "                korea_Target.append(korea_Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 0:\n",
    "#     X = subsample(X, min_us_len, min_korea_len)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Target, test_size=0.2)\n",
    "    \n",
    "elif mode == 1:\n",
    "    us_X = subsample(us_X, min_us_len, min_korea_len)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(us_X, us_Target, test_size=0.2)\n",
    "\n",
    "elif mode == 2:\n",
    "    korea_X = subsample(korea_X, min_us_len, min_korea_len)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(korea_X, korea_Target, test_size=0.2)\n",
    "\n",
    "elif mode == 3:\n",
    "    X_train = subsample(us_X, min_us_len, min_korea_len)\n",
    "    X_test = subsample(korea_X, min_us_len, min_korea_len)\n",
    "    Y_train = us_Target \n",
    "    Y_test = korea_Target\n",
    "\n",
    "else:\n",
    "    X_train = subsample(korea_X, min_us_len, min_korea_len)\n",
    "    X_test = subsample(us_X, min_us_len, min_korea_len)\n",
    "    Y_train = korea_Target\n",
    "    Y_test = us_Target "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------\n",
    "### End Setup, separate model sections\n",
    "-----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative Replay #3 - Variational Autoencoder\n",
    "- https://blog.keras.io/building-autoencoders-in-keras.html (scroll down to VAE section near end)\n",
    "- https://keras.io/examples/generative/vae/\n",
    "- https://blog.paperspace.com/how-to-build-variational-autoencoder-keras/\n",
    "- https://github.com/analytique-bourassa/VAE-Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sckim\\.conda\\envs\\grad\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1 2 3 4 5 6] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "### Data Setup ###\n",
    "\n",
    "#Rebalance the data\n",
    "if bi_class == 0:\n",
    "    sm = imblearn.over_sampling.SMOTE()\n",
    "    X_shape = np.array(X_train).shape\n",
    "    Y_shape = np.array(Y_train).shape\n",
    "    new_X_train = np.array(X_train).reshape(X_shape[0], X_shape[1]*X_shape[2]*X_shape[3])\n",
    "    Y_train = np.array(Y_train).astype('float64')\n",
    "    X_train, Y_train = sm.fit_resample(new_X_train, Y_train)\n",
    "    temp = X_train.shape\n",
    "    X_train = X_train.reshape([temp[0], X_shape[1], X_shape[2], X_shape[3]])\n",
    "    Y_train = Y_train.reshape(temp[0], Y_shape[1])\n",
    "\n",
    "else:\n",
    "    sm = imblearn.over_sampling.SMOTE()         # random state do not set\n",
    "    origin_shape = np.array(X_train).shape\n",
    "    new_X_train = np.array(X_train).reshape(origin_shape[0], origin_shape[1]*origin_shape[2]*origin_shape[3])\n",
    "    Y_train = np.array(Y_train).astype('float64')\n",
    "    X_train, Y_train = sm.fit_resample(new_X_train, Y_train)\n",
    "    temp = X_train.shape\n",
    "    X_train = X_train.reshape([temp[0], origin_shape[1], origin_shape[2], origin_shape[3]])\n",
    "    Y_train = np.eye(2)[Y_train.reshape(temp[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(276, 50, 31)\n",
      "(None, 276, 50, 31)\n"
     ]
    }
   ],
   "source": [
    "# This is the size of our encoded representations\n",
    "encoding_dim = num_classes  # Same as original model above, final dense layer should be \n",
    "input_shape = np.array(X_train[0]).shape\n",
    "print(input_shape)\n",
    "\n",
    "# This is our input data\n",
    "feature_input = keras.Input(shape=input_shape)\n",
    "feat_shape=feature_input.shape\n",
    "print(feat_shape)\n",
    "\n",
    "#Setup latent dims\n",
    "original_dim = feature_num                     #feature count\n",
    "intermediate_dim = 128                 #hidden units\n",
    "latent_dim = feature_num                        #latent count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_unit = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 276, 50, 31) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_1 (Conv2D)         (None, 276, 50, 31)  992         encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "encoder_norm_1 (BatchNormalizat (None, 276, 50, 31)  124         encoder_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_activ_1 (LeakyReLU)     (None, 276, 50, 31)  0           encoder_norm_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_reshape1 (Reshape)      (None, 200, 2139)    0           encoder_activ_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_rnn1 (GRU)              (None, 200)          1404600     encoder_reshape1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_norm_4 (BatchNormalizat (None, 200)          800         encoder_rnn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encoder_fc1 (Dense)             (None, 31)           6231        encoder_norm_4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_mu (Dense)              (None, 31)           992         encoder_fc1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "encoder_log_variance (Dense)    (None, 31)           992         encoder_fc1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "encoder_output (Lambda)         (None, 31)           0           encoder_mu[0][0]                 \n",
      "                                                                 encoder_log_variance[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 1,414,731\n",
      "Trainable params: 1,414,269\n",
      "Non-trainable params: 462\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Encoder\n",
    "x = Input(shape=input_shape, name=\"encoder_input\")\n",
    "\n",
    "encoder_conv_layer1 = Conv2D(filters=feature_num, kernel_size=(1,1), padding=\"same\", strides=1, name=\"encoder_conv_1\")(x)\n",
    "encoder_norm_layer1 = BatchNormalization(name=\"encoder_norm_1\")(encoder_conv_layer1)\n",
    "encoder_activ_layer1 = tf.keras.layers.LeakyReLU(name=\"encoder_activ_1\")(encoder_norm_layer1)\n",
    "\n",
    "# encoder_conv_layer2 = Conv2D(filters=8, kernel_size=(2,2), padding=\"same\", strides=2, name=\"encoder_conv_2\")(encoder_activ_layer1)\n",
    "# encoder_norm_layer2 = BatchNormalization(name=\"encoder_norm_2\")(encoder_conv_layer2)\n",
    "# encoder_activ_layer2 = tf.keras.layers.LeakyReLU(name=\"encoder_activ_layer_2\")(encoder_norm_layer2)\n",
    "\n",
    "shape_before_reshape = K.int_shape(encoder_activ_layer1)[1:]\n",
    "rnn_input = Reshape((rnn_unit, -1), name='encoder_reshape1')(encoder_activ_layer1)\n",
    "rnn_layer = GRU(units=rnn_unit, return_sequences=False, name='encoder_rnn1')(rnn_input)\n",
    "# rnn_layer = TimeDistributed(Dense(rnn_unit), name='encoder_TD1')(rnn_layer)\n",
    "# rnn_layer= BatchNormalization(name='encoder_norm_3')(rnn_layer)\n",
    "# rnn_layer = Bidirectional(GRU(units=rnn_unit, name='encoder_rnn2'))(rnn_layer)\n",
    "rnn_layer= BatchNormalization(name='encoder_norm_4')(rnn_layer)\n",
    "rnn_output = Dense(units=latent_dim, activation='sigmoid', name='encoder_fc1')(rnn_layer)\n",
    "\n",
    "shape_before_flatten = K.int_shape(rnn_input)[1:]\n",
    "# encoder_flatten = Flatten()(rnn_output)\n",
    "\n",
    "encoder_mu = Dense(units=latent_dim, name=\"encoder_mu\")(rnn_output)\n",
    "encoder_log_variance = Dense(units=latent_dim, name=\"encoder_log_variance\")(rnn_output)\n",
    "\n",
    "encoder_mu_log_variance_model = Model(x, (encoder_mu, encoder_log_variance), name=\"encoder_mu_log_variance_model\")\n",
    "\n",
    "def sampling(mu_log_variance):\n",
    "    mu, log_variance = mu_log_variance\n",
    "    epsilon = K.random_normal(shape=K.shape(mu), mean=0.0, stddev=1.0)\n",
    "    random_sample = mu + K.exp(log_variance/2) * epsilon\n",
    "    return random_sample\n",
    "\n",
    "encoder_output = tf.keras.layers.Lambda(sampling, name=\"encoder_output\")([encoder_mu, encoder_log_variance])\n",
    "\n",
    "encoder = Model(x, encoder_output, name=\"encoder_model\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 31)]              0         \n",
      "_________________________________________________________________\n",
      "decoder_dense_1 (Dense)      (None, 427800)            13689600  \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 200, 2139)         0         \n",
      "_________________________________________________________________\n",
      "decoder_rnn1 (GRU)           (None, 200)               1404600   \n",
      "_________________________________________________________________\n",
      "decoder_norm_2 (BatchNormali (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 2139, 200)         0         \n",
      "_________________________________________________________________\n",
      "decoder_reshape1 (Reshape)   (None, 276, 50, 31)       0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_tran_2 (Conv2DT (None, 276, 50, 31)       992       \n",
      "_________________________________________________________________\n",
      "decoder_norm_4 (BatchNormali (None, 276, 50, 31)       124       \n",
      "_________________________________________________________________\n",
      "decoder_output (LeakyReLU)   (None, 276, 50, 31)       0         \n",
      "=================================================================\n",
      "Total params: 15,096,116\n",
      "Trainable params: 15,095,654\n",
      "Non-trainable params: 462\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Decoder\n",
    "\n",
    "decoder_input = Input(shape=(latent_dim), name=\"decoder_input\")\n",
    "decoder_dense_layer1 = Dense(units=np.prod(shape_before_flatten), name=\"decoder_dense_1\")(decoder_input)\n",
    "decoder_reshape = Reshape(target_shape=shape_before_flatten)(decoder_dense_layer1)\n",
    "\n",
    "rnn_layer = GRU(units=rnn_unit, return_sequences=False, name='decoder_rnn1')(decoder_reshape)\n",
    "# rnn_layer = Bidirectional(GRU(units=rnn_unit, return_sequences=True, name='decoder_rnn1'))(decoder_reshape)\n",
    "# rnn_layer = TimeDistributed(Dense(rnn_unit), name='decoder_TD1')(rnn_layer)\n",
    "# rnn_layer = BatchNormalization(name=\"decoder_norm_1\")(rnn_layer)\n",
    "# rnn_layer = Bidirectional(GRU(units=rnn_unit, return_sequences=True, name='decoder_rnn2'))(rnn_layer)\n",
    "# rnn_layer = TimeDistributed(Dense(rnn_unit), name='decoder_TD2')(rnn_layer)\n",
    "rnn_layer = BatchNormalization(name=\"decoder_norm_2\")(rnn_layer)\n",
    "rnn_layer = RepeatVector(shape_before_flatten[1])(rnn_layer)\n",
    "cnn_input = Reshape(shape_before_reshape, name='decoder_reshape1')(rnn_layer)\n",
    "\n",
    "# decoder_conv_tran_layer1 = Conv2DTranspose(filters=8, kernel_size=(2, 2), padding=\"same\", strides=2, name=\"decoder_conv_tran_1\")(cnn_input)\n",
    "# decoder_norm_layer1 = BatchNormalization(name=\"decoder_norm_3\")(decoder_conv_tran_layer1)\n",
    "# decoder_activ_layer1 = tf.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_1\")(decoder_norm_layer1)\n",
    "\n",
    "decoder_conv_tran_layer2 = Conv2DTranspose(filters=feature_num, kernel_size=(1, 1), padding=\"same\", strides=1, name=\"decoder_conv_tran_2\")(cnn_input)\n",
    "decoder_norm_layer2 = BatchNormalization(name=\"decoder_norm_4\")(decoder_conv_tran_layer2)\n",
    "decoder_output = tf.keras.layers.LeakyReLU(name=\"decoder_output\")(decoder_norm_layer2 )\n",
    "\n",
    "decoder = Model(decoder_input, decoder_output, name=\"decoder_model\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VAE\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "VAE_input (InputLayer)       [(None, 276, 50, 31)]     0         \n",
      "_________________________________________________________________\n",
      "encoder_model (Functional)   (None, 31)                1414731   \n",
      "_________________________________________________________________\n",
      "decoder_model (Functional)   (None, 276, 50, 31)       15096116  \n",
      "=================================================================\n",
      "Total params: 16,510,847\n",
      "Trainable params: 16,509,923\n",
      "Non-trainable params: 924\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae_input = Input(shape=input_shape, name=\"VAE_input\")\n",
    "vae_encoder_output = encoder(vae_input)\n",
    "vae_decoder_output = decoder(vae_encoder_output)\n",
    "vae = Model(vae_input, vae_decoder_output, name=\"VAE\")\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(encoder_mu, encoder_log_variance):\n",
    "    def vae_reconstruction_loss(y_true, y_predict):\n",
    "        reconstruction_loss_factor = 1000\n",
    "        reconstruction_loss = K.mean(K.square(y_true-y_predict), axis=[1, 2, 3])\n",
    "        return reconstruction_loss_factor * reconstruction_loss\n",
    "\n",
    "    def vae_kl_loss(encoder_mu, encoder_log_variance):\n",
    "        kl_loss = -0.5 * K.sum(1.0 + encoder_log_variance - K.square(encoder_mu) - K.exp(encoder_log_variance), axis=[1,2,3])\n",
    "        return kl_loss\n",
    "\n",
    "    def vae_kl_loss_metric(y_true, y_predict):\n",
    "        kl_loss = -0.5 * K.sum(1.0 + encoder_log_variance - K.square(encoder_mu) - K.exp(encoder_log_variance), axis=[1,2,3])\n",
    "        return kl_loss\n",
    "\n",
    "    def vae_loss(y_true, y_predict):\n",
    "        reconstruction_loss = vae_reconstruction_loss(y_true, y_predict)\n",
    "        kl_loss = vae_kl_loss(y_true, y_predict)\n",
    "\n",
    "        loss = reconstruction_loss + kl_loss\n",
    "        return loss\n",
    "\n",
    "    return vae_loss\n",
    "\n",
    "vae.compile(optimizer=Adam(lr=0.0005), loss=loss_func(encoder_mu, encoder_log_variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987782656.0000\n",
      "Epoch 2/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987725312.0000 2s \n",
      "Epoch 3/500\n",
      "21/21 [==============================] - 4s 195ms/step - loss: 53987688448.0000 2s - ETA: 0s - loss: 768426547\n",
      "Epoch 4/500\n",
      "21/21 [==============================] - 4s 195ms/step - loss: 53987676160.0000\n",
      "Epoch 5/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987680256.0000\n",
      "Epoch 6/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987667968.0000 2s - loss: \n",
      "Epoch 7/500\n",
      "21/21 [==============================] - 4s 195ms/step - loss: 53987667968.0000\n",
      "Epoch 8/500\n",
      "21/21 [==============================] - 4s 195ms/step - loss: 53987655680.0000 2s\n",
      "Epoch 9/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987647488.0000\n",
      "Epoch 10/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987655680.0000\n",
      "Epoch 11/500\n",
      "21/21 [==============================] - 4s 193ms/step - loss: 53987647488.0000\n",
      "Epoch 12/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987643392.0000s - lo\n",
      "Epoch 13/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987643392.0000s - loss: 81238200\n",
      "Epoch 14/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987655680.0000s - loss: 7290\n",
      "Epoch 15/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987647488.0000\n",
      "Epoch 16/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987655680.0000 1s - loss: 11725809\n",
      "Epoch 17/500\n",
      "21/21 [==============================] - 4s 193ms/step - loss: 53987631104.0000s -\n",
      "Epoch 18/500\n",
      "21/21 [==============================] - 4s 194ms/step - loss: 53987635200.0000\n",
      "Epoch 19/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987631104.0000\n",
      "Epoch 20/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987643392.0000s - loss: 7209\n",
      "Epoch 21/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987635200.0000 2s - los - ETA: 1s - loss: 692025835\n",
      "Epoch 22/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987631104.0000 1s - loss: 94052024320.0 - ETA: 1s - loss: 73291571200 - ETA: 0s - loss: 56078303232.00\n",
      "Epoch 23/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987631104.0000 2s - loss: 120576131 - ETA: 1s - loss: 74027900928. - ETA: 0s - loss: 58943655936.0\n",
      "Epoch 24/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987622912.0000s - loss:  - ETA: 1s - loss: 73919840\n",
      "Epoch 25/500\n",
      "21/21 [==============================] - 4s 194ms/step - loss: 53987631104.0000\n",
      "Epoch 26/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987635200.0000 1s - loss: 693411348\n",
      "Epoch 27/500\n",
      "21/21 [==============================] - 4s 196ms/step - loss: 53987631104.0000s - lo - ETA: 0s - loss: 58981769216.\n",
      "Epoch 28/500\n",
      "21/21 [==============================] - 4s 193ms/step - loss: 53987631104.0000 2s - l\n",
      "Epoch 29/500\n",
      "21/21 [==============================] - 4s 193ms/step - loss: 53987631104.0000\n",
      "Epoch 30/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987647488.0000s - loss: 6140018176. - ETA: 2s - loss: 153453 - ETA: 1s - loss: 77762273\n",
      "Epoch 31/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987631104.0000 0s - loss: 68472578048.00 - ETA: 0s - loss: 61355057152.\n",
      "Epoch 32/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987635200.0000 2s - los - ETA: 1s - loss: 735117148\n",
      "Epoch 33/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987622912.0000\n",
      "Epoch 34/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987635200.0000\n",
      "Epoch 35/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987631104.0000 2s - loss:\n",
      "Epoch 36/500\n",
      "21/21 [==============================] - 4s 193ms/step - loss: 53987622912.0000\n",
      "Epoch 37/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987635200.0000\n",
      "Epoch 38/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987631104.0000 0s - loss: 60899094528.\n",
      "Epoch 39/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987631104.0000 2s - loss: 14 - ETA: 0s - loss: 58749931520.000 - ETA: 0s - loss: 55753797632.0\n",
      "Epoch 40/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987631104.0000 2s - loss - ETA: 0s - loss: 69877514\n",
      "Epoch 41/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987635200.0000s - loss\n",
      "Epoch 42/500\n",
      "21/21 [==============================] - 4s 196ms/step - loss: 53987631104.0000\n",
      "Epoch 43/500\n",
      "21/21 [==============================] - 4s 193ms/step - loss: 53987622912.0000\n",
      "Epoch 44/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987631104.0000s - loss - ETA: 1s - loss: 8311518720.0 - ETA: 1s - loss: 699652341\n",
      "Epoch 45/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987631104.0000\n",
      "Epoch 46/500\n",
      "21/21 [==============================] - 4s 194ms/step - loss: 53987635200.0000\n",
      "Epoch 47/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987631104.0000 2s - loss: \n",
      "Epoch 48/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987631104.0000 1s - loss: 704472924\n",
      "Epoch 49/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987622912.0000\n",
      "Epoch 50/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987631104.0000\n",
      "Epoch 51/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987635200.0000\n",
      "Epoch 52/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987635200.0000\n",
      "Epoch 53/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987631104.0000 1s - loss: 736484638\n",
      "Epoch 54/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987622912.0000s - loss: 38096 - ETA: 2s - loss: 1039\n",
      "Epoch 55/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987635200.0000s - loss: - ETA: 1s - loss: 344 - ETA: 0s - loss: 61821747200.\n",
      "Epoch 56/500\n",
      "21/21 [==============================] - 4s 193ms/step - loss: 53987622912.0000s - loss - ETA: 1s - loss: 867783\n",
      "Epoch 57/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987635200.0000 0s - loss: 56075431936.00\n",
      "Epoch 58/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987622912.0000s - loss\n",
      "Epoch 59/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987622912.0000\n",
      "Epoch 60/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987622912.0000\n",
      "Epoch 61/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987622912.0000\n",
      "Epoch 62/500\n",
      "21/21 [==============================] - 4s 193ms/step - loss: 53987631104.0000 2s - loss: 159 - ETA: 1s - loss: 733153935\n",
      "Epoch 63/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987622912.0000\n",
      "Epoch 64/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987643392.0000 1s - loss: 95192080384.0 - ETA: 1s - loss: 707798384\n",
      "Epoch 65/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987631104.0000 2s - loss: 18913908736 - ETA: 1s - loss: 12890517504.000 - ETA: 1s - loss: 12274890752.000 - ETA: 1s - loss: 12187170816. - ETA: 0s - loss: 61679177728.\n",
      "Epoch 66/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987631104.0000 0s - loss: 6992542105\n",
      "Epoch 67/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987631104.0000s - lo\n",
      "Epoch 68/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987618816.0000 2s - lo - ETA: 0s - loss: 58961047552.0\n",
      "Epoch 69/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987622912.0000 1s - loss: 925238\n",
      "Epoch 70/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987622912.00002s - loss\n",
      "Epoch 71/500\n",
      "21/21 [==============================] - 4s 193ms/step - loss: 53987622912.0000s - loss\n",
      "Epoch 72/500\n",
      "21/21 [==============================] - 4s 193ms/step - loss: 53987643392.0000 0s - loss: 58509848576.\n",
      "Epoch 73/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 4s 191ms/step - loss: 53987631104.0000\n",
      "Epoch 74/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987631104.0000\n",
      "Epoch 75/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987622912.0000\n",
      "Epoch 76/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987643392.0000\n",
      "Epoch 77/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987622912.0000\n",
      "Epoch 78/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987618816.0000\n",
      "Epoch 79/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987622912.0000\n",
      "Epoch 80/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987631104.0000\n",
      "Epoch 81/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987631104.0000 2s - loss: 11\n",
      "Epoch 82/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.0000 2s - loss: 10892 - ETA: 0s - loss: 56066920448.00\n",
      "Epoch 83/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987631104.0000 2s \n",
      "Epoch 84/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987635200.0000\n",
      "Epoch 85/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987631104.0000 2s - lo\n",
      "Epoch 86/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987622912.0000\n",
      "Epoch 87/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987622912.0000s - - ETA: 0s - loss: 65588785152\n",
      "Epoch 88/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987631104.0000 2s - loss: 146220 - ETA: 1s - loss: 78118027\n",
      "Epoch 89/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987622912.0000 2s - loss: 1597 - ETA: 1s - loss: 659118530\n",
      "Epoch 90/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987631104.0000\n",
      "Epoch 91/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987610624.0000s - loss: 79964\n",
      "Epoch 92/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987622912.0000\n",
      "Epoch 93/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987622912.0000s - loss: - ETA: 0s - loss: 62131331072.00 - ETA: 0s - loss: 56059731968.00\n",
      "Epoch 94/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987622912.0000\n",
      "Epoch 95/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987622912.0000s -\n",
      "Epoch 96/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987631104.0000 0s - loss: 66068762624.00 - ETA: 0s - loss: 59013705728.\n",
      "Epoch 97/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987631104.0000s - loss: 1594386 - ETA: 2s - lo\n",
      "Epoch 98/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987622912.0000 0s - loss: 58016923648.0\n",
      "Epoch 99/500\n",
      "21/21 [==============================] - 4s 193ms/step - loss: 53987622912.0000s -\n",
      "Epoch 100/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987631104.0000 2s - loss: 138300817 - ETA: 1s - loss: 870782\n",
      "Epoch 101/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987622912.0000\n",
      "Epoch 102/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987618816.0000s - - ETA: 1s - loss: 688898867\n",
      "Epoch 103/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987631104.0000\n",
      "Epoch 104/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987622912.0000 2s - loss: 135111 - ETA: 0s - loss: 6847969689\n",
      "Epoch 105/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987610624.0000\n",
      "Epoch 106/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987631104.0000\n",
      "Epoch 107/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987622912.0000 1s - loss: 75240259584.000 - ETA: 1s - loss: 702556651\n",
      "Epoch 108/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987635200.0000s \n",
      "Epoch 109/500\n",
      "21/21 [==============================] - 4s 193ms/step - loss: 53987631104.0000\n",
      "Epoch 110/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987631104.0000 2s - loss: 1890 - ETA: 1s - loss: 889861\n",
      "Epoch 111/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987618816.0000 2s - loss: 11\n",
      "Epoch 112/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987622912.0000 1s - loss: 76934946816.00 - ETA: 0s - loss: 6857601024\n",
      "Epoch 113/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987631104.0000 0s - loss: 6849142374\n",
      "Epoch 114/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987622912.0000\n",
      "Epoch 115/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987631104.0000\n",
      "Epoch 116/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987622912.0000 0s - loss: 64881418240\n",
      "Epoch 117/500\n",
      "21/21 [==============================] - 4s 193ms/step - loss: 53987618816.0000\n",
      "Epoch 118/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987618816.0000s - - ETA: 1s - loss: 73255051264 - ETA: 0s - loss: 55729332224.00\n",
      "Epoch 119/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987622912.0000\n",
      "Epoch 120/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987618816.0000 1s - loss: 1190254\n",
      "Epoch 121/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987610624.0000\n",
      "Epoch 122/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987622912.0000 1s - loss: 78882603\n",
      "Epoch 123/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987622912.0000 1s - loss: 727967744\n",
      "Epoch 124/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987618816.0000\n",
      "Epoch 125/500\n",
      "21/21 [==============================] - 4s 194ms/step - loss: 53987631104.0000 0s - loss: 55960633344.00\n",
      "Epoch 126/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987618816.0000 1s - loss: 8124432\n",
      "Epoch 127/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987622912.0000 2s - \n",
      "Epoch 128/500\n",
      "21/21 [==============================] - 4s 193ms/step - loss: 53987622912.0000\n",
      "Epoch 129/500\n",
      "21/21 [==============================] - 4s 198ms/step - loss: 53987622912.0000\n",
      "Epoch 130/500\n",
      "21/21 [==============================] - 4s 194ms/step - loss: 53987622912.0000\n",
      "Epoch 131/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987622912.0000 3s - loss: 21828007936.000 - ETA\n",
      "Epoch 132/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987622912.0000\n",
      "Epoch 133/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987618816.0000s - lo\n",
      "Epoch 134/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.0000\n",
      "Epoch 135/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987631104.0000\n",
      "Epoch 136/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987631104.0000\n",
      "Epoch 137/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987622912.0000 1s - loss: 11629211648 - ETA: 0s - loss: 65091633152\n",
      "Epoch 138/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987618816.0000\n",
      "Epoch 139/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987618816.0000\n",
      "Epoch 140/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987606528.0000\n",
      "Epoch 141/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987618816.0000\n",
      "Epoch 142/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987610624.0000\n",
      "Epoch 143/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987618816.0000\n",
      "Epoch 144/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987618816.0000 0s - loss: 61678477312.\n",
      "Epoch 145/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987618816.0000 2s - lo - ETA: 0s - loss: 58968346624.0\n",
      "Epoch 146/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987618816.0000 2s - loss: 147740 - ETA: 1s - loss: 75561689088.000 - ETA: 1s - loss: 708590551\n",
      "Epoch 147/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987631104.0000\n",
      "Epoch 148/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 4s 190ms/step - loss: 53987622912.0000\n",
      "Epoch 149/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987631104.0000\n",
      "Epoch 150/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987618816.0000 2s - loss: 13108771840.000 - ETA: 2s - loss: \n",
      "Epoch 151/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987618816.0000\n",
      "Epoch 152/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987622912.0000\n",
      "Epoch 153/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987610624.0000\n",
      "Epoch 154/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987610624.0000\n",
      "Epoch 155/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987618816.0000s - lo - ETA: 1s - loss: 1\n",
      "Epoch 156/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987622912.0000s - loss: 1126377 - ETA: 2s - loss: 3632430336.00 - ETA: 2s - loss: \n",
      "Epoch 157/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.0000\n",
      "Epoch 158/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987631104.0000 2s \n",
      "Epoch 159/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987631104.0000 2s - loss: 21198644838 - ETA: 2s - loss: \n",
      "Epoch 160/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.0000: 1s - loss: 864542\n",
      "Epoch 161/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987631104.0000\n",
      "Epoch 162/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987618816.0000\n",
      "Epoch 163/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987622912.0000 0s - loss: 61816242176.\n",
      "Epoch 164/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.0000\n",
      "Epoch 165/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987610624.0000\n",
      "Epoch 166/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987618816.0000 2s - l - ETA: 0s - loss: 55744552960.00\n",
      "Epoch 167/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987622912.0000 2s - \n",
      "Epoch 168/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987631104.0000\n",
      "Epoch 169/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987618816.0000s - los - ETA: 0s - loss: 59001548800.0\n",
      "Epoch 170/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.0000 1s - loss: 11297589248 - ETA: 0s - loss: 56043458560.00\n",
      "Epoch 171/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.0000 0s - loss: 56043184128.00\n",
      "Epoch 172/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987622912.0000\n",
      "Epoch 173/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987610624.0000\n",
      "Epoch 174/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987610624.0000 1s - loss: 743028490\n",
      "Epoch 175/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987618816.0000 2s - loss: 11\n",
      "Epoch 176/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987631104.0000 1s - loss: 812540559 - ETA: 0s - loss: 56089399296.00\n",
      "Epoch 177/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987610624.0000\n",
      "Epoch 178/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987618816.0000\n",
      "Epoch 179/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987622912.0000\n",
      "Epoch 180/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987618816.0000 2s - los\n",
      "Epoch 181/500\n",
      "21/21 [==============================] - 4s 193ms/step - loss: 53987618816.0000: 1s - loss: 88836\n",
      "Epoch 182/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987622912.00002s - loss: 81\n",
      "Epoch 183/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987622912.0000\n",
      "Epoch 184/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987622912.0000 0s - loss: 58983129088\n",
      "Epoch 185/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987622912.0000 0s - loss: 6550218752\n",
      "Epoch 186/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987610624.0000\n",
      "Epoch 187/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987610624.0000\n",
      "Epoch 188/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.0000 1s - loss: 12598\n",
      "Epoch 189/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987622912.0000s - loss: 459152128 - ETA: 2s - loss: \n",
      "Epoch 190/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987618816.0000\n",
      "Epoch 191/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987622912.0000s - loss: 3812 - ETA: 1s - loss: 870406\n",
      "Epoch 192/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987610624.0000s\n",
      "Epoch 193/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987622912.0000 1s - loss: 73352880\n",
      "Epoch 194/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987622912.0000\n",
      "Epoch 195/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987622912.0000s - \n",
      "Epoch 196/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987618816.0000 0s - loss: 65464635392\n",
      "Epoch 197/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.0000\n",
      "Epoch 198/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987618816.0000\n",
      "Epoch 199/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987610624.0000 2s - los - ETA: 0s - loss: 6556000256\n",
      "Epoch 200/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.00002s - loss: 13290 - ETA: 0s - loss: 963040563\n",
      "Epoch 201/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987618816.0000\n",
      "Epoch 202/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987622912.0000 0s - loss: 6912704512\n",
      "Epoch 203/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987618816.0000\n",
      "Epoch 204/500\n",
      "21/21 [==============================] - 4s 195ms/step - loss: 53987606528.0000\n",
      "Epoch 205/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987622912.0000\n",
      "Epoch 206/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987618816.0000\n",
      "Epoch 207/500\n",
      "21/21 [==============================] - 4s 195ms/step - loss: 53987618816.0000\n",
      "Epoch 208/500\n",
      "21/21 [==============================] - 4s 193ms/step - loss: 53987618816.0000 1s - loss: 75018117\n",
      "Epoch 209/500\n",
      "21/21 [==============================] - 4s 193ms/step - loss: 53987618816.0000\n",
      "Epoch 210/500\n",
      "21/21 [==============================] - 4s 193ms/step - loss: 53987622912.0000\n",
      "Epoch 211/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987618816.0000\n",
      "Epoch 212/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987610624.0000\n",
      "Epoch 213/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987622912.0000 2\n",
      "Epoch 214/500\n",
      "21/21 [==============================] - 4s 193ms/step - loss: 53987622912.0000\n",
      "Epoch 215/500\n",
      "21/21 [==============================] - 4s 195ms/step - loss: 53987618816.0000 1s - loss: 690587648\n",
      "Epoch 216/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987618816.0000s \n",
      "Epoch 217/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987622912.0000 1s - loss: 74319142\n",
      "Epoch 218/500\n",
      "21/21 [==============================] - 4s 194ms/step - loss: 53987618816.0000\n",
      "Epoch 219/500\n",
      "21/21 [==============================] - 4s 195ms/step - loss: 53987622912.0000\n",
      "Epoch 220/500\n",
      "21/21 [==============================] - 4s 196ms/step - loss: 53987622912.0000\n",
      "Epoch 221/500\n",
      "21/21 [==============================] - 4s 194ms/step - loss: 53987610624.0000\n",
      "Epoch 222/500\n",
      "21/21 [==============================] - 4s 194ms/step - loss: 53987618816.0000\n",
      "Epoch 223/500\n",
      "21/21 [==============================] - 4s 195ms/step - loss: 53987622912.0000\n",
      "Epoch 224/500\n",
      "21/21 [==============================] - 4s 195ms/step - loss: 53987618816.0000\n",
      "Epoch 225/500\n",
      "21/21 [==============================] - 4s 196ms/step - loss: 53987618816.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226/500\n",
      "21/21 [==============================] - 4s 195ms/step - loss: 53987622912.0000\n",
      "Epoch 227/500\n",
      "21/21 [==============================] - 4s 196ms/step - loss: 53987631104.0000\n",
      "Epoch 228/500\n",
      "21/21 [==============================] - 4s 193ms/step - loss: 53987631104.0000\n",
      "Epoch 229/500\n",
      "21/21 [==============================] - 4s 194ms/step - loss: 53987618816.0000\n",
      "Epoch 230/500\n",
      "21/21 [==============================] - 4s 194ms/step - loss: 53987618816.0000\n",
      "Epoch 231/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987618816.0000\n",
      "Epoch 232/500\n",
      "21/21 [==============================] - 4s 194ms/step - loss: 53987610624.0000 0s - loss: 56068943872.00\n",
      "Epoch 233/500\n",
      "21/21 [==============================] - 4s 195ms/step - loss: 53987631104.0000\n",
      "Epoch 234/500\n",
      "21/21 [==============================] - 4s 195ms/step - loss: 53987610624.0000\n",
      "Epoch 235/500\n",
      "21/21 [==============================] - 4s 196ms/step - loss: 53987618816.0000\n",
      "Epoch 236/500\n",
      "21/21 [==============================] - 4s 196ms/step - loss: 53987610624.0000: 1s - loss: 88587\n",
      "Epoch 237/500\n",
      "21/21 [==============================] - 4s 197ms/step - loss: 53987622912.0000\n",
      "Epoch 238/500\n",
      "21/21 [==============================] - 4s 194ms/step - loss: 53987622912.0000\n",
      "Epoch 239/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987618816.0000 2s - loss: 1361509 - ETA: 2s - loss:  - ETA: 0s - loss: 56054931456.00\n",
      "Epoch 240/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987618816.0000\n",
      "Epoch 241/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987622912.0000 0s - loss: 61999022080.\n",
      "Epoch 242/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987610624.0000 2s - loss: 14829985792.000 - ETA: 1s - loss: 13566882816.000 - ETA: 1s - loss: 13711798272.00 - ETA: 1s - loss: 13332965\n",
      "Epoch 243/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987610624.0000s - loss: 41\n",
      "Epoch 244/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987622912.0000\n",
      "Epoch 245/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987606528.0000\n",
      "Epoch 246/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987622912.0000 2s - loss: 1545 - ETA: 1s - loss: 80142286848.00 - ETA: 1s - loss: 69537185792.00 - ETA: 0s - loss: 65503461376\n",
      "Epoch 247/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987618816.0000s - loss: 1078 - ETA: 2s - loss: 111791865856. - ETA: 1s - loss: 924789\n",
      "Epoch 248/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987622912.0000 2s - loss: \n",
      "Epoch 249/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987618816.0000\n",
      "Epoch 250/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987622912.0000 1s - loss: 8474117\n",
      "Epoch 251/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987618816.0000s - loss: 563747712 - ETA: 2s - loss: 20203780096.00 - ETA: 2s - loss: 1671 - ETA: 0s - loss: 56070545408.00\n",
      "Epoch 252/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987618816.0000\n",
      "Epoch 253/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987622912.0000\n",
      "Epoch 254/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.0000s - los\n",
      "Epoch 255/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987618816.0000 1s - loss: 73429762\n",
      "Epoch 256/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987618816.0000\n",
      "Epoch 257/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987610624.0000\n",
      "Epoch 258/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987610624.0000\n",
      "Epoch 259/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987622912.0000\n",
      "Epoch 260/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987622912.0000\n",
      "Epoch 261/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987618816.0000\n",
      "Epoch 262/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987606528.0000: 1s - loss: 86994\n",
      "Epoch 263/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987618816.0000\n",
      "Epoch 264/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987610624.0000s - loss:\n",
      "Epoch 265/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987618816.0000\n",
      "Epoch 266/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987610624.0000 0s - loss: 61736935424.\n",
      "Epoch 267/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987618816.0000 1s - loss: 74718650\n",
      "Epoch 268/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987618816.0000\n",
      "Epoch 269/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.0000\n",
      "Epoch 270/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987622912.0000 1s - loss: 949483\n",
      "Epoch 271/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.0000\n",
      "Epoch 272/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987618816.0000 2s - lo\n",
      "Epoch 273/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987606528.0000 0s - loss: 65306329088\n",
      "Epoch 274/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987606528.0000\n",
      "Epoch 275/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987618816.0000 2s - loss: 15982936064 - ETA: 2s -\n",
      "Epoch 276/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987618816.0000 2s - loss: 11\n",
      "Epoch 277/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987622912.0000\n",
      "Epoch 278/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987618816.0000 0s - loss: 6581944729\n",
      "Epoch 279/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987610624.0000\n",
      "Epoch 280/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987618816.0000\n",
      "Epoch 281/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987618816.0000\n",
      "Epoch 282/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987618816.0000\n",
      "Epoch 283/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987610624.0000s - loss: 5304746496.00 - ETA: 2s - loss: 5130941440. - ETA: 2s - lo\n",
      "Epoch 284/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987622912.0000\n",
      "Epoch 285/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987618816.0000\n",
      "Epoch 286/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987610624.0000 2s - loss:\n",
      "Epoch 287/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987606528.0000 2s - loss: 11\n",
      "Epoch 288/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987631104.0000 0s - loss: 61812580352.\n",
      "Epoch 289/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987610624.0000 0s - loss: 61459894272.\n",
      "Epoch 290/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987631104.0000 2s - lo\n",
      "Epoch 291/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987622912.0000\n",
      "Epoch 292/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987610624.0000 0s - loss: 65578352640\n",
      "Epoch 293/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987618816.0000\n",
      "Epoch 294/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.0000\n",
      "Epoch 295/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987610624.0000 0s - loss: 56086405120.00\n",
      "Epoch 296/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987618816.0000 2s - loss: 1072\n",
      "Epoch 297/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987618816.0000 1s - loss: 8434038\n",
      "Epoch 298/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987622912.0000\n",
      "Epoch 299/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987618816.0000 0s - loss: 56085569536.00\n",
      "Epoch 300/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.0000\n",
      "Epoch 301/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 4s 189ms/step - loss: 53987610624.0000 2s - loss: 1088\n",
      "Epoch 302/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987618816.0000 2s - loss: 9947 - ETA: 1s - loss: 7214\n",
      "Epoch 303/500\n",
      "21/21 [==============================] - 4s 195ms/step - loss: 53987618816.0000\n",
      "Epoch 304/500\n",
      "21/21 [==============================] - 4s 195ms/step - loss: 53987631104.0000\n",
      "Epoch 305/500\n",
      "21/21 [==============================] - 4s 194ms/step - loss: 53987618816.0000\n",
      "Epoch 306/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987610624.0000\n",
      "Epoch 307/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987618816.0000\n",
      "Epoch 308/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987610624.0000\n",
      "Epoch 309/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987610624.0000\n",
      "Epoch 310/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987618816.0000: 1s - loss: 87949328384.000 - ETA: 1s - loss: 8134741\n",
      "Epoch 311/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987622912.0000\n",
      "Epoch 312/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987631104.0000\n",
      "Epoch 313/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987610624.0000\n",
      "Epoch 314/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987618816.0000 2s - loss: 28482019328.00 - ETA: 2s - lo\n",
      "Epoch 315/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987622912.0000\n",
      "Epoch 316/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987622912.0000 2s - loss: 98672\n",
      "Epoch 317/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987618816.0000s - l - ETA: 0s - loss: 7270674944\n",
      "Epoch 318/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987618816.0000\n",
      "Epoch 319/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987618816.0000\n",
      "Epoch 320/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987610624.0000\n",
      "Epoch 321/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987610624.0000 1s - loss: 735170478\n",
      "Epoch 322/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987610624.0000 1s - loss: 65187016704.000 - ETA: 0s - loss: 6118463078\n",
      "Epoch 323/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987622912.0000\n",
      "Epoch 324/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987618816.0000\n",
      "Epoch 325/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.0000\n",
      "Epoch 326/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987618816.0000\n",
      "Epoch 327/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987610624.0000 2s - loss: 15515976704.000 - ETA: 2s - loss:\n",
      "Epoch 328/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987610624.0000\n",
      "Epoch 329/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987610624.0000 1s - loss: 732134686\n",
      "Epoch 330/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.0000\n",
      "Epoch 331/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987610624.0000 2s - loss:\n",
      "Epoch 332/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.0000\n",
      "Epoch 333/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987618816.0000\n",
      "Epoch 334/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987622912.0000\n",
      "Epoch 335/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987610624.0000 0s - loss: 6622647500\n",
      "Epoch 336/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987606528.0000s - loss: \n",
      "Epoch 337/500\n",
      "21/21 [==============================] - 4s 194ms/step - loss: 53987622912.0000\n",
      "Epoch 338/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987618816.0000 1s - loss: 8338630\n",
      "Epoch 339/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987610624.0000\n",
      "Epoch 340/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987610624.0000 2s - loss: 12671971328 - ETA: 1s - loss: 929405\n",
      "Epoch 341/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987606528.0000\n",
      "Epoch 342/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987622912.0000\n",
      "Epoch 343/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.0000\n",
      "Epoch 344/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987618816.0000\n",
      "Epoch 345/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987622912.0000\n",
      "Epoch 346/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987610624.0000\n",
      "Epoch 347/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987610624.0000 - ETA: 0s - loss: 61505667072.\n",
      "Epoch 348/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.0000\n",
      "Epoch 349/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.0000\n",
      "Epoch 350/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987618816.0000\n",
      "Epoch 351/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987618816.0000\n",
      "Epoch 352/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987618816.0000\n",
      "Epoch 353/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.0000s - loss: 3737054 - ETA: 2s - loss - ETA: 0s - loss: 58415120384.0\n",
      "Epoch 354/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987606528.0000\n",
      "Epoch 355/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987610624.0000\n",
      "Epoch 356/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987610624.0000\n",
      "Epoch 357/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987618816.0000\n",
      "Epoch 358/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987610624.0000 1s - loss: 743516979\n",
      "Epoch 359/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987618816.0000\n",
      "Epoch 360/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987610624.0000\n",
      "Epoch 361/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987606528.0000s - loss: 2369 - ETA: 1s - loss: 78525980\n",
      "Epoch 362/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987622912.0000\n",
      "Epoch 363/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987618816.0000\n",
      "Epoch 364/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987618816.0000\n",
      "Epoch 365/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987610624.0000 2s - loss: 11\n",
      "Epoch 366/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987610624.00001s - loss: 92927\n",
      "Epoch 367/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987622912.0000 0s - loss: 61275156480.\n",
      "Epoch 368/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987610624.0000\n",
      "Epoch 369/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.0000\n",
      "Epoch 370/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987622912.0000\n",
      "Epoch 371/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.0000\n",
      "Epoch 372/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987622912.0000 1s - loss: 76041617408. - ETA: 0s - loss: 65377701888\n",
      "Epoch 373/500\n",
      "21/21 [==============================] - 4s 193ms/step - loss: 53987610624.0000\n",
      "Epoch 374/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987610624.0000 2s - loss: 154 - ETA: 1s - loss: 869294284 - ETA: 0s - loss: 61490544640.\n",
      "Epoch 375/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987598336.0000s - loss:\n",
      "Epoch 376/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.0000 2s - loss: 202310811648.00 - ETA: 2s - loss: 170031 - ETA: 1s - loss: 8742996377 - ETA: 0s - loss: 58909683712.\n",
      "Epoch 377/500\n",
      "21/21 [==============================] - 4s 186ms/step - loss: 53987610624.0000 1s - loss: \n",
      "Epoch 378/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 4s 190ms/step - loss: 53987618816.0000s - loss: 4\n",
      "Epoch 379/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987618816.0000 0s - loss: 55671238656.0\n",
      "Epoch 380/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987618816.0000 2s - loss: 78 - ETA: 1s - loss: 75675811\n",
      "Epoch 381/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987622912.0000\n",
      "Epoch 382/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987618816.0000 2s - loss: 29432055808.0 - ETA: 2s - l\n",
      "Epoch 383/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987610624.0000: 1s - loss: 871576\n",
      "Epoch 384/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987622912.0000 1s - loss: 703340216\n",
      "Epoch 385/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987622912.0000\n",
      "Epoch 386/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987610624.0000 1s - loss: 1\n",
      "Epoch 387/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987618816.0000\n",
      "Epoch 388/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987606528.0000\n",
      "Epoch 389/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987618816.0000\n",
      "Epoch 390/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.0000\n",
      "Epoch 391/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987622912.0000 1s - loss: 93\n",
      "Epoch 392/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987618816.0000\n",
      "Epoch 393/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.0000\n",
      "Epoch 394/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987618816.0000s - los\n",
      "Epoch 395/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987606528.0000 1s - loss: 79007440\n",
      "Epoch 396/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987622912.0000s - lo\n",
      "Epoch 397/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987606528.0000\n",
      "Epoch 398/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987610624.0000: 1s - loss: 840683\n",
      "Epoch 399/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987622912.0000\n",
      "Epoch 400/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987610624.0000\n",
      "Epoch 401/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987610624.0000\n",
      "Epoch 402/500\n",
      "21/21 [==============================] - 4s 185ms/step - loss: 53987606528.0000\n",
      "Epoch 403/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987618816.0000 2s - loss: 1536865 - ETA: 0s - loss: 58977759232.0\n",
      "Epoch 404/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987622912.0000 2s - loss: - ETA: 0s - loss: 61346713600.\n",
      "Epoch 405/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.0000 1s - loss: 741300387\n",
      "Epoch 406/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987610624.0000\n",
      "Epoch 407/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987610624.0000\n",
      "Epoch 408/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987610624.0000\n",
      "Epoch 409/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987606528.0000\n",
      "Epoch 410/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987618816.0000s \n",
      "Epoch 411/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987610624.0000\n",
      "Epoch 412/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987622912.0000\n",
      "Epoch 413/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987610624.0000\n",
      "Epoch 414/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987618816.0000\n",
      "Epoch 415/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987618816.0000\n",
      "Epoch 416/500\n",
      "21/21 [==============================] - 4s 186ms/step - loss: 53987606528.0000\n",
      "Epoch 417/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987618816.0000 1s - loss: 115730370 - ETA: 0s - loss: 9538230272.0\n",
      "Epoch 418/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987610624.0000\n",
      "Epoch 419/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987622912.0000\n",
      "Epoch 420/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987610624.0000\n",
      "Epoch 421/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987610624.0000 0s - loss: 6502483558\n",
      "Epoch 422/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.0000 0s - loss: 61201752064\n",
      "Epoch 423/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987631104.0000\n",
      "Epoch 424/500\n",
      "21/21 [==============================] - 4s 186ms/step - loss: 53987610624.0000\n",
      "Epoch 425/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987618816.0000 1s - loss: 11571944448. - ETA: 0s - loss: 60823158784.\n",
      "Epoch 426/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987618816.0000\n",
      "Epoch 427/500\n",
      "21/21 [==============================] - 4s 185ms/step - loss: 53987622912.0000\n",
      "Epoch 428/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987622912.0000 2s - loss\n",
      "Epoch 429/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987610624.0000\n",
      "Epoch 430/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.0000\n",
      "Epoch 431/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987618816.0000 2s - loss: 1\n",
      "Epoch 432/500\n",
      "21/21 [==============================] - 4s 186ms/step - loss: 53987622912.0000 2s - loss: 11\n",
      "Epoch 433/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987622912.0000\n",
      "Epoch 434/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987610624.0000\n",
      "Epoch 435/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987610624.0000\n",
      "Epoch 436/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987622912.0000\n",
      "Epoch 437/500\n",
      "21/21 [==============================] - 4s 186ms/step - loss: 53987618816.0000\n",
      "Epoch 438/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987610624.0000\n",
      "Epoch 439/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987610624.0000\n",
      "Epoch 440/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987618816.0000\n",
      "Epoch 441/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987610624.0000 2s - loss: 13\n",
      "Epoch 442/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987618816.0000\n",
      "Epoch 443/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987610624.0000s - loss: 9011821568. - ETA: 1s - loss: 786650675 - ETA: 0s - loss: 55887773696.0\n",
      "Epoch 444/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987618816.0000s - loss: 27974\n",
      "Epoch 445/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987622912.0000\n",
      "Epoch 446/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987610624.0000 0s - loss: 6658593996\n",
      "Epoch 447/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987618816.0000\n",
      "Epoch 448/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987610624.0000\n",
      "Epoch 449/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987622912.0000\n",
      "Epoch 450/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987610624.0000\n",
      "Epoch 451/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987610624.0000 2s - loss:\n",
      "Epoch 452/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987610624.0000\n",
      "Epoch 453/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987610624.0000 2s - loss: 1896098 - ETA: 1s - loss: 1011\n",
      "Epoch 454/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987618816.0000\n",
      "Epoch 455/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987610624.0000s - loss: 78361\n",
      "Epoch 456/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987610624.0000\n",
      "Epoch 457/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 4s 190ms/step - loss: 53987618816.0000s -\n",
      "Epoch 458/500\n",
      "21/21 [==============================] - 4s 186ms/step - loss: 53987610624.0000s - loss: \n",
      "Epoch 459/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987618816.0000\n",
      "Epoch 460/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987610624.0000\n",
      "Epoch 461/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987606528.0000\n",
      "Epoch 462/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987622912.0000\n",
      "Epoch 463/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987618816.0000 2s - loss: 98\n",
      "Epoch 464/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987618816.0000\n",
      "Epoch 465/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987606528.0000\n",
      "Epoch 466/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987610624.0000\n",
      "Epoch 467/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987618816.0000\n",
      "Epoch 468/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987618816.0000s - loss: 606548838 - ETA - ETA: 0s - loss: 56062660608.00\n",
      "Epoch 469/500\n",
      "21/21 [==============================] - 4s 193ms/step - loss: 53987618816.0000\n",
      "Epoch 470/500\n",
      "21/21 [==============================] - 4s 194ms/step - loss: 53987631104.0000\n",
      "Epoch 471/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987610624.0000 0s - loss: 58925154304.0\n",
      "Epoch 472/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987618816.0000\n",
      "Epoch 473/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987610624.0000\n",
      "Epoch 474/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987610624.0000 1s - loss: 12357297\n",
      "Epoch 475/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987618816.0000 0s - loss: 56042029056.00\n",
      "Epoch 476/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987618816.0000 2s - lo\n",
      "Epoch 477/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987610624.0000\n",
      "Epoch 478/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987622912.0000\n",
      "Epoch 479/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987622912.0000 2s - lo\n",
      "Epoch 480/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.0000 1s - loss: 8210228\n",
      "Epoch 481/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987606528.0000\n",
      "Epoch 482/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987610624.0000s - loss: - ETA: 0s - loss: 60996161536.\n",
      "Epoch 483/500\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 53987610624.0000\n",
      "Epoch 484/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.0000\n",
      "Epoch 485/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987622912.0000\n",
      "Epoch 486/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987618816.0000\n",
      "Epoch 487/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.0000 2s - loss:\n",
      "Epoch 488/500\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 53987618816.0000: 1s - loss: 87868\n",
      "Epoch 489/500\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 53987606528.0000 2s - los\n",
      "Epoch 490/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987610624.0000\n",
      "Epoch 491/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987618816.0000 0s - loss: 65115590656\n",
      "Epoch 492/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987610624.0000 0s - loss: 64877518848\n",
      "Epoch 493/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987610624.0000\n",
      "Epoch 494/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987610624.0000 2s - loss: 107\n",
      "Epoch 495/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.0000\n",
      "Epoch 496/500\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 53987618816.0000 0s - loss: 55656534016.00\n",
      "Epoch 497/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987618816.0000\n",
      "Epoch 498/500\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 53987618816.0000s - los\n",
      "Epoch 499/500\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 53987610624.0000\n",
      "Epoch 500/500\n",
      "21/21 [==============================] - 4s 181ms/step - loss: 53987610624.0000 0s - loss: 6617009356\n"
     ]
    }
   ],
   "source": [
    "### Train the model###\n",
    "\n",
    "#Fit it to some training data\n",
    "hist = vae.fit(np.array(X_train).transpose([0,1,2,3]), np.array(X_train).transpose([0,1,2,3]),epochs=500, batch_size=None,\n",
    "              verbose=1, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display acc, loss\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "\n",
    "# acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "# acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "# acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 49ms/step - loss: 3854244096.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3854244096.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Test the model###\n",
    "\n",
    "vae.evaluate(np.array(X_test).transpose([0,1,2,3]), np.array(X_test).transpose([0,1,2,3]), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc(enco, bi_class, num_classes):\n",
    "\n",
    "#     den = Dense(17)(enco)\n",
    "#     den = BatchNormalization()(den)\n",
    "#     den = tf.keras.layers.LeakyReLU()(den)\n",
    "    if bi_class == 0:\n",
    "        den = Dense(num_classes, activation='softmax')(enco)\n",
    "    else:\n",
    "        den = Dense(2, activation='softmax')(enco)\n",
    "#     den = BatchNormalization()(den)\n",
    "#     den = tf.keras.layers.LeakyReLU()(den)\n",
    "#     den = Dense(7)(den)\n",
    "#     den = BatchNormalization()(den)\n",
    "#     out = tf.keras.activations.softmax(den)\n",
    "    \n",
    "    return den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Classification_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 276, 50, 31)]     0         \n",
      "_________________________________________________________________\n",
      "encoder_model (Functional)   (None, 31)                1414731   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 224       \n",
      "=================================================================\n",
      "Total params: 1,414,955\n",
      "Trainable params: 224\n",
      "Non-trainable params: 1,414,731\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encode = encoder(feature_input)\n",
    "full_model = Model(feature_input,fc(encode, bi_class, num_classes), name=\"Classification_model\")\n",
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in full_model.layers[0:2]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "17/17 [==============================] - 3s 155ms/step - loss: 1.9153 - accuracy: 0.1974 - auc_3: 0.6201 - f1_score: 0.1453 - val_loss: 3.4387 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1449 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/500\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.8720 - accuracy: 0.2049 - auc_3: 0.6441 - f1_score: 0.1703 - val_loss: 3.0767 - val_accuracy: 0.0075 - val_auc_3: 0.1930 - val_f1_score: 0.0034\n",
      "Epoch 3/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8482 - accuracy: 0.2387 - auc_3: 0.6560 - f1_score: 0.1886 - val_loss: 3.2067 - val_accuracy: 0.0226 - val_auc_3: 0.1954 - val_f1_score: 0.0101\n",
      "Epoch 4/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8271 - accuracy: 0.2350 - auc_3: 0.6619 - f1_score: 0.1914 - val_loss: 2.8332 - val_accuracy: 0.0075 - val_auc_3: 0.2758 - val_f1_score: 0.0034\n",
      "Epoch 5/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8354 - accuracy: 0.2256 - auc_3: 0.6569 - f1_score: 0.1689 - val_loss: 2.9220 - val_accuracy: 0.0301 - val_auc_3: 0.1882 - val_f1_score: 0.0154\n",
      "Epoch 6/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8276 - accuracy: 0.2575 - auc_3: 0.6589 - f1_score: 0.2054 - val_loss: 3.7062 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1615 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.8308 - accuracy: 0.2632 - auc_3: 0.6696 - f1_score: 0.1974 - val_loss: 2.9714 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1801 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7972 - accuracy: 0.2538 - auc_3: 0.6799 - f1_score: 0.1858 - val_loss: 3.0135 - val_accuracy: 0.0150 - val_auc_3: 0.2228 - val_f1_score: 0.0068\n",
      "Epoch 9/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8263 - accuracy: 0.2331 - auc_3: 0.6605 - f1_score: 0.1879 - val_loss: 3.4435 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1289 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8174 - accuracy: 0.2481 - auc_3: 0.6685 - f1_score: 0.1843 - val_loss: 2.7224 - val_accuracy: 0.0376 - val_auc_3: 0.3150 - val_f1_score: 0.0188\n",
      "Epoch 11/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8209 - accuracy: 0.2199 - auc_3: 0.6654 - f1_score: 0.1609 - val_loss: 2.9560 - val_accuracy: 0.0075 - val_auc_3: 0.2291 - val_f1_score: 0.0034\n",
      "Epoch 12/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8378 - accuracy: 0.2049 - auc_3: 0.6554 - f1_score: 0.1752 - val_loss: 3.0955 - val_accuracy: 0.0000e+00 - val_auc_3: 0.2131 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8062 - accuracy: 0.2650 - auc_3: 0.6761 - f1_score: 0.2129 - val_loss: 2.7694 - val_accuracy: 0.0301 - val_auc_3: 0.2869 - val_f1_score: 0.0155\n",
      "Epoch 14/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8068 - accuracy: 0.2350 - auc_3: 0.6724 - f1_score: 0.1861 - val_loss: 3.1652 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1988 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8102 - accuracy: 0.2462 - auc_3: 0.6738 - f1_score: 0.2004 - val_loss: 2.7387 - val_accuracy: 0.0075 - val_auc_3: 0.2939 - val_f1_score: 0.0034\n",
      "Epoch 16/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7808 - accuracy: 0.2669 - auc_3: 0.6822 - f1_score: 0.2007 - val_loss: 2.9070 - val_accuracy: 0.0150 - val_auc_3: 0.2261 - val_f1_score: 0.0068\n",
      "Epoch 17/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7869 - accuracy: 0.2387 - auc_3: 0.6753 - f1_score: 0.1965 - val_loss: 3.5227 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1409 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8565 - accuracy: 0.2274 - auc_3: 0.6593 - f1_score: 0.1582 - val_loss: 2.9053 - val_accuracy: 0.0150 - val_auc_3: 0.2320 - val_f1_score: 0.0087\n",
      "Epoch 19/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8398 - accuracy: 0.2331 - auc_3: 0.6666 - f1_score: 0.1766 - val_loss: 2.8415 - val_accuracy: 0.0000e+00 - val_auc_3: 0.2520 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8098 - accuracy: 0.2594 - auc_3: 0.6727 - f1_score: 0.2115 - val_loss: 2.8797 - val_accuracy: 0.0752 - val_auc_3: 0.3008 - val_f1_score: 0.0336\n",
      "Epoch 21/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8042 - accuracy: 0.2312 - auc_3: 0.6739 - f1_score: 0.1707 - val_loss: 3.0843 - val_accuracy: 0.0150 - val_auc_3: 0.2392 - val_f1_score: 0.0088\n",
      "Epoch 22/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8010 - accuracy: 0.2632 - auc_3: 0.6736 - f1_score: 0.2271 - val_loss: 2.7814 - val_accuracy: 0.0301 - val_auc_3: 0.2670 - val_f1_score: 0.0156\n",
      "Epoch 23/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8056 - accuracy: 0.2500 - auc_3: 0.6734 - f1_score: 0.1906 - val_loss: 2.8797 - val_accuracy: 0.0150 - val_auc_3: 0.2543 - val_f1_score: 0.0068\n",
      "Epoch 24/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7870 - accuracy: 0.2688 - auc_3: 0.6836 - f1_score: 0.2052 - val_loss: 2.7999 - val_accuracy: 0.0301 - val_auc_3: 0.2740 - val_f1_score: 0.0156\n",
      "Epoch 25/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.8317 - accuracy: 0.2613 - auc_3: 0.6698 - f1_score: 0.1988 - val_loss: 2.8708 - val_accuracy: 0.0075 - val_auc_3: 0.2773 - val_f1_score: 0.0054\n",
      "Epoch 26/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.8592 - accuracy: 0.2218 - auc_3: 0.6487 - f1_score: 0.1835 - val_loss: 2.9526 - val_accuracy: 0.0301 - val_auc_3: 0.2505 - val_f1_score: 0.0133\n",
      "Epoch 27/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7959 - accuracy: 0.2613 - auc_3: 0.6747 - f1_score: 0.2020 - val_loss: 3.2507 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1891 - val_f1_score: 0.0000e+00\n",
      "Epoch 28/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7956 - accuracy: 0.2538 - auc_3: 0.6817 - f1_score: 0.1851 - val_loss: 3.0111 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1977 - val_f1_score: 0.0000e+00\n",
      "Epoch 29/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8152 - accuracy: 0.2519 - auc_3: 0.6614 - f1_score: 0.1910 - val_loss: 2.8077 - val_accuracy: 0.0150 - val_auc_3: 0.2608 - val_f1_score: 0.0068\n",
      "Epoch 30/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7946 - accuracy: 0.2425 - auc_3: 0.6809 - f1_score: 0.1835 - val_loss: 2.6388 - val_accuracy: 0.0977 - val_auc_3: 0.3354 - val_f1_score: 0.0461\n",
      "Epoch 31/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8064 - accuracy: 0.2368 - auc_3: 0.6617 - f1_score: 0.2026 - val_loss: 3.3532 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1920 - val_f1_score: 0.0000e+00\n",
      "Epoch 32/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7847 - accuracy: 0.2613 - auc_3: 0.6873 - f1_score: 0.2023 - val_loss: 2.6960 - val_accuracy: 0.0752 - val_auc_3: 0.3171 - val_f1_score: 0.0336\n",
      "Epoch 33/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8165 - accuracy: 0.2086 - auc_3: 0.6671 - f1_score: 0.1554 - val_loss: 2.7160 - val_accuracy: 0.0226 - val_auc_3: 0.3225 - val_f1_score: 0.0101\n",
      "Epoch 34/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7807 - accuracy: 0.2763 - auc_3: 0.6851 - f1_score: 0.2099 - val_loss: 3.2487 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1883 - val_f1_score: 0.0000e+00\n",
      "Epoch 35/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8033 - accuracy: 0.2425 - auc_3: 0.6703 - f1_score: 0.2044 - val_loss: 3.1209 - val_accuracy: 0.0000e+00 - val_auc_3: 0.2076 - val_f1_score: 0.0000e+00\n",
      "Epoch 36/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8306 - accuracy: 0.2444 - auc_3: 0.6644 - f1_score: 0.1825 - val_loss: 2.7592 - val_accuracy: 0.0150 - val_auc_3: 0.2970 - val_f1_score: 0.0068\n",
      "Epoch 37/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8003 - accuracy: 0.2556 - auc_3: 0.6725 - f1_score: 0.1924 - val_loss: 2.8422 - val_accuracy: 0.0301 - val_auc_3: 0.2790 - val_f1_score: 0.0156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8008 - accuracy: 0.2838 - auc_3: 0.6755 - f1_score: 0.2415 - val_loss: 3.1528 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1996 - val_f1_score: 0.0000e+00\n",
      "Epoch 39/500\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.8116 - accuracy: 0.2707 - auc_3: 0.6709 - f1_score: 0.2028 - val_loss: 2.7086 - val_accuracy: 0.0075 - val_auc_3: 0.3154 - val_f1_score: 0.0034\n",
      "Epoch 40/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8337 - accuracy: 0.2519 - auc_3: 0.6568 - f1_score: 0.2010 - val_loss: 3.5874 - val_accuracy: 0.0226 - val_auc_3: 0.1695 - val_f1_score: 0.0153\n",
      "Epoch 41/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8549 - accuracy: 0.2256 - auc_3: 0.6524 - f1_score: 0.1708 - val_loss: 3.3374 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1580 - val_f1_score: 0.0000e+00\n",
      "Epoch 42/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8047 - accuracy: 0.2500 - auc_3: 0.6716 - f1_score: 0.2054 - val_loss: 3.4018 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1647 - val_f1_score: 0.0000e+00\n",
      "Epoch 43/500\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.8229 - accuracy: 0.2613 - auc_3: 0.6653 - f1_score: 0.1964 - val_loss: 2.6932 - val_accuracy: 0.0602 - val_auc_3: 0.3335 - val_f1_score: 0.0254\n",
      "Epoch 44/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8147 - accuracy: 0.2519 - auc_3: 0.6680 - f1_score: 0.1875 - val_loss: 3.2165 - val_accuracy: 0.0075 - val_auc_3: 0.1723 - val_f1_score: 0.0054\n",
      "Epoch 45/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8107 - accuracy: 0.2632 - auc_3: 0.6703 - f1_score: 0.1960 - val_loss: 2.6643 - val_accuracy: 0.0602 - val_auc_3: 0.3419 - val_f1_score: 0.0254\n",
      "Epoch 46/500\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.8101 - accuracy: 0.2538 - auc_3: 0.6688 - f1_score: 0.2075 - val_loss: 2.9152 - val_accuracy: 0.0150 - val_auc_3: 0.2479 - val_f1_score: 0.0068\n",
      "Epoch 47/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7901 - accuracy: 0.2838 - auc_3: 0.6765 - f1_score: 0.2165 - val_loss: 2.9848 - val_accuracy: 0.0075 - val_auc_3: 0.2457 - val_f1_score: 0.0034\n",
      "Epoch 48/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8031 - accuracy: 0.2444 - auc_3: 0.6840 - f1_score: 0.1780 - val_loss: 2.9044 - val_accuracy: 0.0000e+00 - val_auc_3: 0.2642 - val_f1_score: 0.0000e+00\n",
      "Epoch 49/500\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 1.8019 - accuracy: 0.2632 - auc_3: 0.6718 - f1_score: 0.2024 - val_loss: 3.2944 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1832 - val_f1_score: 0.0000e+00\n",
      "Epoch 50/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8046 - accuracy: 0.2312 - auc_3: 0.6727 - f1_score: 0.1900 - val_loss: 2.9493 - val_accuracy: 0.0376 - val_auc_3: 0.2286 - val_f1_score: 0.0164\n",
      "Epoch 51/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8014 - accuracy: 0.2368 - auc_3: 0.6657 - f1_score: 0.2013 - val_loss: 3.2230 - val_accuracy: 0.0075 - val_auc_3: 0.2337 - val_f1_score: 0.0055\n",
      "Epoch 52/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7999 - accuracy: 0.2350 - auc_3: 0.6809 - f1_score: 0.2070 - val_loss: 3.1033 - val_accuracy: 0.0301 - val_auc_3: 0.2118 - val_f1_score: 0.0156\n",
      "Epoch 53/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8203 - accuracy: 0.2575 - auc_3: 0.6631 - f1_score: 0.2063 - val_loss: 3.1543 - val_accuracy: 0.0150 - val_auc_3: 0.1913 - val_f1_score: 0.0068\n",
      "Epoch 54/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8175 - accuracy: 0.2162 - auc_3: 0.6790 - f1_score: 0.1714 - val_loss: 2.9459 - val_accuracy: 0.0526 - val_auc_3: 0.2744 - val_f1_score: 0.0248\n",
      "Epoch 55/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7728 - accuracy: 0.2481 - auc_3: 0.6855 - f1_score: 0.2011 - val_loss: 3.3809 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1505 - val_f1_score: 0.0000e+00\n",
      "Epoch 56/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7527 - accuracy: 0.2669 - auc_3: 0.6984 - f1_score: 0.2262 - val_loss: 2.4079 - val_accuracy: 0.1729 - val_auc_3: 0.4190 - val_f1_score: 0.0731\n",
      "Epoch 57/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7799 - accuracy: 0.2650 - auc_3: 0.6824 - f1_score: 0.2191 - val_loss: 3.2460 - val_accuracy: 0.0000e+00 - val_auc_3: 0.2096 - val_f1_score: 0.0000e+00\n",
      "Epoch 58/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7766 - accuracy: 0.2594 - auc_3: 0.6879 - f1_score: 0.2138 - val_loss: 2.9271 - val_accuracy: 0.0150 - val_auc_3: 0.2489 - val_f1_score: 0.0089\n",
      "Epoch 59/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7883 - accuracy: 0.2650 - auc_3: 0.6816 - f1_score: 0.2107 - val_loss: 2.9298 - val_accuracy: 0.0150 - val_auc_3: 0.2575 - val_f1_score: 0.0068\n",
      "Epoch 60/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8389 - accuracy: 0.2500 - auc_3: 0.6579 - f1_score: 0.2038 - val_loss: 2.9677 - val_accuracy: 0.0301 - val_auc_3: 0.2460 - val_f1_score: 0.0182\n",
      "Epoch 61/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8143 - accuracy: 0.2462 - auc_3: 0.6697 - f1_score: 0.2124 - val_loss: 3.2326 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1707 - val_f1_score: 0.0000e+00\n",
      "Epoch 62/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7958 - accuracy: 0.2951 - auc_3: 0.6884 - f1_score: 0.2189 - val_loss: 3.2512 - val_accuracy: 0.0075 - val_auc_3: 0.1966 - val_f1_score: 0.0034\n",
      "Epoch 63/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8377 - accuracy: 0.2500 - auc_3: 0.6660 - f1_score: 0.2025 - val_loss: 3.2855 - val_accuracy: 0.0075 - val_auc_3: 0.2187 - val_f1_score: 0.0054\n",
      "Epoch 64/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7996 - accuracy: 0.2820 - auc_3: 0.6818 - f1_score: 0.2212 - val_loss: 3.0150 - val_accuracy: 0.0000e+00 - val_auc_3: 0.2598 - val_f1_score: 0.0000e+00\n",
      "Epoch 65/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8369 - accuracy: 0.2331 - auc_3: 0.6648 - f1_score: 0.1943 - val_loss: 3.5020 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1840 - val_f1_score: 0.0000e+00\n",
      "Epoch 66/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8191 - accuracy: 0.2387 - auc_3: 0.6667 - f1_score: 0.1780 - val_loss: 2.8209 - val_accuracy: 0.0226 - val_auc_3: 0.2725 - val_f1_score: 0.0159\n",
      "Epoch 67/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7975 - accuracy: 0.2744 - auc_3: 0.6803 - f1_score: 0.2058 - val_loss: 3.2241 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1634 - val_f1_score: 0.0000e+00\n",
      "Epoch 68/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8109 - accuracy: 0.2387 - auc_3: 0.6703 - f1_score: 0.1775 - val_loss: 3.0028 - val_accuracy: 0.0301 - val_auc_3: 0.2535 - val_f1_score: 0.0133\n",
      "Epoch 69/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8194 - accuracy: 0.2556 - auc_3: 0.6656 - f1_score: 0.2127 - val_loss: 3.1932 - val_accuracy: 0.0075 - val_auc_3: 0.2187 - val_f1_score: 0.0055\n",
      "Epoch 70/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.8245 - accuracy: 0.2669 - auc_3: 0.6675 - f1_score: 0.2114 - val_loss: 3.0836 - val_accuracy: 0.0150 - val_auc_3: 0.2514 - val_f1_score: 0.0068\n",
      "Epoch 71/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.8251 - accuracy: 0.2462 - auc_3: 0.6691 - f1_score: 0.1938 - val_loss: 3.4164 - val_accuracy: 0.0301 - val_auc_3: 0.1915 - val_f1_score: 0.0204\n",
      "Epoch 72/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7843 - accuracy: 0.2632 - auc_3: 0.6844 - f1_score: 0.1904 - val_loss: 3.1761 - val_accuracy: 0.0000e+00 - val_auc_3: 0.2095 - val_f1_score: 0.0000e+00\n",
      "Epoch 73/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7867 - accuracy: 0.2650 - auc_3: 0.6826 - f1_score: 0.1991 - val_loss: 3.3705 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1674 - val_f1_score: 0.0000e+00\n",
      "Epoch 74/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8101 - accuracy: 0.2462 - auc_3: 0.6826 - f1_score: 0.1900 - val_loss: 3.3257 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1931 - val_f1_score: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7975 - accuracy: 0.2951 - auc_3: 0.6745 - f1_score: 0.2418 - val_loss: 2.8173 - val_accuracy: 0.0526 - val_auc_3: 0.3193 - val_f1_score: 0.0250\n",
      "Epoch 76/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7959 - accuracy: 0.2876 - auc_3: 0.6760 - f1_score: 0.2222 - val_loss: 3.0013 - val_accuracy: 0.0451 - val_auc_3: 0.2303 - val_f1_score: 0.0195\n",
      "Epoch 77/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8083 - accuracy: 0.2556 - auc_3: 0.6687 - f1_score: 0.2147 - val_loss: 2.9546 - val_accuracy: 0.0301 - val_auc_3: 0.2397 - val_f1_score: 0.0133\n",
      "Epoch 78/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8234 - accuracy: 0.2613 - auc_3: 0.6764 - f1_score: 0.1877 - val_loss: 2.9026 - val_accuracy: 0.0301 - val_auc_3: 0.2752 - val_f1_score: 0.0133\n",
      "Epoch 79/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7972 - accuracy: 0.2519 - auc_3: 0.6718 - f1_score: 0.2137 - val_loss: 2.8452 - val_accuracy: 0.0226 - val_auc_3: 0.2619 - val_f1_score: 0.0101\n",
      "Epoch 80/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8395 - accuracy: 0.2218 - auc_3: 0.6590 - f1_score: 0.1608 - val_loss: 2.9202 - val_accuracy: 0.0150 - val_auc_3: 0.2736 - val_f1_score: 0.0068\n",
      "Epoch 81/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7901 - accuracy: 0.2575 - auc_3: 0.6815 - f1_score: 0.1904 - val_loss: 3.1469 - val_accuracy: 0.0075 - val_auc_3: 0.2002 - val_f1_score: 0.0034\n",
      "Epoch 82/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8299 - accuracy: 0.2406 - auc_3: 0.6597 - f1_score: 0.1797 - val_loss: 2.8842 - val_accuracy: 0.0226 - val_auc_3: 0.2955 - val_f1_score: 0.0159\n",
      "Epoch 83/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7774 - accuracy: 0.2744 - auc_3: 0.6892 - f1_score: 0.2446 - val_loss: 3.3260 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1557 - val_f1_score: 0.0000e+00\n",
      "Epoch 84/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8233 - accuracy: 0.2444 - auc_3: 0.6746 - f1_score: 0.1802 - val_loss: 2.6098 - val_accuracy: 0.0977 - val_auc_3: 0.3473 - val_f1_score: 0.0493\n",
      "Epoch 85/500\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 1.7998 - accuracy: 0.2350 - auc_3: 0.6735 - f1_score: 0.2124 - val_loss: 3.1293 - val_accuracy: 0.0150 - val_auc_3: 0.1919 - val_f1_score: 0.0068\n",
      "Epoch 86/500\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 1.7952 - accuracy: 0.2688 - auc_3: 0.6843 - f1_score: 0.2001 - val_loss: 2.9086 - val_accuracy: 0.0075 - val_auc_3: 0.3057 - val_f1_score: 0.0034\n",
      "Epoch 87/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8538 - accuracy: 0.2293 - auc_3: 0.6507 - f1_score: 0.1915 - val_loss: 3.2401 - val_accuracy: 0.0150 - val_auc_3: 0.2098 - val_f1_score: 0.0068\n",
      "Epoch 88/500\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.8331 - accuracy: 0.2425 - auc_3: 0.6710 - f1_score: 0.1845 - val_loss: 2.6345 - val_accuracy: 0.0602 - val_auc_3: 0.3121 - val_f1_score: 0.0277\n",
      "Epoch 89/500\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.8220 - accuracy: 0.2556 - auc_3: 0.6709 - f1_score: 0.2086 - val_loss: 2.8670 - val_accuracy: 0.0075 - val_auc_3: 0.2933 - val_f1_score: 0.0054\n",
      "Epoch 90/500\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 1.8056 - accuracy: 0.2425 - auc_3: 0.6674 - f1_score: 0.1990 - val_loss: 2.9378 - val_accuracy: 0.0075 - val_auc_3: 0.2670 - val_f1_score: 0.0034\n",
      "Epoch 91/500\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 1.7961 - accuracy: 0.2538 - auc_3: 0.6799 - f1_score: 0.2142 - val_loss: 3.1447 - val_accuracy: 0.0000e+00 - val_auc_3: 0.2024 - val_f1_score: 0.0000e+00\n",
      "Epoch 92/500\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 1.7978 - accuracy: 0.2538 - auc_3: 0.6802 - f1_score: 0.1955 - val_loss: 2.8330 - val_accuracy: 0.0226 - val_auc_3: 0.2755 - val_f1_score: 0.0142\n",
      "Epoch 93/500\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 1.8158 - accuracy: 0.2575 - auc_3: 0.6648 - f1_score: 0.2017 - val_loss: 3.1633 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1962 - val_f1_score: 0.0000e+00\n",
      "Epoch 94/500\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 1.7756 - accuracy: 0.2763 - auc_3: 0.6959 - f1_score: 0.2057 - val_loss: 2.8749 - val_accuracy: 0.0226 - val_auc_3: 0.2874 - val_f1_score: 0.0150\n",
      "Epoch 95/500\n",
      "17/17 [==============================] - 1s 74ms/step - loss: 1.7858 - accuracy: 0.2650 - auc_3: 0.6772 - f1_score: 0.2368 - val_loss: 3.2038 - val_accuracy: 0.0075 - val_auc_3: 0.2028 - val_f1_score: 0.0034\n",
      "Epoch 96/500\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 1.8064 - accuracy: 0.2500 - auc_3: 0.6727 - f1_score: 0.2029 - val_loss: 2.7570 - val_accuracy: 0.0301 - val_auc_3: 0.3036 - val_f1_score: 0.0153\n",
      "Epoch 97/500\n",
      "17/17 [==============================] - 1s 70ms/step - loss: 1.7912 - accuracy: 0.2556 - auc_3: 0.6784 - f1_score: 0.2175 - val_loss: 3.1247 - val_accuracy: 0.0075 - val_auc_3: 0.1877 - val_f1_score: 0.0055\n",
      "Epoch 98/500\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 1.7772 - accuracy: 0.2744 - auc_3: 0.6880 - f1_score: 0.2051 - val_loss: 2.5463 - val_accuracy: 0.1429 - val_auc_3: 0.3886 - val_f1_score: 0.0557\n",
      "Epoch 99/500\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 1.8185 - accuracy: 0.2274 - auc_3: 0.6647 - f1_score: 0.1891 - val_loss: 3.0654 - val_accuracy: 0.0000e+00 - val_auc_3: 0.2012 - val_f1_score: 0.0000e+00\n",
      "Epoch 100/500\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 1.7948 - accuracy: 0.2632 - auc_3: 0.6751 - f1_score: 0.2084 - val_loss: 2.7635 - val_accuracy: 0.0226 - val_auc_3: 0.2893 - val_f1_score: 0.0138\n",
      "Epoch 101/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7849 - accuracy: 0.2763 - auc_3: 0.6866 - f1_score: 0.2094 - val_loss: 3.0857 - val_accuracy: 0.0150 - val_auc_3: 0.2300 - val_f1_score: 0.0068\n",
      "Epoch 102/500\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 1.7895 - accuracy: 0.2556 - auc_3: 0.6838 - f1_score: 0.2103 - val_loss: 2.9958 - val_accuracy: 0.0451 - val_auc_3: 0.2412 - val_f1_score: 0.0195\n",
      "Epoch 103/500\n",
      "17/17 [==============================] - 1s 70ms/step - loss: 1.7988 - accuracy: 0.2556 - auc_3: 0.6731 - f1_score: 0.1954 - val_loss: 2.7717 - val_accuracy: 0.0226 - val_auc_3: 0.2797 - val_f1_score: 0.0100\n",
      "Epoch 104/500\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 1.8114 - accuracy: 0.2632 - auc_3: 0.6744 - f1_score: 0.2032 - val_loss: 3.0386 - val_accuracy: 0.0150 - val_auc_3: 0.2656 - val_f1_score: 0.0108\n",
      "Epoch 105/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8256 - accuracy: 0.2556 - auc_3: 0.6740 - f1_score: 0.1880 - val_loss: 3.0309 - val_accuracy: 0.0075 - val_auc_3: 0.2153 - val_f1_score: 0.0034\n",
      "Epoch 106/500\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 1.8128 - accuracy: 0.2575 - auc_3: 0.6673 - f1_score: 0.1895 - val_loss: 2.7451 - val_accuracy: 0.0075 - val_auc_3: 0.3386 - val_f1_score: 0.0034\n",
      "Epoch 107/500\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 1.8308 - accuracy: 0.2556 - auc_3: 0.6645 - f1_score: 0.2036 - val_loss: 3.0254 - val_accuracy: 0.0150 - val_auc_3: 0.2587 - val_f1_score: 0.0068\n",
      "Epoch 108/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8035 - accuracy: 0.2820 - auc_3: 0.6775 - f1_score: 0.2115 - val_loss: 2.7710 - val_accuracy: 0.0677 - val_auc_3: 0.2921 - val_f1_score: 0.0396\n",
      "Epoch 109/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7858 - accuracy: 0.2650 - auc_3: 0.6768 - f1_score: 0.2476 - val_loss: 3.5714 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1593 - val_f1_score: 0.0000e+00\n",
      "Epoch 110/500\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 1.8295 - accuracy: 0.2744 - auc_3: 0.6635 - f1_score: 0.2091 - val_loss: 2.9177 - val_accuracy: 0.0150 - val_auc_3: 0.2516 - val_f1_score: 0.0088\n",
      "Epoch 111/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8050 - accuracy: 0.2613 - auc_3: 0.6767 - f1_score: 0.2091 - val_loss: 2.7710 - val_accuracy: 0.0376 - val_auc_3: 0.3084 - val_f1_score: 0.0205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8178 - accuracy: 0.2425 - auc_3: 0.6639 - f1_score: 0.1810 - val_loss: 3.2634 - val_accuracy: 0.0226 - val_auc_3: 0.1852 - val_f1_score: 0.0148\n",
      "Epoch 113/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8047 - accuracy: 0.2669 - auc_3: 0.6769 - f1_score: 0.2007 - val_loss: 2.9082 - val_accuracy: 0.0075 - val_auc_3: 0.2674 - val_f1_score: 0.0034\n",
      "Epoch 114/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7919 - accuracy: 0.2575 - auc_3: 0.6782 - f1_score: 0.1906 - val_loss: 2.6146 - val_accuracy: 0.0526 - val_auc_3: 0.3202 - val_f1_score: 0.0225\n",
      "Epoch 115/500\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 1.8100 - accuracy: 0.2500 - auc_3: 0.6721 - f1_score: 0.1793 - val_loss: 2.9287 - val_accuracy: 0.0301 - val_auc_3: 0.2680 - val_f1_score: 0.0156\n",
      "Epoch 116/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8182 - accuracy: 0.2462 - auc_3: 0.6649 - f1_score: 0.1977 - val_loss: 3.0980 - val_accuracy: 0.0000e+00 - val_auc_3: 0.2222 - val_f1_score: 0.0000e+00\n",
      "Epoch 117/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8076 - accuracy: 0.2462 - auc_3: 0.6717 - f1_score: 0.1934 - val_loss: 3.0326 - val_accuracy: 0.0376 - val_auc_3: 0.2394 - val_f1_score: 0.0164\n",
      "Epoch 118/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7858 - accuracy: 0.2669 - auc_3: 0.6827 - f1_score: 0.2069 - val_loss: 2.8260 - val_accuracy: 0.0376 - val_auc_3: 0.2785 - val_f1_score: 0.0221\n",
      "Epoch 119/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7710 - accuracy: 0.2707 - auc_3: 0.6864 - f1_score: 0.2394 - val_loss: 2.7720 - val_accuracy: 0.0301 - val_auc_3: 0.3149 - val_f1_score: 0.0155\n",
      "Epoch 120/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8227 - accuracy: 0.2632 - auc_3: 0.6637 - f1_score: 0.1944 - val_loss: 2.8143 - val_accuracy: 0.0376 - val_auc_3: 0.3173 - val_f1_score: 0.0209\n",
      "Epoch 121/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8496 - accuracy: 0.2519 - auc_3: 0.6566 - f1_score: 0.1942 - val_loss: 2.7034 - val_accuracy: 0.0526 - val_auc_3: 0.2853 - val_f1_score: 0.0225\n",
      "Epoch 122/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8258 - accuracy: 0.2368 - auc_3: 0.6645 - f1_score: 0.1749 - val_loss: 2.9770 - val_accuracy: 0.0150 - val_auc_3: 0.2580 - val_f1_score: 0.0088\n",
      "Epoch 123/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8142 - accuracy: 0.2538 - auc_3: 0.6685 - f1_score: 0.1881 - val_loss: 2.8048 - val_accuracy: 0.0376 - val_auc_3: 0.3047 - val_f1_score: 0.0164\n",
      "Epoch 124/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8005 - accuracy: 0.2575 - auc_3: 0.6734 - f1_score: 0.2339 - val_loss: 3.3779 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1744 - val_f1_score: 0.0000e+00\n",
      "Epoch 125/500\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.7964 - accuracy: 0.2556 - auc_3: 0.6796 - f1_score: 0.1921 - val_loss: 2.5055 - val_accuracy: 0.1128 - val_auc_3: 0.4031 - val_f1_score: 0.0573\n",
      "Epoch 126/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7935 - accuracy: 0.2519 - auc_3: 0.6816 - f1_score: 0.1965 - val_loss: 3.4146 - val_accuracy: 0.0075 - val_auc_3: 0.1758 - val_f1_score: 0.0034\n",
      "Epoch 127/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8076 - accuracy: 0.2481 - auc_3: 0.6668 - f1_score: 0.1853 - val_loss: 2.9052 - val_accuracy: 0.0075 - val_auc_3: 0.2690 - val_f1_score: 0.0055\n",
      "Epoch 128/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8034 - accuracy: 0.2481 - auc_3: 0.6818 - f1_score: 0.2197 - val_loss: 3.1102 - val_accuracy: 0.0150 - val_auc_3: 0.1922 - val_f1_score: 0.0089\n",
      "Epoch 129/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7985 - accuracy: 0.2726 - auc_3: 0.6733 - f1_score: 0.2305 - val_loss: 2.8710 - val_accuracy: 0.0075 - val_auc_3: 0.2751 - val_f1_score: 0.0034\n",
      "Epoch 130/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8030 - accuracy: 0.2331 - auc_3: 0.6751 - f1_score: 0.1940 - val_loss: 3.2327 - val_accuracy: 0.0075 - val_auc_3: 0.1835 - val_f1_score: 0.0055\n",
      "Epoch 131/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7928 - accuracy: 0.2613 - auc_3: 0.6809 - f1_score: 0.1958 - val_loss: 2.9392 - val_accuracy: 0.0150 - val_auc_3: 0.2326 - val_f1_score: 0.0068\n",
      "Epoch 132/500\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.8028 - accuracy: 0.2650 - auc_3: 0.6786 - f1_score: 0.2176 - val_loss: 3.8105 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1566 - val_f1_score: 0.0000e+00\n",
      "Epoch 133/500\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 1.8451 - accuracy: 0.2744 - auc_3: 0.6706 - f1_score: 0.2060 - val_loss: 3.0594 - val_accuracy: 0.0602 - val_auc_3: 0.2389 - val_f1_score: 0.0336\n",
      "Epoch 134/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7991 - accuracy: 0.2256 - auc_3: 0.6743 - f1_score: 0.1740 - val_loss: 3.0053 - val_accuracy: 0.0000e+00 - val_auc_3: 0.2509 - val_f1_score: 0.0000e+00\n",
      "Epoch 135/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7968 - accuracy: 0.2594 - auc_3: 0.6836 - f1_score: 0.2134 - val_loss: 2.6774 - val_accuracy: 0.1353 - val_auc_3: 0.3662 - val_f1_score: 0.0536\n",
      "Epoch 136/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8452 - accuracy: 0.2406 - auc_3: 0.6548 - f1_score: 0.1749 - val_loss: 2.8476 - val_accuracy: 0.0602 - val_auc_3: 0.2879 - val_f1_score: 0.0333\n",
      "Epoch 137/500\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 1.7701 - accuracy: 0.2726 - auc_3: 0.6887 - f1_score: 0.2256 - val_loss: 2.8146 - val_accuracy: 0.0602 - val_auc_3: 0.3134 - val_f1_score: 0.0320\n",
      "Epoch 138/500\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 1.8503 - accuracy: 0.2519 - auc_3: 0.6563 - f1_score: 0.1962 - val_loss: 2.9043 - val_accuracy: 0.0376 - val_auc_3: 0.2850 - val_f1_score: 0.0186\n",
      "Epoch 139/500\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 1.8016 - accuracy: 0.2669 - auc_3: 0.6707 - f1_score: 0.2018 - val_loss: 2.9002 - val_accuracy: 0.0226 - val_auc_3: 0.2580 - val_f1_score: 0.0142\n",
      "Epoch 140/500\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 1.8080 - accuracy: 0.2594 - auc_3: 0.6746 - f1_score: 0.1962 - val_loss: 2.8817 - val_accuracy: 0.0451 - val_auc_3: 0.2586 - val_f1_score: 0.0195\n",
      "Epoch 141/500\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 1.8130 - accuracy: 0.2293 - auc_3: 0.6638 - f1_score: 0.1609 - val_loss: 3.1693 - val_accuracy: 0.0075 - val_auc_3: 0.2369 - val_f1_score: 0.0034\n",
      "Epoch 142/500\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 1.8136 - accuracy: 0.2632 - auc_3: 0.6680 - f1_score: 0.1900 - val_loss: 2.9647 - val_accuracy: 0.0075 - val_auc_3: 0.2301 - val_f1_score: 0.0055\n",
      "Epoch 143/500\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.7917 - accuracy: 0.2707 - auc_3: 0.6766 - f1_score: 0.2041 - val_loss: 2.8024 - val_accuracy: 0.0677 - val_auc_3: 0.2902 - val_f1_score: 0.0354\n",
      "Epoch 144/500\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 1.7806 - accuracy: 0.2707 - auc_3: 0.6791 - f1_score: 0.2094 - val_loss: 2.8686 - val_accuracy: 0.0451 - val_auc_3: 0.3130 - val_f1_score: 0.0241\n",
      "Epoch 145/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8123 - accuracy: 0.2481 - auc_3: 0.6775 - f1_score: 0.1895 - val_loss: 2.9809 - val_accuracy: 0.0226 - val_auc_3: 0.2501 - val_f1_score: 0.0101\n",
      "Epoch 146/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7995 - accuracy: 0.2895 - auc_3: 0.6768 - f1_score: 0.2337 - val_loss: 3.1751 - val_accuracy: 0.0150 - val_auc_3: 0.2049 - val_f1_score: 0.0068\n",
      "Epoch 147/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7905 - accuracy: 0.2688 - auc_3: 0.6778 - f1_score: 0.2117 - val_loss: 2.6431 - val_accuracy: 0.0827 - val_auc_3: 0.3429 - val_f1_score: 0.0420\n",
      "Epoch 148/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7857 - accuracy: 0.2556 - auc_3: 0.6794 - f1_score: 0.2145 - val_loss: 3.3459 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1652 - val_f1_score: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/500\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 1.8290 - accuracy: 0.2481 - auc_3: 0.6714 - f1_score: 0.1909 - val_loss: 2.9796 - val_accuracy: 0.0075 - val_auc_3: 0.2804 - val_f1_score: 0.0034\n",
      "Epoch 150/500\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 1.8139 - accuracy: 0.2462 - auc_3: 0.6717 - f1_score: 0.2216 - val_loss: 3.2357 - val_accuracy: 0.0075 - val_auc_3: 0.1816 - val_f1_score: 0.0034\n",
      "Epoch 151/500\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.7746 - accuracy: 0.2594 - auc_3: 0.6842 - f1_score: 0.1995 - val_loss: 2.8947 - val_accuracy: 0.0451 - val_auc_3: 0.2574 - val_f1_score: 0.0264\n",
      "Epoch 152/500\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.7808 - accuracy: 0.2556 - auc_3: 0.6815 - f1_score: 0.2163 - val_loss: 3.4705 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1915 - val_f1_score: 0.0000e+00\n",
      "Epoch 153/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8043 - accuracy: 0.2801 - auc_3: 0.6772 - f1_score: 0.2196 - val_loss: 3.0325 - val_accuracy: 0.0226 - val_auc_3: 0.2659 - val_f1_score: 0.0119\n",
      "Epoch 154/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8075 - accuracy: 0.2519 - auc_3: 0.6737 - f1_score: 0.1983 - val_loss: 3.2367 - val_accuracy: 0.0075 - val_auc_3: 0.2183 - val_f1_score: 0.0034\n",
      "Epoch 155/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7857 - accuracy: 0.2726 - auc_3: 0.6834 - f1_score: 0.1993 - val_loss: 2.8735 - val_accuracy: 0.0602 - val_auc_3: 0.2871 - val_f1_score: 0.0276\n",
      "Epoch 156/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7937 - accuracy: 0.2406 - auc_3: 0.6750 - f1_score: 0.1808 - val_loss: 2.7594 - val_accuracy: 0.0752 - val_auc_3: 0.3081 - val_f1_score: 0.0356\n",
      "Epoch 157/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8103 - accuracy: 0.2650 - auc_3: 0.6692 - f1_score: 0.2182 - val_loss: 3.0889 - val_accuracy: 0.0150 - val_auc_3: 0.2264 - val_f1_score: 0.0068\n",
      "Epoch 158/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7934 - accuracy: 0.2688 - auc_3: 0.6821 - f1_score: 0.2035 - val_loss: 2.5342 - val_accuracy: 0.0902 - val_auc_3: 0.3503 - val_f1_score: 0.0471\n",
      "Epoch 159/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7888 - accuracy: 0.2575 - auc_3: 0.6770 - f1_score: 0.1973 - val_loss: 3.1464 - val_accuracy: 0.0075 - val_auc_3: 0.2091 - val_f1_score: 0.0055\n",
      "Epoch 160/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7941 - accuracy: 0.2594 - auc_3: 0.6780 - f1_score: 0.1921 - val_loss: 2.8188 - val_accuracy: 0.0301 - val_auc_3: 0.3052 - val_f1_score: 0.0174\n",
      "Epoch 161/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7975 - accuracy: 0.2632 - auc_3: 0.6732 - f1_score: 0.2052 - val_loss: 3.0168 - val_accuracy: 0.0301 - val_auc_3: 0.2271 - val_f1_score: 0.0176\n",
      "Epoch 162/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8066 - accuracy: 0.2763 - auc_3: 0.6760 - f1_score: 0.2202 - val_loss: 2.8834 - val_accuracy: 0.0000e+00 - val_auc_3: 0.2598 - val_f1_score: 0.0000e+00\n",
      "Epoch 163/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7935 - accuracy: 0.2500 - auc_3: 0.6752 - f1_score: 0.1899 - val_loss: 2.8353 - val_accuracy: 0.0376 - val_auc_3: 0.3136 - val_f1_score: 0.0164\n",
      "Epoch 164/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7860 - accuracy: 0.2594 - auc_3: 0.6808 - f1_score: 0.2313 - val_loss: 3.3419 - val_accuracy: 0.0075 - val_auc_3: 0.1923 - val_f1_score: 0.0053\n",
      "Epoch 165/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7790 - accuracy: 0.2575 - auc_3: 0.6891 - f1_score: 0.1902 - val_loss: 2.7848 - val_accuracy: 0.0000e+00 - val_auc_3: 0.3373 - val_f1_score: 0.0000e+00\n",
      "Epoch 166/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8054 - accuracy: 0.2519 - auc_3: 0.6780 - f1_score: 0.2017 - val_loss: 2.8024 - val_accuracy: 0.0451 - val_auc_3: 0.2714 - val_f1_score: 0.0254\n",
      "Epoch 167/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7758 - accuracy: 0.2650 - auc_3: 0.6899 - f1_score: 0.2071 - val_loss: 2.9007 - val_accuracy: 0.0301 - val_auc_3: 0.2861 - val_f1_score: 0.0156\n",
      "Epoch 168/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8177 - accuracy: 0.2425 - auc_3: 0.6669 - f1_score: 0.1863 - val_loss: 2.8730 - val_accuracy: 0.0075 - val_auc_3: 0.2825 - val_f1_score: 0.0055\n",
      "Epoch 169/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7885 - accuracy: 0.2726 - auc_3: 0.6812 - f1_score: 0.2228 - val_loss: 2.9778 - val_accuracy: 0.0150 - val_auc_3: 0.2213 - val_f1_score: 0.0088\n",
      "Epoch 170/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8144 - accuracy: 0.2500 - auc_3: 0.6697 - f1_score: 0.1928 - val_loss: 2.5953 - val_accuracy: 0.0827 - val_auc_3: 0.3493 - val_f1_score: 0.0366\n",
      "Epoch 171/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7891 - accuracy: 0.2538 - auc_3: 0.6811 - f1_score: 0.2033 - val_loss: 2.9013 - val_accuracy: 0.0301 - val_auc_3: 0.2845 - val_f1_score: 0.0133\n",
      "Epoch 172/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7914 - accuracy: 0.2707 - auc_3: 0.6825 - f1_score: 0.2248 - val_loss: 2.8366 - val_accuracy: 0.0451 - val_auc_3: 0.2997 - val_f1_score: 0.0265\n",
      "Epoch 173/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7911 - accuracy: 0.2556 - auc_3: 0.6788 - f1_score: 0.1971 - val_loss: 2.9685 - val_accuracy: 0.0226 - val_auc_3: 0.2867 - val_f1_score: 0.0101\n",
      "Epoch 174/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7979 - accuracy: 0.2857 - auc_3: 0.6771 - f1_score: 0.2175 - val_loss: 2.7720 - val_accuracy: 0.0977 - val_auc_3: 0.3054 - val_f1_score: 0.0436\n",
      "Epoch 175/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7670 - accuracy: 0.2763 - auc_3: 0.6874 - f1_score: 0.2120 - val_loss: 3.0979 - val_accuracy: 0.0226 - val_auc_3: 0.2335 - val_f1_score: 0.0121\n",
      "Epoch 176/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7782 - accuracy: 0.2669 - auc_3: 0.6862 - f1_score: 0.2193 - val_loss: 3.0878 - val_accuracy: 0.0075 - val_auc_3: 0.2243 - val_f1_score: 0.0053\n",
      "Epoch 177/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7792 - accuracy: 0.2650 - auc_3: 0.6873 - f1_score: 0.1944 - val_loss: 2.7834 - val_accuracy: 0.0752 - val_auc_3: 0.3413 - val_f1_score: 0.0360\n",
      "Epoch 178/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8157 - accuracy: 0.2312 - auc_3: 0.6662 - f1_score: 0.1883 - val_loss: 3.3039 - val_accuracy: 0.0000e+00 - val_auc_3: 0.2239 - val_f1_score: 0.0000e+00\n",
      "Epoch 179/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7865 - accuracy: 0.2613 - auc_3: 0.6903 - f1_score: 0.2051 - val_loss: 2.8064 - val_accuracy: 0.0526 - val_auc_3: 0.2962 - val_f1_score: 0.0270\n",
      "Epoch 180/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7905 - accuracy: 0.2556 - auc_3: 0.6755 - f1_score: 0.2127 - val_loss: 3.1632 - val_accuracy: 0.0075 - val_auc_3: 0.2181 - val_f1_score: 0.0055\n",
      "Epoch 181/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8408 - accuracy: 0.2556 - auc_3: 0.6633 - f1_score: 0.1977 - val_loss: 3.2235 - val_accuracy: 0.0000e+00 - val_auc_3: 0.2105 - val_f1_score: 0.0000e+00\n",
      "Epoch 182/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8021 - accuracy: 0.2613 - auc_3: 0.6745 - f1_score: 0.1969 - val_loss: 2.6450 - val_accuracy: 0.1053 - val_auc_3: 0.3196 - val_f1_score: 0.0483\n",
      "Epoch 183/500\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.7836 - accuracy: 0.2989 - auc_3: 0.6831 - f1_score: 0.2613 - val_loss: 3.5899 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1803 - val_f1_score: 0.0000e+00\n",
      "Epoch 184/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8123 - accuracy: 0.2669 - auc_3: 0.6760 - f1_score: 0.1985 - val_loss: 2.8507 - val_accuracy: 0.0301 - val_auc_3: 0.3081 - val_f1_score: 0.0133\n",
      "Epoch 185/500\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.8330 - accuracy: 0.2312 - auc_3: 0.6617 - f1_score: 0.1902 - val_loss: 2.8478 - val_accuracy: 0.0376 - val_auc_3: 0.2917 - val_f1_score: 0.0185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8278 - accuracy: 0.2594 - auc_3: 0.6709 - f1_score: 0.1876 - val_loss: 3.0000 - val_accuracy: 0.0075 - val_auc_3: 0.2300 - val_f1_score: 0.0034\n",
      "Epoch 187/500\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.8023 - accuracy: 0.2425 - auc_3: 0.6782 - f1_score: 0.1826 - val_loss: 2.7116 - val_accuracy: 0.0827 - val_auc_3: 0.3015 - val_f1_score: 0.0380\n",
      "Epoch 188/500\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 1.8076 - accuracy: 0.2312 - auc_3: 0.6708 - f1_score: 0.1730 - val_loss: 2.6923 - val_accuracy: 0.1203 - val_auc_3: 0.3259 - val_f1_score: 0.0580\n",
      "Epoch 189/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8170 - accuracy: 0.2538 - auc_3: 0.6686 - f1_score: 0.2097 - val_loss: 3.1297 - val_accuracy: 0.0301 - val_auc_3: 0.2560 - val_f1_score: 0.0208\n",
      "Epoch 190/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8040 - accuracy: 0.2519 - auc_3: 0.6699 - f1_score: 0.1869 - val_loss: 2.9452 - val_accuracy: 0.0150 - val_auc_3: 0.2744 - val_f1_score: 0.0067\n",
      "Epoch 191/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7933 - accuracy: 0.2613 - auc_3: 0.6841 - f1_score: 0.2003 - val_loss: 2.8179 - val_accuracy: 0.0301 - val_auc_3: 0.3063 - val_f1_score: 0.0174\n",
      "Epoch 192/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8304 - accuracy: 0.2594 - auc_3: 0.6589 - f1_score: 0.2287 - val_loss: 2.7454 - val_accuracy: 0.0376 - val_auc_3: 0.3154 - val_f1_score: 0.0227\n",
      "Epoch 193/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8205 - accuracy: 0.2726 - auc_3: 0.6684 - f1_score: 0.2222 - val_loss: 2.6702 - val_accuracy: 0.0602 - val_auc_3: 0.3510 - val_f1_score: 0.0317\n",
      "Epoch 194/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8055 - accuracy: 0.2519 - auc_3: 0.6737 - f1_score: 0.1928 - val_loss: 3.4156 - val_accuracy: 0.0150 - val_auc_3: 0.1967 - val_f1_score: 0.0108\n",
      "Epoch 195/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8005 - accuracy: 0.2669 - auc_3: 0.6718 - f1_score: 0.1961 - val_loss: 2.7517 - val_accuracy: 0.0902 - val_auc_3: 0.2977 - val_f1_score: 0.0388\n",
      "Epoch 196/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8059 - accuracy: 0.2481 - auc_3: 0.6742 - f1_score: 0.2121 - val_loss: 3.1221 - val_accuracy: 0.0075 - val_auc_3: 0.2227 - val_f1_score: 0.0055\n",
      "Epoch 197/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8029 - accuracy: 0.2613 - auc_3: 0.6738 - f1_score: 0.1965 - val_loss: 2.9833 - val_accuracy: 0.0226 - val_auc_3: 0.2535 - val_f1_score: 0.0122\n",
      "Epoch 198/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7609 - accuracy: 0.2669 - auc_3: 0.6970 - f1_score: 0.2059 - val_loss: 2.6238 - val_accuracy: 0.0677 - val_auc_3: 0.3399 - val_f1_score: 0.0331\n",
      "Epoch 199/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7968 - accuracy: 0.2350 - auc_3: 0.6753 - f1_score: 0.1996 - val_loss: 3.3145 - val_accuracy: 0.0075 - val_auc_3: 0.2111 - val_f1_score: 0.0034\n",
      "Epoch 200/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7800 - accuracy: 0.2726 - auc_3: 0.6854 - f1_score: 0.2239 - val_loss: 2.9555 - val_accuracy: 0.0075 - val_auc_3: 0.2637 - val_f1_score: 0.0054\n",
      "Epoch 201/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7644 - accuracy: 0.3008 - auc_3: 0.6969 - f1_score: 0.2430 - val_loss: 3.0958 - val_accuracy: 0.0301 - val_auc_3: 0.2509 - val_f1_score: 0.0133\n",
      "Epoch 202/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7919 - accuracy: 0.2669 - auc_3: 0.6759 - f1_score: 0.2380 - val_loss: 3.1363 - val_accuracy: 0.0150 - val_auc_3: 0.2503 - val_f1_score: 0.0108\n",
      "Epoch 203/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7754 - accuracy: 0.2895 - auc_3: 0.6864 - f1_score: 0.2183 - val_loss: 2.8301 - val_accuracy: 0.0752 - val_auc_3: 0.3164 - val_f1_score: 0.0338\n",
      "Epoch 204/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8520 - accuracy: 0.2274 - auc_3: 0.6520 - f1_score: 0.1892 - val_loss: 2.7880 - val_accuracy: 0.0677 - val_auc_3: 0.2834 - val_f1_score: 0.0309\n",
      "Epoch 205/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8090 - accuracy: 0.2368 - auc_3: 0.6695 - f1_score: 0.1793 - val_loss: 2.9669 - val_accuracy: 0.0150 - val_auc_3: 0.2382 - val_f1_score: 0.0068\n",
      "Epoch 206/500\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.7916 - accuracy: 0.2669 - auc_3: 0.6874 - f1_score: 0.1966 - val_loss: 3.5802 - val_accuracy: 0.0075 - val_auc_3: 0.1801 - val_f1_score: 0.0054\n",
      "Epoch 207/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8372 - accuracy: 0.2218 - auc_3: 0.6592 - f1_score: 0.1754 - val_loss: 2.9452 - val_accuracy: 0.0526 - val_auc_3: 0.2772 - val_f1_score: 0.0292\n",
      "Epoch 208/500\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.7923 - accuracy: 0.2575 - auc_3: 0.6810 - f1_score: 0.2115 - val_loss: 3.0448 - val_accuracy: 0.0451 - val_auc_3: 0.2571 - val_f1_score: 0.0218\n",
      "Epoch 209/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8066 - accuracy: 0.2538 - auc_3: 0.6743 - f1_score: 0.1950 - val_loss: 2.9188 - val_accuracy: 0.0226 - val_auc_3: 0.2622 - val_f1_score: 0.0123\n",
      "Epoch 210/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7952 - accuracy: 0.2481 - auc_3: 0.6758 - f1_score: 0.2107 - val_loss: 2.9787 - val_accuracy: 0.0150 - val_auc_3: 0.2571 - val_f1_score: 0.0089\n",
      "Epoch 211/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8184 - accuracy: 0.2538 - auc_3: 0.6702 - f1_score: 0.1934 - val_loss: 2.7927 - val_accuracy: 0.0376 - val_auc_3: 0.2845 - val_f1_score: 0.0164\n",
      "Epoch 212/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7896 - accuracy: 0.2632 - auc_3: 0.6809 - f1_score: 0.2015 - val_loss: 3.1790 - val_accuracy: 0.0000e+00 - val_auc_3: 0.2007 - val_f1_score: 0.0000e+00\n",
      "Epoch 213/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7955 - accuracy: 0.2462 - auc_3: 0.6766 - f1_score: 0.2020 - val_loss: 3.1968 - val_accuracy: 0.0000e+00 - val_auc_3: 0.2143 - val_f1_score: 0.0000e+00\n",
      "Epoch 214/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7905 - accuracy: 0.2744 - auc_3: 0.6805 - f1_score: 0.2237 - val_loss: 3.2554 - val_accuracy: 0.0150 - val_auc_3: 0.2073 - val_f1_score: 0.0089\n",
      "Epoch 215/500\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 1.8371 - accuracy: 0.2575 - auc_3: 0.6642 - f1_score: 0.1930 - val_loss: 2.5145 - val_accuracy: 0.0977 - val_auc_3: 0.3687 - val_f1_score: 0.0383\n",
      "Epoch 216/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8102 - accuracy: 0.2838 - auc_3: 0.6693 - f1_score: 0.2316 - val_loss: 2.9518 - val_accuracy: 0.0075 - val_auc_3: 0.2353 - val_f1_score: 0.0034\n",
      "Epoch 217/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8123 - accuracy: 0.2707 - auc_3: 0.6734 - f1_score: 0.2052 - val_loss: 3.1502 - val_accuracy: 0.0075 - val_auc_3: 0.1990 - val_f1_score: 0.0034\n",
      "Epoch 218/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8104 - accuracy: 0.2989 - auc_3: 0.6764 - f1_score: 0.2219 - val_loss: 2.5007 - val_accuracy: 0.1278 - val_auc_3: 0.4281 - val_f1_score: 0.0481\n",
      "Epoch 219/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7953 - accuracy: 0.2688 - auc_3: 0.6781 - f1_score: 0.2232 - val_loss: 3.2961 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1681 - val_f1_score: 0.0000e+00\n",
      "Epoch 220/500\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.7938 - accuracy: 0.2500 - auc_3: 0.6781 - f1_score: 0.1895 - val_loss: 2.9493 - val_accuracy: 0.0226 - val_auc_3: 0.2419 - val_f1_score: 0.0142\n",
      "Epoch 221/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7917 - accuracy: 0.3102 - auc_3: 0.6821 - f1_score: 0.2371 - val_loss: 3.1194 - val_accuracy: 0.0150 - val_auc_3: 0.2127 - val_f1_score: 0.0089\n",
      "Epoch 222/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7931 - accuracy: 0.2688 - auc_3: 0.6807 - f1_score: 0.2079 - val_loss: 2.8811 - val_accuracy: 0.0526 - val_auc_3: 0.3069 - val_f1_score: 0.0272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8152 - accuracy: 0.2575 - auc_3: 0.6745 - f1_score: 0.2032 - val_loss: 3.1090 - val_accuracy: 0.0075 - val_auc_3: 0.2043 - val_f1_score: 0.0054\n",
      "Epoch 224/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8185 - accuracy: 0.2406 - auc_3: 0.6593 - f1_score: 0.1857 - val_loss: 2.9201 - val_accuracy: 0.0376 - val_auc_3: 0.2891 - val_f1_score: 0.0209\n",
      "Epoch 225/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7998 - accuracy: 0.2538 - auc_3: 0.6781 - f1_score: 0.2003 - val_loss: 3.0503 - val_accuracy: 0.0075 - val_auc_3: 0.2237 - val_f1_score: 0.0034\n",
      "Epoch 226/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8135 - accuracy: 0.2124 - auc_3: 0.6622 - f1_score: 0.1666 - val_loss: 2.9251 - val_accuracy: 0.0075 - val_auc_3: 0.2829 - val_f1_score: 0.0055\n",
      "Epoch 227/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7659 - accuracy: 0.2857 - auc_3: 0.6938 - f1_score: 0.2472 - val_loss: 3.0691 - val_accuracy: 0.0150 - val_auc_3: 0.2216 - val_f1_score: 0.0068\n",
      "Epoch 228/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8005 - accuracy: 0.2632 - auc_3: 0.6805 - f1_score: 0.1986 - val_loss: 3.2039 - val_accuracy: 0.0075 - val_auc_3: 0.2026 - val_f1_score: 0.0055\n",
      "Epoch 229/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7855 - accuracy: 0.2406 - auc_3: 0.6770 - f1_score: 0.2118 - val_loss: 2.6561 - val_accuracy: 0.0977 - val_auc_3: 0.3561 - val_f1_score: 0.0488\n",
      "Epoch 230/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7664 - accuracy: 0.2838 - auc_3: 0.6858 - f1_score: 0.2511 - val_loss: 3.6571 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1893 - val_f1_score: 0.0000e+00- accuracy: 0.2838 - auc_3: 0.6858 - f1_score: 0.251\n",
      "Epoch 231/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8138 - accuracy: 0.2462 - auc_3: 0.6809 - f1_score: 0.1874 - val_loss: 2.8460 - val_accuracy: 0.0226 - val_auc_3: 0.2946 - val_f1_score: 0.0142\n",
      "Epoch 232/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8051 - accuracy: 0.2575 - auc_3: 0.6783 - f1_score: 0.2126 - val_loss: 3.1307 - val_accuracy: 0.0000e+00 - val_auc_3: 0.2330 - val_f1_score: 0.0000e+00\n",
      "Epoch 233/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8142 - accuracy: 0.2462 - auc_3: 0.6754 - f1_score: 0.1851 - val_loss: 2.5780 - val_accuracy: 0.1654 - val_auc_3: 0.3804 - val_f1_score: 0.0752\n",
      "Epoch 234/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8649 - accuracy: 0.2481 - auc_3: 0.6444 - f1_score: 0.2094 - val_loss: 3.0913 - val_accuracy: 0.0376 - val_auc_3: 0.2698 - val_f1_score: 0.0239\n",
      "Epoch 235/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8028 - accuracy: 0.2387 - auc_3: 0.6700 - f1_score: 0.1816 - val_loss: 2.7163 - val_accuracy: 0.0977 - val_auc_3: 0.3180 - val_f1_score: 0.0415\n",
      "Epoch 236/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7878 - accuracy: 0.2763 - auc_3: 0.6805 - f1_score: 0.2233 - val_loss: 2.8978 - val_accuracy: 0.0226 - val_auc_3: 0.3037 - val_f1_score: 0.0133\n",
      "Epoch 237/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8128 - accuracy: 0.2519 - auc_3: 0.6682 - f1_score: 0.1937 - val_loss: 3.2042 - val_accuracy: 0.0000e+00 - val_auc_3: 0.2055 - val_f1_score: 0.0000e+00\n",
      "Epoch 238/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7978 - accuracy: 0.2650 - auc_3: 0.6775 - f1_score: 0.2045 - val_loss: 2.9703 - val_accuracy: 0.0602 - val_auc_3: 0.3216 - val_f1_score: 0.0251\n",
      "Epoch 239/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8336 - accuracy: 0.2688 - auc_3: 0.6696 - f1_score: 0.1999 - val_loss: 2.7575 - val_accuracy: 0.1053 - val_auc_3: 0.3365 - val_f1_score: 0.0570\n",
      "Epoch 240/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8189 - accuracy: 0.2632 - auc_3: 0.6699 - f1_score: 0.2182 - val_loss: 3.2513 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1970 - val_f1_score: 0.0000e+00\n",
      "Epoch 241/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8068 - accuracy: 0.2500 - auc_3: 0.6763 - f1_score: 0.1918 - val_loss: 2.9344 - val_accuracy: 0.0150 - val_auc_3: 0.2680 - val_f1_score: 0.0089\n",
      "Epoch 242/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8325 - accuracy: 0.2594 - auc_3: 0.6691 - f1_score: 0.2153 - val_loss: 2.8353 - val_accuracy: 0.0451 - val_auc_3: 0.3285 - val_f1_score: 0.0257\n",
      "Epoch 243/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7871 - accuracy: 0.2444 - auc_3: 0.6800 - f1_score: 0.1811 - val_loss: 3.1115 - val_accuracy: 0.0075 - val_auc_3: 0.2287 - val_f1_score: 0.0034\n",
      "Epoch 244/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7927 - accuracy: 0.2312 - auc_3: 0.6783 - f1_score: 0.1869 - val_loss: 3.0524 - val_accuracy: 0.0075 - val_auc_3: 0.2376 - val_f1_score: 0.0055\n",
      "Epoch 245/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7736 - accuracy: 0.2632 - auc_3: 0.6900 - f1_score: 0.2028 - val_loss: 3.0120 - val_accuracy: 0.0075 - val_auc_3: 0.2732 - val_f1_score: 0.0054\n",
      "Epoch 246/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8106 - accuracy: 0.2744 - auc_3: 0.6786 - f1_score: 0.1995 - val_loss: 2.8943 - val_accuracy: 0.0000e+00 - val_auc_3: 0.3122 - val_f1_score: 0.0000e+00\n",
      "Epoch 247/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7961 - accuracy: 0.2951 - auc_3: 0.6863 - f1_score: 0.2429 - val_loss: 2.6821 - val_accuracy: 0.1203 - val_auc_3: 0.3285 - val_f1_score: 0.0462\n",
      "Epoch 248/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8170 - accuracy: 0.2594 - auc_3: 0.6750 - f1_score: 0.1994 - val_loss: 3.1532 - val_accuracy: 0.0226 - val_auc_3: 0.2454 - val_f1_score: 0.0122\n",
      "Epoch 249/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8408 - accuracy: 0.2406 - auc_3: 0.6644 - f1_score: 0.1912 - val_loss: 2.8257 - val_accuracy: 0.0677 - val_auc_3: 0.2964 - val_f1_score: 0.0377\n",
      "Epoch 250/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7948 - accuracy: 0.2575 - auc_3: 0.6767 - f1_score: 0.2113 - val_loss: 3.0034 - val_accuracy: 0.0301 - val_auc_3: 0.2459 - val_f1_score: 0.0174\n",
      "Epoch 251/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7800 - accuracy: 0.2444 - auc_3: 0.6811 - f1_score: 0.1886 - val_loss: 2.9071 - val_accuracy: 0.0150 - val_auc_3: 0.2991 - val_f1_score: 0.0068\n",
      "Epoch 252/500\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.8086 - accuracy: 0.2312 - auc_3: 0.6702 - f1_score: 0.1775 - val_loss: 2.9674 - val_accuracy: 0.0075 - val_auc_3: 0.2446 - val_f1_score: 0.0034\n",
      "Epoch 253/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8354 - accuracy: 0.2199 - auc_3: 0.6633 - f1_score: 0.1626 - val_loss: 2.8463 - val_accuracy: 0.0075 - val_auc_3: 0.3074 - val_f1_score: 0.0055\n",
      "Epoch 254/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8424 - accuracy: 0.2462 - auc_3: 0.6616 - f1_score: 0.1965 - val_loss: 3.0127 - val_accuracy: 0.0226 - val_auc_3: 0.2211 - val_f1_score: 0.0123\n",
      "Epoch 255/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8081 - accuracy: 0.2632 - auc_3: 0.6768 - f1_score: 0.2075 - val_loss: 2.5470 - val_accuracy: 0.1504 - val_auc_3: 0.3722 - val_f1_score: 0.0644\n",
      "Epoch 256/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.8221 - accuracy: 0.2500 - auc_3: 0.6646 - f1_score: 0.1934 - val_loss: 2.9416 - val_accuracy: 0.0226 - val_auc_3: 0.2700 - val_f1_score: 0.0142\n",
      "Epoch 257/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7792 - accuracy: 0.2707 - auc_3: 0.6799 - f1_score: 0.2035 - val_loss: 2.8100 - val_accuracy: 0.0226 - val_auc_3: 0.2972 - val_f1_score: 0.0101\n",
      "Epoch 258/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7874 - accuracy: 0.2782 - auc_3: 0.6858 - f1_score: 0.2016 - val_loss: 3.0651 - val_accuracy: 0.0150 - val_auc_3: 0.2304 - val_f1_score: 0.0108\n",
      "Epoch 259/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8119 - accuracy: 0.2519 - auc_3: 0.6698 - f1_score: 0.2097 - val_loss: 2.7292 - val_accuracy: 0.1203 - val_auc_3: 0.3237 - val_f1_score: 0.0544\n",
      "Epoch 260/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7713 - accuracy: 0.2650 - auc_3: 0.6878 - f1_score: 0.2021 - val_loss: 2.9687 - val_accuracy: 0.0376 - val_auc_3: 0.2676 - val_f1_score: 0.0164\n",
      "Epoch 261/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7761 - accuracy: 0.2594 - auc_3: 0.6937 - f1_score: 0.2131 - val_loss: 2.7143 - val_accuracy: 0.0827 - val_auc_3: 0.3188 - val_f1_score: 0.0361\n",
      "Epoch 262/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8128 - accuracy: 0.2556 - auc_3: 0.6713 - f1_score: 0.1988 - val_loss: 2.6227 - val_accuracy: 0.0752 - val_auc_3: 0.3762 - val_f1_score: 0.0311\n",
      "Epoch 263/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7976 - accuracy: 0.2613 - auc_3: 0.6782 - f1_score: 0.1942 - val_loss: 3.2134 - val_accuracy: 0.0075 - val_auc_3: 0.2088 - val_f1_score: 0.0055\n",
      "Epoch 264/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7721 - accuracy: 0.2914 - auc_3: 0.6928 - f1_score: 0.2397 - val_loss: 2.5774 - val_accuracy: 0.1053 - val_auc_3: 0.3770 - val_f1_score: 0.0443\n",
      "Epoch 265/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7996 - accuracy: 0.2406 - auc_3: 0.6797 - f1_score: 0.2027 - val_loss: 3.0311 - val_accuracy: 0.0226 - val_auc_3: 0.2539 - val_f1_score: 0.0123\n",
      "Epoch 266/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8016 - accuracy: 0.2594 - auc_3: 0.6732 - f1_score: 0.1969 - val_loss: 2.9839 - val_accuracy: 0.0075 - val_auc_3: 0.2302 - val_f1_score: 0.0034\n",
      "Epoch 267/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7964 - accuracy: 0.2481 - auc_3: 0.6788 - f1_score: 0.2067 - val_loss: 3.0274 - val_accuracy: 0.0075 - val_auc_3: 0.2345 - val_f1_score: 0.0034\n",
      "Epoch 268/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7905 - accuracy: 0.2650 - auc_3: 0.6810 - f1_score: 0.2128 - val_loss: 2.8674 - val_accuracy: 0.0226 - val_auc_3: 0.2777 - val_f1_score: 0.0122\n",
      "Epoch 269/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7963 - accuracy: 0.2500 - auc_3: 0.6801 - f1_score: 0.1883 - val_loss: 2.7783 - val_accuracy: 0.0526 - val_auc_3: 0.2792 - val_f1_score: 0.0282\n",
      "Epoch 270/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8093 - accuracy: 0.2613 - auc_3: 0.6771 - f1_score: 0.1961 - val_loss: 3.1785 - val_accuracy: 0.0075 - val_auc_3: 0.2406 - val_f1_score: 0.0054\n",
      "Epoch 271/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8291 - accuracy: 0.2650 - auc_3: 0.6668 - f1_score: 0.2182 - val_loss: 3.2073 - val_accuracy: 0.0075 - val_auc_3: 0.2482 - val_f1_score: 0.0055\n",
      "Epoch 272/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8384 - accuracy: 0.2030 - auc_3: 0.6634 - f1_score: 0.1497 - val_loss: 3.0047 - val_accuracy: 0.0226 - val_auc_3: 0.2402 - val_f1_score: 0.0142: 1.8290 - accuracy: 0.2091 - auc_3: 0.6683 - f1_score: 0.\n",
      "Epoch 273/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7899 - accuracy: 0.2707 - auc_3: 0.6841 - f1_score: 0.2033 - val_loss: 3.1997 - val_accuracy: 0.0301 - val_auc_3: 0.2187 - val_f1_score: 0.0208\n",
      "Epoch 274/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7848 - accuracy: 0.2838 - auc_3: 0.6863 - f1_score: 0.2261 - val_loss: 2.9825 - val_accuracy: 0.0075 - val_auc_3: 0.2595 - val_f1_score: 0.0055\n",
      "Epoch 275/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7877 - accuracy: 0.2613 - auc_3: 0.6802 - f1_score: 0.2200 - val_loss: 3.0181 - val_accuracy: 0.0451 - val_auc_3: 0.2631 - val_f1_score: 0.0291\n",
      "Epoch 276/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7728 - accuracy: 0.2650 - auc_3: 0.6945 - f1_score: 0.2125 - val_loss: 2.9182 - val_accuracy: 0.0301 - val_auc_3: 0.2964 - val_f1_score: 0.0193\n",
      "Epoch 277/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7988 - accuracy: 0.2613 - auc_3: 0.6759 - f1_score: 0.1956 - val_loss: 3.0574 - val_accuracy: 0.0150 - val_auc_3: 0.2530 - val_f1_score: 0.0068\n",
      "Epoch 278/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7956 - accuracy: 0.2613 - auc_3: 0.6825 - f1_score: 0.1971 - val_loss: 3.0484 - val_accuracy: 0.0150 - val_auc_3: 0.2481 - val_f1_score: 0.0089\n",
      "Epoch 279/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7693 - accuracy: 0.2312 - auc_3: 0.6893 - f1_score: 0.1712 - val_loss: 2.8479 - val_accuracy: 0.0226 - val_auc_3: 0.2670 - val_f1_score: 0.0122\n",
      "Epoch 280/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8123 - accuracy: 0.2387 - auc_3: 0.6648 - f1_score: 0.2161 - val_loss: 3.3881 - val_accuracy: 0.0000e+00 - val_auc_3: 0.2147 - val_f1_score: 0.0000e+00\n",
      "Epoch 281/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7838 - accuracy: 0.2857 - auc_3: 0.6902 - f1_score: 0.2115 - val_loss: 3.0327 - val_accuracy: 0.0150 - val_auc_3: 0.2390 - val_f1_score: 0.0087\n",
      "Epoch 282/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8274 - accuracy: 0.2312 - auc_3: 0.6562 - f1_score: 0.2049 - val_loss: 3.2965 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1993 - val_f1_score: 0.0000e+00\n",
      "Epoch 283/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8371 - accuracy: 0.2312 - auc_3: 0.6622 - f1_score: 0.1878 - val_loss: 2.9690 - val_accuracy: 0.0226 - val_auc_3: 0.2937 - val_f1_score: 0.0100\n",
      "Epoch 284/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8148 - accuracy: 0.2425 - auc_3: 0.6767 - f1_score: 0.1830 - val_loss: 2.5959 - val_accuracy: 0.1805 - val_auc_3: 0.3902 - val_f1_score: 0.0800\n",
      "Epoch 285/500\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 1.7827 - accuracy: 0.2538 - auc_3: 0.6816 - f1_score: 0.2003 - val_loss: 2.7761 - val_accuracy: 0.0301 - val_auc_3: 0.3373 - val_f1_score: 0.0133\n",
      "Epoch 286/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7986 - accuracy: 0.2444 - auc_3: 0.6759 - f1_score: 0.1916 - val_loss: 3.1773 - val_accuracy: 0.0075 - val_auc_3: 0.1944 - val_f1_score: 0.0034\n",
      "Epoch 287/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8100 - accuracy: 0.2387 - auc_3: 0.6684 - f1_score: 0.1888 - val_loss: 3.1016 - val_accuracy: 0.0301 - val_auc_3: 0.2590 - val_f1_score: 0.0133\n",
      "Epoch 288/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7924 - accuracy: 0.2500 - auc_3: 0.6755 - f1_score: 0.1961 - val_loss: 2.7128 - val_accuracy: 0.0526 - val_auc_3: 0.3404 - val_f1_score: 0.0289\n",
      "Epoch 289/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7862 - accuracy: 0.2726 - auc_3: 0.6841 - f1_score: 0.2080 - val_loss: 2.8913 - val_accuracy: 0.0376 - val_auc_3: 0.3093 - val_f1_score: 0.0164\n",
      "Epoch 290/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7955 - accuracy: 0.2406 - auc_3: 0.6753 - f1_score: 0.1844 - val_loss: 3.0129 - val_accuracy: 0.0226 - val_auc_3: 0.2408 - val_f1_score: 0.0159\n",
      "Epoch 291/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7762 - accuracy: 0.2857 - auc_3: 0.6902 - f1_score: 0.2248 - val_loss: 2.7027 - val_accuracy: 0.0602 - val_auc_3: 0.3257 - val_f1_score: 0.0303\n",
      "Epoch 292/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8319 - accuracy: 0.2368 - auc_3: 0.6591 - f1_score: 0.1954 - val_loss: 2.8445 - val_accuracy: 0.0150 - val_auc_3: 0.2910 - val_f1_score: 0.0068\n",
      "Epoch 293/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8192 - accuracy: 0.2650 - auc_3: 0.6719 - f1_score: 0.1932 - val_loss: 2.9672 - val_accuracy: 0.0376 - val_auc_3: 0.2585 - val_f1_score: 0.0255\n",
      "Epoch 294/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8079 - accuracy: 0.2406 - auc_3: 0.6770 - f1_score: 0.2004 - val_loss: 3.0116 - val_accuracy: 0.0150 - val_auc_3: 0.2283 - val_f1_score: 0.0106\n",
      "Epoch 295/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7944 - accuracy: 0.2462 - auc_3: 0.6732 - f1_score: 0.1941 - val_loss: 2.7267 - val_accuracy: 0.0075 - val_auc_3: 0.3199 - val_f1_score: 0.0034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296/500\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.7830 - accuracy: 0.2613 - auc_3: 0.6853 - f1_score: 0.1979 - val_loss: 3.0742 - val_accuracy: 0.0301 - val_auc_3: 0.2498 - val_f1_score: 0.0193\n",
      "Epoch 297/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7967 - accuracy: 0.2744 - auc_3: 0.6780 - f1_score: 0.2140 - val_loss: 2.6113 - val_accuracy: 0.0752 - val_auc_3: 0.3778 - val_f1_score: 0.0395\n",
      "Epoch 298/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7661 - accuracy: 0.2575 - auc_3: 0.6852 - f1_score: 0.2143 - val_loss: 2.7615 - val_accuracy: 0.0827 - val_auc_3: 0.3153 - val_f1_score: 0.0437\n",
      "Epoch 299/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8079 - accuracy: 0.2575 - auc_3: 0.6696 - f1_score: 0.2303 - val_loss: 2.9199 - val_accuracy: 0.0301 - val_auc_3: 0.3021 - val_f1_score: 0.0174\n",
      "Epoch 300/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7859 - accuracy: 0.2594 - auc_3: 0.6862 - f1_score: 0.1940 - val_loss: 2.9473 - val_accuracy: 0.0075 - val_auc_3: 0.2653 - val_f1_score: 0.0034\n",
      "Epoch 301/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7803 - accuracy: 0.2613 - auc_3: 0.6860 - f1_score: 0.2095 - val_loss: 2.8542 - val_accuracy: 0.0752 - val_auc_3: 0.2928 - val_f1_score: 0.0399\n",
      "Epoch 302/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8202 - accuracy: 0.2669 - auc_3: 0.6680 - f1_score: 0.2074 - val_loss: 2.8790 - val_accuracy: 0.0301 - val_auc_3: 0.3003 - val_f1_score: 0.0175\n",
      "Epoch 303/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8009 - accuracy: 0.2462 - auc_3: 0.6779 - f1_score: 0.1986 - val_loss: 2.7196 - val_accuracy: 0.0451 - val_auc_3: 0.3256 - val_f1_score: 0.0195\n",
      "Epoch 304/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7693 - accuracy: 0.2801 - auc_3: 0.6893 - f1_score: 0.2298 - val_loss: 3.1582 - val_accuracy: 0.0000e+00 - val_auc_3: 0.2332 - val_f1_score: 0.0000e+00\n",
      "Epoch 305/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8186 - accuracy: 0.2594 - auc_3: 0.6692 - f1_score: 0.2085 - val_loss: 2.8439 - val_accuracy: 0.0526 - val_auc_3: 0.2605 - val_f1_score: 0.0290\n",
      "Epoch 306/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7713 - accuracy: 0.2970 - auc_3: 0.6863 - f1_score: 0.2364 - val_loss: 2.9627 - val_accuracy: 0.0075 - val_auc_3: 0.2840 - val_f1_score: 0.0034\n",
      "Epoch 307/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7939 - accuracy: 0.2613 - auc_3: 0.6815 - f1_score: 0.2112 - val_loss: 2.9358 - val_accuracy: 0.0000e+00 - val_auc_3: 0.2623 - val_f1_score: 0.0000e+00\n",
      "Epoch 308/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7883 - accuracy: 0.2650 - auc_3: 0.6833 - f1_score: 0.2079 - val_loss: 2.9263 - val_accuracy: 0.0301 - val_auc_3: 0.3025 - val_f1_score: 0.0133\n",
      "Epoch 309/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8279 - accuracy: 0.2613 - auc_3: 0.6714 - f1_score: 0.2092 - val_loss: 2.9525 - val_accuracy: 0.0451 - val_auc_3: 0.2255 - val_f1_score: 0.0254\n",
      "Epoch 310/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7983 - accuracy: 0.2951 - auc_3: 0.6787 - f1_score: 0.2239 - val_loss: 2.7727 - val_accuracy: 0.0301 - val_auc_3: 0.3304 - val_f1_score: 0.0174\n",
      "Epoch 311/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7816 - accuracy: 0.2632 - auc_3: 0.6845 - f1_score: 0.2230 - val_loss: 3.0862 - val_accuracy: 0.0000e+00 - val_auc_3: 0.2141 - val_f1_score: 0.0000e+00\n",
      "Epoch 312/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7946 - accuracy: 0.2632 - auc_3: 0.6780 - f1_score: 0.1993 - val_loss: 2.9133 - val_accuracy: 0.0226 - val_auc_3: 0.2841 - val_f1_score: 0.0101\n",
      "Epoch 313/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8012 - accuracy: 0.2519 - auc_3: 0.6809 - f1_score: 0.1921 - val_loss: 2.6619 - val_accuracy: 0.0977 - val_auc_3: 0.3750 - val_f1_score: 0.0478\n",
      "Epoch 314/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7971 - accuracy: 0.2538 - auc_3: 0.6697 - f1_score: 0.2168 - val_loss: 3.0380 - val_accuracy: 0.0226 - val_auc_3: 0.2329 - val_f1_score: 0.0121\n",
      "Epoch 315/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8087 - accuracy: 0.2462 - auc_3: 0.6695 - f1_score: 0.1848 - val_loss: 2.5863 - val_accuracy: 0.1278 - val_auc_3: 0.3766 - val_f1_score: 0.0521\n",
      "Epoch 316/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8152 - accuracy: 0.2726 - auc_3: 0.6690 - f1_score: 0.2043 - val_loss: 3.1358 - val_accuracy: 0.0000e+00 - val_auc_3: 0.2316 - val_f1_score: 0.0000e+00\n",
      "Epoch 317/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8010 - accuracy: 0.2801 - auc_3: 0.6774 - f1_score: 0.2154 - val_loss: 2.9081 - val_accuracy: 0.0075 - val_auc_3: 0.2696 - val_f1_score: 0.0034\n",
      "Epoch 318/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7795 - accuracy: 0.2688 - auc_3: 0.6893 - f1_score: 0.2125 - val_loss: 2.8155 - val_accuracy: 0.0226 - val_auc_3: 0.2940 - val_f1_score: 0.0142\n",
      "Epoch 319/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8054 - accuracy: 0.2538 - auc_3: 0.6785 - f1_score: 0.1966 - val_loss: 3.0855 - val_accuracy: 0.0226 - val_auc_3: 0.2469 - val_f1_score: 0.0122\n",
      "Epoch 320/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8117 - accuracy: 0.2162 - auc_3: 0.6673 - f1_score: 0.1666 - val_loss: 3.0405 - val_accuracy: 0.0226 - val_auc_3: 0.2471 - val_f1_score: 0.0148\n",
      "Epoch 321/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7756 - accuracy: 0.2500 - auc_3: 0.6839 - f1_score: 0.1959 - val_loss: 2.7321 - val_accuracy: 0.0301 - val_auc_3: 0.3305 - val_f1_score: 0.0133\n",
      "Epoch 322/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8099 - accuracy: 0.2350 - auc_3: 0.6762 - f1_score: 0.1829 - val_loss: 2.8012 - val_accuracy: 0.0301 - val_auc_3: 0.2783 - val_f1_score: 0.0154\n",
      "Epoch 323/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7944 - accuracy: 0.2481 - auc_3: 0.6778 - f1_score: 0.2197 - val_loss: 3.0645 - val_accuracy: 0.0150 - val_auc_3: 0.2428 - val_f1_score: 0.0108\n",
      "Epoch 324/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8270 - accuracy: 0.2256 - auc_3: 0.6608 - f1_score: 0.1704 - val_loss: 2.9607 - val_accuracy: 0.0451 - val_auc_3: 0.2961 - val_f1_score: 0.0219\n",
      "Epoch 325/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7778 - accuracy: 0.2820 - auc_3: 0.6892 - f1_score: 0.2128 - val_loss: 3.0576 - val_accuracy: 0.0301 - val_auc_3: 0.2288 - val_f1_score: 0.0201\n",
      "Epoch 326/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7892 - accuracy: 0.2782 - auc_3: 0.6779 - f1_score: 0.2204 - val_loss: 2.6714 - val_accuracy: 0.0602 - val_auc_3: 0.3232 - val_f1_score: 0.0280\n",
      "Epoch 327/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8248 - accuracy: 0.2312 - auc_3: 0.6655 - f1_score: 0.1970 - val_loss: 3.3866 - val_accuracy: 0.0000e+00 - val_auc_3: 0.2174 - val_f1_score: 0.0000e+00\n",
      "Epoch 328/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7976 - accuracy: 0.2462 - auc_3: 0.6785 - f1_score: 0.2111 - val_loss: 3.1423 - val_accuracy: 0.0150 - val_auc_3: 0.2465 - val_f1_score: 0.0089\n",
      "Epoch 329/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8110 - accuracy: 0.2613 - auc_3: 0.6718 - f1_score: 0.2111 - val_loss: 3.1618 - val_accuracy: 0.0226 - val_auc_3: 0.2341 - val_f1_score: 0.0159\n",
      "Epoch 330/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7920 - accuracy: 0.2575 - auc_3: 0.6788 - f1_score: 0.2093 - val_loss: 2.8875 - val_accuracy: 0.0301 - val_auc_3: 0.2754 - val_f1_score: 0.0133\n",
      "Epoch 331/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7939 - accuracy: 0.2707 - auc_3: 0.6789 - f1_score: 0.2172 - val_loss: 2.8432 - val_accuracy: 0.0301 - val_auc_3: 0.3015 - val_f1_score: 0.0156\n",
      "Epoch 332/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7913 - accuracy: 0.2669 - auc_3: 0.6817 - f1_score: 0.2150 - val_loss: 2.8917 - val_accuracy: 0.0150 - val_auc_3: 0.2804 - val_f1_score: 0.0088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 333/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8056 - accuracy: 0.2669 - auc_3: 0.6755 - f1_score: 0.2038 - val_loss: 3.0648 - val_accuracy: 0.0075 - val_auc_3: 0.2516 - val_f1_score: 0.0034\n",
      "Epoch 334/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8072 - accuracy: 0.2274 - auc_3: 0.6694 - f1_score: 0.1771 - val_loss: 2.7397 - val_accuracy: 0.0526 - val_auc_3: 0.3307 - val_f1_score: 0.0250\n",
      "Epoch 335/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7953 - accuracy: 0.2613 - auc_3: 0.6792 - f1_score: 0.1969 - val_loss: 3.2290 - val_accuracy: 0.0075 - val_auc_3: 0.2025 - val_f1_score: 0.0055\n",
      "Epoch 336/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8213 - accuracy: 0.2312 - auc_3: 0.6626 - f1_score: 0.1898 - val_loss: 3.9337 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1775 - val_f1_score: 0.0000e+00\n",
      "Epoch 337/500\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 1.8210 - accuracy: 0.2707 - auc_3: 0.6821 - f1_score: 0.1994 - val_loss: 3.1984 - val_accuracy: 0.0075 - val_auc_3: 0.1772 - val_f1_score: 0.0034\n",
      "Epoch 338/500\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 1.7882 - accuracy: 0.2613 - auc_3: 0.6816 - f1_score: 0.2111 - val_loss: 2.6780 - val_accuracy: 0.0602 - val_auc_3: 0.3090 - val_f1_score: 0.0248\n",
      "Epoch 339/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8199 - accuracy: 0.2519 - auc_3: 0.6731 - f1_score: 0.2100 - val_loss: 3.1555 - val_accuracy: 0.0000e+00 - val_auc_3: 0.2481 - val_f1_score: 0.0000e+00\n",
      "Epoch 340/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8612 - accuracy: 0.2444 - auc_3: 0.6594 - f1_score: 0.1904 - val_loss: 2.8640 - val_accuracy: 0.0376 - val_auc_3: 0.2876 - val_f1_score: 0.0186\n",
      "Epoch 341/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7941 - accuracy: 0.2387 - auc_3: 0.6814 - f1_score: 0.1906 - val_loss: 3.2014 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1970 - val_f1_score: 0.0000e+00\n",
      "Epoch 342/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8009 - accuracy: 0.2594 - auc_3: 0.6782 - f1_score: 0.2073 - val_loss: 3.1372 - val_accuracy: 0.0075 - val_auc_3: 0.2347 - val_f1_score: 0.0054\n",
      "Epoch 343/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8153 - accuracy: 0.2650 - auc_3: 0.6652 - f1_score: 0.1985 - val_loss: 2.9687 - val_accuracy: 0.0075 - val_auc_3: 0.2457 - val_f1_score: 0.0034\n",
      "Epoch 344/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7931 - accuracy: 0.2594 - auc_3: 0.6861 - f1_score: 0.1856 - val_loss: 2.7997 - val_accuracy: 0.0752 - val_auc_3: 0.3062 - val_f1_score: 0.0311\n",
      "Epoch 345/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8032 - accuracy: 0.2444 - auc_3: 0.6709 - f1_score: 0.2247 - val_loss: 3.6276 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1380 - val_f1_score: 0.0000e+00\n",
      "Epoch 346/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8242 - accuracy: 0.2632 - auc_3: 0.6669 - f1_score: 0.1959 - val_loss: 2.8111 - val_accuracy: 0.0677 - val_auc_3: 0.2833 - val_f1_score: 0.0381\n",
      "Epoch 347/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8010 - accuracy: 0.2556 - auc_3: 0.6725 - f1_score: 0.2176 - val_loss: 3.4361 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1787 - val_f1_score: 0.0000e+00\n",
      "Epoch 348/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7903 - accuracy: 0.2538 - auc_3: 0.6850 - f1_score: 0.1948 - val_loss: 2.7657 - val_accuracy: 0.0827 - val_auc_3: 0.3373 - val_f1_score: 0.0432\n",
      "Epoch 349/500\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 1.8339 - accuracy: 0.2425 - auc_3: 0.6700 - f1_score: 0.1863 - val_loss: 2.7648 - val_accuracy: 0.0977 - val_auc_3: 0.3106 - val_f1_score: 0.0415\n",
      "Epoch 350/500\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 1.8195 - accuracy: 0.2444 - auc_3: 0.6653 - f1_score: 0.2137 - val_loss: 3.2077 - val_accuracy: 0.0150 - val_auc_3: 0.1822 - val_f1_score: 0.0108\n",
      "Epoch 351/500\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 1.8067 - accuracy: 0.2575 - auc_3: 0.6776 - f1_score: 0.1995 - val_loss: 2.7424 - val_accuracy: 0.0977 - val_auc_3: 0.3293 - val_f1_score: 0.0420\n",
      "Epoch 352/500\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 1.7750 - accuracy: 0.2895 - auc_3: 0.6843 - f1_score: 0.2380 - val_loss: 2.9791 - val_accuracy: 0.0226 - val_auc_3: 0.2383 - val_f1_score: 0.0123\n",
      "Epoch 353/500\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.8314 - accuracy: 0.2575 - auc_3: 0.6614 - f1_score: 0.1976 - val_loss: 2.9766 - val_accuracy: 0.0150 - val_auc_3: 0.2478 - val_f1_score: 0.0108\n",
      "Epoch 354/500\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 1.8107 - accuracy: 0.2406 - auc_3: 0.6753 - f1_score: 0.1901 - val_loss: 2.6415 - val_accuracy: 0.0526 - val_auc_3: 0.3307 - val_f1_score: 0.0301\n",
      "Epoch 355/500\n",
      "17/17 [==============================] - 1s 64ms/step - loss: 1.7739 - accuracy: 0.2613 - auc_3: 0.6826 - f1_score: 0.2073 - val_loss: 3.0107 - val_accuracy: 0.0677 - val_auc_3: 0.2600 - val_f1_score: 0.0306\n",
      "Epoch 356/500\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 1.8164 - accuracy: 0.2782 - auc_3: 0.6859 - f1_score: 0.2072 - val_loss: 2.7354 - val_accuracy: 0.0752 - val_auc_3: 0.3647 - val_f1_score: 0.0427\n",
      "Epoch 357/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8969 - accuracy: 0.1936 - auc_3: 0.6321 - f1_score: 0.1643 - val_loss: 3.2535 - val_accuracy: 0.0000e+00 - val_auc_3: 0.2108 - val_f1_score: 0.0000e+00\n",
      "Epoch 358/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7824 - accuracy: 0.2707 - auc_3: 0.6852 - f1_score: 0.2013 - val_loss: 2.8131 - val_accuracy: 0.0677 - val_auc_3: 0.3263 - val_f1_score: 0.0309\n",
      "Epoch 359/500\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 1.8120 - accuracy: 0.2538 - auc_3: 0.6723 - f1_score: 0.2069 - val_loss: 3.3037 - val_accuracy: 0.0075 - val_auc_3: 0.1993 - val_f1_score: 0.0054\n",
      "Epoch 360/500\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 1.8201 - accuracy: 0.2368 - auc_3: 0.6711 - f1_score: 0.1983 - val_loss: 3.1055 - val_accuracy: 0.0000e+00 - val_auc_3: 0.2698 - val_f1_score: 0.0000e+00\n",
      "Epoch 361/500\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 1.8269 - accuracy: 0.2500 - auc_3: 0.6698 - f1_score: 0.2042 - val_loss: 2.9393 - val_accuracy: 0.0526 - val_auc_3: 0.2617 - val_f1_score: 0.0292\n",
      "Epoch 362/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8075 - accuracy: 0.2594 - auc_3: 0.6773 - f1_score: 0.2136 - val_loss: 3.0524 - val_accuracy: 0.0301 - val_auc_3: 0.2502 - val_f1_score: 0.0176\n",
      "Epoch 363/500\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.7932 - accuracy: 0.2481 - auc_3: 0.6816 - f1_score: 0.1908 - val_loss: 3.1288 - val_accuracy: 0.0150 - val_auc_3: 0.2223 - val_f1_score: 0.0089\n",
      "Epoch 364/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7956 - accuracy: 0.2237 - auc_3: 0.6776 - f1_score: 0.1833 - val_loss: 2.9531 - val_accuracy: 0.0376 - val_auc_3: 0.2915 - val_f1_score: 0.0224\n",
      "Epoch 365/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7840 - accuracy: 0.2763 - auc_3: 0.6855 - f1_score: 0.2120 - val_loss: 2.6487 - val_accuracy: 0.0977 - val_auc_3: 0.3474 - val_f1_score: 0.0416\n",
      "Epoch 366/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7865 - accuracy: 0.2556 - auc_3: 0.6812 - f1_score: 0.1988 - val_loss: 2.8106 - val_accuracy: 0.0301 - val_auc_3: 0.3406 - val_f1_score: 0.0204\n",
      "Epoch 367/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8220 - accuracy: 0.2387 - auc_3: 0.6655 - f1_score: 0.1800 - val_loss: 2.7177 - val_accuracy: 0.1053 - val_auc_3: 0.3525 - val_f1_score: 0.0511\n",
      "Epoch 368/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8069 - accuracy: 0.2556 - auc_3: 0.6737 - f1_score: 0.2328 - val_loss: 2.9472 - val_accuracy: 0.0376 - val_auc_3: 0.2716 - val_f1_score: 0.0224\n",
      "Epoch 369/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7811 - accuracy: 0.2726 - auc_3: 0.6785 - f1_score: 0.2019 - val_loss: 2.8261 - val_accuracy: 0.0075 - val_auc_3: 0.2972 - val_f1_score: 0.0034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 370/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7770 - accuracy: 0.2726 - auc_3: 0.6881 - f1_score: 0.2078 - val_loss: 3.2007 - val_accuracy: 0.0451 - val_auc_3: 0.2171 - val_f1_score: 0.0273\n",
      "Epoch 371/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7926 - accuracy: 0.2613 - auc_3: 0.6795 - f1_score: 0.2167 - val_loss: 3.0303 - val_accuracy: 0.0075 - val_auc_3: 0.2430 - val_f1_score: 0.0034\n",
      "Epoch 372/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8263 - accuracy: 0.2444 - auc_3: 0.6600 - f1_score: 0.1941 - val_loss: 3.2498 - val_accuracy: 0.0075 - val_auc_3: 0.2042 - val_f1_score: 0.0034\n",
      "Epoch 373/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8068 - accuracy: 0.2556 - auc_3: 0.6793 - f1_score: 0.2162 - val_loss: 3.7237 - val_accuracy: 0.0075 - val_auc_3: 0.1858 - val_f1_score: 0.0055\n",
      "Epoch 374/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8476 - accuracy: 0.2387 - auc_3: 0.6627 - f1_score: 0.1971 - val_loss: 3.6410 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1693 - val_f1_score: 0.0000e+00\n",
      "Epoch 375/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8155 - accuracy: 0.2500 - auc_3: 0.6682 - f1_score: 0.2040 - val_loss: 3.4298 - val_accuracy: 0.0376 - val_auc_3: 0.2141 - val_f1_score: 0.0251\n",
      "Epoch 376/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8351 - accuracy: 0.2575 - auc_3: 0.6702 - f1_score: 0.1923 - val_loss: 3.0729 - val_accuracy: 0.0451 - val_auc_3: 0.2207 - val_f1_score: 0.0286\n",
      "Epoch 377/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7899 - accuracy: 0.2688 - auc_3: 0.6785 - f1_score: 0.2413 - val_loss: 2.9933 - val_accuracy: 0.0376 - val_auc_3: 0.2737 - val_f1_score: 0.0218\n",
      "Epoch 378/500\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.7778 - accuracy: 0.2669 - auc_3: 0.6851 - f1_score: 0.2011 - val_loss: 2.9572 - val_accuracy: 0.0451 - val_auc_3: 0.2584 - val_f1_score: 0.0257\n",
      "Epoch 379/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8177 - accuracy: 0.2613 - auc_3: 0.6633 - f1_score: 0.2300 - val_loss: 2.9362 - val_accuracy: 0.0226 - val_auc_3: 0.2668 - val_f1_score: 0.0101\n",
      "Epoch 380/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8255 - accuracy: 0.2350 - auc_3: 0.6635 - f1_score: 0.1754 - val_loss: 2.9362 - val_accuracy: 0.0526 - val_auc_3: 0.2546 - val_f1_score: 0.0300\n",
      "Epoch 381/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7889 - accuracy: 0.2500 - auc_3: 0.6832 - f1_score: 0.1938 - val_loss: 2.9402 - val_accuracy: 0.0150 - val_auc_3: 0.2713 - val_f1_score: 0.0067\n",
      "Epoch 382/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8020 - accuracy: 0.2143 - auc_3: 0.6656 - f1_score: 0.1841 - val_loss: 3.4974 - val_accuracy: 0.0226 - val_auc_3: 0.1648 - val_f1_score: 0.0156\n",
      "Epoch 383/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8003 - accuracy: 0.2838 - auc_3: 0.6811 - f1_score: 0.2140 - val_loss: 3.2782 - val_accuracy: 0.0075 - val_auc_3: 0.1942 - val_f1_score: 0.0054\n",
      "Epoch 384/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7891 - accuracy: 0.2857 - auc_3: 0.6765 - f1_score: 0.2223 - val_loss: 3.1052 - val_accuracy: 0.0150 - val_auc_3: 0.2124 - val_f1_score: 0.0108\n",
      "Epoch 385/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8036 - accuracy: 0.2387 - auc_3: 0.6762 - f1_score: 0.1779 - val_loss: 2.7487 - val_accuracy: 0.0827 - val_auc_3: 0.2978 - val_f1_score: 0.0338\n",
      "Epoch 386/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7937 - accuracy: 0.2444 - auc_3: 0.6730 - f1_score: 0.1946 - val_loss: 3.0182 - val_accuracy: 0.0075 - val_auc_3: 0.2378 - val_f1_score: 0.0034\n",
      "Epoch 387/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8193 - accuracy: 0.2331 - auc_3: 0.6637 - f1_score: 0.2072 - val_loss: 2.9750 - val_accuracy: 0.0150 - val_auc_3: 0.2796 - val_f1_score: 0.0089\n",
      "Epoch 388/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8071 - accuracy: 0.2594 - auc_3: 0.6751 - f1_score: 0.2139 - val_loss: 3.1162 - val_accuracy: 0.0075 - val_auc_3: 0.2053 - val_f1_score: 0.0034\n",
      "Epoch 389/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7951 - accuracy: 0.2594 - auc_3: 0.6772 - f1_score: 0.2074 - val_loss: 2.9275 - val_accuracy: 0.0602 - val_auc_3: 0.2657 - val_f1_score: 0.0336\n",
      "Epoch 390/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8165 - accuracy: 0.2632 - auc_3: 0.6669 - f1_score: 0.2149 - val_loss: 3.0729 - val_accuracy: 0.0226 - val_auc_3: 0.2441 - val_f1_score: 0.0101\n",
      "Epoch 391/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7891 - accuracy: 0.2575 - auc_3: 0.6823 - f1_score: 0.1942 - val_loss: 3.0848 - val_accuracy: 0.0150 - val_auc_3: 0.2598 - val_f1_score: 0.0088\n",
      "Epoch 392/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7689 - accuracy: 0.2857 - auc_3: 0.6916 - f1_score: 0.2333 - val_loss: 2.7393 - val_accuracy: 0.0752 - val_auc_3: 0.3416 - val_f1_score: 0.0419\n",
      "Epoch 393/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7920 - accuracy: 0.2274 - auc_3: 0.6814 - f1_score: 0.1761 - val_loss: 3.0341 - val_accuracy: 0.0150 - val_auc_3: 0.3008 - val_f1_score: 0.0068\n",
      "Epoch 394/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8018 - accuracy: 0.2538 - auc_3: 0.6764 - f1_score: 0.1896 - val_loss: 3.2212 - val_accuracy: 0.0376 - val_auc_3: 0.2399 - val_f1_score: 0.0235\n",
      "Epoch 395/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7887 - accuracy: 0.2632 - auc_3: 0.6786 - f1_score: 0.2074 - val_loss: 2.9354 - val_accuracy: 0.0301 - val_auc_3: 0.2655 - val_f1_score: 0.0133\n",
      "Epoch 396/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8352 - accuracy: 0.2707 - auc_3: 0.6603 - f1_score: 0.2144 - val_loss: 3.0931 - val_accuracy: 0.0075 - val_auc_3: 0.2808 - val_f1_score: 0.0034\n",
      "Epoch 397/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8087 - accuracy: 0.2387 - auc_3: 0.6732 - f1_score: 0.1854 - val_loss: 2.8294 - val_accuracy: 0.0451 - val_auc_3: 0.3029 - val_f1_score: 0.0237\n",
      "Epoch 398/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7907 - accuracy: 0.2575 - auc_3: 0.6806 - f1_score: 0.2078 - val_loss: 3.1233 - val_accuracy: 0.0000e+00 - val_auc_3: 0.2373 - val_f1_score: 0.0000e+00\n",
      "Epoch 399/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7881 - accuracy: 0.2594 - auc_3: 0.6734 - f1_score: 0.2312 - val_loss: 2.7650 - val_accuracy: 0.0376 - val_auc_3: 0.3240 - val_f1_score: 0.0188\n",
      "Epoch 400/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8031 - accuracy: 0.2500 - auc_3: 0.6718 - f1_score: 0.2069 - val_loss: 3.2222 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1887 - val_f1_score: 0.0000e+00\n",
      "Epoch 401/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7731 - accuracy: 0.2632 - auc_3: 0.6873 - f1_score: 0.2038 - val_loss: 2.9025 - val_accuracy: 0.0602 - val_auc_3: 0.3066 - val_f1_score: 0.0277\n",
      "Epoch 402/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8027 - accuracy: 0.2744 - auc_3: 0.6809 - f1_score: 0.2223 - val_loss: 2.7022 - val_accuracy: 0.0827 - val_auc_3: 0.3088 - val_f1_score: 0.0425\n",
      "Epoch 403/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7984 - accuracy: 0.2575 - auc_3: 0.6773 - f1_score: 0.1949 - val_loss: 2.8989 - val_accuracy: 0.0301 - val_auc_3: 0.2724 - val_f1_score: 0.0133\n",
      "Epoch 404/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.8119 - accuracy: 0.2350 - auc_3: 0.6699 - f1_score: 0.2131 - val_loss: 2.8566 - val_accuracy: 0.0526 - val_auc_3: 0.2692 - val_f1_score: 0.0305\n",
      "Epoch 405/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7948 - accuracy: 0.2556 - auc_3: 0.6757 - f1_score: 0.1986 - val_loss: 2.9526 - val_accuracy: 0.0075 - val_auc_3: 0.2829 - val_f1_score: 0.0055\n",
      "Epoch 406/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7886 - accuracy: 0.2857 - auc_3: 0.6895 - f1_score: 0.2096 - val_loss: 2.8562 - val_accuracy: 0.0226 - val_auc_3: 0.3034 - val_f1_score: 0.0122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8285 - accuracy: 0.2500 - auc_3: 0.6591 - f1_score: 0.2053 - val_loss: 3.1331 - val_accuracy: 0.0075 - val_auc_3: 0.2200 - val_f1_score: 0.0034\n",
      "Epoch 408/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8013 - accuracy: 0.2876 - auc_3: 0.6794 - f1_score: 0.2373 - val_loss: 2.8161 - val_accuracy: 0.0677 - val_auc_3: 0.2925 - val_f1_score: 0.0368\n",
      "Epoch 409/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8258 - accuracy: 0.2237 - auc_3: 0.6675 - f1_score: 0.1690 - val_loss: 3.0780 - val_accuracy: 0.0000e+00 - val_auc_3: 0.2271 - val_f1_score: 0.0000e+00\n",
      "Epoch 410/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7916 - accuracy: 0.2462 - auc_3: 0.6717 - f1_score: 0.1918 - val_loss: 2.6953 - val_accuracy: 0.0526 - val_auc_3: 0.3100 - val_f1_score: 0.0250\n",
      "Epoch 411/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7877 - accuracy: 0.2744 - auc_3: 0.6863 - f1_score: 0.2058 - val_loss: 2.8108 - val_accuracy: 0.0827 - val_auc_3: 0.3289 - val_f1_score: 0.0422\n",
      "Epoch 412/500\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.7993 - accuracy: 0.2312 - auc_3: 0.6732 - f1_score: 0.1891 - val_loss: 2.8430 - val_accuracy: 0.0301 - val_auc_3: 0.3239 - val_f1_score: 0.0204\n",
      "Epoch 413/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7965 - accuracy: 0.2519 - auc_3: 0.6764 - f1_score: 0.1991 - val_loss: 3.0216 - val_accuracy: 0.0150 - val_auc_3: 0.2343 - val_f1_score: 0.0089\n",
      "Epoch 414/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7796 - accuracy: 0.2368 - auc_3: 0.6812 - f1_score: 0.2037 - val_loss: 3.0734 - val_accuracy: 0.0075 - val_auc_3: 0.2587 - val_f1_score: 0.0051\n",
      "Epoch 415/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7705 - accuracy: 0.2688 - auc_3: 0.6927 - f1_score: 0.2245 - val_loss: 2.6957 - val_accuracy: 0.0677 - val_auc_3: 0.3328 - val_f1_score: 0.0348\n",
      "Epoch 416/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8104 - accuracy: 0.2462 - auc_3: 0.6698 - f1_score: 0.2311 - val_loss: 2.9544 - val_accuracy: 0.0376 - val_auc_3: 0.2629 - val_f1_score: 0.0187\n",
      "Epoch 417/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7877 - accuracy: 0.2857 - auc_3: 0.6853 - f1_score: 0.2276 - val_loss: 2.8620 - val_accuracy: 0.0526 - val_auc_3: 0.2981 - val_f1_score: 0.0314\n",
      "Epoch 418/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7726 - accuracy: 0.2744 - auc_3: 0.6910 - f1_score: 0.2050 - val_loss: 3.1656 - val_accuracy: 0.0000e+00 - val_auc_3: 0.2552 - val_f1_score: 0.0000e+00\n",
      "Epoch 419/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8146 - accuracy: 0.2613 - auc_3: 0.6718 - f1_score: 0.1981 - val_loss: 2.8545 - val_accuracy: 0.0677 - val_auc_3: 0.3082 - val_f1_score: 0.0283\n",
      "Epoch 420/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8120 - accuracy: 0.2481 - auc_3: 0.6701 - f1_score: 0.2036 - val_loss: 3.1902 - val_accuracy: 0.0150 - val_auc_3: 0.2163 - val_f1_score: 0.0108\n",
      "Epoch 421/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8032 - accuracy: 0.2406 - auc_3: 0.6761 - f1_score: 0.1817 - val_loss: 2.8394 - val_accuracy: 0.0376 - val_auc_3: 0.3092 - val_f1_score: 0.0231\n",
      "Epoch 422/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8061 - accuracy: 0.2444 - auc_3: 0.6753 - f1_score: 0.1902 - val_loss: 3.5025 - val_accuracy: 0.0075 - val_auc_3: 0.1916 - val_f1_score: 0.0055\n",
      "Epoch 423/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8140 - accuracy: 0.2538 - auc_3: 0.6767 - f1_score: 0.2028 - val_loss: 2.8925 - val_accuracy: 0.0301 - val_auc_3: 0.2807 - val_f1_score: 0.0193\n",
      "Epoch 424/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8238 - accuracy: 0.2575 - auc_3: 0.6689 - f1_score: 0.2058 - val_loss: 3.0553 - val_accuracy: 0.0226 - val_auc_3: 0.2730 - val_f1_score: 0.0159\n",
      "Epoch 425/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7899 - accuracy: 0.2594 - auc_3: 0.6806 - f1_score: 0.2029 - val_loss: 2.7903 - val_accuracy: 0.0451 - val_auc_3: 0.2993 - val_f1_score: 0.0195\n",
      "Epoch 426/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7963 - accuracy: 0.2575 - auc_3: 0.6755 - f1_score: 0.2216 - val_loss: 3.0353 - val_accuracy: 0.0376 - val_auc_3: 0.2907 - val_f1_score: 0.0164\n",
      "Epoch 427/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8255 - accuracy: 0.2538 - auc_3: 0.6704 - f1_score: 0.2024 - val_loss: 2.7751 - val_accuracy: 0.0526 - val_auc_3: 0.2654 - val_f1_score: 0.0249\n",
      "Epoch 428/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8026 - accuracy: 0.2538 - auc_3: 0.6757 - f1_score: 0.1868 - val_loss: 3.1340 - val_accuracy: 0.0075 - val_auc_3: 0.2172 - val_f1_score: 0.0034s: 1.8044 - accuracy: 0.2612 - auc_3: 0.6746 - f1_score: 0.1\n",
      "Epoch 429/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8164 - accuracy: 0.2707 - auc_3: 0.6726 - f1_score: 0.2031 - val_loss: 2.8194 - val_accuracy: 0.0376 - val_auc_3: 0.3586 - val_f1_score: 0.0188\n",
      "Epoch 430/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8316 - accuracy: 0.2519 - auc_3: 0.6643 - f1_score: 0.1943 - val_loss: 2.8384 - val_accuracy: 0.0827 - val_auc_3: 0.3099 - val_f1_score: 0.0424\n",
      "Epoch 431/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8120 - accuracy: 0.2820 - auc_3: 0.6761 - f1_score: 0.2030 - val_loss: 2.6797 - val_accuracy: 0.0752 - val_auc_3: 0.3486 - val_f1_score: 0.0419\n",
      "Epoch 432/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7947 - accuracy: 0.2820 - auc_3: 0.6807 - f1_score: 0.2199 - val_loss: 3.1741 - val_accuracy: 0.0075 - val_auc_3: 0.2249 - val_f1_score: 0.0034\n",
      "Epoch 433/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7887 - accuracy: 0.2594 - auc_3: 0.6774 - f1_score: 0.1913 - val_loss: 3.0907 - val_accuracy: 0.0301 - val_auc_3: 0.2594 - val_f1_score: 0.0176\n",
      "Epoch 434/500\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.7723 - accuracy: 0.2575 - auc_3: 0.6855 - f1_score: 0.2146 - val_loss: 3.0671 - val_accuracy: 0.0226 - val_auc_3: 0.2318 - val_f1_score: 0.0101\n",
      "Epoch 435/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8049 - accuracy: 0.2481 - auc_3: 0.6781 - f1_score: 0.1920 - val_loss: 2.9608 - val_accuracy: 0.0602 - val_auc_3: 0.3013 - val_f1_score: 0.0379\n",
      "Epoch 436/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8321 - accuracy: 0.2331 - auc_3: 0.6648 - f1_score: 0.1838 - val_loss: 2.9474 - val_accuracy: 0.0150 - val_auc_3: 0.3191 - val_f1_score: 0.0067\n",
      "Epoch 437/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7876 - accuracy: 0.2707 - auc_3: 0.6870 - f1_score: 0.1970 - val_loss: 2.7015 - val_accuracy: 0.0677 - val_auc_3: 0.3403 - val_f1_score: 0.0309\n",
      "Epoch 438/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8122 - accuracy: 0.2575 - auc_3: 0.6749 - f1_score: 0.2334 - val_loss: 3.0060 - val_accuracy: 0.0376 - val_auc_3: 0.2402 - val_f1_score: 0.0235\n",
      "Epoch 439/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8163 - accuracy: 0.2256 - auc_3: 0.6661 - f1_score: 0.1739 - val_loss: 2.8132 - val_accuracy: 0.0301 - val_auc_3: 0.3205 - val_f1_score: 0.0133\n",
      "Epoch 440/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8121 - accuracy: 0.2519 - auc_3: 0.6782 - f1_score: 0.1875 - val_loss: 2.8434 - val_accuracy: 0.0977 - val_auc_3: 0.3056 - val_f1_score: 0.0485\n",
      "Epoch 441/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8025 - accuracy: 0.2500 - auc_3: 0.6723 - f1_score: 0.2022 - val_loss: 3.5565 - val_accuracy: 0.0000e+00 - val_auc_3: 0.1948 - val_f1_score: 0.0000e+00\n",
      "Epoch 442/500\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.7734 - accuracy: 0.2932 - auc_3: 0.6952 - f1_score: 0.2365 - val_loss: 2.8541 - val_accuracy: 0.0451 - val_auc_3: 0.2825 - val_f1_score: 0.0217\n",
      "Epoch 443/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7968 - accuracy: 0.2726 - auc_3: 0.6789 - f1_score: 0.2056 - val_loss: 2.9732 - val_accuracy: 0.0075 - val_auc_3: 0.2657 - val_f1_score: 0.0054\n",
      "Epoch 444/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8067 - accuracy: 0.2462 - auc_3: 0.6692 - f1_score: 0.2139 - val_loss: 2.7538 - val_accuracy: 0.0602 - val_auc_3: 0.3037 - val_f1_score: 0.0333\n",
      "Epoch 445/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7963 - accuracy: 0.2500 - auc_3: 0.6806 - f1_score: 0.2000 - val_loss: 2.8616 - val_accuracy: 0.0226 - val_auc_3: 0.2654 - val_f1_score: 0.0122\n",
      "Epoch 446/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8017 - accuracy: 0.2387 - auc_3: 0.6753 - f1_score: 0.1980 - val_loss: 3.1446 - val_accuracy: 0.0075 - val_auc_3: 0.2230 - val_f1_score: 0.0055\n",
      "Epoch 447/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8303 - accuracy: 0.2406 - auc_3: 0.6631 - f1_score: 0.1763 - val_loss: 3.1127 - val_accuracy: 0.0075 - val_auc_3: 0.2208 - val_f1_score: 0.0034\n",
      "Epoch 448/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8121 - accuracy: 0.2425 - auc_3: 0.6744 - f1_score: 0.1887 - val_loss: 2.9193 - val_accuracy: 0.0226 - val_auc_3: 0.2385 - val_f1_score: 0.0150\n",
      "Epoch 449/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7888 - accuracy: 0.2782 - auc_3: 0.6790 - f1_score: 0.2204 - val_loss: 2.7853 - val_accuracy: 0.0451 - val_auc_3: 0.2796 - val_f1_score: 0.0251\n",
      "Epoch 450/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7914 - accuracy: 0.2632 - auc_3: 0.6802 - f1_score: 0.1962 - val_loss: 2.9466 - val_accuracy: 0.0150 - val_auc_3: 0.2649 - val_f1_score: 0.0068\n",
      "Epoch 451/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8077 - accuracy: 0.2500 - auc_3: 0.6666 - f1_score: 0.2014 - val_loss: 2.9057 - val_accuracy: 0.0150 - val_auc_3: 0.2884 - val_f1_score: 0.0089\n",
      "Epoch 452/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7980 - accuracy: 0.2462 - auc_3: 0.6814 - f1_score: 0.1912 - val_loss: 2.8925 - val_accuracy: 0.0526 - val_auc_3: 0.2997 - val_f1_score: 0.0289\n",
      "Epoch 453/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8045 - accuracy: 0.2462 - auc_3: 0.6776 - f1_score: 0.1992 - val_loss: 2.9387 - val_accuracy: 0.0301 - val_auc_3: 0.2850 - val_f1_score: 0.0176\n",
      "Epoch 454/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8082 - accuracy: 0.2744 - auc_3: 0.6735 - f1_score: 0.2155 - val_loss: 3.0584 - val_accuracy: 0.0376 - val_auc_3: 0.2449 - val_f1_score: 0.0251\n",
      "Epoch 455/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8289 - accuracy: 0.2500 - auc_3: 0.6642 - f1_score: 0.1987 - val_loss: 2.9195 - val_accuracy: 0.0451 - val_auc_3: 0.3023 - val_f1_score: 0.0195\n",
      "Epoch 456/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7904 - accuracy: 0.2669 - auc_3: 0.6704 - f1_score: 0.2262 - val_loss: 3.0915 - val_accuracy: 0.0301 - val_auc_3: 0.2222 - val_f1_score: 0.0185\n",
      "Epoch 457/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7617 - accuracy: 0.2838 - auc_3: 0.6958 - f1_score: 0.2334 - val_loss: 2.7817 - val_accuracy: 0.0451 - val_auc_3: 0.3082 - val_f1_score: 0.0241\n",
      "Epoch 458/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7858 - accuracy: 0.2669 - auc_3: 0.6827 - f1_score: 0.2093 - val_loss: 3.0683 - val_accuracy: 0.0150 - val_auc_3: 0.2454 - val_f1_score: 0.0068\n",
      "Epoch 459/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7704 - accuracy: 0.2838 - auc_3: 0.6880 - f1_score: 0.2407 - val_loss: 2.9711 - val_accuracy: 0.0602 - val_auc_3: 0.2776 - val_f1_score: 0.0323\n",
      "Epoch 460/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8264 - accuracy: 0.2519 - auc_3: 0.6731 - f1_score: 0.1892 - val_loss: 3.0687 - val_accuracy: 0.0000e+00 - val_auc_3: 0.2396 - val_f1_score: 0.0000e+00\n",
      "Epoch 461/500\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.7884 - accuracy: 0.2650 - auc_3: 0.6865 - f1_score: 0.2133 - val_loss: 3.0199 - val_accuracy: 0.0301 - val_auc_3: 0.2474 - val_f1_score: 0.0204\n",
      "Epoch 462/500\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.8403 - accuracy: 0.2293 - auc_3: 0.6582 - f1_score: 0.1756 - val_loss: 3.0015 - val_accuracy: 0.0451 - val_auc_3: 0.2701 - val_f1_score: 0.0291\n",
      "Epoch 463/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8176 - accuracy: 0.2387 - auc_3: 0.6701 - f1_score: 0.1763 - val_loss: 2.9969 - val_accuracy: 0.0226 - val_auc_3: 0.2535 - val_f1_score: 0.0100\n",
      "Epoch 464/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8018 - accuracy: 0.2519 - auc_3: 0.6720 - f1_score: 0.2001 - val_loss: 3.0627 - val_accuracy: 0.0451 - val_auc_3: 0.2691 - val_f1_score: 0.0269\n",
      "Epoch 465/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7669 - accuracy: 0.2613 - auc_3: 0.6899 - f1_score: 0.1956 - val_loss: 3.1114 - val_accuracy: 0.0150 - val_auc_3: 0.2411 - val_f1_score: 0.0068\n",
      "Epoch 466/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7732 - accuracy: 0.2650 - auc_3: 0.6901 - f1_score: 0.2127 - val_loss: 2.7036 - val_accuracy: 0.0451 - val_auc_3: 0.3136 - val_f1_score: 0.0269\n",
      "Epoch 467/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7927 - accuracy: 0.2237 - auc_3: 0.6770 - f1_score: 0.1845 - val_loss: 3.0361 - val_accuracy: 0.0301 - val_auc_3: 0.2118 - val_f1_score: 0.0174\n",
      "Epoch 468/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7823 - accuracy: 0.2613 - auc_3: 0.6871 - f1_score: 0.1942 - val_loss: 2.8724 - val_accuracy: 0.0075 - val_auc_3: 0.2769 - val_f1_score: 0.0055\n",
      "Epoch 469/500\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.8166 - accuracy: 0.2613 - auc_3: 0.6716 - f1_score: 0.2124 - val_loss: 3.1113 - val_accuracy: 0.0000e+00 - val_auc_3: 0.2423 - val_f1_score: 0.0000e+00\n",
      "Epoch 470/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8385 - accuracy: 0.2726 - auc_3: 0.6579 - f1_score: 0.2045 - val_loss: 2.6096 - val_accuracy: 0.0677 - val_auc_3: 0.3435 - val_f1_score: 0.0348\n",
      "Epoch 471/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7833 - accuracy: 0.2575 - auc_3: 0.6799 - f1_score: 0.2156 - val_loss: 3.0683 - val_accuracy: 0.0000e+00 - val_auc_3: 0.2091 - val_f1_score: 0.0000e+00\n",
      "Epoch 472/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7913 - accuracy: 0.2368 - auc_3: 0.6777 - f1_score: 0.1825 - val_loss: 2.8632 - val_accuracy: 0.0150 - val_auc_3: 0.2813 - val_f1_score: 0.0087\n",
      "Epoch 473/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7964 - accuracy: 0.2594 - auc_3: 0.6773 - f1_score: 0.1976 - val_loss: 2.9944 - val_accuracy: 0.0150 - val_auc_3: 0.2370 - val_f1_score: 0.0104\n",
      "Epoch 474/500\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 1.7876 - accuracy: 0.2650 - auc_3: 0.6853 - f1_score: 0.2060 - val_loss: 3.2385 - val_accuracy: 0.0150 - val_auc_3: 0.1942 - val_f1_score: 0.0088\n",
      "Epoch 475/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8145 - accuracy: 0.2519 - auc_3: 0.6718 - f1_score: 0.1975 - val_loss: 2.7857 - val_accuracy: 0.0451 - val_auc_3: 0.2845 - val_f1_score: 0.0281\n",
      "Epoch 476/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8065 - accuracy: 0.2838 - auc_3: 0.6749 - f1_score: 0.2419 - val_loss: 2.8554 - val_accuracy: 0.0150 - val_auc_3: 0.2809 - val_f1_score: 0.0088\n",
      "Epoch 477/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8099 - accuracy: 0.2801 - auc_3: 0.6691 - f1_score: 0.2123 - val_loss: 3.3810 - val_accuracy: 0.0301 - val_auc_3: 0.2161 - val_f1_score: 0.0197\n",
      "Epoch 478/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7904 - accuracy: 0.2669 - auc_3: 0.6852 - f1_score: 0.2011 - val_loss: 2.9841 - val_accuracy: 0.0301 - val_auc_3: 0.2576 - val_f1_score: 0.0184\n",
      "Epoch 479/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7857 - accuracy: 0.2538 - auc_3: 0.6796 - f1_score: 0.1926 - val_loss: 3.0146 - val_accuracy: 0.0150 - val_auc_3: 0.2452 - val_f1_score: 0.0089\n",
      "Epoch 480/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7485 - accuracy: 0.2688 - auc_3: 0.6988 - f1_score: 0.2144 - val_loss: 2.7145 - val_accuracy: 0.0902 - val_auc_3: 0.3379 - val_f1_score: 0.0448\n",
      "Epoch 481/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7960 - accuracy: 0.2387 - auc_3: 0.6805 - f1_score: 0.1974 - val_loss: 2.7788 - val_accuracy: 0.0451 - val_auc_3: 0.2938 - val_f1_score: 0.0260\n",
      "Epoch 482/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7870 - accuracy: 0.2519 - auc_3: 0.6830 - f1_score: 0.1886 - val_loss: 2.8914 - val_accuracy: 0.0150 - val_auc_3: 0.3053 - val_f1_score: 0.0108\n",
      "Epoch 483/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8186 - accuracy: 0.2444 - auc_3: 0.6695 - f1_score: 0.1932 - val_loss: 2.9461 - val_accuracy: 0.0226 - val_auc_3: 0.2561 - val_f1_score: 0.0142\n",
      "Epoch 484/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8209 - accuracy: 0.2556 - auc_3: 0.6697 - f1_score: 0.2009 - val_loss: 3.2106 - val_accuracy: 0.0000e+00 - val_auc_3: 0.2415 - val_f1_score: 0.0000e+00\n",
      "Epoch 485/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7823 - accuracy: 0.2688 - auc_3: 0.6844 - f1_score: 0.2031 - val_loss: 2.7338 - val_accuracy: 0.0677 - val_auc_3: 0.3589 - val_f1_score: 0.0308\n",
      "Epoch 486/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7950 - accuracy: 0.2801 - auc_3: 0.6852 - f1_score: 0.2445 - val_loss: 3.2615 - val_accuracy: 0.0226 - val_auc_3: 0.1955 - val_f1_score: 0.0132\n",
      "Epoch 487/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8110 - accuracy: 0.2613 - auc_3: 0.6716 - f1_score: 0.1947 - val_loss: 3.1346 - val_accuracy: 0.0150 - val_auc_3: 0.2785 - val_f1_score: 0.0108\n",
      "Epoch 488/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8006 - accuracy: 0.2876 - auc_3: 0.6849 - f1_score: 0.2361 - val_loss: 2.9939 - val_accuracy: 0.0075 - val_auc_3: 0.2290 - val_f1_score: 0.0054\n",
      "Epoch 489/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7915 - accuracy: 0.2575 - auc_3: 0.6820 - f1_score: 0.1975 - val_loss: 2.7637 - val_accuracy: 0.0752 - val_auc_3: 0.3321 - val_f1_score: 0.0334\n",
      "Epoch 490/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.8140 - accuracy: 0.2613 - auc_3: 0.6761 - f1_score: 0.2328 - val_loss: 3.1906 - val_accuracy: 0.0451 - val_auc_3: 0.2406 - val_f1_score: 0.0281\n",
      "Epoch 491/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8218 - accuracy: 0.2632 - auc_3: 0.6709 - f1_score: 0.2160 - val_loss: 2.8334 - val_accuracy: 0.0451 - val_auc_3: 0.2866 - val_f1_score: 0.0261\n",
      "Epoch 492/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8197 - accuracy: 0.2707 - auc_3: 0.6674 - f1_score: 0.2208 - val_loss: 2.7059 - val_accuracy: 0.0827 - val_auc_3: 0.3497 - val_f1_score: 0.0387\n",
      "Epoch 493/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.8162 - accuracy: 0.2387 - auc_3: 0.6735 - f1_score: 0.1964 - val_loss: 2.4713 - val_accuracy: 0.1278 - val_auc_3: 0.4142 - val_f1_score: 0.0545\n",
      "Epoch 494/500\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.7941 - accuracy: 0.2801 - auc_3: 0.6792 - f1_score: 0.2222 - val_loss: 3.1088 - val_accuracy: 0.0301 - val_auc_3: 0.2388 - val_f1_score: 0.0201\n",
      "Epoch 495/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7883 - accuracy: 0.2613 - auc_3: 0.6821 - f1_score: 0.2010 - val_loss: 2.7442 - val_accuracy: 0.0977 - val_auc_3: 0.3491 - val_f1_score: 0.0473\n",
      "Epoch 496/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.8082 - accuracy: 0.2368 - auc_3: 0.6671 - f1_score: 0.1969 - val_loss: 2.9414 - val_accuracy: 0.0226 - val_auc_3: 0.2455 - val_f1_score: 0.0138\n",
      "Epoch 497/500\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.7686 - accuracy: 0.2801 - auc_3: 0.6915 - f1_score: 0.2186 - val_loss: 2.8544 - val_accuracy: 0.0150 - val_auc_3: 0.2775 - val_f1_score: 0.0068\n",
      "Epoch 498/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7972 - accuracy: 0.2575 - auc_3: 0.6802 - f1_score: 0.2241 - val_loss: 2.9407 - val_accuracy: 0.0150 - val_auc_3: 0.2574 - val_f1_score: 0.0088\n",
      "Epoch 499/500\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.7912 - accuracy: 0.2462 - auc_3: 0.6803 - f1_score: 0.2127 - val_loss: 2.8257 - val_accuracy: 0.0602 - val_auc_3: 0.2953 - val_f1_score: 0.0303\n",
      "Epoch 500/500\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.7690 - accuracy: 0.2782 - auc_3: 0.6885 - f1_score: 0.2307 - val_loss: 2.8291 - val_accuracy: 0.0150 - val_auc_3: 0.2972 - val_f1_score: 0.0088\n"
     ]
    }
   ],
   "source": [
    "if bi_class == 0:\n",
    "    full_model.compile(optimizer=Adam(lr=0.05), loss='categorical_crossentropy', metrics=['accuracy', keras.metrics.AUC(), tfa.metrics.F1Score(num_classes=num_classes)])\n",
    "    hist = full_model.fit(x=np.array(X_train).transpose([0,1,2,3]), y=np.array(Y_train).transpose([0,1]), batch_size=None, validation_split=0.2, epochs=500)\n",
    "else:\n",
    "    full_model.compile(optimizer=Adam(lr=0.05), loss='binary_crossentropy', metrics=['accuracy', keras.metrics.AUC()])\n",
    "    hist = full_model.fit(x=np.array(X_train).transpose([0,1,2,3]), y=np.array(Y_train).transpose([0,1]), batch_size=None, validation_split=0.2, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display acc, loss\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Test AUC:  0.5850009852327457\n"
     ]
    }
   ],
   "source": [
    "predictions = full_model.predict(np.array(X_test).transpose([0,1,2,3]))\n",
    "\n",
    "if bi_class==0:\n",
    "    auc = roc_auc_score(Y_test, predictions, multi_class='raise')\n",
    "    print('Multiclass Test AUC: ', auc)\n",
    "else:\n",
    "    auc = roc_auc_score(Y_test, predictions)\n",
    "    print('Test AUC: ', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15., 19., 17.,  5., 13.,  3.,  1.])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency = np.zeros(len(Y_test[0]))\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    frequency[np.argmax(predictions[i])] +=1\n",
    "\n",
    "frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.  7. 23. 23.  7.  6.  3.]\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(Y_test, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 2.0185 - accuracy: 0.1233 - auc_3: 0.5711 - f1_score: 0.0786\n",
      "\n",
      "Accuracy: 0.12328767031431198\n"
     ]
    }
   ],
   "source": [
    "if bi_class == 0:\n",
    "    test_loss, test_acc, test_auc, test_F1 = full_model.evaluate(np.array(X_test).transpose([0,1,2,3]),  np.array(Y_test).transpose([0,1]), verbose=2)\n",
    "    print('\\nAccuracy:', test_acc)\n",
    "else:\n",
    "    test_loss, test_acc, test_auc = full_model.evaluate(np.array(X_test).transpose([0,1,2,3]),  np.array(Y_test).transpose([0,1]), verbose=2)\n",
    "    print('\\nAccuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ###Visualize Latent Space###\n",
    "\n",
    "# x_test_encoded = encoder.predict(np.array(X_test).transpose([0,1,2,3]), batch_size=1)\n",
    "# plt.figure(figsize=(6, 6))\n",
    "# plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=Y_test)\n",
    "# plt.colorbar()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
