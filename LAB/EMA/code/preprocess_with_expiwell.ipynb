{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to clean the code\n",
    "1. dir 일원화\n",
    "2. 데이터 형식의 차이에 따른 if문 사용\n",
    "3. 이미 전처리 된 데이터가 있는 경우 제외\n",
    "4. light cat 수정 필요\n",
    "5. integrate시 존재하는 파일에 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os, sys\n",
    "from os.path import join, dirname\n",
    "\n",
    "import datetime, time\n",
    "import csv\n",
    "from glob import glob\n",
    "import chardet\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '../Data'\n",
    "\n",
    "EMA_dir = root_dir + '/KOR_EMA_Data'\n",
    "Collar_dir = root_dir + '/KOR_Collar_Data'\n",
    "preprocessed_dir = root_dir + '/Preprocessed'\n",
    "\n",
    "pass_list = glob(preprocessed_dir + '/*.CSV')\n",
    "EMA_list = glob(EMA_dir + '/*.xlsx')\n",
    "Collar_list = glob(Collar_dir + '/*.CSV')\n",
    "preprocessed_data_name = preprocessed_dir + '/preprocessed_data(with_4_korean).csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_list = []\n",
    "target_data_list = []\n",
    "feature_data_list = []\n",
    "\n",
    "\n",
    "for path in EMA_list:\n",
    "    temp = path.split('\\\\')\n",
    "    temp = temp[1].split('_')\n",
    "    ID_list.append(temp[0])\n",
    "\n",
    "for name in ID_list:\n",
    "    tmp_target = preprocessed_dir + '\\\\target_' + name + '.csv'\n",
    "    tmp_feature = preprocessed_dir + '\\\\feature_' + name + '.csv'\n",
    "    target_data_list.append(tmp_target)\n",
    "    feature_data_list.append(tmp_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Time stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert24(time_stamp): \n",
    "    \n",
    "    time_stamp = str(pd.to_datetime(time_stamp, infer_datetime_format=True))\n",
    "    # Checking if last two elements of time \n",
    "    # is AM and first two elements are 12 \n",
    "    \n",
    "    if time_stamp[-2:] == \"AM\" or time_stamp[-2:] == \"PM\":\n",
    "        if time_stamp[-2:] == \"AM\" and time_stamp[11:13] == \"12\": \n",
    "            return time_stamp[:11] + \"00\" + time_stamp[13:-2] \n",
    "\n",
    "        # remove the AM  \n",
    "        elif time_stamp[-2:] == \"AM\": \n",
    "            return time_stamp[:-2] \n",
    "\n",
    "        # Checking if last two elements of time \n",
    "        # is PM and first two elements are 12 \n",
    "        elif time_stamp[-2:] == \"PM\" and time_stamp[11:13] == \"12\": \n",
    "            return time_stamp[:-2] \n",
    "\n",
    "        else: \n",
    "\n",
    "            # add 12 to hours and remove PM \n",
    "            return time_stamp[:11] + str(int(time_stamp[11:13]) + 12) + time_stamp[13:-2]\n",
    "    \n",
    "    else: \n",
    "        return time_stamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Target Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dictionary for response types\n",
    "res = {\"0\" : \"Playing\",\n",
    "       \"1\" : \"Talking\",\n",
    "       \"2\" : \"Petting\",\n",
    "       \"3\" : \"TV / Radio\",\n",
    "       \"4\" : \"Eating / Cooking\",\n",
    "       \"5\" : \"Moved It\",\n",
    "       \"6\" : \"None of the above\",\n",
    "       \"7\" : \"Other\"}\n",
    "\n",
    "## EMA Data collumn name\n",
    "EMA_col_name = [\"Start Date\",\"End Date\",\"Time Scheduled\",\"Duration (in seconds)\",\"Finished\",\"Participant ID\",\"Location - Lat\",\n",
    "                \"Location - Long\",\"Survey\",\"Question 1\",\"Question 2\",\"Question 3\",\"Question 4.1\",\"Question 4.2\",\"Question 4.3\",\n",
    "                \"Question 4.4\",\"Question 4.5\",\"Question 4.6\",\"Question 4.7\",\"Question 4.8\",\"Question 5\",\"Question 6\",\"Question 7\"]\n",
    "\n",
    "for x in range(len(EMA_list)):\n",
    "    \n",
    "    EMA = pd.read_excel(EMA_list[x], engine ='openpyxl')\n",
    "    EMA = EMA.to_records(index=False)\n",
    "    \n",
    "    ## Row number in will-be-created file\n",
    "    rowid = 1\n",
    "    prox = 0\n",
    "    \n",
    "    ## Write a csv file\n",
    "    if target_data_list[x] not in pass_list:\n",
    "        with open(target_data_list[x], 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"RowID\", \"Modality_cat\", \"Modality\", \"Proximity\", \"Start Window\", \"End Window\"])\n",
    "\n",
    "\n",
    "            for i in range(len(EMA)):\n",
    "                if EMA[i][\"Question 1\"] == \"Yes\":  # Check if the participant has interacted\n",
    "\n",
    "                    interation_type = []\n",
    "                    prox = 0  # prox reset\n",
    "\n",
    "                    ## Check the number of interaction types\n",
    "                    for j in range(12, 20):\n",
    "                        if EMA[i][j] == \"Yes\":\n",
    "                            interation_type.append(j-12)\n",
    "\n",
    "                    for k in range(len(interation_type)):\n",
    "                        end_time = convert24(EMA[i][\"Start Date\"])\n",
    "                        start_time = pd.to_datetime(end_time, infer_datetime_format=True) - pd.Timedelta(pd.offsets.Minute(15))\n",
    "                        writer.writerow([rowid, interation_type[k], res[str(interation_type[k])], EMA[i][\"Question 6\"], start_time, end_time]) # Write data one (row) by one..\n",
    "                        rowid += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Feature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Data/KOR_Collar_Data\\\\KORp1_Collar_data.CSV',\n",
       " '../Data/KOR_Collar_Data\\\\KORp2_Collar_data.CSV',\n",
       " '../Data/KOR_Collar_Data\\\\KORp3_Collar_data.CSV',\n",
       " '../Data/KOR_Collar_Data\\\\KORp4_Collar_data.CSV']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Collar_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KORp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sckim\\.conda\\envs\\grad\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3145: DtypeWarning: Columns (0,1,3,4,5,7,8,9,10,12,13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eec1d2b48904bbdb8b3b60c6544a7a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KORp4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "936ac5b1d11a40ff8318609c40ee30e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=121.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "collar_col_name = ['awake', 'sound_val', 'sound_cat', 'light_val', 'accel_x', 'accel_y', 'accel_z', 'orient', 'motion_detect', 'sound_detect)', 'Realtime']\n",
    "\n",
    "for i in range(len(Collar_list)):\n",
    "    \n",
    "    if feature_data_list[i] not in pass_list:\n",
    "        print(ID_list[i])\n",
    "\n",
    "        collar_data = pd.read_csv(Collar_list[i])           # load ith collar_data\n",
    "        collar_data = collar_data[collar_col_name]          # \n",
    "    #     idx = collar_data[collar_data[\"Realtime\"] == \"Realtime\"].index\n",
    "        collar_data.drop(collar_data[collar_data[\"Realtime\"] == \"Realtime\"].index,inplace=True)\n",
    "        collar_data = collar_data.to_records(index=False)\n",
    "\n",
    "        target_data = pd.read_csv(target_data_list[i])\n",
    "        target_data = target_data.to_records(index=False)\n",
    "\n",
    "        with open(feature_data_list[i], 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['RowID', 'Real_time', 'awake', 'sound_val', 'sound_cat', 'light_val', 'accel_x', 'accel_y', 'accel_z', 'orient', 'motion_detect', 'sound_detect)'])\n",
    "\n",
    "            start = 0\n",
    "\n",
    "            for row in notebook.tqdm(range(len(target_data))):\n",
    "                for j in range(start, len(collar_data)):\n",
    "                    if convert24(collar_data[j][\"Realtime\"]) > convert24(target_data[row]['End Window']):\n",
    "                        break\n",
    "\n",
    "                    if convert24(collar_data[j][\"Realtime\"]) < convert24(target_data[row]['Start Window']):\n",
    "                        start += 1\n",
    "\n",
    "                    if convert24(collar_data[j][\"Realtime\"]) >= convert24(target_data[row]['Start Window']) and convert24(collar_data[j][\"Realtime\"]) <= convert24(target_data[row]['End Window']):\n",
    "                        writer.writerow([target_data[row]['RowID'], collar_data[j]['Realtime'], collar_data[j]['awake'], collar_data[j]['sound_val'], collar_data[j]['sound_cat'], collar_data[j]['light_val'], collar_data[j]['accel_x'], collar_data[j]['accel_y'], collar_data[j]['accel_z'], collar_data[j]['orient'], collar_data[j]['motion_detect'], collar_data[j]['sound_detect)']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KORp1   0.40425531914893614\n",
      "19 47104\n",
      "\n",
      "\n",
      "KORp2   0.37254901960784315\n",
      "95 199641\n",
      "\n",
      "\n",
      "KORp3   0.6538461538461539\n",
      "17 37857\n",
      "\n",
      "\n",
      "KORp4   0.8181818181818182\n",
      "99 153037\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ID_list)):\n",
    "    rowid = []\n",
    "    \n",
    "    feature_data = pd.read_csv(feature_data_list[i])\n",
    "    feature_data = feature_data.to_records(index=False)\n",
    "    target_data = pd.read_csv(target_data_list[i])\n",
    "    \n",
    "    for j in range(len(feature_data)):\n",
    "        if feature_data[j]['RowID'] not in rowid:\n",
    "            rowid.append(feature_data[j]['RowID'])\n",
    "            \n",
    "    print(ID_list[i], ' ', len(rowid) / len(target_data))\n",
    "    print(len(rowid), len(feature_data))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_create(df, accel_k, diff_k):\n",
    "    df[diff_k]=df[accel_k]\n",
    "    for i in range(len(df)):\n",
    "        if i==0:\n",
    "            continue\n",
    "        elif df['RowID'][i]!=df['RowID'][i-1]:\n",
    "            df[diff_k][i]=0\n",
    "            continue\n",
    "        else:\n",
    "            df[diff_k][i]-=df[accel_k][i-1]\n",
    "    df[diff_k][0]=0\n",
    "\n",
    "def chord_arc_create (df,diff_x,diff_y,diff_z) :\n",
    "    df['chord'] = np.sqrt(df[diff_x]**2+df[diff_y]**2+df[diff_z]**2)\n",
    "    df['arc'] = 2*np.arcsin(df['chord']/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../Data/Preprocessed/feature_Bree.csv', '../Data/Preprocessed/feature_Daisey.csv', '../Data/Preprocessed/feature_Grace.csv', '../Data/Preprocessed/feature_KORp1.csv', '../Data/Preprocessed/feature_KORp2.csv', '../Data/Preprocessed/feature_KORp3.csv', '../Data/Preprocessed/feature_KORp4.csv', '../Data/Preprocessed/feature_Mickey.csv']\n"
     ]
    }
   ],
   "source": [
    "file_list = os.listdir(preprocessed_dir)\n",
    "target = []\n",
    "feature = []\n",
    "\n",
    "for path in file_list:\n",
    "    temp = path.split('_')\n",
    "    if temp[0] == 'feature':\n",
    "        temp_dir = preprocessed_dir + \"/\" + path\n",
    "        feature.append(temp_dir)\n",
    "    elif temp[0] == 'target':\n",
    "        temp_dir = preprocessed_dir + \"/\" + path\n",
    "        target.append(temp_dir)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scaler(num):\n",
    "#     max_num = 4000\n",
    "#     min_num = 0\n",
    "    \n",
    "#     if (num - min_num) / (max_num - min_num) * 1024 > 1024:\n",
    "#         return 1\n",
    "#     else: \n",
    "#         return round((num - min_num) / (max_num - min_num) * 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-4c135b961834>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[diff_k][i]-=df[accel_k][i-1]\n",
      "<ipython-input-5-4c135b961834>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[diff_k][i]=0\n",
      "<ipython-input-5-4c135b961834>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[diff_k][0]=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bree\n",
      "Daisey\n",
      "Grace\n",
      "KORp1\n",
      "KORp2\n",
      "KORp3\n",
      "KORp4\n",
      "Mickey\n"
     ]
    }
   ],
   "source": [
    "with open(preprocessed_data_name, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['RowID', 'Real_time', 'awake', 'sound_val', 'sound_cat', 'light_val', 'accel_x', 'accel_y', 'accel_z', 'orient', 'chord', 'arc', 'motion_detect', 'sound_detect)', \"Modality_cat\", \"Modality\"])\n",
    "    \n",
    "    for i in range(len(target)):\n",
    "        rowid = []\n",
    "\n",
    "        feature_data = pd.read_csv(feature[i])\n",
    "        target_data = pd.read_csv(target[i])\n",
    "        target_data = target_data.to_records(index=False)\n",
    "\n",
    "        diff_create(feature_data,'accel_x','diff_x')\n",
    "        diff_create(feature_data,'accel_y','diff_y')\n",
    "        diff_create(feature_data,'accel_z','diff_z')\n",
    "        chord_arc_create (feature_data,'diff_x','diff_y','diff_z')\n",
    "\n",
    "        feature_data = feature_data.to_records(index=False)\n",
    "        \n",
    "        temp = feature[i].split(\"/\")\n",
    "        temp = temp[3].split(\".\")\n",
    "        temp = temp[0].split(\"_\")\n",
    "        \n",
    "        if temp[1][:3] == 'KOR':\n",
    "            print(temp[1])\n",
    "            for j in range(len(feature_data)):\n",
    "                idx = np.where(target_data['RowID'] == feature_data[j]['RowID'])\n",
    "                new_RowID = '1' + '_' + str(i) + '_' + str(feature_data[j]['RowID'])\n",
    "                writer.writerow([new_RowID, feature_data[j]['Real_time'], feature_data[j]['awake'], feature_data[j]['sound_val'], feature_data[j]['sound_cat'], feature_data[j]['light_val'], feature_data[j]['accel_x'], feature_data[j]['accel_y'], feature_data[j]['accel_z'], feature_data[j]['orient'], feature_data[j]['chord'], feature_data[j]['arc'], feature_data[j]['motion_detect'], feature_data[j]['sound_detect)'], target_data[idx[0][0]][\"Modality_cat\"], target_data[idx[0][0]][\"Modality\"]])\n",
    "        \n",
    "        else:\n",
    "            print(temp[1])\n",
    "            for j in range(len(feature_data)):\n",
    "                idx = np.where(target_data['RowID'] == feature_data[j]['RowID'])\n",
    "                new_RowID = '0' + '_' + str(i) + '_' + str(feature_data[j]['RowID'])\n",
    "                writer.writerow([new_RowID, feature_data[j]['Real_time'], feature_data[j]['awake'], feature_data[j]['sound_val'], feature_data[j]['sound_cat'], feature_data[j]['light_val'], feature_data[j]['accel_x'], feature_data[j]['accel_y'], feature_data[j]['accel_z'], feature_data[j]['orient'], feature_data[j]['chord'], feature_data[j]['arc'], feature_data[j]['motion_detect'], feature_data[j]['sound_detect)'], target_data[idx[0][0]][\"Modality_cat\"], target_data[idx[0][0]][\"Modality\"]])            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
