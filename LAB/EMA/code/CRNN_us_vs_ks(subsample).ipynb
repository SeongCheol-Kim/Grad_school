{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model structure\n",
    "# input layer >> 2D CNN >> 1D CNN >> RNN (LSTM)  >> output layer (Dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 9266412417316748300,\n",
       " name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 15594058652304138290\n",
       " physical_device_desc: \"device: XLA_CPU device\",\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 3129973147\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 4799988611098435099\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\",\n",
       " name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 12755133327561341058\n",
       " physical_device_desc: \"device: XLA_GPU device\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os, sys\n",
    "from os.path import join, dirname\n",
    "\n",
    "import datetime, time\n",
    "import csv\n",
    "from glob import glob\n",
    "import chardet\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Conv1D, Conv2D, Dense, SimpleRNN, LSTM, GRU, Reshape, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "\n",
    "from IPython.display import SVG\n",
    "\n",
    "import imblearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(tf.__version__)\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 8                           # {\"0\" : \"Playing\", \"1\" : \"Talking\", \"2\" : \"Petting\", \"3\" : \"TV / Radio\", \"4\" : \"Eating / Cooking\", \"5\" : \"Moved It\", \"6\" : \"None of the above\", \"7\" : \"Other\"}\n",
    "time_offset = 10\n",
    "window_size = 10\n",
    "overlap_ratio = 0.5\n",
    "bi_class = 6                              # Binary Classification (1 : Playing or not, 2 : Talking or not, 3 : Petting or not, 4: TV / Radio or not, 5 : Eating / Cooking or not, 6 : Moved It or not)\n",
    "cross_val = 0\n",
    "rand_st=1\n",
    "mode = 0                                 # Split data {0: Didn't split, 1: US only, 2: Korea only, 3: train with US and test with Korea 4: train with Korea and test with US}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fname = '../Data/Preprocessed/preprocessed_data(with_4_korean_scaled).csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_fname)\n",
    "data = pd.concat([data,pd.get_dummies(data['sound_cat'])],axis=1)         # Onehot encode sound category\n",
    "data = pd.concat([data,pd.get_dummies(data['orient'])],axis=1)            # Onehot encode Orient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rowID list\n",
    "rowID_list = np.array(data['RowID'].drop_duplicates())\n",
    "data = data.to_records(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split US and Korea\n",
    "us_rowIDs = []\n",
    "korea_rowIDs = []\n",
    "\n",
    "if mode != 0:\n",
    "    for rowid in rowID_list:\n",
    "    #     print(rowid, rowid[0])\n",
    "        if rowid[0] == '1':\n",
    "            korea_rowIDs.append(rowid)\n",
    "        else:\n",
    "            us_rowIDs.append(rowid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    #Convert string to num\n",
    "    if data[i]['sound_cat'] == 'Quiet':\n",
    "        data[i]['sound_cat'] = 0\n",
    "    elif data[i]['sound_cat'] == 'Moderate':\n",
    "        data[i]['sound_cat'] = 1\n",
    "    else:\n",
    "        data[i]['sound_cat'] = 2\n",
    "    \n",
    "    if data[i]['orient'] == 'Portrait Up':\n",
    "        data[i]['orient'] = 0\n",
    "    elif data[i]['orient'] == 'Portrait Down':\n",
    "        data[i]['orient'] = 1\n",
    "    elif data[i]['orient'] == 'Landscape Right':\n",
    "        data[i]['orient'] = 2\n",
    "    elif data[i]['orient'] == 'Landscape Left':\n",
    "        data[i]['orient'] = 3\n",
    "    else:\n",
    "        data[i]['orient'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col_name = ['awake', 'sound_val', 'light_val', 'accel_x', 'accel_y', 'accel_z', 'chord', 'motion_detect','sound_detect)',\n",
    "                   'Loud', 'Moderate', 'Quiet', 'Flat', 'Landscape Left', 'Landscape Right', 'Portrait Down', 'Portrait Up']\n",
    "target_col_name = ['Modality_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "us_X = []\n",
    "korea_X = []\n",
    "\n",
    "Y = []\n",
    "us_Y = []\n",
    "korea_Y = []\n",
    "\n",
    "\n",
    "if mode != 0:\n",
    "    for rowID in us_rowIDs:\n",
    "        #Split raw data by rowID & split X, Y data\n",
    "        tmp_data = data[data['RowID'] == rowID]\n",
    "        feature = tmp_data[feature_col_name]\n",
    "        feature = np.array(feature.tolist())\n",
    "        target = tmp_data[target_col_name][0][0]\n",
    "        target = np.array(target.tolist())\n",
    "        us_X.append(feature)\n",
    "        us_Y.append(target)\n",
    "    \n",
    "    for rowID in korea_rowIDs:\n",
    "        #Split raw data by rowID & split X, Y data\n",
    "        tmp_data = data[data['RowID'] == rowID]\n",
    "        feature = tmp_data[feature_col_name]\n",
    "        feature = np.array(feature.tolist())\n",
    "        target = tmp_data[target_col_name][0][0]\n",
    "        target = np.array(target.tolist())\n",
    "        korea_X.append(feature)\n",
    "        korea_Y.append(target)\n",
    "\n",
    "else:\n",
    "    for rowID in rowID_list:\n",
    "        #Split raw data by rowID & split X, Y data\n",
    "        tmp_data = data[data['RowID'] == rowID]\n",
    "        feature = tmp_data[feature_col_name]\n",
    "        feature = np.array(feature.tolist())\n",
    "        target = tmp_data[target_col_name][0][0]\n",
    "        target = np.array(target.tolist())\n",
    "        X.append(feature)\n",
    "        Y.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bi_class != 0:\n",
    "    #Transit multi classification to binary classification\n",
    "    if mode != 0:\n",
    "        for idx in range(len(us_Y)):\n",
    "            if us_Y[idx] == bi_class-1:\n",
    "                us_Y[idx]=1\n",
    "            else:\n",
    "                us_Y[idx]=0\n",
    "                \n",
    "        for idx in range(len(korea_Y)):\n",
    "            if korea_Y[idx] == bi_class-1:\n",
    "                korea_Y[idx]=1\n",
    "            else:\n",
    "                korea_Y[idx]=0\n",
    "    else:\n",
    "        for idx in range(len(Y)):\n",
    "            if Y[idx] == bi_class-1:\n",
    "                Y[idx]=1\n",
    "            else:\n",
    "                Y[idx]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_preprocess(X, window_size, overlap_ratio):\n",
    "    #Transform data shape using the set time window\n",
    "    processed_X = []\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        tmp_X = X[i]\n",
    "        tmp = []\n",
    "        start_row = 0\n",
    "        end_row = start_row + window_size\n",
    "        \n",
    "        if len(tmp_X)%int(window_size*overlap_ratio) == 0:\n",
    "            for j in range(len(tmp_X)//int(window_size*overlap_ratio)-1):\n",
    "                tmp.append(tmp_X[int(start_row):int(end_row)])\n",
    "                start_row += (window_size*overlap_ratio)\n",
    "                end_row += (window_size*overlap_ratio)\n",
    "        else:\n",
    "            for j in range(len(tmp_X)//int(window_size*overlap_ratio)+1):\n",
    "                if end_row > len(tmp_X):\n",
    "                    \n",
    "                    tmp.append(tmp_X[-window_size:])\n",
    "                    start_row += (window_size*overlap_ratio)\n",
    "                    end_row += (window_size*overlap_ratio)\n",
    "                    break\n",
    "                else:\n",
    "                    \n",
    "                    tmp.append(tmp_X[int(start_row):int(end_row)])\n",
    "                    start_row += (window_size*overlap_ratio)\n",
    "                    end_row += (window_size*overlap_ratio)\n",
    "        processed_X.append(tmp)\n",
    "        \n",
    "    return processed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode != 0:\n",
    "    us_X = X_preprocess(us_X, window_size, overlap_ratio)        ### preprocess with input shape\n",
    "    korea_X = X_preprocess(korea_X, window_size, overlap_ratio)\n",
    "    if bi_class == 0:\n",
    "        ### onehot encode Y\n",
    "        us_Y = np.eye(num_classes)[us_Y]\n",
    "        korea_Y = np.eye(num_classes)[korea_Y]\n",
    "    else: \n",
    "        us_Y = np.eye(2)[us_Y]\n",
    "        korea_Y = np.eye(2)[korea_Y]\n",
    "\n",
    "else:    \n",
    "    X = X_preprocess(X, window_size, overlap_ratio)        ### preprocess with input shape\n",
    "    if bi_class == 0:\n",
    "        ### onehot encode Y\n",
    "        Y = np.eye(num_classes)[Y]\n",
    "    else: Y = np.eye(2)[Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample X Data size\n",
    "\n",
    "def subsample(X, min_us_len, min_korea_len):\n",
    "    sampled_X = []\n",
    "    addon = 0\n",
    "    \n",
    "    if min_korea_len > min_us_len:\n",
    "        if np.array(X).shape[1] == min_us_len:\n",
    "            return X\n",
    "        else:\n",
    "            interval = min_korea_len / min_us_len\n",
    "            quotient = int(np.modf(interval)[1])\n",
    "            remainder = np.modf(interval)[0]\n",
    "\n",
    "            for i in range(len(X)):\n",
    "                temp_X = []\n",
    "                for j in range(min_us_len):\n",
    "                    if addon >= 1:\n",
    "                        temp_X.append(X[i][j*quotient + 1])\n",
    "                        addon = 0\n",
    "                        addon += remainder\n",
    "                    else:\n",
    "                        temp_X.append(X[i][j*quotient])\n",
    "                        addon += remainder\n",
    "\n",
    "                sampled_X.append(temp_X)\n",
    "            \n",
    "    else:\n",
    "        if np.array(X).shape[1] == min_korea_len:\n",
    "            return X\n",
    "        else:\n",
    "            interval = min_us_len / min_korea_len\n",
    "            quotient = int(np.modf(interval)[1])\n",
    "            remainder = np.modf(interval)[0]\n",
    "\n",
    "            for i in range(len(X)):\n",
    "                temp_X = []\n",
    "                for j in range(min_korea_len):\n",
    "                    if addon >= 1:\n",
    "                        temp_X.append(X[i][j*quotient + 1])\n",
    "                        addon = 0\n",
    "                        addon += remainder\n",
    "                    else:\n",
    "                        temp_X.append(X[i][j*quotient])\n",
    "                        addon += remainder\n",
    "\n",
    "            sampled_X.append(temp_X)\n",
    "                    \n",
    "    return sampled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit to minimum length\n",
    "\n",
    "min_len = 99999999\n",
    "min_us_len = 99999999\n",
    "min_korea_len = 99999999\n",
    "min_X = []\n",
    "min_us_X = []\n",
    "min_korea_X = []\n",
    "\n",
    "if mode == 0:\n",
    "    for x in X:\n",
    "        if len(x) < min_len:\n",
    "            min_len = len(x)\n",
    "\n",
    "    for x in X:\n",
    "        min_X.append(x[:min_len])\n",
    "\n",
    "else:\n",
    "    for x in us_X:\n",
    "        if len(x) < min_us_len:\n",
    "            min_us_len = len(x)\n",
    "            \n",
    "    for x in korea_X:\n",
    "        if len(x) < min_korea_len:\n",
    "            min_korea_len = len(x)\n",
    "            \n",
    "    if mode == 1:\n",
    "        for x in us_X:\n",
    "            min_us_X.append(x[:min_us_len])\n",
    "        for x in korea_X:\n",
    "            min_korea_X.append(x[:min_korea_len])\n",
    "        \n",
    "    elif mode == 2:\n",
    "        min_korea_len = 60\n",
    "        for x in us_X:\n",
    "            min_us_X.append(x[:min_us_len])\n",
    "        for x in korea_X:\n",
    "            min_korea_X.append(x[:min_korea_len])\n",
    "        \n",
    "    else:\n",
    "        if min_korea_len < min_us_len:\n",
    "            min_len = min_korea_len\n",
    "        else: min_len = min_us_len\n",
    "\n",
    "        for x in us_X:\n",
    "            min_us_X.append(x[:min_len])\n",
    "\n",
    "        for x in korea_X:\n",
    "            min_korea_X.append(x[:min_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop duplicate\n",
    "\n",
    "if bi_class != 0:\n",
    "    \n",
    "    target_list = []\n",
    "    us_target_list = []\n",
    "    korea_target_list = []\n",
    "    del_list = []\n",
    "    us_del_list = []\n",
    "    korea_del_list = []\n",
    "    \n",
    "    if mode == 0:\n",
    "        for i in range(len(Y)):\n",
    "            if Y[i][1] == 1:\n",
    "                target_list.append(i)\n",
    "\n",
    "        for i in target_list:\n",
    "            for j in range(len(min_X)):\n",
    "                if j in target_list:\n",
    "                    pass\n",
    "                else:\n",
    "                    if np.array_equal(np.array(min_X[i]), np.array(min_X[j])):\n",
    "                        if j not in del_list:\n",
    "                            del_list.append(j)\n",
    "        X = []\n",
    "        Target = []\n",
    "\n",
    "        for i in range(len(Y)):\n",
    "            if i not in del_list:\n",
    "                X.append(min_X[i])\n",
    "                Target.append(Y[i])\n",
    "                \n",
    "    else:\n",
    "        for i in range(len(us_Y)):\n",
    "            if us_Y[i][1] == 1:\n",
    "                us_target_list.append(i)\n",
    "\n",
    "        for i in us_target_list:\n",
    "            for j in range(len(min_us_X)):\n",
    "                if j in us_target_list:\n",
    "                    pass\n",
    "                else:\n",
    "                    if np.array_equal(np.array(min_us_X[i]), np.array(min_us_X[j])):\n",
    "                        if j not in us_del_list:\n",
    "                            us_del_list.append(j)\n",
    "                            \n",
    "        for i in range(len(korea_Y)):\n",
    "            if korea_Y[i][1] == 1:\n",
    "                korea_target_list.append(i)\n",
    "\n",
    "        for i in korea_target_list:\n",
    "            for j in range(len(min_korea_X)):\n",
    "                if j in korea_target_list:\n",
    "                    pass\n",
    "                else:\n",
    "                    if np.array_equal(np.array(min_korea_X[i]), np.array(min_korea_X[j])):\n",
    "                        if j not in korea_del_list:\n",
    "                            korea_del_list.append(j)\n",
    "        \n",
    "        us_X = []\n",
    "        us_Target = []\n",
    "        korea_X = []\n",
    "        korea_Target = []\n",
    "\n",
    "        for i in range(len(us_Y)):\n",
    "            if i not in us_del_list:\n",
    "                us_X.append(min_us_X[i])\n",
    "                us_Target.append(us_Y[i])\n",
    "                \n",
    "        for i in range(len(korea_Y)):\n",
    "            if i not in korea_del_list:\n",
    "                korea_X.append(min_korea_X[i])\n",
    "                korea_Target.append(korea_Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 0:\n",
    "#     X = subsample(X, min_us_len, min_korea_len)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Target, test_size=0.2)\n",
    "    \n",
    "elif mode == 1:\n",
    "    us_X = subsample(us_X, min_us_len, min_korea_len)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(us_X, us_Target, test_size=0.2)\n",
    "\n",
    "elif mode == 2:\n",
    "    korea_X = subsample(korea_X, min_us_len, min_korea_len)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(korea_X, korea_Target, test_size=0.2)\n",
    "\n",
    "elif mode == 3:\n",
    "    X_train = subsample(us_X, min_us_len, min_korea_len)\n",
    "    X_test = subsample(korea_X, min_us_len, min_korea_len)\n",
    "    Y_train = us_Target \n",
    "    Y_test = korea_Target\n",
    "\n",
    "else:\n",
    "    X_train = subsample(korea_X, min_us_len, min_korea_len)\n",
    "    X_test = subsample(us_X, min_us_len, min_korea_len)\n",
    "    Y_train = korea_Target\n",
    "    Y_test = us_Target "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_classes, rnn_unit, input_shape):\n",
    "    \"\"\" build CNN-RNN model \"\"\"\n",
    "\n",
    "    feature_input = Input(shape=input_shape)\n",
    "    \n",
    "    cnn_layer = Conv2D(1, 1, padding='same', activation='relu', name='conv1')(feature_input)\n",
    "#     cnn_layer = MaxPooling2D(pool_size=(2, 2))(cnn_layer)\n",
    "    \n",
    "    rnn_input = Reshape((-1, rnn_unit), name='reshape1')(cnn_layer)\n",
    "    rnn_layer = LSTM(units=rnn_unit, activation='relu', recurrent_activation='sigmoid', return_sequences=None, name='rnn1')(rnn_input)\n",
    "    rnn_output = Dense(units=num_classes, activation='softmax', name='fc1')(rnn_layer)\n",
    "    \n",
    "    model = Model(inputs=feature_input, outputs=rnn_output, name='CRNN')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_divisor(n):\n",
    "    n = int(n)\n",
    "    divisors = []\n",
    "    divisors_back = [] \n",
    "\n",
    "    for i in range(1, int(n**(1/2)) + 1): \n",
    "        if (n % i == 0):            \n",
    "            divisors.append(i)\n",
    "            if (i != (n // i)): \n",
    "                divisors_back.append(n//i)\n",
    "\n",
    "    return divisors + divisors_back[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sckim\\.conda\\envs\\grad\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer rnn1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"CRNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 20, 10, 17)]      0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 20, 10, 1)         18        \n",
      "_________________________________________________________________\n",
      "reshape1 (Reshape)           (None, 10, 20)            0         \n",
      "_________________________________________________________________\n",
      "rnn1 (LSTM)                  (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 3,340\n",
      "Trainable params: 3,340\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if bi_class == 0:    \n",
    "    model = build_model(num_classes=num_classes, rnn_unit=100, input_shape=np.array(X_train[0]).shape)\n",
    "    model.summary()\n",
    "    plot_model(model, show_shapes=True, to_file='model.png')\n",
    "    plt = SVG(model_to_dot(model).create(prog='dot', format='svg')) \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', keras.metrics.AUC(), tfa.metrics.F1Score(num_classes=num_classes)])\n",
    "else:\n",
    "    sm = imblearn.over_sampling.SMOTE()         # random state do not set\n",
    "    origin_shape = np.array(X_train).shape\n",
    "    new_X_train = np.array(X_train).reshape(origin_shape[0], origin_shape[1]*origin_shape[2]*origin_shape[3])\n",
    "    Y_train = np.array(Y_train).astype('float64')\n",
    "    X_train, Y_train = sm.fit_resample(new_X_train, Y_train)\n",
    "    temp = X_train.shape\n",
    "    X_train = X_train.reshape([temp[0], origin_shape[1], origin_shape[2], origin_shape[3]])\n",
    "    Y_train = np.eye(2)[Y_train.reshape(temp[0])]\n",
    "    model = build_model(num_classes=2, rnn_unit=20, input_shape=np.array(X_train[0]).shape)\n",
    "    model.summary()\n",
    "    plot_model(model, show_shapes=True, to_file='model.png')\n",
    "    SVG(model_to_dot(model).create(prog='dot', format='svg')) \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', keras.metrics.AUC()])\n",
    "#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 5.4275 - accuracy: 0.5194 - auc: 0.5365\n",
      "Epoch 2/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 5.4096 - accuracy: 0.5388 - auc: 0.5657\n",
      "Epoch 3/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 5.1963 - accuracy: 0.5291 - auc: 0.5556\n",
      "Epoch 4/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 4.8160 - accuracy: 0.5146 - auc: 0.5558\n",
      "Epoch 5/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 4.7268 - accuracy: 0.5291 - auc: 0.5585\n",
      "Epoch 6/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 4.6755 - accuracy: 0.5825 - auc: 0.5920\n",
      "Epoch 7/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 5.2193 - accuracy: 0.5680 - auc: 0.5570\n",
      "Epoch 8/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 4.2887 - accuracy: 0.6408 - auc: 0.6401\n",
      "Epoch 9/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 4.2830 - accuracy: 0.6262 - auc: 0.6169\n",
      "Epoch 10/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 5.1798 - accuracy: 0.5825 - auc: 0.5740\n",
      "Epoch 11/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 4.8218 - accuracy: 0.5874 - auc: 0.5841\n",
      "Epoch 12/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 4.2987 - accuracy: 0.5583 - auc: 0.5292\n",
      "Epoch 13/500\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 3.8078 - accuracy: 0.5340 - auc: 0.5031\n",
      "Epoch 14/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 3.2113 - accuracy: 0.5097 - auc: 0.5009\n",
      "Epoch 15/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2.2264 - accuracy: 0.4951 - auc: 0.4674\n",
      "Epoch 16/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2.2253 - accuracy: 0.5437 - auc: 0.5272\n",
      "Epoch 17/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.9204 - accuracy: 0.5631 - auc: 0.5500\n",
      "Epoch 18/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.4717 - accuracy: 0.5340 - auc: 0.5180\n",
      "Epoch 19/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.6953 - accuracy: 0.5680 - auc: 0.5287\n",
      "Epoch 20/500\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 1.8387 - accuracy: 0.5485 - auc: 0.5234\n",
      "Epoch 21/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.7726 - accuracy: 0.5534 - auc: 0.5572\n",
      "Epoch 22/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.6333 - accuracy: 0.6068 - auc: 0.5996\n",
      "Epoch 23/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.3850 - accuracy: 0.6068 - auc: 0.5832\n",
      "Epoch 24/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.2376 - accuracy: 0.5340 - auc: 0.5598\n",
      "Epoch 25/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.1287 - accuracy: 0.5825 - auc: 0.6211\n",
      "Epoch 26/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.1348 - accuracy: 0.5583 - auc: 0.5848\n",
      "Epoch 27/500\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.0695 - accuracy: 0.5825 - auc: 0.6036\n",
      "Epoch 28/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.0304 - accuracy: 0.6117 - auc: 0.6303\n",
      "Epoch 29/500\n",
      "7/7 [==============================] - ETA: 0s - loss: 1.0651 - accuracy: 0.6042 - auc: 0.62 - 0s 23ms/step - loss: 1.0526 - accuracy: 0.6117 - auc: 0.6228\n",
      "Epoch 30/500\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.9074 - accuracy: 0.6553 - auc: 0.6717\n",
      "Epoch 31/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.0012 - accuracy: 0.6262 - auc: 0.6388\n",
      "Epoch 32/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.8978 - accuracy: 0.6456 - auc: 0.6878\n",
      "Epoch 33/500\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.9262 - accuracy: 0.6456 - auc: 0.6640\n",
      "Epoch 34/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.8704 - accuracy: 0.6505 - auc: 0.6858\n",
      "Epoch 35/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.8834 - accuracy: 0.6602 - auc: 0.6968\n",
      "Epoch 36/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.8608 - accuracy: 0.6408 - auc: 0.6832\n",
      "Epoch 37/500\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.9151 - accuracy: 0.6602 - auc: 0.6793\n",
      "Epoch 38/500\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.8188 - accuracy: 0.6650 - auc: 0.7123\n",
      "Epoch 39/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.9645 - accuracy: 0.6262 - auc: 0.6912\n",
      "Epoch 40/500\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.9270 - accuracy: 0.6505 - auc: 0.7199\n",
      "Epoch 41/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.0121 - accuracy: 0.6117 - auc: 0.6639\n",
      "Epoch 42/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.9402 - accuracy: 0.6456 - auc: 0.7007\n",
      "Epoch 43/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.9470 - accuracy: 0.6117 - auc: 0.6612\n",
      "Epoch 44/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.9325 - accuracy: 0.6019 - auc: 0.6549\n",
      "Epoch 45/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.9087 - accuracy: 0.5971 - auc: 0.6634\n",
      "Epoch 46/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.0210 - accuracy: 0.6262 - auc: 0.6366\n",
      "Epoch 47/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2.0243 - accuracy: 0.5485 - auc: 0.5734\n",
      "Epoch 48/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1.0804 - accuracy: 0.5680 - auc: 0.6107\n",
      "Epoch 49/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.0350 - accuracy: 0.5631 - auc: 0.6021\n",
      "Epoch 50/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.0907 - accuracy: 0.6117 - auc: 0.6012\n",
      "Epoch 51/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.1723 - accuracy: 0.5680 - auc: 0.5708\n",
      "Epoch 52/500\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.0232 - accuracy: 0.6359 - auc: 0.6313\n",
      "Epoch 53/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.0010 - accuracy: 0.6214 - auc: 0.6117\n",
      "Epoch 54/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.9818 - accuracy: 0.5922 - auc: 0.6250\n",
      "Epoch 55/500\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.9780 - accuracy: 0.6262 - auc: 0.6262\n",
      "Epoch 56/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.8640 - accuracy: 0.6602 - auc: 0.6988\n",
      "Epoch 57/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.0792 - accuracy: 0.5777 - auc: 0.6056\n",
      "Epoch 58/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.0106 - accuracy: 0.6456 - auc: 0.6516\n",
      "Epoch 59/500\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.8891 - accuracy: 0.6748 - auc: 0.6811\n",
      "Epoch 60/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.8650 - accuracy: 0.6359 - auc: 0.6460\n",
      "Epoch 61/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.8079 - accuracy: 0.6262 - auc: 0.6622\n",
      "Epoch 62/500\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.9075 - accuracy: 0.6165 - auc: 0.6182\n",
      "Epoch 63/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.7184 - accuracy: 0.6602 - auc: 0.7094\n",
      "Epoch 64/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.7235 - accuracy: 0.6602 - auc: 0.6987\n",
      "Epoch 65/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.7809 - accuracy: 0.6214 - auc: 0.6605\n",
      "Epoch 66/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6704 - accuracy: 0.6699 - auc: 0.7274\n",
      "Epoch 67/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6050 - accuracy: 0.6602 - auc: 0.7300\n",
      "Epoch 68/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.6358 - accuracy: 0.6650 - auc: 0.7258\n",
      "Epoch 69/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.6144 - accuracy: 0.6699 - auc: 0.7484\n",
      "Epoch 70/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.6281 - accuracy: 0.6796 - auc: 0.7395\n",
      "Epoch 71/500\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.5969 - accuracy: 0.6845 - auc: 0.7611\n",
      "Epoch 72/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5982 - accuracy: 0.6990 - auc: 0.7554\n",
      "Epoch 73/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 16ms/step - loss: 0.6691 - accuracy: 0.6456 - auc: 0.6929\n",
      "Epoch 74/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.6051 - accuracy: 0.7039 - auc: 0.7618\n",
      "Epoch 75/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6522 - accuracy: 0.6748 - auc: 0.7110\n",
      "Epoch 76/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5797 - accuracy: 0.7233 - auc: 0.7803\n",
      "Epoch 77/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.5650 - accuracy: 0.7330 - auc: 0.7924\n",
      "Epoch 78/500\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.5757 - accuracy: 0.6990 - auc: 0.7707\n",
      "Epoch 79/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.5744 - accuracy: 0.6990 - auc: 0.7680\n",
      "Epoch 80/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.5707 - accuracy: 0.7039 - auc: 0.7846\n",
      "Epoch 81/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.5779 - accuracy: 0.6796 - auc: 0.7666\n",
      "Epoch 82/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.5652 - accuracy: 0.6990 - auc: 0.7740\n",
      "Epoch 83/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.5547 - accuracy: 0.7184 - auc: 0.7905\n",
      "Epoch 84/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.5459 - accuracy: 0.7136 - auc: 0.7981\n",
      "Epoch 85/500\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.5450 - accuracy: 0.7184 - auc: 0.7967\n",
      "Epoch 86/500\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.5351 - accuracy: 0.7282 - auc: 0.8010\n",
      "Epoch 87/500\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.5327 - accuracy: 0.7136 - auc: 0.8048\n",
      "Epoch 88/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.6182 - accuracy: 0.6796 - auc: 0.7554\n",
      "Epoch 89/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.6527 - accuracy: 0.6942 - auc: 0.7462\n",
      "Epoch 90/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.5552 - accuracy: 0.6650 - auc: 0.7689\n",
      "Epoch 91/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5696 - accuracy: 0.6796 - auc: 0.7715\n",
      "Epoch 92/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.5077 - accuracy: 0.7427 - auc: 0.8209\n",
      "Epoch 93/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.5034 - accuracy: 0.7039 - auc: 0.8173\n",
      "Epoch 94/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.5003 - accuracy: 0.7087 - auc: 0.8184\n",
      "Epoch 95/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5042 - accuracy: 0.7282 - auc: 0.8135\n",
      "Epoch 96/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5054 - accuracy: 0.7524 - auc: 0.8312\n",
      "Epoch 97/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.5560 - accuracy: 0.6845 - auc: 0.7858\n",
      "Epoch 98/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.5516 - accuracy: 0.7282 - auc: 0.8100\n",
      "Epoch 99/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5405 - accuracy: 0.6796 - auc: 0.7954\n",
      "Epoch 100/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.5838 - accuracy: 0.7767 - auc: 0.7892\n",
      "Epoch 101/500\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.5757 - accuracy: 0.7136 - auc: 0.7764\n",
      "Epoch 102/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.5763 - accuracy: 0.7233 - auc: 0.7727\n",
      "Epoch 103/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5838 - accuracy: 0.6893 - auc: 0.7658\n",
      "Epoch 104/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.5619 - accuracy: 0.7184 - auc: 0.7882\n",
      "Epoch 105/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5451 - accuracy: 0.7379 - auc: 0.7927\n",
      "Epoch 106/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.5425 - accuracy: 0.7379 - auc: 0.7994\n",
      "Epoch 107/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.6070 - accuracy: 0.6845 - auc: 0.7413\n",
      "Epoch 108/500\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.5550 - accuracy: 0.6893 - auc: 0.7752\n",
      "Epoch 109/500\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.5095 - accuracy: 0.7136 - auc: 0.8205\n",
      "Epoch 110/500\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.4986 - accuracy: 0.7282 - auc: 0.8291\n",
      "Epoch 111/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.5323 - accuracy: 0.7233 - auc: 0.7989\n",
      "Epoch 112/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.5006 - accuracy: 0.7524 - auc: 0.8210\n",
      "Epoch 113/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5162 - accuracy: 0.7282 - auc: 0.8126\n",
      "Epoch 114/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.5179 - accuracy: 0.7233 - auc: 0.8122\n",
      "Epoch 115/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4976 - accuracy: 0.7233 - auc: 0.8244\n",
      "Epoch 116/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.4778 - accuracy: 0.7670 - auc: 0.8388\n",
      "Epoch 117/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.4798 - accuracy: 0.7087 - auc: 0.8350\n",
      "Epoch 118/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4558 - accuracy: 0.7330 - auc: 0.8555\n",
      "Epoch 119/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4839 - accuracy: 0.7330 - auc: 0.8293\n",
      "Epoch 120/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4507 - accuracy: 0.7670 - auc: 0.8625\n",
      "Epoch 121/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4457 - accuracy: 0.7573 - auc: 0.8613\n",
      "Epoch 122/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4453 - accuracy: 0.7524 - auc: 0.8582\n",
      "Epoch 123/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.4381 - accuracy: 0.7718 - auc: 0.8645\n",
      "Epoch 124/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4499 - accuracy: 0.7767 - auc: 0.8564\n",
      "Epoch 125/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4625 - accuracy: 0.7476 - auc: 0.8425\n",
      "Epoch 126/500\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.4414 - accuracy: 0.7379 - auc: 0.8572\n",
      "Epoch 127/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.4389 - accuracy: 0.7621 - auc: 0.8616\n",
      "Epoch 128/500\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.4346 - accuracy: 0.7427 - auc: 0.8624\n",
      "Epoch 129/500\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.4535 - accuracy: 0.7670 - auc: 0.8583\n",
      "Epoch 130/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4390 - accuracy: 0.7330 - auc: 0.8552\n",
      "Epoch 131/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4341 - accuracy: 0.7427 - auc: 0.8602\n",
      "Epoch 132/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4803 - accuracy: 0.7330 - auc: 0.8448\n",
      "Epoch 133/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4545 - accuracy: 0.7864 - auc: 0.8635\n",
      "Epoch 134/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.5325 - accuracy: 0.7330 - auc: 0.8243\n",
      "Epoch 135/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.6399 - accuracy: 0.7330 - auc: 0.8043\n",
      "Epoch 136/500\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.5200 - accuracy: 0.7233 - auc: 0.8324\n",
      "Epoch 137/500\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.4718 - accuracy: 0.7767 - auc: 0.8544\n",
      "Epoch 138/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4642 - accuracy: 0.7282 - auc: 0.8377\n",
      "Epoch 139/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4274 - accuracy: 0.7718 - auc: 0.8682\n",
      "Epoch 140/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.4354 - accuracy: 0.7670 - auc: 0.8632\n",
      "Epoch 141/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4324 - accuracy: 0.7767 - auc: 0.8638\n",
      "Epoch 142/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.4800 - accuracy: 0.7330 - auc: 0.8434\n",
      "Epoch 143/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4622 - accuracy: 0.7718 - auc: 0.8513\n",
      "Epoch 144/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.4475 - accuracy: 0.7427 - auc: 0.8556\n",
      "Epoch 145/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4641 - accuracy: 0.7427 - auc: 0.8456\n",
      "Epoch 146/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4992 - accuracy: 0.7524 - auc: 0.8303\n",
      "Epoch 147/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4970 - accuracy: 0.7233 - auc: 0.8224\n",
      "Epoch 148/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.4510 - accuracy: 0.7670 - auc: 0.8562\n",
      "Epoch 149/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.5040 - accuracy: 0.7476 - auc: 0.8318\n",
      "Epoch 150/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4378 - accuracy: 0.7427 - auc: 0.8608\n",
      "Epoch 151/500\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.4198 - accuracy: 0.7913 - auc: 0.8745\n",
      "Epoch 152/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4299 - accuracy: 0.7718 - auc: 0.8605\n",
      "Epoch 153/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4112 - accuracy: 0.8010 - auc: 0.8808\n",
      "Epoch 154/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4342 - accuracy: 0.7476 - auc: 0.8564\n",
      "Epoch 155/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.4003 - accuracy: 0.7621 - auc: 0.8823\n",
      "Epoch 156/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4001 - accuracy: 0.7816 - auc: 0.8809\n",
      "Epoch 157/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.4145 - accuracy: 0.7621 - auc: 0.8647\n",
      "Epoch 158/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.4120 - accuracy: 0.7670 - auc: 0.8733\n",
      "Epoch 159/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4445 - accuracy: 0.7621 - auc: 0.8588\n",
      "Epoch 160/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4130 - accuracy: 0.8010 - auc: 0.8809\n",
      "Epoch 161/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.8374 - accuracy: 0.6311 - auc: 0.7140\n",
      "Epoch 162/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.9044 - accuracy: 0.5777 - auc: 0.6158\n",
      "Epoch 163/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.7134 - accuracy: 0.6117 - auc: 0.6633\n",
      "Epoch 164/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6647 - accuracy: 0.6214 - auc: 0.6993\n",
      "Epoch 165/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.7714 - accuracy: 0.6262 - auc: 0.6710\n",
      "Epoch 166/500\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.6715 - accuracy: 0.6505 - auc: 0.7125\n",
      "Epoch 167/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5545 - accuracy: 0.6699 - auc: 0.7716\n",
      "Epoch 168/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.5581 - accuracy: 0.6650 - auc: 0.7598\n",
      "Epoch 169/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.5190 - accuracy: 0.7039 - auc: 0.7890\n",
      "Epoch 170/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6552 - accuracy: 0.6553 - auc: 0.7292\n",
      "Epoch 171/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6328 - accuracy: 0.6456 - auc: 0.7239\n",
      "Epoch 172/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5874 - accuracy: 0.6699 - auc: 0.7571\n",
      "Epoch 173/500\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.5556 - accuracy: 0.6748 - auc: 0.7770\n",
      "Epoch 174/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.5680 - accuracy: 0.6942 - auc: 0.7884\n",
      "Epoch 175/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.5479 - accuracy: 0.6650 - auc: 0.7756\n",
      "Epoch 176/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.5234 - accuracy: 0.7136 - auc: 0.7968\n",
      "Epoch 177/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5377 - accuracy: 0.6796 - auc: 0.7782\n",
      "Epoch 178/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.5280 - accuracy: 0.6845 - auc: 0.7871\n",
      "Epoch 179/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.5190 - accuracy: 0.6845 - auc: 0.8063\n",
      "Epoch 180/500\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.4970 - accuracy: 0.6942 - auc: 0.8208\n",
      "Epoch 181/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4928 - accuracy: 0.7282 - auc: 0.8184\n",
      "Epoch 182/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.5297 - accuracy: 0.7136 - auc: 0.8072\n",
      "Epoch 183/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5682 - accuracy: 0.6699 - auc: 0.7664\n",
      "Epoch 184/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5819 - accuracy: 0.7039 - auc: 0.7960\n",
      "Epoch 185/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.7416 - accuracy: 0.6845 - auc: 0.7512\n",
      "Epoch 186/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.7122 - accuracy: 0.6942 - auc: 0.7484\n",
      "Epoch 187/500\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.5215 - accuracy: 0.7184 - auc: 0.8304\n",
      "Epoch 188/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6116 - accuracy: 0.7087 - auc: 0.7850\n",
      "Epoch 189/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5602 - accuracy: 0.7524 - auc: 0.8047\n",
      "Epoch 190/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5164 - accuracy: 0.7282 - auc: 0.8261\n",
      "Epoch 191/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5090 - accuracy: 0.7427 - auc: 0.8308\n",
      "Epoch 192/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4947 - accuracy: 0.7282 - auc: 0.8367\n",
      "Epoch 193/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4721 - accuracy: 0.7718 - auc: 0.8608\n",
      "Epoch 194/500\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.4883 - accuracy: 0.7476 - auc: 0.8435\n",
      "Epoch 195/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4712 - accuracy: 0.7670 - auc: 0.8608\n",
      "Epoch 196/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4669 - accuracy: 0.7718 - auc: 0.8594\n",
      "Epoch 197/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4849 - accuracy: 0.7476 - auc: 0.8450\n",
      "Epoch 198/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4811 - accuracy: 0.7573 - auc: 0.8469\n",
      "Epoch 199/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4728 - accuracy: 0.7427 - auc: 0.8479\n",
      "Epoch 200/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4996 - accuracy: 0.7087 - auc: 0.8203\n",
      "Epoch 201/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4677 - accuracy: 0.7816 - auc: 0.8534\n",
      "Epoch 202/500\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.4426 - accuracy: 0.7524 - auc: 0.8774\n",
      "Epoch 203/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4438 - accuracy: 0.7621 - auc: 0.8742\n",
      "Epoch 204/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4440 - accuracy: 0.7573 - auc: 0.8684\n",
      "Epoch 205/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.5353 - accuracy: 0.7136 - auc: 0.8150\n",
      "Epoch 206/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4273 - accuracy: 0.7621 - auc: 0.8805\n",
      "Epoch 207/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4444 - accuracy: 0.7621 - auc: 0.8617\n",
      "Epoch 208/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4227 - accuracy: 0.7670 - auc: 0.8762\n",
      "Epoch 209/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4148 - accuracy: 0.7670 - auc: 0.8846\n",
      "Epoch 210/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.4636 - accuracy: 0.7039 - auc: 0.8450\n",
      "Epoch 211/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4286 - accuracy: 0.7670 - auc: 0.8724\n",
      "Epoch 212/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4435 - accuracy: 0.7670 - auc: 0.8650\n",
      "Epoch 213/500\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4262 - accuracy: 0.7816 - auc: 0.8771\n",
      "Epoch 214/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4171 - accuracy: 0.7816 - auc: 0.8730\n",
      "Epoch 215/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4012 - accuracy: 0.8010 - auc: 0.8825\n",
      "Epoch 216/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4147 - accuracy: 0.7864 - auc: 0.8827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4683 - accuracy: 0.7184 - auc: 0.8535\n",
      "Epoch 218/500\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.4861 - accuracy: 0.7864 - auc: 0.8664\n",
      "Epoch 219/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.5375 - accuracy: 0.7330 - auc: 0.8385\n",
      "Epoch 220/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3877 - accuracy: 0.7913 - auc: 0.8941\n",
      "Epoch 221/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4265 - accuracy: 0.7718 - auc: 0.8690\n",
      "Epoch 222/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4034 - accuracy: 0.7573 - auc: 0.8758\n",
      "Epoch 223/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3888 - accuracy: 0.7864 - auc: 0.8906\n",
      "Epoch 224/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3809 - accuracy: 0.7767 - auc: 0.8951\n",
      "Epoch 225/500\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3701 - accuracy: 0.7913 - auc: 0.9042\n",
      "Epoch 226/500\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3719 - accuracy: 0.7913 - auc: 0.8954\n",
      "Epoch 227/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3621 - accuracy: 0.7670 - auc: 0.9042\n",
      "Epoch 228/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3719 - accuracy: 0.7767 - auc: 0.8965\n",
      "Epoch 229/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3867 - accuracy: 0.7573 - auc: 0.8837\n",
      "Epoch 230/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3801 - accuracy: 0.7816 - auc: 0.8928\n",
      "Epoch 231/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4260 - accuracy: 0.7573 - auc: 0.8782\n",
      "Epoch 232/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4532 - accuracy: 0.7524 - auc: 0.8654\n",
      "Epoch 233/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3851 - accuracy: 0.7864 - auc: 0.8924\n",
      "Epoch 234/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.3887 - accuracy: 0.8010 - auc: 0.8951\n",
      "Epoch 235/500\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4128 - accuracy: 0.7573 - auc: 0.8765\n",
      "Epoch 236/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4018 - accuracy: 0.7816 - auc: 0.8860\n",
      "Epoch 237/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3998 - accuracy: 0.7524 - auc: 0.8756\n",
      "Epoch 238/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.3899 - accuracy: 0.7476 - auc: 0.8688\n",
      "Epoch 239/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.3771 - accuracy: 0.7670 - auc: 0.8887\n",
      "Epoch 240/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.3686 - accuracy: 0.7961 - auc: 0.8995\n",
      "Epoch 241/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3636 - accuracy: 0.7816 - auc: 0.9033\n",
      "Epoch 242/500\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.3723 - accuracy: 0.7816 - auc: 0.8946\n",
      "Epoch 243/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3815 - accuracy: 0.7864 - auc: 0.8983\n",
      "Epoch 244/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.5403 - accuracy: 0.7087 - auc: 0.8146\n",
      "Epoch 245/500\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4484 - accuracy: 0.7476 - auc: 0.8559\n",
      "Epoch 246/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4213 - accuracy: 0.7961 - auc: 0.8798\n",
      "Epoch 247/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4080 - accuracy: 0.7961 - auc: 0.8854\n",
      "Epoch 248/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.3883 - accuracy: 0.7767 - auc: 0.9008\n",
      "Epoch 249/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3814 - accuracy: 0.7913 - auc: 0.9014\n",
      "Epoch 250/500\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.4216 - accuracy: 0.7767 - auc: 0.8756\n",
      "Epoch 251/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.4183 - accuracy: 0.7718 - auc: 0.8748\n",
      "Epoch 252/500\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.4213 - accuracy: 0.7670 - auc: 0.8816\n",
      "Epoch 253/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.3809 - accuracy: 0.7718 - auc: 0.8887\n",
      "Epoch 254/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3766 - accuracy: 0.7816 - auc: 0.8892\n",
      "Epoch 255/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.3707 - accuracy: 0.7670 - auc: 0.9003\n",
      "Epoch 256/500\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.4309 - accuracy: 0.7816 - auc: 0.8735\n",
      "Epoch 257/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4275 - accuracy: 0.7864 - auc: 0.8881\n",
      "Epoch 258/500\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.3863 - accuracy: 0.7573 - auc: 0.8878\n",
      "Epoch 259/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.3705 - accuracy: 0.7767 - auc: 0.8955\n",
      "Epoch 260/500\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.3784 - accuracy: 0.7621 - auc: 0.8828\n",
      "Epoch 261/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.3590 - accuracy: 0.7864 - auc: 0.9015\n",
      "Epoch 262/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3844 - accuracy: 0.7864 - auc: 0.8858\n",
      "Epoch 263/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.3634 - accuracy: 0.7816 - auc: 0.8945\n",
      "Epoch 264/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.3449 - accuracy: 0.7864 - auc: 0.9079\n",
      "Epoch 265/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3741 - accuracy: 0.8058 - auc: 0.8992\n",
      "Epoch 266/500\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.3562 - accuracy: 0.8010 - auc: 0.9089\n",
      "Epoch 267/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.3382 - accuracy: 0.7864 - auc: 0.9203\n",
      "Epoch 268/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.3419 - accuracy: 0.7913 - auc: 0.9115\n",
      "Epoch 269/500\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.3483 - accuracy: 0.8010 - auc: 0.9076\n",
      "Epoch 270/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.3519 - accuracy: 0.7816 - auc: 0.9086\n",
      "Epoch 271/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3566 - accuracy: 0.7767 - auc: 0.9020\n",
      "Epoch 272/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.3727 - accuracy: 0.8010 - auc: 0.9002\n",
      "Epoch 273/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3398 - accuracy: 0.8010 - auc: 0.9158\n",
      "Epoch 274/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.3371 - accuracy: 0.7961 - auc: 0.9124\n",
      "Epoch 275/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.4044 - accuracy: 0.7476 - auc: 0.8821\n",
      "Epoch 276/500\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.3935 - accuracy: 0.8010 - auc: 0.9012\n",
      "Epoch 277/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4162 - accuracy: 0.7718 - auc: 0.8957\n",
      "Epoch 278/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4329 - accuracy: 0.7621 - auc: 0.8846\n",
      "Epoch 279/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.4037 - accuracy: 0.8058 - auc: 0.8957\n",
      "Epoch 280/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.4093 - accuracy: 0.7864 - auc: 0.8924\n",
      "Epoch 281/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.4438 - accuracy: 0.8010 - auc: 0.8917\n",
      "Epoch 282/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.4035 - accuracy: 0.7427 - auc: 0.8933\n",
      "Epoch 283/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.4466 - accuracy: 0.8058 - auc: 0.8921\n",
      "Epoch 284/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.4096 - accuracy: 0.7670 - auc: 0.8823\n",
      "Epoch 285/500\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.3386 - accuracy: 0.7816 - auc: 0.9090\n",
      "Epoch 286/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.3573 - accuracy: 0.8107 - auc: 0.9120\n",
      "Epoch 287/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.4640 - accuracy: 0.7379 - auc: 0.8736\n",
      "Epoch 288/500\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.3999 - accuracy: 0.7767 - auc: 0.8927\n",
      "Epoch 289/500\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.3721 - accuracy: 0.7621 - auc: 0.8973\n",
      "Epoch 290/500\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.3535 - accuracy: 0.7670 - auc: 0.8979\n",
      "Epoch 291/500\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.3514 - accuracy: 0.7864 - auc: 0.9073\n",
      "Epoch 292/500\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.3362 - accuracy: 0.8010 - auc: 0.9146\n",
      "Epoch 293/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.3330 - accuracy: 0.8252 - auc: 0.9150\n",
      "Epoch 294/500\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3508 - accuracy: 0.7573 - auc: 0.8989\n",
      "Epoch 295/500\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.3856 - accuracy: 0.8058 - auc: 0.9104\n",
      "Epoch 296/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3721 - accuracy: 0.7864 - auc: 0.8975\n",
      "Epoch 297/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3719 - accuracy: 0.8252 - auc: 0.9090\n",
      "Epoch 298/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3358 - accuracy: 0.8107 - auc: 0.9148\n",
      "Epoch 299/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.3327 - accuracy: 0.8252 - auc: 0.9219\n",
      "Epoch 300/500\n",
      "7/7 [==============================] - 0s 35ms/step - loss: 0.3812 - accuracy: 0.7621 - auc: 0.8879\n",
      "Epoch 301/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.3290 - accuracy: 0.8204 - auc: 0.9139\n",
      "Epoch 302/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.3362 - accuracy: 0.8010 - auc: 0.9135\n",
      "Epoch 303/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3283 - accuracy: 0.8155 - auc: 0.9109\n",
      "Epoch 304/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3382 - accuracy: 0.8204 - auc: 0.9168\n",
      "Epoch 305/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3238 - accuracy: 0.7961 - auc: 0.9191\n",
      "Epoch 306/500\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.3223 - accuracy: 0.7961 - auc: 0.9171\n",
      "Epoch 307/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.3262 - accuracy: 0.8155 - auc: 0.9176\n",
      "Epoch 308/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3275 - accuracy: 0.8155 - auc: 0.9183\n",
      "Epoch 309/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.3385 - accuracy: 0.8107 - auc: 0.9117\n",
      "Epoch 310/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.3164 - accuracy: 0.8155 - auc: 0.9232\n",
      "Epoch 311/500\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.3212 - accuracy: 0.7864 - auc: 0.9185\n",
      "Epoch 312/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3121 - accuracy: 0.7961 - auc: 0.9222\n",
      "Epoch 313/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3283 - accuracy: 0.8155 - auc: 0.9128\n",
      "Epoch 314/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.3179 - accuracy: 0.8155 - auc: 0.9219\n",
      "Epoch 315/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.3508 - accuracy: 0.7961 - auc: 0.9112\n",
      "Epoch 316/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3310 - accuracy: 0.8107 - auc: 0.9172\n",
      "Epoch 317/500\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.3152 - accuracy: 0.8058 - auc: 0.9210\n",
      "Epoch 318/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3243 - accuracy: 0.8204 - auc: 0.9191\n",
      "Epoch 319/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3401 - accuracy: 0.7718 - auc: 0.9043\n",
      "Epoch 320/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.3288 - accuracy: 0.8058 - auc: 0.9205\n",
      "Epoch 321/500\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.3358 - accuracy: 0.8155 - auc: 0.9155\n",
      "Epoch 322/500\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.3358 - accuracy: 0.7670 - auc: 0.9100\n",
      "Epoch 323/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3687 - accuracy: 0.7816 - auc: 0.9006\n",
      "Epoch 324/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3421 - accuracy: 0.8010 - auc: 0.9091\n",
      "Epoch 325/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.3777 - accuracy: 0.7767 - auc: 0.9012\n",
      "Epoch 326/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.4086 - accuracy: 0.7864 - auc: 0.8957\n",
      "Epoch 327/500\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.3924 - accuracy: 0.7379 - auc: 0.8814\n",
      "Epoch 328/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3490 - accuracy: 0.8301 - auc: 0.9096\n",
      "Epoch 329/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3831 - accuracy: 0.7670 - auc: 0.8937\n",
      "Epoch 330/500\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.4128 - accuracy: 0.7476 - auc: 0.8804\n",
      "Epoch 331/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.4164 - accuracy: 0.7961 - auc: 0.8825\n",
      "Epoch 332/500\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.4823 - accuracy: 0.7816 - auc: 0.8615\n",
      "Epoch 333/500\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.3666 - accuracy: 0.8252 - auc: 0.9076\n",
      "Epoch 334/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3568 - accuracy: 0.8107 - auc: 0.9076\n",
      "Epoch 335/500\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.3557 - accuracy: 0.7816 - auc: 0.9027\n",
      "Epoch 336/500\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.3282 - accuracy: 0.7961 - auc: 0.9227\n",
      "Epoch 337/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3330 - accuracy: 0.7816 - auc: 0.9097\n",
      "Epoch 338/500\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.3157 - accuracy: 0.8107 - auc: 0.9262\n",
      "Epoch 339/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3131 - accuracy: 0.8155 - auc: 0.9280\n",
      "Epoch 340/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3148 - accuracy: 0.8301 - auc: 0.9237\n",
      "Epoch 341/500\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.3470 - accuracy: 0.7670 - auc: 0.9010\n",
      "Epoch 342/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3269 - accuracy: 0.8252 - auc: 0.9248\n",
      "Epoch 343/500\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.3345 - accuracy: 0.7718 - auc: 0.9087\n",
      "Epoch 344/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3480 - accuracy: 0.7816 - auc: 0.9033\n",
      "Epoch 345/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3371 - accuracy: 0.8301 - auc: 0.9203\n",
      "Epoch 346/500\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.3868 - accuracy: 0.7718 - auc: 0.9033\n",
      "Epoch 347/500\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.3798 - accuracy: 0.8058 - auc: 0.9105\n",
      "Epoch 348/500\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.3846 - accuracy: 0.7524 - auc: 0.8887\n",
      "Epoch 349/500\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.3441 - accuracy: 0.8010 - auc: 0.9193\n",
      "Epoch 350/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3132 - accuracy: 0.7961 - auc: 0.9218\n",
      "Epoch 351/500\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.3148 - accuracy: 0.8155 - auc: 0.9301\n",
      "Epoch 352/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3360 - accuracy: 0.7864 - auc: 0.9108\n",
      "Epoch 353/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3365 - accuracy: 0.8301 - auc: 0.9205\n",
      "Epoch 354/500\n",
      "7/7 [==============================] - 0s 35ms/step - loss: 0.3326 - accuracy: 0.7718 - auc: 0.9098\n",
      "Epoch 355/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3219 - accuracy: 0.8058 - auc: 0.9225\n",
      "Epoch 356/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3236 - accuracy: 0.8010 - auc: 0.9152\n",
      "Epoch 357/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3200 - accuracy: 0.8107 - auc: 0.9219\n",
      "Epoch 358/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3273 - accuracy: 0.8058 - auc: 0.9160\n",
      "Epoch 359/500\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.3421 - accuracy: 0.7864 - auc: 0.9027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3155 - accuracy: 0.8010 - auc: 0.9204\n",
      "Epoch 361/500\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.3251 - accuracy: 0.7816 - auc: 0.9176\n",
      "Epoch 362/500\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.3174 - accuracy: 0.7864 - auc: 0.9191\n",
      "Epoch 363/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3080 - accuracy: 0.8107 - auc: 0.9243\n",
      "Epoch 364/500\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.3566 - accuracy: 0.8107 - auc: 0.9149\n",
      "Epoch 365/500\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.4725 - accuracy: 0.7379 - auc: 0.8594\n",
      "Epoch 366/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.4037 - accuracy: 0.7476 - auc: 0.8696\n",
      "Epoch 367/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.4541 - accuracy: 0.7379 - auc: 0.8531\n",
      "Epoch 368/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3875 - accuracy: 0.7718 - auc: 0.8950\n",
      "Epoch 369/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.3971 - accuracy: 0.7621 - auc: 0.8789\n",
      "Epoch 370/500\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.3545 - accuracy: 0.8058 - auc: 0.9103\n",
      "Epoch 371/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.3734 - accuracy: 0.8058 - auc: 0.9033\n",
      "Epoch 372/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.3825 - accuracy: 0.7621 - auc: 0.8900\n",
      "Epoch 373/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.3445 - accuracy: 0.7767 - auc: 0.9029\n",
      "Epoch 374/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3332 - accuracy: 0.7913 - auc: 0.9183\n",
      "Epoch 375/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3372 - accuracy: 0.8252 - auc: 0.9140\n",
      "Epoch 376/500\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.3353 - accuracy: 0.8155 - auc: 0.9128\n",
      "Epoch 377/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.3411 - accuracy: 0.8058 - auc: 0.9181\n",
      "Epoch 378/500\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.4063 - accuracy: 0.7621 - auc: 0.8828\n",
      "Epoch 379/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.3336 - accuracy: 0.7961 - auc: 0.9132\n",
      "Epoch 380/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.3362 - accuracy: 0.8155 - auc: 0.9201\n",
      "Epoch 381/500\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.3471 - accuracy: 0.7961 - auc: 0.9098\n",
      "Epoch 382/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.6024 - accuracy: 0.7379 - auc: 0.8596\n",
      "Epoch 383/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.5842 - accuracy: 0.7427 - auc: 0.8462\n",
      "Epoch 384/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.6701 - accuracy: 0.6796 - auc: 0.7935\n",
      "Epoch 385/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.5632 - accuracy: 0.7476 - auc: 0.8535\n",
      "Epoch 386/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.6481 - accuracy: 0.7184 - auc: 0.8403\n",
      "Epoch 387/500\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.9516 - accuracy: 0.5874 - auc: 0.7035\n",
      "Epoch 388/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.7259 - accuracy: 0.6796 - auc: 0.7527\n",
      "Epoch 389/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.7082 - accuracy: 0.6553 - auc: 0.7386\n",
      "Epoch 390/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.6904 - accuracy: 0.7087 - auc: 0.7691\n",
      "Epoch 391/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.6826 - accuracy: 0.7136 - auc: 0.7671\n",
      "Epoch 392/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.6691 - accuracy: 0.6650 - auc: 0.7804\n",
      "Epoch 393/500\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.6356 - accuracy: 0.6796 - auc: 0.7966\n",
      "Epoch 394/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.6268 - accuracy: 0.7136 - auc: 0.8076\n",
      "Epoch 395/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.6040 - accuracy: 0.7136 - auc: 0.8214\n",
      "Epoch 396/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.5986 - accuracy: 0.7087 - auc: 0.8160\n",
      "Epoch 397/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.6020 - accuracy: 0.6990 - auc: 0.8190\n",
      "Epoch 398/500\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.5812 - accuracy: 0.7282 - auc: 0.8415\n",
      "Epoch 399/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.5858 - accuracy: 0.7184 - auc: 0.8288\n",
      "Epoch 400/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.5777 - accuracy: 0.7233 - auc: 0.8415\n",
      "Epoch 401/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.5688 - accuracy: 0.7621 - auc: 0.8469\n",
      "Epoch 402/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.5575 - accuracy: 0.7718 - auc: 0.8594\n",
      "Epoch 403/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.5582 - accuracy: 0.7524 - auc: 0.8594\n",
      "Epoch 404/500\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.5589 - accuracy: 0.7524 - auc: 0.8518\n",
      "Epoch 405/500\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.5589 - accuracy: 0.7330 - auc: 0.8500\n",
      "Epoch 406/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.5563 - accuracy: 0.7136 - auc: 0.8382\n",
      "Epoch 407/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.5599 - accuracy: 0.7282 - auc: 0.8442\n",
      "Epoch 408/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.5490 - accuracy: 0.7427 - auc: 0.8523\n",
      "Epoch 409/500\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.5415 - accuracy: 0.7573 - auc: 0.8611\n",
      "Epoch 410/500\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.5417 - accuracy: 0.7330 - auc: 0.8574\n",
      "Epoch 411/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5471 - accuracy: 0.7573 - auc: 0.8560\n",
      "Epoch 412/500\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.5555 - accuracy: 0.7476 - auc: 0.8549\n",
      "Epoch 413/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5377 - accuracy: 0.7718 - auc: 0.8656\n",
      "Epoch 414/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5518 - accuracy: 0.7670 - auc: 0.8620\n",
      "Epoch 415/500\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.5556 - accuracy: 0.7282 - auc: 0.8520\n",
      "Epoch 416/500\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.5318 - accuracy: 0.7573 - auc: 0.8704\n",
      "Epoch 417/500\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.5276 - accuracy: 0.7718 - auc: 0.8705\n",
      "Epoch 418/500\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.5262 - accuracy: 0.7767 - auc: 0.8779\n",
      "Epoch 419/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5393 - accuracy: 0.7621 - auc: 0.8622\n",
      "Epoch 420/500\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.5228 - accuracy: 0.7573 - auc: 0.8755\n",
      "Epoch 421/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5144 - accuracy: 0.7961 - auc: 0.8882\n",
      "Epoch 422/500\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.5167 - accuracy: 0.7913 - auc: 0.8778\n",
      "Epoch 423/500\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.5223 - accuracy: 0.7718 - auc: 0.8772\n",
      "Epoch 424/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5546 - accuracy: 0.7524 - auc: 0.8512\n",
      "Epoch 425/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5853 - accuracy: 0.7379 - auc: 0.8644\n",
      "Epoch 426/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5912 - accuracy: 0.7330 - auc: 0.8430\n",
      "Epoch 427/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5921 - accuracy: 0.7330 - auc: 0.8464\n",
      "Epoch 428/500\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.5406 - accuracy: 0.7573 - auc: 0.8721\n",
      "Epoch 429/500\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.4481 - accuracy: 0.7573 - auc: 0.8549\n",
      "Epoch 430/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5389 - accuracy: 0.7621 - auc: 0.8682\n",
      "Epoch 431/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.6452 - accuracy: 0.7476 - auc: 0.8527\n",
      "Epoch 432/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.6390 - accuracy: 0.7330 - auc: 0.8351\n",
      "Epoch 433/500\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.5641 - accuracy: 0.7330 - auc: 0.8415\n",
      "Epoch 434/500\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.6147 - accuracy: 0.7039 - auc: 0.8143\n",
      "Epoch 435/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5418 - accuracy: 0.7621 - auc: 0.8590\n",
      "Epoch 436/500\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.5312 - accuracy: 0.7524 - auc: 0.8650\n",
      "Epoch 437/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5275 - accuracy: 0.7573 - auc: 0.8690\n",
      "Epoch 438/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5279 - accuracy: 0.7573 - auc: 0.8662\n",
      "Epoch 439/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5275 - accuracy: 0.7816 - auc: 0.8651\n",
      "Epoch 440/500\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.5217 - accuracy: 0.7524 - auc: 0.8756\n",
      "Epoch 441/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.5252 - accuracy: 0.7573 - auc: 0.8612\n",
      "Epoch 442/500\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.5202 - accuracy: 0.7524 - auc: 0.8685\n",
      "Epoch 443/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5320 - accuracy: 0.7573 - auc: 0.8732\n",
      "Epoch 444/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5524 - accuracy: 0.7573 - auc: 0.8617\n",
      "Epoch 445/500\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.5127 - accuracy: 0.7670 - auc: 0.8794\n",
      "Epoch 446/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5274 - accuracy: 0.7670 - auc: 0.8648\n",
      "Epoch 447/500\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.5256 - accuracy: 0.7864 - auc: 0.8804\n",
      "Epoch 448/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5597 - accuracy: 0.7524 - auc: 0.8538\n",
      "Epoch 449/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5363 - accuracy: 0.7670 - auc: 0.8714\n",
      "Epoch 450/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5205 - accuracy: 0.7330 - auc: 0.8591\n",
      "Epoch 451/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5229 - accuracy: 0.7573 - auc: 0.8769\n",
      "Epoch 452/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5437 - accuracy: 0.7573 - auc: 0.8695\n",
      "Epoch 453/500\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.7881 - accuracy: 0.7039 - auc: 0.7967\n",
      "Epoch 454/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.7373 - accuracy: 0.6990 - auc: 0.7727\n",
      "Epoch 455/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.6888 - accuracy: 0.7233 - auc: 0.7914\n",
      "Epoch 456/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.6190 - accuracy: 0.7330 - auc: 0.8154\n",
      "Epoch 457/500\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.5925 - accuracy: 0.7573 - auc: 0.8410\n",
      "Epoch 458/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5643 - accuracy: 0.7670 - auc: 0.8678\n",
      "Epoch 459/500\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.5422 - accuracy: 0.7816 - auc: 0.8798\n",
      "Epoch 460/500\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.5293 - accuracy: 0.7816 - auc: 0.8814\n",
      "Epoch 461/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5248 - accuracy: 0.8010 - auc: 0.8807\n",
      "Epoch 462/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5181 - accuracy: 0.7670 - auc: 0.8795\n",
      "Epoch 463/500\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.5200 - accuracy: 0.7476 - auc: 0.8772\n",
      "Epoch 464/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5567 - accuracy: 0.7282 - auc: 0.8499\n",
      "Epoch 465/500\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.5242 - accuracy: 0.7573 - auc: 0.8672\n",
      "Epoch 466/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5052 - accuracy: 0.7767 - auc: 0.8827\n",
      "Epoch 467/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5083 - accuracy: 0.7670 - auc: 0.8803\n",
      "Epoch 468/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5005 - accuracy: 0.7816 - auc: 0.8860\n",
      "Epoch 469/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5030 - accuracy: 0.7573 - auc: 0.8812\n",
      "Epoch 470/500\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.5083 - accuracy: 0.7670 - auc: 0.8855\n",
      "Epoch 471/500\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.5000 - accuracy: 0.8107 - auc: 0.8942\n",
      "Epoch 472/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.5143 - accuracy: 0.7913 - auc: 0.8883\n",
      "Epoch 473/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.5414 - accuracy: 0.7718 - auc: 0.8668\n",
      "Epoch 474/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.5458 - accuracy: 0.7670 - auc: 0.8721\n",
      "Epoch 475/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.5040 - accuracy: 0.7282 - auc: 0.8768\n",
      "Epoch 476/500\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.5031 - accuracy: 0.7621 - auc: 0.8800\n",
      "Epoch 477/500\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.4927 - accuracy: 0.7767 - auc: 0.8881\n",
      "Epoch 478/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.5039 - accuracy: 0.7670 - auc: 0.8783\n",
      "Epoch 479/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.4975 - accuracy: 0.7670 - auc: 0.8880\n",
      "Epoch 480/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.5066 - accuracy: 0.7767 - auc: 0.8882\n",
      "Epoch 481/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.4990 - accuracy: 0.7767 - auc: 0.8860\n",
      "Epoch 482/500\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.4943 - accuracy: 0.7961 - auc: 0.8888\n",
      "Epoch 483/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.5079 - accuracy: 0.7864 - auc: 0.8823\n",
      "Epoch 484/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.5993 - accuracy: 0.7330 - auc: 0.8485\n",
      "Epoch 485/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.5961 - accuracy: 0.7670 - auc: 0.8693\n",
      "Epoch 486/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.5776 - accuracy: 0.7427 - auc: 0.8506\n",
      "Epoch 487/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.5278 - accuracy: 0.7476 - auc: 0.8625\n",
      "Epoch 488/500\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.5318 - accuracy: 0.7621 - auc: 0.8715\n",
      "Epoch 489/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.5086 - accuracy: 0.7573 - auc: 0.8730\n",
      "Epoch 490/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.4982 - accuracy: 0.7816 - auc: 0.8836\n",
      "Epoch 491/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.5052 - accuracy: 0.7573 - auc: 0.8757\n",
      "Epoch 492/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.4975 - accuracy: 0.7524 - auc: 0.8831\n",
      "Epoch 493/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.4994 - accuracy: 0.7573 - auc: 0.8832\n",
      "Epoch 494/500\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.4986 - accuracy: 0.7718 - auc: 0.8818\n",
      "Epoch 495/500\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.5061 - accuracy: 0.7573 - auc: 0.8836\n",
      "Epoch 496/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.4944 - accuracy: 0.7913 - auc: 0.8890\n",
      "Epoch 497/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.5051 - accuracy: 0.7670 - auc: 0.8788\n",
      "Epoch 498/500\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.5099 - accuracy: 0.7524 - auc: 0.8734\n",
      "Epoch 499/500\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.5194 - accuracy: 0.7379 - auc: 0.8725\n",
      "Epoch 500/500\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.5106 - accuracy: 0.7282 - auc: 0.8713\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x=np.array(X_train).transpose([0,1,2,3]), y=Y_train, batch_size=None, validation_split=0, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  7  96]\n",
      " [  0 103]]\n",
      "7 96 0 103\n",
      "Neg %: 0.06796116504854369 Pos %: 1.0\n"
     ]
    }
   ],
   "source": [
    "## Train Confusion Matrix\n",
    "\n",
    "train_predictions = model.predict(np.array(X_train).transpose([0,1,2,3]))\n",
    "\n",
    "flatten_Y_train = []\n",
    "flatten_train_predictions = []\n",
    "\n",
    "for i in range(len(Y_train)):\n",
    "    if Y_train[i][0] == 1:\n",
    "        flatten_Y_train.append(0)\n",
    "    else:\n",
    "        flatten_Y_train.append(1)\n",
    "        \n",
    "\n",
    "for i in range(len(train_predictions)):\n",
    "    if train_predictions[i][0] == 1:\n",
    "        flatten_train_predictions.append(0)\n",
    "    else:\n",
    "        flatten_train_predictions.append(1)\n",
    "\n",
    "\n",
    "conf_mat = confusion_matrix(flatten_Y_train, flatten_train_predictions)\n",
    "print(conf_mat)\n",
    "\n",
    "tn, fp, fn, tp = conf_mat.ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "print('Neg %:', tn/(tn+fp), 'Pos %:', tp/(tp+fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display acc, loss\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC:  0.7716346153846154\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(np.array(X_test).transpose([0,1,2,3]))\n",
    "\n",
    "if bi_class==0:\n",
    "    auc = roc_auc_score(Y_test, predictions, multi_class='raise')\n",
    "    print('Multiclass Test AUC: ', auc)\n",
    "else:\n",
    "    auc = roc_auc_score(Y_test, predictions)\n",
    "    print('Test AUC: ', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29., 13.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency = np.zeros(len(Y_test[0]))\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    frequency[np.argmax(predictions[i])] +=1\n",
    "\n",
    "frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 1.0526 - accuracy: 0.7381 - auc: 0.7999\n",
      "\n",
      "Accuracy: 0.738095223903656\n"
     ]
    }
   ],
   "source": [
    "if bi_class == 0:\n",
    "    test_loss, test_acc, test_auc, test_F1 = model.evaluate(np.array(X_test).transpose([0,1,2,3]),  np.array(Y_test).transpose([0,1]), verbose=2)\n",
    "    print('\\nAccuracy:', test_acc)\n",
    "else:\n",
    "    test_loss, test_acc, test_auc = model.evaluate(np.array(X_test).transpose([0,1,2,3]),  np.array(Y_test).transpose([0,1]), verbose=2)\n",
    "    print('\\nAccuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 25]\n",
      " [ 0 16]]\n",
      "1 25 0 16\n",
      "Neg %: 0.038461538461538464 Pos %: 1.0\n"
     ]
    }
   ],
   "source": [
    "## Test Confusion Matrix\n",
    "\n",
    "flatten_Y_test = []\n",
    "flatten_predictions = []\n",
    "\n",
    "for i in range(len(Y_test)):\n",
    "    if Y_test[i][0] == 1:\n",
    "        flatten_Y_test.append(0)\n",
    "    else:\n",
    "        flatten_Y_test.append(1)\n",
    "\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i][0] == 1:\n",
    "        flatten_predictions.append(0)\n",
    "    else:\n",
    "        flatten_predictions.append(1)\n",
    "        \n",
    "\n",
    "conf_mat = confusion_matrix(flatten_Y_test, flatten_predictions)\n",
    "print(conf_mat)\n",
    "\n",
    "tn, fp, fn, tp = conf_mat.ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "print('Neg %:', tn/(tn+fp), 'Pos %:', tp/(tp+fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
