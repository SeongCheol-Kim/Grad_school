{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m80rXVF8I5AN"
   },
   "source": [
    "# Game Theory With Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a_WtqfivI5AO"
   },
   "source": [
    "### Welcome to the course. \n",
    "### Glad to have you onboard in this journey to explore two Game Theory packages in Python\n",
    "\n",
    "#### Nashpy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8gKmBcHBI5AP"
   },
   "source": [
    "#### 7 Tasks\n",
    "#### 1. Create games with Nashpy\n",
    "#### 2. Mixed strategies and Utilities\n",
    "#### 3. Nash Equilibrium\n",
    "#### 4. Games with multiple Nash Equilibria\n",
    "#### 5. Zero Sum Game\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iQPnHp9SI5AQ"
   },
   "source": [
    "## Two Player Games with Nashpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fKYKZgVyI5AR"
   },
   "source": [
    "## 1. Create 2 player games - Using Nashpy\n",
    "\n",
    "### Consider the following Prisoner's Dilemma matrix\n",
    "\n",
    "![picture](https://drive.google.com/uc?id=1fw7j7O8XLGQR3Rt_c9UK_PE6KgLsFeEw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vDUwerlDI5AS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nashpy in /Users/sungshinkim/opt/anaconda3/lib/python3.7/site-packages (0.0.19)\r\n",
      "Requirement already satisfied: scipy>=0.19.0 in /Users/sungshinkim/opt/anaconda3/lib/python3.7/site-packages (from nashpy) (1.4.1)\r\n",
      "Requirement already satisfied: numpy>=1.12.1 in /Users/sungshinkim/opt/anaconda3/lib/python3.7/site-packages (from nashpy) (1.19.4)\r\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "!pip install nashpy\n",
    "#!pip install axelrod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nashpy as nash\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D-rB1BgYI5Aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bi matrix game with payoff matrices:\n",
       "\n",
       "Row player:\n",
       "[[ 8  1]\n",
       " [15  3]]\n",
       "\n",
       "Column player:\n",
       "[[ 8 15]\n",
       " [ 1  3]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the payoff matrix\n",
    "\n",
    "P1 =  np.array([[8,1],[15,3]])# P1 is the row player\n",
    "P2 =  np.array([[8,15],[1,3]])# P2 is the column player\n",
    "pd = nash.Game(P1, P2)\n",
    "pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mapgZsumI5Ae"
   },
   "source": [
    "### Exercise: Create a two player game, where,\n",
    "\n",
    "#### I. Name players as A and B\n",
    "#### II. Name the game as 'gm' and \n",
    "#### III. Use the follwing matrix\n",
    "\n",
    "![picture](https://drive.google.com/uc?id=1eHhyXZVZWQ3oPto4qcbL1EefxUsWq4bp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LBZatKa-I5Af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bi matrix game with payoff matrices:\n",
       "\n",
       "Row player:\n",
       "[[ 5 17]\n",
       " [14 12]]\n",
       "\n",
       "Column player:\n",
       "[[15 16]\n",
       " [ 2  8]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[5, 17],[14,12]])\n",
    "B = np.array([[15, 16],[2, 8]])\n",
    "gm = nash.Game(A,B)\n",
    "gm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CvPz8NuJI5Aj"
   },
   "source": [
    "## 2. Mixed Strategy and Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6-_cqcSQI5Ak"
   },
   "source": [
    "### Pure Strategy: \n",
    "\n",
    "A complete definition of how a player will play a game, it yields optimum payoff to the player. \n",
    "\n",
    "### Mixed Strategy: \n",
    "\n",
    "Assigns a probability to each pure strategy. This allows for a player to randomly select a pure strategy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sV3SS2IKI5Am"
   },
   "source": [
    "### Calculating Utilities:\n",
    "\n",
    "![picture](https://drive.google.com/uc?id=1eIMuJo8w5EgJC5mLaxT9kzH8-rdQwm3_)\n",
    "\n",
    "#### Consider the following Mixed Strategy\n",
    "\n",
    "σr=(.2,.8) and σc=(.6,.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XPaaw8GXI5An"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.2, 3.6])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Utilities\n",
    "\n",
    "sigma_r = np.array([0.2, 0.8])\n",
    "sigma_c = np.array([0.6, 0.4])\n",
    "pd = nash.Game(P1, P2)\n",
    "pd[sigma_r, sigma_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bi matrix game with payoff matrices:\n",
       "\n",
       "Row player:\n",
       "[[ 8  1]\n",
       " [15  3]]\n",
       "\n",
       "Column player:\n",
       "[[ 8 15]\n",
       " [ 1  3]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-nGQbdBQI5A0"
   },
   "source": [
    "### Validate the computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pmuAEpSII5Ar"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ur(σr,σc)\n",
    "ur=0.2*0.6*8+0.2*0.4*1+0.8*0.6*15+0.8*0.4*3\n",
    "ur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6KZrnGxI5Au"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6000000000000005"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#uc(σr,σc)\n",
    "uc=0.2*0.6*8+0.2*0.4*15+0.8*0.6*1+0.8*0.4*3\n",
    "uc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y28VJqzfI5A2"
   },
   "source": [
    "### Exercise: Calculate the utilities of the game 'gm' created in the previous exercise, using \n",
    "#### σr=(.3,.7) and σc=(.5,.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qf6LY92kI5A3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.4 ,  8.15])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_r = np.array([.3, .7])\n",
    "sigma_c = np.array([.5, .5])\n",
    "gm = nash.Game(A,B)\n",
    "gm[sigma_r, sigma_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sF4K0KlOI5A7"
   },
   "source": [
    "## 3. The Nash Equilibrium\n",
    "\n",
    "Strict and unique Nash Equilibrium\n",
    "\n",
    "![picture](https://drive.google.com/uc?id=1_B9Wk5Sb1jwK1AADXR1xj9n0tmALNykM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H9mFNqgOI5A8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0., 1.]), array([0., 1.]))\n"
     ]
    }
   ],
   "source": [
    "# Find the Nash Equilibrium with Support Enumeration\n",
    "\n",
    "equilibria = pd.support_enumeration()\n",
    "for eq in equilibria:\n",
    "    print(eq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "faBuCYODI5A_"
   },
   "source": [
    "#### Both solutions match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7nFjsLoUI5BA"
   },
   "source": [
    "### Exercise: Find out the Nash Equilibrium for gm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-WDnIp6SI5BB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1., 0.]), array([0., 1.]))\n"
     ]
    }
   ],
   "source": [
    "equilibria = gm.support_enumeration()\n",
    "for eq in equilibria:\n",
    "    print(eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bi matrix game with payoff matrices:\n",
       "\n",
       "Row player:\n",
       "[[ 5 17]\n",
       " [14 12]]\n",
       "\n",
       "Column player:\n",
       "[[15 16]\n",
       " [ 2  8]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NY2yrKJNI5BG"
   },
   "source": [
    "## 4. Games with Multiple Nash Equilibria\n",
    "\n",
    "### Hawk - Dove Game\n",
    "\n",
    "![picture](https://drive.google.com/uc?id=1b8kKho3qu1s5b7Qriq6NYWqJxd5uKI6x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aQg_1AIMI5BG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bi matrix game with payoff matrices:\n",
       "\n",
       "Row player:\n",
       "[[3 1]\n",
       " [4 0]]\n",
       "\n",
       "Column player:\n",
       "[[3 4]\n",
       " [1 0]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P3 =  np.array([[3, 1], [4, 0]])# P3 is the row player\n",
    "P4 =  np.array([[3, 4], [1, 0]])# P4 is the column player \n",
    "hd = nash.Game(P3, P4)\n",
    "hd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HdUrrBQ9I5BK"
   },
   "source": [
    "#### Nash Equilibria\n",
    "\n",
    "![picture](https://drive.google.com/uc?id=1JJxdwZ3y6U_hxMH-0l4i6LpuuTVhF5w0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BiVKP_72I5BL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1., 0.]), array([0., 1.]))\n",
      "(array([0., 1.]), array([1., 0.]))\n",
      "(array([0.5, 0.5]), array([0.5, 0.5]))\n"
     ]
    }
   ],
   "source": [
    "equilibria = hd.support_enumeration()\n",
    "for eq in equilibria:\n",
    "    print(eq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xolws3tSI5BO"
   },
   "source": [
    "Sol. (D,H)\n",
    "\n",
    "P3 : D = 1, H = 0\n",
    "\n",
    "P4 : D = 0, H = 1\n",
    "\n",
    "Sol. (H,D)\n",
    "\n",
    "P3 : D = 0, H = 1\n",
    "\n",
    "P4 : D = 1, H = 0\n",
    "\n",
    "Sol. (D,D) or (H,H)\n",
    "\n",
    "P3 : D = 0.5, H = 0.5\n",
    "\n",
    "P4 : D = 0.5, H = 0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iVaY16XNI5BO"
   },
   "source": [
    "### Exercise: Find out the number of NE for the following matrix\n",
    "#### Players: M and N\n",
    "#### Name of game mn\n",
    "\n",
    "\n",
    "![picture](https://drive.google.com/uc?id=1mAeVXw3qHTyzEx4kgMsOlyrP6rJvpKlN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4NW4qyI4I5BP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bi matrix game with payoff matrices:\n",
       "\n",
       "Row player:\n",
       "[[1 1 3 2]\n",
       " [2 3 4 3]\n",
       " [5 1 1 4]]\n",
       "\n",
       "Column player:\n",
       "[[3 2 2 4]\n",
       " [1 4 2 0]\n",
       " [3 3 2 3]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = np.array([[1, 1, 3, 2], [2, 3, 4, 3], [5, 1, 1, 4]])\n",
    "N = np.array([[3, 2, 2, 4],[1, 4, 2, 0],[3, 3, 2, 3]])\n",
    "mn = nash.Game(M, N)\n",
    "mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dbR3SnMPI5BS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0., 1., 0.]), array([0., 1., 0., 0.]))\n",
      "(array([0., 0., 1.]), array([1., 0., 0., 0.]))\n",
      "(array([0., 0., 1.]), array([0., 0., 0., 1.]))\n"
     ]
    }
   ],
   "source": [
    "equilibria = mn.support_enumeration()\n",
    "for eq in equilibria:\n",
    "    print(eq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I2_Z8uVlI5BW"
   },
   "source": [
    "![picture](https://drive.google.com/uc?id=11UeEgrEh4VYWYAMwyvwLVGZlHT7On2Eo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5NhqPum6I5BX"
   },
   "source": [
    "## 5. Zero Sum Game\n",
    "\n",
    "Matching the pennies game\n",
    "\n",
    "![picture](https://drive.google.com/uc?id=1DJhLFiRbUah8Cvku03oGP5C2eFuDPxBQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3w_YHAZTI5BX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Zero sum game with payoff matrices:\n",
       "\n",
       "Row player:\n",
       "[[ 1 -1]\n",
       " [-1  1]]\n",
       "\n",
       "Column player:\n",
       "[[-1  1]\n",
       " [ 1 -1]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P5 = np.array([[1, -1],[-1, 1]])\n",
    "P6 = np.array([[-1, 1],[1, -1]])\n",
    "mp = nash.Game(P5, P6)\n",
    "mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U9bM_W8eI5Bg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.5, 0.5]), array([0.5, 0.5]))\n"
     ]
    }
   ],
   "source": [
    "equilibria = mp.support_enumeration()\n",
    "for eq in equilibria:\n",
    "    print(eq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AwgfpFL-I5Bk"
   },
   "source": [
    "### Exercise: Find out the solution for the following zero sum game 'zs'\n",
    "#### Use payoff matrix - np.array([[5, -6.5], [-2.5, 7]]) \n",
    "#### For players Z1 and Z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9ypJKPZI5Bl"
   },
   "outputs": [],
   "source": [
    "Z1 = np.array([[5, -6.5], [-2.5, 7]])\n",
    "Z2 = np.array([[5, -6.5], [-2.5, 7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9qPZdieaI5Bo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1., 0.]), array([1., 0.]))\n",
      "(array([0., 1.]), array([0., 1.]))\n",
      "(array([0.45238095, 0.54761905]), array([0.64285714, 0.35714286]))\n"
     ]
    }
   ],
   "source": [
    "Z12 = nash.Game(Z1, Z2)\n",
    "for eq in Z12.support_enumeration():\n",
    "    print(eq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eVM0LDlfI5Br"
   },
   "source": [
    "## Two Player-Repeated Games with Axelrod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gJtMM67EI5Bs"
   },
   "source": [
    "## 6. Create repeated game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-qiWUNZ2I5Bs"
   },
   "outputs": [],
   "source": [
    "#!pip install -U pyYAML     # Troubleshoot: Execute this line if Axelrod does not run and AttributeError: module 'yaml' has no attribute 'FullLoader' occurs\n",
    "\n",
    "# Import package\n",
    "\n",
    "import axelrod as axl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xAlZskFMI5Bv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(C, C), (C, D), (C, C), (C, D), (C, C)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create matches\n",
    "\n",
    "players = (axl.Cooperator(), axl.Alternator())                  # using players of Cooperator and Alternator strategy\n",
    "match1 =  axl.Match(players, turns=5)                           # play for 5 turns\n",
    "match1.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "InpWBSpII5Bx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[axelrod.strategies.memoryone.ALLCorALLD,\n",
       " axelrod.strategies.memorytwo.AON2,\n",
       " axelrod.strategies.apavlov.APavlov2006,\n",
       " axelrod.strategies.apavlov.APavlov2011,\n",
       " axelrod.strategies.adaptive.Adaptive,\n",
       " axelrod.strategies.titfortat.AdaptiveTitForTat,\n",
       " axelrod.strategies.adaptor.AdaptorBrief,\n",
       " axelrod.strategies.adaptor.AdaptorLong,\n",
       " axelrod.strategies.grudger.Aggravater,\n",
       " axelrod.strategies.titfortat.Alexei,\n",
       " axelrod.strategies.alternator.Alternator,\n",
       " axelrod.strategies.hunter.AlternatorHunter,\n",
       " axelrod.strategies.cycler.AntiCycler,\n",
       " axelrod.strategies.titfortat.AntiTitForTat,\n",
       " axelrod.strategies.appeaser.Appeaser,\n",
       " axelrod.strategies.qlearner.ArrogantQLearner,\n",
       " axelrod.strategies.averagecopier.AverageCopier,\n",
       " axelrod.strategies.backstabber.BackStabber,\n",
       " axelrod.strategies.better_and_better.BetterAndBetter,\n",
       " axelrod.strategies.titfortat.Bully,\n",
       " axelrod.strategies.bush_mosteller.BushMosteller,\n",
       " axelrod.strategies.calculator.Calculator,\n",
       " axelrod.strategies.qlearner.CautiousQLearner,\n",
       " axelrod.strategies.prober.CollectiveStrategy,\n",
       " axelrod.strategies.titfortat.ContriteTitForTat,\n",
       " axelrod.strategies.cooperator.Cooperator,\n",
       " axelrod.strategies.hunter.CooperatorHunter,\n",
       " axelrod.strategies.hunter.CycleHunter,\n",
       " axelrod.strategies.cycler.CyclerCCCCCD,\n",
       " axelrod.strategies.cycler.CyclerCCCD,\n",
       " axelrod.strategies.cycler.CyclerCCCDCD,\n",
       " axelrod.strategies.cycler.CyclerCCD,\n",
       " axelrod.strategies.cycler.CyclerDC,\n",
       " axelrod.strategies.cycler.CyclerDDC,\n",
       " axelrod.strategies.dbs.DBS,\n",
       " axelrod.strategies.darwin.Darwin,\n",
       " axelrod.strategies.defector.Defector,\n",
       " axelrod.strategies.hunter.DefectorHunter,\n",
       " axelrod.strategies.memorytwo.DelayedAON1,\n",
       " axelrod.strategies.mutual.Desperate,\n",
       " axelrod.strategies.prober.Detective,\n",
       " axelrod.strategies.backstabber.DoubleCrosser,\n",
       " axelrod.strategies.resurrection.DoubleResurrection,\n",
       " axelrod.strategies.doubler.Doubler,\n",
       " axelrod.strategies.titfortat.DynamicTwoTitsForTat,\n",
       " axelrod.strategies.grudger.EasyGo,\n",
       " axelrod.strategies.titfortat.EugineNier,\n",
       " axelrod.strategies.hunter.EventualCycleHunter,\n",
       " axelrod.strategies.ann.EvolvedANN,\n",
       " axelrod.strategies.ann.EvolvedANN5,\n",
       " axelrod.strategies.ann.EvolvedANNNoise05,\n",
       " axelrod.strategies.finite_state_machines.EvolvedFSM16,\n",
       " axelrod.strategies.finite_state_machines.EvolvedFSM16Noise05,\n",
       " axelrod.strategies.finite_state_machines.EvolvedFSM4,\n",
       " axelrod.strategies.hmm.EvolvedHMM5,\n",
       " axelrod.strategies.lookerup.EvolvedLookerUp1_1_1,\n",
       " axelrod.strategies.lookerup.EvolvedLookerUp2_2_2,\n",
       " axelrod.strategies.memoryone.FirmButFair,\n",
       " axelrod.strategies.axelrod_first.FirstByAnonymous,\n",
       " axelrod.strategies.axelrod_first.FirstByDavis,\n",
       " axelrod.strategies.axelrod_first.FirstByDowning,\n",
       " axelrod.strategies.axelrod_first.FirstByFeld,\n",
       " axelrod.strategies.axelrod_first.FirstByGraaskamp,\n",
       " axelrod.strategies.axelrod_first.FirstByGrofman,\n",
       " axelrod.strategies.axelrod_first.FirstByJoss,\n",
       " axelrod.strategies.axelrod_first.FirstByNydegger,\n",
       " axelrod.strategies.axelrod_first.FirstByShubik,\n",
       " axelrod.strategies.axelrod_first.FirstBySteinAndRapoport,\n",
       " axelrod.strategies.axelrod_first.FirstByTidemanAndChieruzzi,\n",
       " axelrod.strategies.axelrod_first.FirstByTullock,\n",
       " axelrod.strategies.oncebitten.FoolMeOnce,\n",
       " axelrod.strategies.oncebitten.ForgetfulFoolMeOnce,\n",
       " axelrod.strategies.grudger.ForgetfulGrudger,\n",
       " axelrod.strategies.forgiver.Forgiver,\n",
       " axelrod.strategies.forgiver.ForgivingTitForTat,\n",
       " axelrod.strategies.finite_state_machines.Fortress3,\n",
       " axelrod.strategies.finite_state_machines.Fortress4,\n",
       " axelrod.strategies.memoryone.GTFT,\n",
       " axelrod.strategies.geller.Geller,\n",
       " axelrod.strategies.geller.GellerCooperator,\n",
       " axelrod.strategies.geller.GellerDefector,\n",
       " axelrod.strategies.grudger.GeneralSoftGrudger,\n",
       " axelrod.strategies.gobymajority.GoByMajority,\n",
       " axelrod.strategies.gobymajority.GoByMajority10,\n",
       " axelrod.strategies.gobymajority.GoByMajority20,\n",
       " axelrod.strategies.gobymajority.GoByMajority40,\n",
       " axelrod.strategies.gobymajority.GoByMajority5,\n",
       " axelrod.strategies.mathematicalconstants.Golden,\n",
       " axelrod.strategies.titfortat.Gradual,\n",
       " axelrod.strategies.gradualkiller.GradualKiller,\n",
       " axelrod.strategies.grudger.Grudger,\n",
       " axelrod.strategies.grudger.GrudgerAlternator,\n",
       " axelrod.strategies.grumpy.Grumpy,\n",
       " axelrod.strategies.handshake.Handshake,\n",
       " axelrod.strategies.gobymajority.HardGoByMajority,\n",
       " axelrod.strategies.gobymajority.HardGoByMajority10,\n",
       " axelrod.strategies.gobymajority.HardGoByMajority20,\n",
       " axelrod.strategies.gobymajority.HardGoByMajority40,\n",
       " axelrod.strategies.gobymajority.HardGoByMajority5,\n",
       " axelrod.strategies.prober.HardProber,\n",
       " axelrod.strategies.titfortat.HardTitFor2Tats,\n",
       " axelrod.strategies.titfortat.HardTitForTat,\n",
       " axelrod.strategies.qlearner.HesitantQLearner,\n",
       " axelrod.strategies.mutual.Hopeless,\n",
       " axelrod.strategies.inverse.Inverse,\n",
       " axelrod.strategies.punisher.InversePunisher,\n",
       " axelrod.strategies.worse_and_worse.KnowledgeableWorseAndWorse,\n",
       " axelrod.strategies.punisher.LevelPunisher,\n",
       " axelrod.strategies.retaliate.LimitedRetaliate,\n",
       " axelrod.strategies.retaliate.LimitedRetaliate2,\n",
       " axelrod.strategies.retaliate.LimitedRetaliate3,\n",
       " axelrod.strategies.memorytwo.MEM2,\n",
       " axelrod.strategies.hunter.MathConstantHunter,\n",
       " axelrod.strategies.titfortat.Michaelos,\n",
       " axelrod.strategies.mindcontrol.MindBender,\n",
       " axelrod.strategies.mindcontrol.MindController,\n",
       " axelrod.strategies.mindreader.MindReader,\n",
       " axelrod.strategies.mindcontrol.MindWarper,\n",
       " axelrod.strategies.mindreader.MirrorMindReader,\n",
       " axelrod.strategies.titfortat.NTitsForMTats,\n",
       " axelrod.strategies.prober.NaiveProber,\n",
       " axelrod.strategies.negation.Negation,\n",
       " axelrod.strategies.averagecopier.NiceAverageCopier,\n",
       " axelrod.strategies.titfortat.OmegaTFT,\n",
       " axelrod.strategies.oncebitten.OnceBitten,\n",
       " axelrod.strategies.grudger.OppositeGrudger,\n",
       " axelrod.strategies.titfortat.OriginalGradual,\n",
       " axelrod.strategies.gambler.PSOGambler1_1_1,\n",
       " axelrod.strategies.gambler.PSOGambler2_2_2,\n",
       " axelrod.strategies.gambler.PSOGambler2_2_2_Noise05,\n",
       " axelrod.strategies.gambler.PSOGamblerMem1,\n",
       " axelrod.strategies.mathematicalconstants.Pi,\n",
       " axelrod.strategies.finite_state_machines.Predator,\n",
       " axelrod.strategies.prober.Prober,\n",
       " axelrod.strategies.prober.Prober2,\n",
       " axelrod.strategies.prober.Prober3,\n",
       " axelrod.strategies.prober.Prober4,\n",
       " axelrod.strategies.mindreader.ProtectedMindReader,\n",
       " axelrod.strategies.finite_state_machines.Pun1,\n",
       " axelrod.strategies.punisher.Punisher,\n",
       " axelrod.strategies.finite_state_machines.Raider,\n",
       " axelrod.strategies.rand.Random,\n",
       " axelrod.strategies.hunter.RandomHunter,\n",
       " axelrod.strategies.titfortat.RandomTitForTat,\n",
       " axelrod.strategies.prober.RemorsefulProber,\n",
       " axelrod.strategies.resurrection.Resurrection,\n",
       " axelrod.strategies.retaliate.Retaliate,\n",
       " axelrod.strategies.retaliate.Retaliate2,\n",
       " axelrod.strategies.retaliate.Retaliate3,\n",
       " axelrod.strategies.revised_downing.RevisedDowning,\n",
       " axelrod.strategies.finite_state_machines.Ripoff,\n",
       " axelrod.strategies.qlearner.RiskyQLearner,\n",
       " axelrod.strategies.axelrod_second.SecondByAppold,\n",
       " axelrod.strategies.axelrod_second.SecondByBlack,\n",
       " axelrod.strategies.axelrod_second.SecondByBorufsen,\n",
       " axelrod.strategies.axelrod_second.SecondByCave,\n",
       " axelrod.strategies.axelrod_second.SecondByChampion,\n",
       " axelrod.strategies.axelrod_second.SecondByColbert,\n",
       " axelrod.strategies.axelrod_second.SecondByEatherley,\n",
       " axelrod.strategies.axelrod_second.SecondByGetzler,\n",
       " axelrod.strategies.axelrod_second.SecondByGladstein,\n",
       " axelrod.strategies.axelrod_second.SecondByGraaskampKatzen,\n",
       " axelrod.strategies.axelrod_second.SecondByGrofman,\n",
       " axelrod.strategies.axelrod_second.SecondByHarrington,\n",
       " axelrod.strategies.axelrod_second.SecondByKluepfel,\n",
       " axelrod.strategies.axelrod_second.SecondByLeyvraz,\n",
       " axelrod.strategies.axelrod_second.SecondByMikkelson,\n",
       " axelrod.strategies.axelrod_second.SecondByRichardHufford,\n",
       " axelrod.strategies.axelrod_second.SecondByRowsam,\n",
       " axelrod.strategies.axelrod_second.SecondByTester,\n",
       " axelrod.strategies.axelrod_second.SecondByTidemanAndChieruzzi,\n",
       " axelrod.strategies.axelrod_second.SecondByTranquilizer,\n",
       " axelrod.strategies.axelrod_second.SecondByWeiner,\n",
       " axelrod.strategies.axelrod_second.SecondByWhite,\n",
       " axelrod.strategies.axelrod_second.SecondByWmAdams,\n",
       " axelrod.strategies.axelrod_second.SecondByYamachi,\n",
       " axelrod.strategies.selfsteem.SelfSteem,\n",
       " axelrod.strategies.shortmem.ShortMem,\n",
       " axelrod.strategies.titfortat.SlowTitForTwoTats2,\n",
       " axelrod.strategies.titfortat.SneakyTitForTat,\n",
       " axelrod.strategies.grudger.SoftGrudger,\n",
       " axelrod.strategies.memoryone.SoftJoss,\n",
       " axelrod.strategies.finite_state_machines.SolutionB1,\n",
       " axelrod.strategies.finite_state_machines.SolutionB5,\n",
       " axelrod.strategies.titfortat.SpitefulTitForTat,\n",
       " axelrod.strategies.stalker.Stalker,\n",
       " axelrod.strategies.memoryone.StochasticCooperator,\n",
       " axelrod.strategies.memoryone.StochasticWSLS,\n",
       " axelrod.strategies.titfortat.SuspiciousTitForTat,\n",
       " axelrod.strategies.finite_state_machines.TF1,\n",
       " axelrod.strategies.finite_state_machines.TF2,\n",
       " axelrod.strategies.finite_state_machines.TF3,\n",
       " axelrod.strategies.sequence_player.ThueMorse,\n",
       " axelrod.strategies.sequence_player.ThueMorseInverse,\n",
       " axelrod.strategies.finite_state_machines.Thumper,\n",
       " axelrod.strategies.titfortat.TitFor2Tats,\n",
       " axelrod.strategies.titfortat.TitForTat,\n",
       " axelrod.strategies.cooperator.TrickyCooperator,\n",
       " axelrod.strategies.defector.TrickyDefector,\n",
       " axelrod.strategies.punisher.TrickyLevelPunisher,\n",
       " axelrod.strategies.titfortat.TwoTitsForTat,\n",
       " axelrod.strategies.finite_state_machines.UsuallyCooperates,\n",
       " axelrod.strategies.finite_state_machines.UsuallyDefects,\n",
       " axelrod.strategies.verybad.VeryBad,\n",
       " axelrod.strategies.mutual.Willing,\n",
       " axelrod.strategies.memoryone.WinShiftLoseStay,\n",
       " axelrod.strategies.memoryone.WinStayLoseShift,\n",
       " axelrod.strategies.lookerup.Winner12,\n",
       " axelrod.strategies.lookerup.Winner21,\n",
       " axelrod.strategies.worse_and_worse.WorseAndWorse,\n",
       " axelrod.strategies.worse_and_worse.WorseAndWorse2,\n",
       " axelrod.strategies.worse_and_worse.WorseAndWorse3,\n",
       " axelrod.strategies.zero_determinant.ZDExtort2,\n",
       " axelrod.strategies.zero_determinant.ZDExtort2v2,\n",
       " axelrod.strategies.zero_determinant.ZDExtort3,\n",
       " axelrod.strategies.zero_determinant.ZDExtort4,\n",
       " axelrod.strategies.zero_determinant.ZDExtortion,\n",
       " axelrod.strategies.zero_determinant.ZDGTFT2,\n",
       " axelrod.strategies.zero_determinant.ZDGen2,\n",
       " axelrod.strategies.gambler.ZDMem2,\n",
       " axelrod.strategies.zero_determinant.ZDMischief,\n",
       " axelrod.strategies.zero_determinant.ZDSet2,\n",
       " axelrod.strategies.mathematicalconstants.e,\n",
       " axelrod.strategies.meta.MemoryDecay,\n",
       " axelrod.strategies.meta.MetaHunter,\n",
       " axelrod.strategies.meta.MetaHunterAggressive,\n",
       " axelrod.strategies.meta.MetaMajority,\n",
       " axelrod.strategies.meta.MetaMajorityMemoryOne,\n",
       " axelrod.strategies.meta.MetaMajorityFiniteMemory,\n",
       " axelrod.strategies.meta.MetaMajorityLongMemory,\n",
       " axelrod.strategies.meta.MetaMinority,\n",
       " axelrod.strategies.meta.MetaMixer,\n",
       " axelrod.strategies.meta.MetaWinner,\n",
       " axelrod.strategies.meta.MetaWinnerDeterministic,\n",
       " axelrod.strategies.meta.MetaWinnerEnsemble,\n",
       " axelrod.strategies.meta.MetaWinnerMemoryOne,\n",
       " axelrod.strategies.meta.MetaWinnerFiniteMemory,\n",
       " axelrod.strategies.meta.MetaWinnerLongMemory,\n",
       " axelrod.strategies.meta.MetaWinnerStochastic,\n",
       " axelrod.strategies.meta.NMWEDeterministic,\n",
       " axelrod.strategies.meta.NMWEFiniteMemory,\n",
       " axelrod.strategies.meta.NMWELongMemory,\n",
       " axelrod.strategies.meta.NMWEMemoryOne,\n",
       " axelrod.strategies.meta.NMWEStochastic,\n",
       " axelrod.strategies.meta.NiceMetaWinner,\n",
       " axelrod.strategies.meta.NiceMetaWinnerEnsemble]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "axl.all_strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZwEQbFjbI5B2"
   },
   "source": [
    "### Exercise: Create a repeated game with 2 players having:\n",
    "#### I. TitForTat and Random Strategy \n",
    "#### II. Name it as match2\n",
    "#### III. Run it for 15 turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M8tlSW99I5B3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(C, D),\n",
       " (D, C),\n",
       " (C, C),\n",
       " (C, C),\n",
       " (C, C),\n",
       " (C, C),\n",
       " (C, D),\n",
       " (D, D),\n",
       " (D, D),\n",
       " (D, C),\n",
       " (C, D),\n",
       " (D, D),\n",
       " (D, D),\n",
       " (D, C),\n",
       " (C, C)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players = (axl.TitForTat(), axl.Random())\n",
    "match2 = axl.Match(players, turns=15)\n",
    "match2.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8hZOv2xQI5B_"
   },
   "source": [
    "## 7. Analyze Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eD9qeCgEI5B_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Axelrod game: (R,P,S,T) = (3, 1, 0, 5)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Payoffs\n",
    "\n",
    "match1.game        #Analyze the match\n",
    "\n",
    "#These payoffs are commonly referred to as:\n",
    "\n",
    "#R: the Reward payoff (default value in the library: 3) C-C\n",
    "#P: the Punishment payoff (default value in the library: 1) D-D\n",
    "#S: the Loss payoff (default value in the library: 0) C-D\n",
    "#T: the Temptation payoff (default value in the library: 5) D-C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xs7rQEyZI5CC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 3), (0, 5), (3, 3), (0, 5), (3, 3)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scores of a match\n",
    "\n",
    "match1.scores()     #Retrieve match scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zCkP68lJI5CF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█████\n",
      "█ █ █\n"
     ]
    }
   ],
   "source": [
    "# The result of the match can also be viewed as sparklines where cooperation is shown as a solid block and defection as a space. \n",
    "\n",
    "print(match1.sparklines())  # Get output using sparklines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rkbk8a-NI5CH"
   },
   "source": [
    "### Exercise: Analyze match2. \n",
    "#### Find the score and create the sparklines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "snBJkfDJI5CI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Axelrod game: (R,P,S,T) = (3, 1, 0, 5)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match2.game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 5),\n",
       " (5, 0),\n",
       " (3, 3),\n",
       " (3, 3),\n",
       " (3, 3),\n",
       " (3, 3),\n",
       " (0, 5),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (5, 0),\n",
       " (0, 5),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (5, 0),\n",
       " (3, 3)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match2.scores()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0665Gwk4I5CL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█ █████   █   █\n",
      " █████   █   ██\n"
     ]
    }
   ],
   "source": [
    "print(match2.sparklines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B9h2o5YmI5CP"
   },
   "source": [
    "#### References:\n",
    "\n",
    "Package Documentations\n",
    "\n",
    "https://nashpy.readthedocs.io/en/stable/index.html#\n",
    "\n",
    "https://axelrod.readthedocs.io/en/stable/#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "game-theory-with-python-notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
